Automatically generated by Mendeley 1.7.1
Any changes to this file will be lost if it is regenerated by Mendeley.

@article{Ave2010,
author = {Ave, Park and Park, Florham},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ave, Park - 2010 - DEMONSTRATION OF AT \& T “ LET ’ S GO ” A PRODUCTION-GRADE STATISTICAL SPOKEN DIALOG SYSTEM Jason D . Williams , Iker Arizmendi and Alistair Conkie.pdf:pdf},
title = {{DEMONSTRATION OF AT \& T “ LET ’ S GO ”: A PRODUCTION-GRADE STATISTICAL SPOKEN DIALOG SYSTEM Jason D . Williams , Iker Arizmendi and Alistair Conkie}},
year = {2010}
}
@inbook{Traum03,
    author = {Traum, David and Larsson, Staffan},
    booktitle = {Current and New Directions in Discourse \& Dialogue},
    citeulike-article-id = {6113306},
    editor = {Smith and Kuppevelt},
    keywords = {dialog, dialog\_framework, information\_state, trindi},
    pages = {325--353},
    posted-at = {2009-11-15 15:54:11},
    priority = {2},
    publisher = {Kluwer Academic Publishers},
    title = {{The Information State Approach to Dialogue Management}},
    year = {2003}
}
@inproceedings{singh2000empirical,
  title={Empirical evaluation of a reinforcement learning spoken dialogue system},
  author={Singh, Satinder and Kearns, Michael and Litman, Diane J and Walker, Marilyn A and others},
  booktitle={AAAI/IAAI},
  pages={645--651},
  year={2000}
}

@inproceedings{scheffler2002automatic,
  title={Automatic learning of dialogue strategy using dialogue simulation and reinforcement learning},
  author={Scheffler, Konrad and Young, Steve},
  booktitle={Proceedings of the second international conference on Human Language Technology Research},
  pages={12--19},
  year={2002},
  organization={Morgan Kaufmann Publishers Inc.}
}

@article{SASSI,
  title={Towards a tool for the subjective assessment of speech system interfaces (SASSI)},
  author={Hone, Kate S and Graham, Robert},
  journal={Natural Language Engineering},
  volume={6},
  number={3,4},
  pages={287--303},
  year={2000},
  publisher={Cambridge Univ Press}
}

@article{kennedy2012active,
  title={Active assistance technology for health-related behavior change: an interdisciplinary review},
  author={Kennedy, Catriona M and Powell, John and Payne, Thomas H and Ainsworth, John and Boyd, Alan and Buchan, Iain},
  journal={Journal of Medical Internet Research},
  volume={14},
  number={3},
  year={2012},
  publisher={JMIR Publications Inc.}
}

@Article{Levin2006Spoken,
author={Levin, Esther
and Levin, Alex},
title={Evaluation of Spoken Dialogue Technology for Real-Time Health Data Collection},
journal={J Med Internet Res},
year={2006},
month={Dec},
day={11},
volume={8},
number={4},
pages={e30},
keywords={Human factors},
keywords={ecological momentary assessment},
keywords={data collection},
keywords={voice recognition},
abstract={Background:  A real-time assessment of patients' experiences is an important methodology for studies in health care, quality of life, behavioral sciences, and new drug and treatment development. Ecological momentary assessment is a methodology that allows for real-time assessment of experience and behavior in a subject's natural environment. Recently, electronic data collection techniques have been introduced, including systems utilizing interactive voice response. Objective:  The objective of this project was evaluation of spoken dialogue methodology for real-time data collection of information from patients for health, behavioral, and lifestyle studies and monitoring. While the management of the data collection process was Internet-based, this additional eHealth communication channel was based on over-the-phone natural language conversation with a dialogue system utilizing automated speech recognition technology. For this study we implemented a dialogue system for patients' assessment and monitoring of chronic pain. Methods:  Experimental evaluation of usability of the Pain Monitoring Voice Diary was performed with 24 volunteers. The volunteers were asked to contribute 10 sessions with the system over a period of 2 weeks; in practice, the number of sessions per subject ranged from 1 to 20. The subjects were asked to either relate to pain episodes in their past while answering the system's questions, or use as a guidance one of nine provided medical scenarios compiled by a pain specialist, ranging from migraines and back pain to post-surgical pain (knee injury) and cancer- and chemotherapy-related afflictions. Results:  From 24 volunteers, we collected a total of 177 dialogue sessions: 171 sessions were completed, while the caller hung up in the other 6 sessions. There were a total of 2437 dialogue turns, where a dialogue turn corresponds to one system prompt and one user utterance. The data capture rate, measuring the percentage of slots filled automatically, was 98\%, while the other 2\% were flagged for transcription. Among the utterances sent to transcription, where the user had opted for the ``none of those'' option, 70\% corresponded to the ``type of pain'' slot, 20\% to the ``symptoms'' slot, and 10\% to the ``body part'' slot, indicating that those are the grammars with the highest out-of-vocabulary rate. Conclusions:  The results of this feasibility study indicated that desired accuracy of data can be achieved with a high degree of automation (98\% in the study) and that the users were indeed capable of utilizing the flexible interface, the sessions becoming more and more efficient as users' experience increased, both in terms of session duration and avoidance of troublesome dialogue situations. },
doi={10.2196/jmir.8.4.e30},
url={http://www.jmir.org/2006/4/e30/}
}

@article{Turunen2011,
  title={Multimodal and mobile conversational health and fitness companions},
  author={Turunen, Markku and Hakulinen, Jaakko and St{\aa}hl, Olov and Gamb{\"a}ck, Bj{\"o}rn and Hansen, Preben and Rodr{\'\i}guez Gancedo, Mari C and de la C{\'a}mara, Ra{\'u}l Santos and Smith, Cameron and Charlton, Daniel and Cavazza, Marc},
  journal={Computer Speech \& Language},
  volume={25},
  number={2},
  pages={192--209},
  year={2011},
  publisher={Elsevier}
}

@incollection{RLTutoring2010,
year={2010},
isbn={978-3-642-13387-9},
booktitle={Intelligent Tutoring Systems},
volume={6094},
series={Lecture Notes in Computer Science},
editor={Aleven, Vincent and Kay, Judy and Mostow, Jack},
doi={10.1007/978-3-642-13388-6_27},
title={Do Micro-Level Tutorial Decisions Matter: Applying Reinforcement Learning to Induce Pedagogical Tutorial Tactics},
url={http://dx.doi.org/10.1007/978-3-642-13388-6_27},
publisher={Springer Berlin Heidelberg},
keywords={Reinforcement Learning; Human Learning; Intelligent Tutoring Systems; Pedagogical Strategy},
author={Chi, Min and VanLehn, Kurt and Litman, Diane},
pages={224-234}
}

@article{Moridis2012a,
abstract = {—Empathetic behavior has been suggested to be one effective way for Embodied Conversational Agents (ECAs) to provide feedback to learners’ emotions. An issue that has been raised is the effective integration of parallel and reactive empathy. The aim of this study is to examine the impact of ECAs’ emotional facial and tone of voice expressions combined with empathetic verbal behavior when displayed as feedback to students’ fear, sad, and happy emotions in the context of a self-assessment test. Three identical female agents were used for this experiment: 1) an ECA performing parallel empathy combined with neutral emotional expressions, 2) an ECA performing parallel empathy displaying emotional expressions that were relevant to the emotional state of the student, and 3) an ECA performing parallel empathy by displaying relevant emotional expressions followed by emotional expressions of reactive empathy with the goal of altering the student’s emotional state. Results indicate that an agent performing parallel empathy displaying emotional expressions relevant to the emotional state of the student may cause this emotion to persist. Moreover, the agent performing parallel and then reactive empathy appeared to be effective in altering an emotional state of fear to a neutral one.},
author = {Moridis, Christos N and Economides, Anastasios A and Member, Senior},
file = {:C$\backslash$:/Users/ramin001/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Moridis, Economides, Member - 2012 - Affective Learning Empathetic Agents with Emotional Facial and Tone of Voice Expressions.pdf:pdf},
journal = {IEEE Transactions on Affective Computing},
keywords = {empathy,intelligent agents,user interfaces,—Computers and education},
number = {3},
pages = {260--272},
title = {{Affective Learning : Empathetic Agents with Emotional Facial and Tone of Voice Expressions}},
volume = {3},
year = {2012}
}



@Article{OnlineAlcoholInterventionRev2011,
author={Riper, Heleen
and Spek, Viola
and Boon, Brigitte
and Conijn, Barbara
and Kramer, Jeannet
and Martin-Abello, Katherina
and Smit, Filip},
title={Effectiveness of E-Self-help Interventions for Curbing Adult Problem Drinking: A Meta-analysis},
journal={J Med Internet Res},
year={2011},
month={Jun},
day={30},
volume={13},
number={2},
pages={e42},
keywords={Meta-analysis},
keywords={alcohol},
keywords={problem drinking},
keywords={randomized controlled trial},
keywords={self-help},
keywords={e-self-help},
keywords={intervention},
keywords={unguided self-help},
keywords={low intensity interventions},
keywords={Internet},
keywords={adults},
abstract={Background: Self-help interventions without professional contact to curb adult problem drinking in the community are increasingly being delivered via the Internet. Objective: The objective of this meta-analysis was to assess the overall effectiveness of these eHealth interventions. Methods: In all, 9 randomized controlled trials (RCTs), all from high-income countries, with 9 comparison conditions and a total of 1553 participants, were identified, and their combined effectiveness in reducing alcohol consumption was evaluated by means of a meta-analysis. Results: An overall medium effect size (g = 0.44, 95\% CI 0.17-0.71, random effect model) was found for the 9 studies, all of which compared no-contact interventions to control conditions. The medium effect was maintained (g = 0.39; 95\% CI 0.23-0.57, random effect model) after exclusion of two outliers. Type of control group, treatment location, type of analysis, and sample size did not have differential impacts on treatment outcome. A significant difference (P = .04) emerged between single-session personalized normative feedback interventions (g = 0.27, 95\% CI 0.11-0.43) and more extended e- self-help (g = 0.61, 95\% CI 0.33-0.90). Conclusion: E-self-help interventions without professional contact are effective in curbing adult problem drinking in high-income countries. In view of the easy scalability and low dissemination costs of such interventions, we recommend exploration of whether these could broaden the scope of effective public health interventions in low- and middle-income countries as well. },
doi={10.2196/jmir.1691},
url={http://www.jmir.org/2011/2/e42/},
url={http://www.ncbi.nlm.nih.gov/pubmed/21719411}
}

@misc{niaaaAlcoholAlert2006,
  title={NIAAA alcohol alert No. 66: brief interventions},
  author={National Institutes of Health and others},
  year={2006}
}

@inproceedings{PhoenixParser1991,
 author = {Ward, W.},
 title = {Understanding spontaneous speech: the Phoenix system},
 booktitle = {Proceedings of the Acoustics, Speech, and Signal Processing, 1991. ICASSP-91., 1991 International Conference},
 series = {ICASSP '91},
 year = {1991},
 isbn = {0-7803-0003-3},
 pages = {365--367},
 numpages = {3},
 url = {http://dl.acm.org/citation.cfm?id=1170742.1170864},
 acmid = {1170864},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
} 


@article{Bouchery2011,
title = "Economic Costs of Excessive Alcohol Consumption in the U.S., 2006 ",
journal = "American Journal of Preventive Medicine ",
volume = "41",
number = "5",
pages = "516 - 524",
year = "2011",
note = "",
issn = "0749-3797",
doi = "10.1016/j.amepre.2011.06.045",
url = "http://www.sciencedirect.com/science/article/pii/S0749379711005381",
author = "Ellen E. Bouchery and Henrick J. Harwood and Jeffrey J. Sacks and Carol J. Simon and Robert D. Brewer"
}



@article{Mokdad2004Death,
author = {Mokdad AH and Marks JS and Stroup DF and Gerberding JL},
title = {Actual causes of death in the united states, 2000},
journal = {JAMA},
volume = {291},
number = {10},
pages = {1238-1245},
year = {2004},
doi = {10.1001/jama.291.10.1238},
URL = { + http://dx.doi.org/10.1001/jama.291.10.1238},
eprint = {/data/Journals/JAMA/4919/JSC40095.pdf}
}

@inproceedings{morbiniFlores2012,
	address = {Paris, France},
	title = {{FLoReS:} A Forward Looking, Reward Seeking, Dialogue Manager},
	abstract = {We present {FLoReS}, a new information-state based dialogue manager, making use of forward inference, local dialogue structure, and plan operators representing sub-dialogue structure. The aim is to support both advanced, ﬂexible, mixed initiative interaction and efﬁcient policy creation by domain experts. The dialogue manager has been used for two characters in the {SimCoach} project, and is currently being used in several related projects. We present the design of the dialogue manager and preliminary comparative evaluation with a previous system that uses a more conventional state chart dialogue manager.},
	booktitle = {4th International Workshop on Spoken Dialog Systems},
	author = {Morbini, Fabrizio and {DeVault}, David and Sagae, Kenji and Gerten, Jillian and Nazarian, Angela and Traum, David},
	month = nov,
	year = {2012},
	keywords = {Virtual Humans}
}

@inproceedings{singh1999reinforcement,
  title={Reinforcement learning for spoken dialogue systems},
  author={Singh, Satinder and Kearns, Michael and Litman, Diane and Walker, Marilyn},
  booktitle={Proc. NIPS99},
  year={1999}
}

@phdthesis{barry2009hmdp,
  title={Fast approximate hierarchical solution of MDPs},
  author={Barry, Jennifer L},
  year={2009},
  school={Massachusetts Institute of Technology}
}

@article{Rich01collagen,
    author = {Charles Rich and Ace L. Sidner and Neal Lesh},
    title = {Collagen: Applying Collaborative Discourse Theory to Human-Computer Interaction},
    journal = {AI Magazine},
    year = {2001},
    volume = {22},
    pages = {15--25}
}

@book{steinberg2005brief,
  title={Brief counseling for marijuana dependence: a manual for treating adults},
  author={Steinberg, Karen L and Roffman, Roger A and Carroll, Kathleen M and McRee, Bonnie and Babor, TF and Miller, M and Kadden, R and Duresky, D and Stephens, R},
  year={2005},
  publisher={Center for Substance Abuse Treatment, Substance Abuse and Mental Health Services Administration Rockville, MD}
}

@article{humeniuk2010assist,
  title={The ASSIST-linked brief intervention for hazardous and harmful substance use: a manual for use in primary care/prepared by R. HumeniukƯ [et al]},
  author={Humeniuk, Rachel and Henry-Edwards, S and Ali, Robert and Poznyak, Vladimir and Monteiro, Maristela G and World Health Organization and others},
  year={2010},
  publisher={Geneva: World Health Organization}
}

@article{Bohus2009,
title = "The RavenClaw dialog management framework: Architecture and systems",
journal = "Computer Speech \& Language",
volume = "23",
number = "3",
pages = "332 - 361",
year = "2009",
note = "",
issn = "0885-2308",
doi = "10.1016/j.csl.2008.10.001",
url = "http://www.sciencedirect.com/science/article/pii/S0885230808000545",
author = "Dan Bohus and Alexander I. Rudnicky",
keywords = "Dialog management",
keywords = "Spoken dialog systems",
keywords = "Error handling",
keywords = "Focus shifting",
keywords = "Mixed-initiative"
}

@inproceedings{RieserMDP2011,
 author = {Rieser, Verena and Keizer, Simon and Liu, Xingkun and Lemon, Oliver},
 title = {Adaptive information presentation for spoken dialogue systems: evaluation with human subjects},
 booktitle = {Proceedings of the 13th European Workshop on Natural Language Generation},
 series = {ENLG '11},
 year = {2011},
 location = {Nancy, France},
 pages = {102--109},
 numpages = {8},
 url = {http://dl.acm.org/citation.cfm?id=2187681.2187698},
 acmid = {2187698},
 publisher = {Association for Computational Linguistics},
 address = {Stroudsburg, PA, USA},
} 

@inproceedings{LemonTalkProject2006,
 author = {Lemon, Oliver and Georgila, Kallirroi and Henderson, James and Stuttle, Matthew},
 title = {An ISU dialogue system exhibiting reinforcement learning of dialogue policies: generic slot-filling in the TALK in-car system},
 booktitle = {Proceedings of the Eleventh Conference of the European Chapter of the Association for Computational Linguistics: Posters \&\#38; Demonstrations},
 series = {EACL '06},
 year = {2006},
 location = {Trento, Italy},
 pages = {119--122},
 numpages = {4},
 url = {http://dl.acm.org/citation.cfm?id=1608974.1608986},
 acmid = {1608986},
 publisher = {Association for Computational Linguistics},
 address = {Stroudsburg, PA, USA},
} 

@article{ClassicD5,
  title={D5. 4: Proof-of-concept CLASSIC Appointment Scheduling system (“System 2”)},
  author={Jurc{\i}cek, Filip and Keizer, Simon and Mairesse, Fran{\c{c}}ois and Yu, Kai and Young, Steve and Janarthanam, Srinivanan and Hastie, Helen and Liu, Xingkun and Lemon, Oliver},
  year={2010}
}

@ARTICLE{Walker2000,
    author = {Marilyn A. Walker},
    title = { An Application of Reinforcement Learning to Dialogue Strategy Selection in a Spoken Dialogue System for Email},
    journal = {JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH},
    year = {2000},
    volume = {12},
    pages = {387--416}
}


@ARTICLE{NjFunSingh02,
    author = {Satinder Singh and Diane Litman and Michael Kearns and Marilyn Walker},
    title = {Optimizing Dialogue Management with Reinforcement Learning: Experiments with the NJFun System},
    journal = {Journal of Artificial Intelligence Research},
    year = {2002},
    volume = {16},
    pages = {105--133}
}



@inproceedings{levin1998,
  title={Using Markov decision process for learning dialogue strategies},
  author={Levin, Esther and Pieraccini, Roberto and Eckert, Wieland},
  booktitle={Acoustics, Speech and Signal Processing, 1998. Proceedings of the 1998 IEEE International Conference on},
  volume={1},
  pages={201--204},
  year={1998},
  organization={IEEE}
}


@article{Rieser2011b,
address = {Berlin, Heidelberg},
author = {Rieser, Verena and Lemon, Oliver},
doi = {10.1007/978-3-642-24942-6},
file = {:C$\backslash$:/Users/uyasa001/Downloads/chp\%3A10.1007\%2F978-3-642-24942-6\_3 (1).pdf:pdf},
isbn = {978-3-642-24941-9},
publisher = {Springer Berlin Heidelberg},
title = {{Reinforcement Learning for Adaptive Dialogue Systems}},
url = {http://www.springerlink.com/index/10.1007/978-3-642-24942-6},
year = {2011}
}

@book{sutton1998reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  volume={1},
  number={1},
  year={1998},
  publisher={Cambridge Univ Press}
}

@article{thomson2010bayesian,
  title={Bayesian update of dialogue state: A POMDP framework for spoken dialogue systems},
  author={Thomson, Blaise and Young, Steve},
  journal={Computer Speech \& Language},
  volume={24},
  number={4},
  pages={562--588},
  year={2010},
  publisher={Elsevier}
}

@inproceedings{rieser2011adaptive,
  title={Adaptive Information Presentation for Spoken Dialogue Systems: Evaluation with human subjects},
  author={Rieser, Verena and Keizer, Simon and Liu, Xingkun and Lemon, Oliver},
  booktitle={Proceedings of the 13th European Workshop on Natural Language Generation (ENLG)},
  year={2011}
}

@inproceedings{Black2011,
 author = {Black, Alan W. and Burger, Susanne and Conkie, Alistair and Hastie, Helen and Keizer, Simon and Lemon, Oliver and Merigaud, Nicolas and Parent, Gabriel and Schubiner, Gabriel and Thomson, Blaise and Williams, Jason D. and Yu, Kai and Young, Steve and Eskenazi, Maxine},
 title = {Spoken Dialog Challenge 2010: comparison of live and control test results},
 booktitle = {Proceedings of the SIGDIAL 2011 Conference},
 series = {SIGDIAL '11},
 year = {2011},
 isbn = {978-1-937284-10-7},
 location = {Portland, Oregon},
 pages = {2--7},
 numpages = {6},
 url = {http://dl.acm.org/citation.cfm?id=2132890.2132892},
 acmid = {2132892},
 publisher = {Association for Computational Linguistics},
 address = {Stroudsburg, PA, USA},
}

@inproceedings{ferguson1998trips,
  title={TRIPS: An integrated intelligent problem-solving assistant},
  author={Ferguson, G. and Allen, J.F. and others},
  booktitle={Proceedings of the National Conference on Artificial Intelligence},
  pages={567--573},
  year={1998},
  organization={JOHN WILEY \& SONS LTD}
}

@article{hartholt2008,
  title={A common ground for virtual humans: Using an ontology in a natural language oriented virtual human architecture},
  author={Hartholt, A. and Russ, T. and Traum, D. and Hovy, E. and Robinson, S.},
  journal={Proceedings of LREC, Marrakech, Morocco, may},
  year={2008}
}

@article{Desy200811,
title = "Alcohol Screening, Brief Intervention, and Referral in the Emergency Department: An Implementation Study",
journal = "Journal of Emergency Nursing",
volume = "34",
number = "1",
pages = "11 - 19",
year = "2008",
note = "",
issn = "0099-1767",
doi = "10.1016/j.jen.2007.03.019",
url = "http://www.sciencedirect.com/science/article/pii/S0099176707002012",
author = "Pierre M. Desy and Cydne Perhats"
}

@inproceedings{lemon2007machine,
  title={Machine learning for spoken dialogue systems},
  author={Lemon, Olivier and Pietquin, Olivier and others},
  booktitle={Proceedings of the European Conference on Speech Communication and Technologies (Interspeech'07)},
  pages={2685--2688},
  year={2007}
}

@misc{national2006niaaa,
  title={NIAAA Alcohol Alert No. 66: Brief Interventions},
  author={NIAAA},
  url="http://pubs.niaaa.nih.gov/publications/AA66/AA66.pdf",
  year="2006"
}


@inproceedings{Morbini2012,
 author = {Morbini, Fabrizio and Forbell, Eric and DeVault, David and Sagae, Kenji and Traum, David R. and Rizzo, Albert A.},
 title = {A mixed-initiative conversational dialogue system for healthcare},
 booktitle = {Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 series = {SIGDIAL '12},
 year = {2012},
 location = {Seoul, South Korea},
 pages = {137--139},
 numpages = {3},
 url = {http://dl.acm.org/citation.cfm?id=2392800.2392825},
 acmid = {2392825},
 publisher = {Association for Computational Linguistics},
 address = {Stroudsburg, PA, USA},
} 

@inproceedings{bos2003dipper,
  title={DIPPER: Description and formalisation of an information-state update dialogue system architecture},
  author={Bos, J. and Klein, E. and Lemon, O. and Oka, T.},
  booktitle={4th SIGdial Workshop on Discourse and Dialogue},
  pages={115--124},
  year={2003}
}

@inproceedings{sutton1998CSLU,
  title={Universal speech tools: The CSLU toolkit},
  author={Sutton, S. and Cole, R. and De Villiers, J. and Schalkwyk, J. and Vermeulen, P. and Macon, M. and Yan, Y. and Kaiser, E. and Rundle, B. and Shobaki, K. and others},
  booktitle={Proceedings of the International Conference on Spoken Language Processing (ICSLP)},
  pages={3221--3224},
  year={1998},
  organization={Sydney, Australia.}
}
@article{hettema2005motivational,
  title={Motivational interviewing},
  author={Hettema, J. and Steele, J. and Miller, W.R.},
  journal={Annu. Rev. Clin. Psychol.},
  volume={1},
  pages={91--111},
  year={2005},
  publisher={Annual Reviews}
}

@article{McTear2002,
 author = {McTear, Michael F.},
 title = {Spoken dialogue technology: enabling the conversational user interface},
 journal = {ACM Comput. Surv.},
 issue_date = {March 2002},
 volume = {34},
 number = {1},
 month = mar,
 year = {2002},
 issn = {0360-0300},
 pages = {90--169},
 numpages = {80},
 url = {http://doi.acm.org/10.1145/505282.505285},
 doi = {10.1145/505282.505285},
 acmid = {505285},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Dialogue management, human computer interaction, language generation, language understanding, speech recognition, speech synthesis},
} 
 

@incollection{McTear2011,
year={2011},
isbn={978-1-4419-7933-9},
booktitle={Spoken Dialogue Systems Technology and Design},
editor={Minker, Wolfgang and Lee, Gary Geunbae and Nakamura, Satoshi and Mariani, Joseph},
doi={10.1007/978-1-4419-7934-6_6},
title={Trends, Challenges and Opportunities in Spoken Dialogue Research},
url={http://dx.doi.org/10.1007/978-1-4419-7934-6_6},
publisher={Springer New York},
keywords={Spoken dialogue systems; Voice search; Ambient intelligence},
author={McTear, Michael},
pages={135-161},
language={English}
}
@inproceedings{Yang2012,
 author = {Yang, Christopher C. and Chen, Hsinchun and Wactlar, Howard and Combi, Carlo K. and Tang, Xuning},
 title = {SHB 2012: international workshop on smart health and wellbeing},
 booktitle = {Proceedings of the 21st ACM international conference on Information and knowledge management},
 series = {CIKM '12},
 year = {2012},
 isbn = {978-1-4503-1156-4},
 location = {Maui, Hawaii, USA},
 pages = {2762--2763},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2396761.2398756},
 doi = {10.1145/2396761.2398756},
 acmid = {2398756},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {healthcare, information technology, wellness},
} 

@article{Allen2006,
 author = {Allen, James and Ferguson, George and Blaylock, Nate and Byron, Donna and Chambers, Nathanael and Dzikovska, Myroslava and Galescu, Lucian and Swift, Mary},
 title = {Chester: towards a personal medication advisor},
 journal = {J. of Biomedical Informatics},
 issue_date = {October 2006},
 volume = {39},
 number = {5},
 month = oct,
 year = {2006},
 issn = {1532-0464},
 pages = {500--513},
 numpages = {14},
 url = {http://dx.doi.org/10.1016/j.jbi.2006.02.004},
 doi = {10.1016/j.jbi.2006.02.004},
 acmid = {1217515},
 publisher = {Elsevier Science},
 address = {San Diego, USA},
 keywords = {artificial intelligence, personal medical advisor, prescription compliance, spoken dialogue system},
} 

@article{Qiu2010,
author = {Qiu, Yu and Guan, Genliang and Feng, Dagan},
doi = {10.1109/DICTA.2010.47},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Qiu, Guan, Feng - 2010 - Improving News Video Annotation with Semantic Context.pdf:pdf},
isbn = {978-1-4244-8816-2},
journal = {2010 International Conference on Digital Image Computing: Techniques and Applications},
month = dec,
pages = {214--219},
publisher = {Ieee},
title = {{Improving News Video Annotation with Semantic Context}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5692567},
year = {2010}
}
@article{Velicer1999,
abstract = {This study compared interactive and noninteractive smoking cessation interventions for a population of smokers who were all members of 1 division of a managed care company. In addition, it examined whether a dose-response relationship existed. Screening was completed for 19,236 members who were contacted by telephone or mail. Of the 4,653 who were identified as smokers, 85.3\% were enrolled. A 2 Intervention (interactive or noninteractive) x 4 Contacts (1, 2, 3, or 6 contacts) x 4 Occasions (0, 6, 12, and 18 months) design was used. The interactive intervention was stage-matched expert-system reports plus manuals; the noninteractive intervention was stage-matched manuals. Contact occurred in 1 of 4 series (1, 2, 3 or 6 contacts) at 3-month intervals. The expert system outperformed the stage-matched manuals, but there was no clear dose-response relationship for either intervention.},
author = {Velicer, WF and Prochaska, JO and Fava, JL},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Velicer, Prochaska, Fava - 1999 - Interactive versus noninteractive interventions and dose-response relationships for stage-matched smoking cessation programs in a managed care set.pdf:pdf},
issn = {0278-6133},
journal = {Health},
keywords = {Adult,Analysis of Variance,Chi-Square Distribution,Computer-Assisted,Computer-Assisted: standards,Episode of Care,Expert Systems,Feedback,Female,Follow-Up Studies,Health Care Surveys,Humans,Male,Managed Care Programs,Managed Care Programs: statistics \& numerical data,Manuals as Topic,Manuals as Topic: standards,Patient Compliance,Patient Compliance: statistics \& numerical data,Patient Selection,Population Surveillance,Population Surveillance: methods,Prevalence,Self Care,Self Care: methods,Self Care: standards,Smoking,Smoking Cessation,Smoking Cessation: methods,Smoking: epidemiology,Smoking: prevention \& control,Therapy},
month = jan,
number = {1},
pages = {21--8},
pmid = {9925042},
title = {{Interactive versus noninteractive interventions and dose-response relationships for stage-matched smoking cessation programs in a managed care setting.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9925042 http://psycnet.apa.org/journals/hea/18/1/21/},
volume = {18},
year = {1999}
}
@article{Boukricha2011c,
author = {Boukricha, Hana and Wachsmuth, Ipke},
doi = {10.1007/s13218-011-0109-8},
file = {:C$\backslash$:/Users/ugan/Desktop/2012 Spring/e-health/22 subat/BoukrichaWachsmuth-Empathy-Three-Step-KI-2011.pdf:pdf},
issn = {0933-1875},
journal = {KI - K\"{u}nstliche Intelligenz},
keywords = {agent-agent interaction,empathic virtual humans,human-agent,internal simulation},
month = may,
number = {3},
pages = {195--204},
title = {{Empathy-Based Emotional Alignment for a Virtual Human: A Three-Step Approach}},
url = {http://www.springerlink.com/index/10.1007/s13218-011-0109-8},
volume = {25},
year = {2011}
}
@article{Hester2005,
abstract = {Sixty-one problem drinkers were randomly assigned to either immediate treatment or a 4-week wait-list control group. Treatment consisted of a computer-based brief motivational intervention, the Drinker's Check-up (DCU). Outcomes strongly support the experimental hypotheses and long-term effectiveness of the treatment. Overall, participants reduced the quantity and frequency of drinking by 50\%, and had similar reductions in alcohol-related problems that were sustained through 12-month follow-up. The DCU seems to be effective in enhancing problem drinkers' motivation for change.},
author = {Hester, Reid K and Squires, Daniel D and Delaney, Harold D},
doi = {10.1016/j.jsat.2004.12.002},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hester, Squires, Delaney - 2005 - The Drinker's Check-up 12-month outcomes of a controlled clinical trial of a stand-alone software program for problem drinkers.pdf:pdf},
issn = {0740-5472},
journal = {Journal of substance abuse treatment},
keywords = {Adult,Alcohol Drinking,Alcohol Drinking: epidemiology,Alcohol Drinking: psychology,Alcoholism,Alcoholism: epidemiology,Alcoholism: psychology,Alcoholism: rehabilitation,Ethanol,Ethanol: blood,Female,Follow-Up Studies,Humans,Male,Middle Aged,Motivation,Outcome Assessment (Health Care),Outcome Assessment (Health Care): statistics \& num,Patient Compliance,Patient Compliance: psychology,Patient Compliance: statistics \& numerical data,Patient Dropouts,Patient Dropouts: psychology,Patient Dropouts: statistics \& numerical data,Personality Assessment,Personality Assessment: statistics \& numerical dat,Psychometrics,Psychometrics: statistics \& numerical data,Software,Therapy, Computer-Assisted,Therapy, Computer-Assisted: statistics \& numerical,United States,Waiting Lists},
month = mar,
number = {2},
pages = {159--69},
pmid = {15780546},
title = {{The Drinker's Check-up: 12-month outcomes of a controlled clinical trial of a stand-alone software program for problem drinkers.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15780546},
volume = {28},
year = {2005}
}
@article{Greenlaw2010,
author = {Greenlaw, Raymond},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Greenlaw - 2010 - An activity profile model and dynamic-matching results for social networks regarding wellness applications.pdf:pdf},
journal = {ECTI- CON—Int. Conf. Electrical Eng./Electronics, Computer, Telecommun. Inform. Technol.},
keywords = {and the complexity results,as opposed to traditional,computers and information technology,matching,mobile wellness applica-,of dynamic matching,oped,proved involve a new,social networking,type},
pages = {656--660},
title = {{An activity profile model and dynamic-matching results for social networks regarding wellness applications}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5491406},
year = {2010}
}
@article{Lustria2009,
abstract = {This systematic review explores how computer-tailored, behavioral interventions implemented and delivered via the Web have been operationalized in a variety of settings.},
author = {Lustria, Mia Liza a and Cortese, Juliann and Noar, Seth M and Glueckauf, Robert L},
doi = {10.1016/j.pec.2008.08.023},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lustria et al. - 2009 - Computer-tailored health interventions delivered over the Web review and analysis of key components.pdf:pdf},
issn = {0738-3991},
journal = {Patient education and counseling},
keywords = {Adaptation, Psychological,Computer-Assisted Instruction,Computer-Assisted Instruction: methods,Decision Support Techniques,Evidence-Based Practice,Feedback, Psychological,Goals,Health Behavior,Health Education,Health Education: organization \& administration,Humans,Internet,Internet: organization \& administration,Motivation,Needs Assessment,Nursing Assessment,Patient Care Planning,Patient Care Planning: organization \& administrati,Patient Participation,Practice Guidelines as Topic,Randomized Controlled Trials as Topic,Research Design,Risk Assessment,Self Care},
month = feb,
number = {2},
pages = {156--73},
pmid = {18947966},
title = {{Computer-tailored health interventions delivered over the Web: review and analysis of key components.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18947966},
volume = {74},
year = {2009}
}
@article{Allen2006,
abstract = {Dialogue systems for health communication hold out the promise of providing intelligent assistance to patients through natural interfaces that require no training to use. But in order to make the development of such systems cost effective, we must be able to use generic techniques and components which are then specialized as needed to the specific health problem and patient population. In this paper, we describe Chester, a prototype intelligent assistant that interacts with its user via conversational natural spoken language to provide them with information and advice regarding their prescribed medications. Chester builds on our prior experience constructing conversational assistants in other domains. The emphasis of this paper is on the portability of our generic spoken dialogue technology, and presents a case study of the application of these techniques to the development of a dialogue system for health communication.},
author = {Allen, James and Ferguson, George and Blaylock, Nate and Byron, Donna and Chambers, Nathanael and Dzikovska, Myroslava and Galescu, Lucian and Swift, Mary},
doi = {10.1016/j.jbi.2006.02.004},
file = {:C$\backslash$:/Users/ugan/Desktop/2012 Spring/e-health/7 mart sunumum/AllenFerguson-et-al-chester-PersonalMedAdvisor-biomedical-informatics-2006.pdf:pdf},
issn = {1532-0480},
journal = {Journal of biomedical informatics},
keywords = {Artificial Intelligence,Communication,Humans,Medical Records Systems, Computerized,Patient Education as Topic,Patient Education as Topic: methods,Software},
month = oct,
number = {5},
pages = {500--13},
pmid = {16545620},
title = {{Chester: towards a personal medication advisor.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16545620},
volume = {39},
year = {2006}
}
@article{Miller1996,
author = {Miller, William R. and Tonigan, J. Scott},
doi = {10.1037//0893-164X.10.2.81},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Miller, Tonigan - 1996 - Assessing drinkers' motivations for change The Stages of Change Readiness and Treatment Eagerness Scale (SOCRATES).pdf:pdf},
issn = {0893-164X},
journal = {Psychology of Addictive Behaviors},
number = {2},
pages = {81--89},
title = {{Assessing drinkers' motivations for change: The Stages of Change Readiness and Treatment Eagerness Scale (SOCRATES).}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0893-164X.10.2.81},
volume = {10},
year = {1996}
}
@article{Neviarouskaya2010,
author = {Neviarouskaya, Alena},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Neviarouskaya - 2010 - Recognition of Affect , Judgment , and Appreciation in Text.pdf:pdf},
journal = {Proceedings of the 23rd \ldots},
number = {August},
pages = {806--814},
title = {{Recognition of affect, judgment, and appreciation in text}},
url = {http://dl.acm.org/citation.cfm?id=1873872},
year = {2010}
}
@article{Sari2009,
author = {Sari, Yunita and Hassan, M. Fadzil and Zamin, Norshuhani},
doi = {10.1109/ICFCC.2009.52},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sari, Hassan, Zamin - 2009 - A Hybrid Approach to Semi-supervised Named Entity Recognition in Health, Safety and Environment Reports.pdf:pdf},
isbn = {978-0-7695-3591-3},
journal = {2009 International Conference on Future Computer and Communication},
keywords = {accident,basilisk algorithm,date identification used in,environment,for instance,health and safety,in e-mail text,link grammar,name entity recognition,report and date used,reports,though both of them},
month = apr,
pages = {599--602},
publisher = {Ieee},
title = {{A Hybrid Approach to Semi-supervised Named Entity Recognition in Health, Safety and Environment Reports}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5189853},
year = {2009}
}
@inproceedings{Bickmore2009,
author = {Bickmore, T.W. and Pfeifer, L.M. and Jack, B.W.},
booktitle = {Proceedings of the 27th international conference on Human factors in computing systems},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bickmore, Pfeifer, Jack - 2009 - Taking the time to care empowering low health literacy hospital patients with virtual nurse agents.pdf:pdf},
pages = {1265--1274},
publisher = {ACM},
title = {{Taking the time to care: empowering low health literacy hospital patients with virtual nurse agents}},
url = {http://dl.acm.org/citation.cfm?id=1518891},
year = {2009}
}
@inproceedings{Marsella2003,
author = {Marsella, S. and Johnson, W.L. and LaBore, C.},
booktitle = {Conference on Artificial Intelligence in Education, Sydney, Australia},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Marsella, Johnson, Labore - 2003 - Interactive Pedagogical Drama for Health Interventions.pdf:pdf},
title = {{Interactive pedagogical drama for health interventions}},
url = {http://people.ict.usc.edu/~marsella/publications/marsella-aied03.pdf},
year = {2003}
}
@article{Ozcan2010,
author = {Ozcan, Alper and Oguducu, Sule Gunduz},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ozcan, Oguducu - 2010 - A Recommendation Framework for Mobile Phones.pdf:pdf},
journal = {Studies Computational Intelligence},
keywords = {aware recommendation framework,community detection,context-,data mining,social network analysis},
pages = {139--149},
title = {{A Recommendation Framework for Mobile Phones}},
year = {2010}
}
@article{Noar2007,
author = {Noar, S.M. and Benac, C.N. and Harris, M.S.},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Noar, Benac, Harris - 2007 - Does tailoring matter Meta-analytic review of tailored print health behavior change interventions.pdf:pdf},
journal = {Psychological bulletin},
number = {4},
pages = {673},
publisher = {American Psychological Association},
title = {{Does tailoring matter? Meta-analytic review of tailored print health behavior change interventions.}},
url = {http://psycnet.apa.org/psycinfo/2007-09203-006},
volume = {133},
year = {2007}
}
@article {Moyer2002,
author = {Moyer, Anne and Finney, John W. and Swearingen, Carolyn E. and Vergun, Pamela},
title = {Brief interventions for alcohol problems: a meta-analytic review of controlled investigations in treatment-seeking and non-treatment-seeking populations},
journal = {Addiction},
volume = {97},
number = {3},
publisher = {Blackwell Science Ltd.},
issn = {1360-0443},
url = {http://dx.doi.org/10.1046/j.1360-0443.2002.00018.x},
doi = {10.1046/j.1360-0443.2002.00018.x},
pages = {279--292},
keywords = {Alcohol problems, brief interventions, treatment},
year = {2002},
}

@article{moyer2004brief,
  title={Brief interventions for alcohol problems: Factors that facilitate implementation},
  author={Moyer, Anne and Finney, John W and others},
  journal={Alcohol Research and Health},
  volume={28},
  number={1},
  pages={44},
  year={2004},
  publisher={US NATIONAL INSTITUTE ON ALCOHOL ABUSE AND ALCOHOLISM}
}

@article{Bickmore2010a,
author = {Bickmore, Timothy W. and Puskar, Kathryn and Schlenk, Elizabeth a. and Pfeifer, Laura M. and Sereika, Susan M.},
doi = {10.1016/j.intcom.2010.02.001},
file = {:C$\backslash$:/Users/uyasa001/Downloads/Bickmore-Adherence-IwC-2010.pdf:pdf},
issn = {09535438},
journal = {Interacting with Computers},
month = jul,
number = {4},
pages = {276--288},
publisher = {Elsevier B.V.},
title = {{Maintaining reality: Relational agents for antipsychotic medication adherence}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S095354381000010X},
volume = {22},
year = {2010}
}
@article{Bickmore2011,
abstract = {Automated approaches to promoting health behavior change, such as exercise, diet, and medication adherence promotion, have the potential for significant positive impact on society. We describe a theory-driven computational model of dialogue that simulates a human health counselor who is helping his or her clients to change via a series of conversations over time. Applications built using this model can be used to change the health behavior of patients and consumers at low cost over a wide range of media including the web and the phone. The model is implemented using an OWL ontology of health behavior change concepts and a public standard task modeling language (ANSI/CEA-2018). We demonstrate the power of modeling dialogue using an ontology and task model by showing how an exercise promotion system developed in the framework was re-purposed for diet promotion with 98\% reuse of the abstract models. Evaluations of these two systems are presented, demonstrating high levels of fidelity to best practices in health behavior change counseling.},
author = {Bickmore, Timothy W and Schulman, Daniel and Sidner, Candace L},
doi = {10.1016/j.jbi.2010.12.006},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bickmore, Schulman, Sidner - 2011 - A reusable framework for health counseling dialogue systems based on a behavioral medicine ontology.pdf:pdf},
issn = {1532-0480},
journal = {Journal of biomedical informatics},
keywords = {Adult,Behavior Therapy,Behavioral Medicine,Behavioral Medicine: methods,Counseling,Counseling: methods,Female,Health Behavior,Health Promotion,Health Promotion: methods,Humans,Interviews as Topic,Male},
month = apr,
number = {2},
pages = {183--97},
pmid = {21220044},
title = {{A reusable framework for health counseling dialogue systems based on a behavioral medicine ontology.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3063319\&tool=pmcentrez\&rendertype=abstract},
volume = {44},
year = {2011}
}
@article{Johnston2002,
author = {Johnston, Michael and Bangalore, Srinivas and Vasireddy, Gunaranjan},
file = {:C$\backslash$:/Users/ugan/Desktop/papers/spoken dialogue systems/p376-johnston.pdf:pdf},
journal = {Proceedings of the 40th},
number = {July},
pages = {376--383},
title = {{MATCH: An architecture for multimodal dialogue systems}},
url = {http://dl.acm.org/citation.cfm?id=1073146},
year = {2002}
}

@article{Moller2007,
title = "Evaluating spoken dialogue systems according to de-facto standards: A case study",
journal = "Computer Speech \& Language",
volume = "21",
number = "1",
pages = "26 - 53",
year = "2007",
note = "",
issn = "0885-2308",
doi = "10.1016/j.csl.2005.11.003",
url = "http://www.sciencedirect.com/science/article/pii/S0885230805000781",
author = "Sebastian Molller and Paula Smeele and Heleen Boland and Jan Krebber"
}

@article{hone2000towards,
  title={Towards a tool for the subjective assessment of speech system interfaces (SASSI)},
  author={Hone, Kate S and Graham, Robert},
  journal={Natural Language Engineering},
  volume={6},
  number={3,4},
  pages={287--303},
  year={2000},
  publisher={Cambridge Univ Press}
}

@article{Chen2006,
abstract = {This study investigated whether young people's substance use and aggressive behaviors are related to their listening to music containing messages of substance use and violence.},
author = {Chen, Meng-Jinn and Miller, Brenda a and Grube, Joel W and Waiters, Elizabeth D},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2006 - Music, substance use, and aggression.pdf:pdf},
issn = {0096-882X},
journal = {Journal of studies on alcohol},
keywords = {Adolescent,Adult,Age Factors,Aged,Aggression,Aggression: psychology,Alcohol Drinking,Alcohol Drinking: epidemiology,Alcohol Drinking: psychology,Exploratory Behavior,Female,Humans,Male,Middle Aged,Music,Questionnaires,Semantics,Street Drugs,Substance-Related Disorders,Substance-Related Disorders: epidemiology,Substance-Related Disorders: psychology},
month = may,
number = {3},
pages = {373--81},
pmid = {16608146},
title = {{Music, substance use, and aggression.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16608146},
volume = {67},
year = {2006}
}
@article{Noar2010,
author = {Noar, S. M. and {Grant Harrington}, N. and {Van Stee}, S. K. and {Shemanski Aldrich}, R.},
doi = {10.1177/1559827610387255},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Noar et al. - 2010 - Tailored Health Communication to Change Lifestyle Behaviors.pdf:pdf},
isbn = {1559827610},
issn = {1559-8276},
journal = {American Journal of Lifestyle Medicine},
keywords = {behavior change,communication,health,tailored message},
month = nov,
number = {2},
pages = {112--122},
title = {{Tailored Health Communication to Change Lifestyle Behaviors}},
url = {http://ajl.sagepub.com/cgi/doi/10.1177/1559827610387255},
volume = {5},
year = {2010}
}
@article{Miller1983,
author = {Miller, William R.},
journal = {Behavioural Psychotherapy},
pages = {147--172},
title = {{Motivational Interviewing with Problem Drinkers}},
volume = {11},
year = {1983}
}
@book{Miller1995,
address = {Rockville, MD},
author = {Miller, WR and Tonigan, JS},
booktitle = {Project MATCH Monograph Series},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Miller, Tonigan - 1995 - The drinker inventory of consequences (DrInC).pdf:pdf},
keywords = {National Institutes of Health},
mendeley-tags = {National Institutes of Health},
publisher = {Project MATCH Monograph Series Vol. 4. NIAAA},
title = {{The drinker inventory of consequences (DrInC)}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:the+drinker+inventory+of+consequences+DrInC\#1},
year = {1995}
}
@article{Miller1994,
address = {Morristown, NJ, USA},
author = {Miller, Scott and Schwartz, Richard and Bobrow, Robert and Ingria, Robert},
doi = {10.3115/1075812.1075874},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Miller et al. - 1994 - Statistical language processing using hidden understanding models.pdf:pdf},
isbn = {1558603573},
journal = {Proceedings of the workshop on Human Language Technology - HLT '94},
pages = {278},
publisher = {Association for Computational Linguistics},
title = {{Statistical language processing using hidden understanding models}},
url = {http://portal.acm.org/citation.cfm?doid=1075812.1075874},
year = {1994}
}
@article{WillettWalterC2006,
author = {{Willet, Walter J}},
file = {:C$\backslash$:/Users/ugan/Documents/Papers/lifestyle change and chronic diseas prevention/DCP44.pdf:pdf},
journal = {A custom publication of the Disease Control Priorities Project},
number = {chapter 45},
pages = {47},
title = {{Prevention of Chronic Disease by Means of Diet and Lifestyle Changes}},
url = {http://files.dcp2.org/pdf/expressbooks/prevent.pdf\#page=4},
year = {2006}
}
@article{Grasso2011a,
author = {Grasso, Floriana and Paris, C\'{e}cile},
doi = {10.1007/s11257-011-9099-3},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Grasso, Paris - 2011 - Preface to the special issue on personalization for e-health.pdf:pdf},
isbn = {1125701190993},
issn = {0924-1868},
journal = {User Modeling and User-Adapted Interaction},
month = may,
number = {4-5},
pages = {333--340},
title = {{Preface to the special issue on personalization for e-health}},
url = {http://www.springerlink.com/index/10.1007/s11257-011-9099-3},
volume = {21},
year = {2011}
}
@misc{Williams2010,
author = {Williams, Jason D},
title = {{AT\&T Statistical Dialog Toolkit}},
url = {http://www.research.att.com/people/ Williams\_Jason\_D},
year = {2010}
}
@article{Brug1999a,
abstract = {Computer-tailored nutrition education may be more effective than general nutrition education because messages are tailored to individual behavior, needs and beliefs of subjects. Therefore, the messages are likely to be of more personal relevance and may have stronger motivational effects. Computer-generated nutrition education has been studied for different dietary behaviors, in different target populations, and in different settings. In recent years, eight studies have been published that assessed the impact of comprehensive computer-generated nutrition interventions that were based on behavior change theory. In this article, the process of providing people with computer-tailored nutrition education is described and the studies on the impact of computer-tailored nutrition education are reviewed. The results point to the conclusion that computer-tailored nutrition education is more likely to be read, remembered, and experienced as personally relevant compared to standard materials. Furthermore, computer-tailored nutrition education also appears to have a greater impact in motivating people to change their diet, their fat intake in particular, although at present no definite conclusions can be drawn.},
author = {Brug, J and Campbell, M and van Assema, P},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Brug, Campbell, van Assema - 1999 - The application and impact of computer-generated personalized nutrition education a review of the literature.pdf:pdf},
issn = {0738-3991},
journal = {Patient education and counseling},
keywords = {Attitude to Health,Computer-Assisted Instruction,Computer-Assisted Instruction: methods,Feedback,Health Education,Health Education: methods,Health Knowledge, Attitudes, Practice,Humans,Motivation,Needs Assessment,Nutrition Assessment,Nutritional Sciences,Nutritional Sciences: education,Patient Care Planning,Self Efficacy,Treatment Outcome},
month = feb,
number = {2},
pages = {145--56},
pmid = {10223019},
title = {{The application and impact of computer-generated personalized nutrition education: a review of the literature.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10223019},
volume = {36},
year = {1999}
}
@article{Thomson2010,
author = {Thomson, Blaise and Young, Steve},
doi = {10.1016/j.csl.2009.07.003},
file = {:C$\backslash$:/Users/ugan/Desktop/papers/spoken dialogue systems/1-s2.0-S0885230809000497-main (2).pdf:pdf},
issn = {08852308},
journal = {Computer Speech \& Language},
keywords = {dialogue systems,pomdp,reinforcement learning,robustness},
month = oct,
number = {4},
pages = {562--588},
publisher = {Elsevier Ltd},
title = {{Bayesian update of dialogue state: A POMDP framework for spoken dialogue systems}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0885230809000497},
volume = {24},
year = {2010}
}
@article{Neviarouskaya2011,
author = {Neviarouskaya, a and Prendinger, H and Ishizuka, M},
doi = {10.1109/T-AFFC.2011.1},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Neviarouskaya, Prendinger, Ishizuka - 2011 - SentiFul A Lexicon for Sentiment Analysis.pdf:pdf},
issn = {1949-3045},
journal = {IEEE Transactions on Affective Computing},
month = jan,
number = {1},
pages = {22--36},
title = {{SentiFul: A Lexicon for Sentiment Analysis}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5708128},
volume = {2},
year = {2011}
}
@misc{TheMendeleySupportTeam2011,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/The Mendeley Support Team - 2011 - Getting Started with Mendeley(4).pdf:pdf},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@article{BickmoreReview2005,
author = {Bickmore, Timothy and Toni Giorgino},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bickmore, Pavia - Unknown - Methodological Review Health Dialog Systems for Patients and Consumers.pdf:pdf},
journal = {Journal of Biomedical Informatics},
number = {617},
pages = {1--61},
title = {{Methodological Review : Health Dialog Systems for Patients and Consumers}}
}
@article{Cassell2000,
author = {{Cassell, Justine and Bickmore}, Timothy},
doi = {http://doi.acm.org/10.1145/355112.355123},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cassell, Justine and Bickmore - 2000 - External manifestations of trustworthiness in the interface.pdf:pdf},
journal = {Communications of the ACM},
number = {12},
pages = {50--56},
title = {{External manifestations of trustworthiness in the interface}},
url = {http://dl.acm.org/citation.cfm?id=355123},
volume = {43},
year = {2000}
}
@article{McTear1998,
author = {McTear, MF},
file = {:C$\backslash$:/Users/ugan/Desktop/papers/spoken dialogue systems/mctear\_ICSLP\_98.pdf:pdf},
journal = {Fifth International Conference on Spoken Language},
title = {{Modelling spoken dialogues with state transition diagrams: experiences with the CSLU toolkit}},
url = {http://www.isca-speech.org/archive/icslp\_1998/i98\_0545.html},
year = {1998}
}
@article{Cooper2000a,
abstract = {The present study tested a motivational model in which personality influences on risky behaviors were hypothesized to be primarily indirectly mediated, by shaping the nature and quality of emotional experience as well as characteristic styles of coping with these emotions. This model was tested in a representative community sample of 1,666 young adults, aged 18 to 25 years old. Results revealed strong support for the model, indicating that broad traits related to neuroticism and extraversion promote involvement in alcohol use and risky sex via distinct pathways. Neurotic individuals were prone to engage in risky behaviors as a way to cope with aversive mood states, whereas extraverted individuals were more likely to engage in risky behaviors as a way to enhance positive affective experience. In contrast, impulsivity directly predicted some forms of risk taking, and interacted with extraversion and neuroticism to predict motives for risky behaviors. The model provides a highly general though not complete account of risky behaviors.},
author = {Cooper, M L and Agocha, V B and Sheldon, M S},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cooper, Agocha, Sheldon - 2000 - A motivational perspective on risky behaviors the role of personality and affect regulatory processes.pdf:pdf},
issn = {0022-3506},
journal = {Journal of personality},
keywords = {Adaptation, Psychological,Adolescent,Adult,Alcohol Drinking,Alcohol Drinking: psychology,Female,Health Behavior,Health Knowledge, Attitudes, Practice,Humans,Male,Mental Disorders,Mental Disorders: psychology,Motivation,Neurotic Disorders,Neurotic Disorders: diagnosis,Neurotic Disorders: psychology,Personality Disorders,Personality Disorders: diagnosis,Personality Disorders: psychology,Risk-Taking,Safe Sex},
month = dec,
number = {6},
pages = {1059--88},
pmid = {11130732},
title = {{A motivational perspective on risky behaviors: the role of personality and affect regulatory processes.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11130732},
volume = {68},
year = {2000}
}
@article{Cepeda2006,
author = {Cepeda, Lisa M. and Davenport, Donna S.},
doi = {10.1037/0033-3204.43.1.1},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cepeda, Davenport - 2006 - Person-centered therapy and solution-focused brief therapy An integration of present and future awareness.pdf:pdf},
issn = {1939-1536},
journal = {Psychotherapy: Theory, Research, Practice, Training},
keywords = {focused,person-centered,psychother-,solution-,theory integration},
number = {1},
pages = {1--12},
title = {{Person-centered therapy and solution-focused brief therapy: An integration of present and future awareness.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0033-3204.43.1.1},
volume = {43},
year = {2006}
}
@article{Bickmore2010,
abstract = {Relational agents are computational artifacts, such as animated, screen-based characters or social robots, that are designed to establish a sense of rapport, trust, and even therapeutic alliance with patients, using ideal therapeutic relationships between human counselors and patients as role models. We describe the development and evaluation of several such agents designed for health counseling and behavioral-change interventions, in which a therapeutic alliance is established with patients in order to enhance the efficacy of the intervention. We also discuss the promise of using such agents as adjuncts to clinical psychiatry, a range of possible applications, and some of the challenges and ethical issues in developing and fielding them in psychiatric interventions.},
author = {Bickmore, Timothy and Gruber, Amanda},
doi = {10.3109/10673221003707538},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bickmore, Gruber - 2010 - Relational agents in clinical psychiatry.pdf:pdf},
issn = {1465-7309},
journal = {Harvard review of psychiatry},
keywords = {Counseling,Counseling: methods,Humans,Internet,Internet: instrumentation,Psychiatry,Psychiatry: instrumentation,Psychiatry: methods},
month = mar,
number = {2},
pages = {119--30},
pmid = {20235777},
title = {{Relational agents in clinical psychiatry.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20235777},
volume = {18},
year = {2010}
}
@article{Quercia2010,
author = {Quercia, Daniele and Ellis, J},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Quercia, Ellis - 2010 - Using mobile phones to nurture social networks.pdf:pdf},
journal = {IEEE Pervasive Computing},
pages = {12--20},
title = {{Using mobile phones to nurture social networks}},
url = {http://www.computer.org/portal/web/csdl/doi/10.1109/MPRV.2010.43},
volume = {09},
year = {2010}
}
@article{Bewick2008a,
abstract = {Alcohol misuse amongst University students is a serious concern, and research has started to investigate the feasibility of using e-health interventions. This study aimed to establish the effectiveness of an electronic web-based personalised feedback intervention through the use of a randomised control trial (RCT).},
author = {Bewick, Bridgette M and Trusler, Karen and Mulhern, Brendan and Barkham, Michael and Hill, Andrew J},
doi = {10.1016/j.addbeh.2008.05.002},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bewick et al. - 2008 - The feasibility and effectiveness of a web-based personalised feedback and social norms alcohol intervention in UK university students a randomised control t.pdf:pdf},
issn = {0306-4603},
journal = {Addictive behaviors},
keywords = {Adolescent,Alcohol Drinking,Alcohol Drinking: prevention \& control,Alcohol Drinking: psychology,Alcoholism,Alcoholism: prevention \& control,Alcoholism: psychology,Feasibility Studies,Feedback,Feedback, Psychological,Female,Humans,Internet,Male,Patient Acceptance of Health Care,Program Evaluation,Sex Distribution,Students,Students: psychology,Universities,Young Adult},
month = sep,
number = {9},
pages = {1192--8},
pmid = {18554819},
title = {{The feasibility and effectiveness of a web-based personalised feedback and social norms alcohol intervention in UK university students: a randomised control trial.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18554819},
volume = {33},
year = {2008}
}
@article{Davis2008,
author = {Davis, Selena and Abidi, Syed},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Davis, Abidi - 2008 - Generating personalised cardiovascular risk management educational interventions linking SCORE and behaviour change.pdf:pdf},
journal = {J. Inform. Technol. Healthcare},
number = {1},
pages = {73--82},
title = {{Generating personalised cardiovascular risk management educational interventions linking SCORE and behaviour change}},
url = {http://web.cs.dal.ca/~sraza/papers/JITH2008b.pdf},
volume = {6},
year = {2008}
}
@misc{DeRosis2006,
abstract = {In this paper, we describe our experience with the design and implementation of an embodied conversational agent (ECA) that converses with users to change their dietary behavior. Our intent is to develop a system that dynamically models the agent and the user and adapts the agent's counseling dialog accordingly. Towards this end, we discuss our efforts to automatically determine the user's dietary behavior stage of change and attitude towards the agent on the basis of unconstrained typed text dialog, first with another person and then with an ECA controlled by an experimenter in a wizard of Oz study. We describe how the results of these studies have been incorporated into an algorithm that combines the results from simple parsing rules together with contextual features using a Bayesian network to determine user stage and attitude automatically.},
author = {de Rosis, Fiorella and Novielli, Nicole and Carofiglio, Valeria and Cavalluzzi, Addolorata and {De Carolis}, Berardina},
booktitle = {Journal of biomedical informatics},
doi = {10.1016/j.jbi.2006.01.001},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/de Rosis et al. - 2006 - User modeling and adaptation in health promotion dialogs with an animated character(3).pdf:pdf},
issn = {1532-0480},
keywords = {Artificial Intelligence,Communication,Health Promotion,Health Promotion: methods,Humans,Information Storage and Retrieval,Information Storage and Retrieval: methods,User-Computer Interface,dialog adaption,stage or change,user model},
mendeley-tags = {dialog adaption,stage or change,user model},
month = oct,
number = {5},
pages = {514--31},
pmid = {16524784},
title = {{User modeling and adaptation in health promotion dialogs with an animated character.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16524784},
volume = {39},
year = {2006}
}

@book{Reiter2000,
address = {Cambridge},
author = {Reiter, Ehud and Dale, Robert},
booktitle = {Language},
doi = {10.1017/CBO9780511519857},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Reiter, Dale - 2000 - Building Natural Language Generation Systems.pdf:pdf},
isbn = {9780511519857},
publisher = {Cambridge University Press},
title = {{Building Natural Language Generation Systems}},
url = {http://ebooks.cambridge.org/ref/id/CBO9780511519857},
year = {2000}
}

@article{Krupka1998,
author = {Krupka, GR and Hausman, K},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Krupka, Hausman - 1998 - IsoQuest Inc. Description of the NetOwl (TM) Extractor System as Used for MUC-7.pdf:pdf},
journal = {In Proceedings of the Seventh Message Understanding Conference (MUC-7)},
pages = {1--10},
title = {{IsoQuest Inc.: Description of the NetOwl (TM) Extractor System as Used for MUC-7}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:IsoQuest+Inc.:+Description+of+the+NetOWL+Extractor+System+as+Used+for+MUC-7\#0},
year = {1998}
}
@article{Boulos2007,
abstract = {This hybrid review-case study introduces three-dimensional (3-D) virtual worlds and their educational potential to medical/health librarians and educators. Second life (http://secondlife.com/) is perhaps the most popular virtual world platform in use today, with an emphasis on social interaction. We describe some medical and health education examples from Second Life, including Second Life Medical and Consumer Health Libraries (Healthinfo Island-funded by a grant from the US National Library of Medicine), and VNEC (Virtual Neurological Education Centre-developed at the University of Plymouth, UK), which we present as two detailed 'case studies'. The pedagogical potentials of Second Life are then discussed, as well as some issues and challenges related to the use of virtual worlds. We have also compiled an up-to-date resource page (http://healthcybermap.org/sl.htm), with additional online material and pointers to support and extend this study.},
author = {Boulos, Maged N Kamel and Hetherington, Lee and Wheeler, Steve},
doi = {10.1111/j.1471-1842.2007.00733.x},
file = {:C$\backslash$:/Users/ugan/Desktop/papers/second life/j.1471-1842.2007.00733.x.pdf:pdf},
issn = {1471-1834},
journal = {Health information and libraries journal},
keywords = {Education, Medical,Great Britain,Health Education,Humans,Imaging, Three-Dimensional,Libraries, Digital,Libraries, Medical,User-Computer Interface},
month = dec,
number = {4},
pages = {233--45},
pmid = {18005298},
title = {{Second Life: an overview of the potential of 3-D virtual worlds in medical and health education.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18005298},
volume = {24},
year = {2007}
}
@book{Adomavicius2011,
address = {Boston, MA},
author = {Adomavicius, Gediminas and Tuzhilin, Alexander},
doi = {10.1007/978-0-387-85820-3},
editor = {Ricci, Francesco and Rokach, Lior and Shapira, Bracha and Kantor, Paul B.},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Adomavicius, Tuzhilin - 2011 - Recommender Systems Handbook.pdf:pdf},
isbn = {978-0-387-85819-7},
pages = {217--253},
publisher = {Springer US},
title = {{Recommender Systems Handbook}},
url = {http://www.springerlink.com/index/10.1007/978-0-387-85820-3},
year = {2011}
}
@inproceedings{Sutton1996,
author = {Sutton, Stephen and Novick, D.G. and Cole, Ronald and Vermeulen, Pieter and de Villiers, J. and Schalkwyk, Johan and Fanty, Mark},
booktitle = {Spoken Language, 1996. ICSLP 96. Proceedings., Fourth International Conference on},
file = {:C$\backslash$:/Users/ugan/Desktop/papers/spoken dialogue systems/00607460.pdf:pdf},
pages = {709--712},
publisher = {IEEE},
title = {{Building 10,000 spoken dialogue systems}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=607460},
volume = {2},
year = {1996}
}
@article{Angelova1996,
author = {Angelova, Galia},
file = {:C$\backslash$:/Users/ugan/Downloads/10.1.1.47.2009.pdf:pdf},
journal = {Conceptual Structures: Knowledge},
title = {{DB-MAT: Knowledge acquisition, processing and NL generation using conceptual graphs}},
url = {http://www.springerlink.com/index/77r4kg53u2567w07.pdf},
year = {1996}
}
@inproceedings{Johnson2004,
author = {Johnson, W.L. and LaBore, C. and Chiu, Y.C.},
booktitle = {AAAI Fall Symposium on Dialogue Systems for Health Communication},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Johnson, LaBore, Chiu - 2004 - A pedagogical agent for psychosocial intervention on a handheld computer(4).pdf:pdf},
pages = {22--24},
title = {{A pedagogical agent for psychosocial intervention on a handheld computer}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:A+Pedagogical+Agent+for+Psychosocial+Intervention+on+a+Handheld+Computer\#0},
year = {2004}
}
@article{Becker-Asano2009,
abstract = {We introduce theWASABI ([W]ASABI [A]ffect [S]imulation for [A]gents with [B]elievable [I]nteractivity)Affect SimulationArchitecture, in which a virtual human’s cog- nitive reasoning capabilities are combined with simulated embodiment to achieve the sim- ulation of primary and secondary emotions. In modeling primary emotions we follow the idea of “Core Affect” in combination with a continuous progression of bodily feeling in three-dimensional emotion space (PADspace), that is subsequently categorized into discrete emotions. In humans, primary emotions are understood as onto-genetically earlier emotions, which directly influence facial expressions. Secondary emotions, in contrast, afford the abil- ity to reason about current events in the light of experiences and expectations.},
author = {Becker-Asano, Christian and Wachsmuth, Ipke},
doi = {10.1007/s10458-009-9094-9},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Becker-Asano, Wachsmuth - 2009 - Affective computing with primary and secondary emotions in a virtual human(3).pdf:pdf},
issn = {1387-2532},
journal = {Autonomous Agents and Multi-Agent Systems},
keywords = {affect simulation,affective computing,affective gaming,architecture,aware emotions,bdi-based architecture,embodied agent,emotion dynamics,emotion expression,emotion modeling,pad emotion space,primary and secondary emotions,reality,virtual,virtual human},
month = may,
number = {1},
pages = {32--49},
title = {{Affective computing with primary and secondary emotions in a virtual human}},
volume = {20},
year = {2009}
}
@article{Neighbors2009,
abstract = {This article presents an initial randomized controlled trial of an event-specific prevention intervention. Participants included 295 college students (41.69\% male, 58.31\% female) who intended to consume 2 or more drinks on their 21st birthday. Participants completed a screening/baseline assessment approximately 1 week before they turned 21 and were randomly assigned to receive Web-based personalized feedback or assessment only. Feedback included normative information, protective behaviors, and personalized blood alcohol concentration information. A follow-up assessment was completed approximately 1 week after a student's birthday. Results indicated a significant intervention effect in reducing estimated blood alcohol concentration (d = 0.33). The intervention effect was moderated by 21st-birthday drinking intentions, and the intervention was primarily effective among those who intended to reach higher levels of intoxication. Results provide some support for normative information as a mediator of intervention efficacy. Overall results provide support for Web-based personalized feedback as an intervention approach for specific events associated with extreme drinking.},
author = {Neighbors, Clayton and Lee, Christine M and Lewis, Melissa a and Fossos, Nicole and Walter, Theresa},
doi = {10.1037/a0014386},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Neighbors et al. - 2009 - Internet-based personalized feedback to reduce 21st-birthday drinking a randomized controlled trial of an event-specific prevention intervention.pdf:pdf},
issn = {1939-2117},
journal = {Journal of consulting and clinical psychology},
keywords = {Age Factors,Alcohol Drinking,Alcohol Drinking: prevention \& control,Anniversaries and Special Events,Feedback,Female,Humans,Internet,Life Change Events,Male,Social Behavior,Young Adult},
month = feb,
number = {1},
pages = {51--63},
pmid = {19170453},
title = {{Internet-based personalized feedback to reduce 21st-birthday drinking: a randomized controlled trial of an event-specific prevention intervention.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2682322\&tool=pmcentrez\&rendertype=abstract},
volume = {77},
year = {2009}
}
@article{Fundel2007,
abstract = {The discovery of regulatory pathways, signal cascades, metabolic processes or disease models requires knowledge on individual relations like e.g. physical or regulatory interactions between genes and proteins. Most interactions mentioned in the free text of biomedical publications are not yet contained in structured databases.},
author = {Fundel, Katrin and K\"{u}ffner, Robert and Zimmer, Ralf},
doi = {10.1093/bioinformatics/btl616},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fundel, K\"{u}ffner, Zimmer - 2007 - RelEx--relation extraction using dependency parse trees.pdf:pdf},
issn = {1367-4811},
journal = {Bioinformatics (Oxford, England)},
keywords = {Algorithms,Database Management Systems,Gene Expression,Gene Expression: physiology,Information Storage and Retrieval,Information Storage and Retrieval: methods,MEDLINE,Natural Language Processing,Protein Interaction Mapping,Protein Interaction Mapping: methods,Proteins,Proteins: classification,Proteins: genetics,Proteins: metabolism,Software},
month = feb,
number = {3},
pages = {365--71},
pmid = {17142812},
title = {{RelEx--relation extraction using dependency parse trees.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17142812},
volume = {23},
year = {2007}
}
@article{Hatzivassiloglou1997,
address = {Morristown, NJ, USA},
author = {Hatzivassiloglou, Vasileios and McKeown, Kathleen R.},
doi = {10.3115/976909.979640},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hatzivassiloglou, McKeown - 1997 - Predicting the semantic orientation of adjectives.pdf:pdf},
journal = {Proceedings of the 35th annual meeting on Association for Computational Linguistics -},
pages = {174--181},
publisher = {Association for Computational Linguistics},
title = {{Predicting the semantic orientation of adjectives}},
url = {http://portal.acm.org/citation.cfm?doid=976909.979640},
year = {1997}
}
@article{Hartholt2008,
author = {Hartholt, Arno and Russ, Thomas and Traum, David},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hartholt, Russ, Traum - 2008 - A common ground for virtual humans Using an ontology in a natural language oriented virtual human architecture.pdf:pdf},
journal = {Language},
title = {{A common ground for virtual humans: Using an ontology in a natural language oriented virtual human architecture}},
url = {http://pages.cs.brandeis.edu/~marc/misc/proceedings/lrec-2008/pdf/811\_paper.pdf},
year = {2008}
}
@article{Liu2004,
author = {Liu, H},
file = {:C$\backslash$:/Users/ugan/Desktop/papers/spoken dialogue systems/fulltext (3).pdf:pdf},
journal = {BT technology journal},
number = {4},
pages = {211--226},
title = {{ConceptNet — a practical commonsense reasoning tool-kit}},
url = {http://www.springerlink.com/index/T551Q7U40671780V.pdf},
volume = {22},
year = {2004}
}
@article{Adomavicius,
author = {Adomavicius, Gediminas and Tuzhilin, Alexander},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Adomavicius, Tuzhilin - Unknown - Towards the Next Generation of Recommender Systems A Survey of the State-of-the-Art and Possible Extensions.pdf:pdf},
pages = {1--43},
title = {{Towards the Next Generation of Recommender Systems : A Survey of the State-of-the-Art and Possible Extensions}}
}
@article{Lisetti2012,
author = {Lisetti, Christine and Yasavur, Ugan and Leon, Claudia De and Amini, Reza and Rishe, Napthali and Visser, Ubbo},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lisetti et al. - 2012 - Building an On-demand Avatar-based Health Intervention for Behavior Change.pdf:pdf},
journal = {FLAIRS$\backslash$},
title = {{Building an On-demand Avatar-based Health Intervention for Behavior Change}},
year = {2012}
}
@article{Denecke2002,
author = {Denecke, M},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Denecke - 2002 - Rapid prototyping for spoken dialogue systems.pdf:pdf},
journal = {Proceedings of the 19th international conference on},
title = {{Rapid prototyping for spoken dialogue systems}},
url = {http://dl.acm.org/citation.cfm?id=1072375},
year = {2002}
}
@article{Hu2002,
abstract = {Coronary heart disease (CHD) remains the leading cause of mortality in industrialized countries and is rapidly becoming a primary cause of death worldwide. Thus, identification of the dietary changes that most effectively prevent CHD is critical.},
author = {Hu, Frank B and Willett, Walter C},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hu, Willett - 2002 - Optimal diets for prevention of coronary heart disease.pdf:pdf},
issn = {0098-7484},
journal = {JAMA : the journal of the American Medical Association},
keywords = {Coronary Artery Disease,Coronary Artery Disease: diet therapy,Coronary Artery Disease: epidemiology,Coronary Artery Disease: prevention \& control,Diet,Dietary Carbohydrates,Dietary Fats,Dietary Fiber,Folic Acid,Humans,Life Style,Lipoproteins,Lipoproteins: blood},
month = nov,
number = {20},
pages = {2569--78},
pmid = {12444864},
title = {{Optimal diets for prevention of coronary heart disease.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12444864},
volume = {288},
year = {2002}
}
@article{Silverman2001,
author = {Silverman, B.G. and Holmes, J. and Kimmel, S. and Branas, C. and Ivins, D. and Weaver, R. and Chen, Y.},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Silverman et al. - 2001 - Modeling emotion and behavior in animated personas to facilitate human behavior change the case of the HEART-SENSE game(4).pdf:pdf},
journal = {Health Care Management Science},
number = {3},
pages = {213--228},
publisher = {Springer},
title = {{Modeling emotion and behavior in animated personas to facilitate human behavior change: the case of the HEART-SENSE game}},
url = {http://www.springerlink.com/index/p3u25338247p8365.pdf},
volume = {4},
year = {2001}
}
@article{Colineau2010c,
author = {Colineau, Nathalie and Paris, C\'{e}cile},
doi = {10.1007/s11257-010-9089-x},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Colineau, Paris - 2010 - Motivating reflection about health within the family the use of goal setting and tailored feedback.pdf:pdf},
issn = {0924-1868},
journal = {User Modeling and User-Adapted Interaction},
keywords = {evaluation,family support,goal setting theory,health behaviour,lifestyle and wellbeing,motivation strategies},
month = dec,
pages = {341--376},
title = {{Motivating reflection about health within the family: the use of goal setting and tailored feedback}},
url = {http://www.springerlink.com/index/10.1007/s11257-010-9089-x},
year = {2010}
}
@article{Marcus1994,
abstract = {The transtheoretical model has been used to understand the stages individuals progress through, and the cognitive and behavioral processes they use while changing health behaviors. The model postulates that individuals engaging in a new behavior move through the stages of Precontemplation, Contemplation, Preparation, Action, and Maintenance. Movement through these stages does not always occur in a linear manner, but may also be cyclical as many individuals must make several attempts at behavior change before their goals are realized. The amount of progress people make as a result of intervention tends to be a function of the stage they are in at the start of treatment. Instruments have been developed to measure the stages and processes of exercise adoption and maintenance and the related constructs of exercise specific self-efficacy and decision making. Psychometric data on these instruments are reviewed. Additionally, data collected on these measures from worksites in the U.S. and Australia are presented along with data from interventions aimed at increasing the adoption of physical activity among community volunteers and worksite employees. Applications of the transtheoretical model for the initiation, adoption, and maintenance of exercise behavior from clinical, community, and public health perspectives are discussed.},
author = {Marcus, B H and Simkin, L R},
institution = {Department of Psychiatry and Human Behavior, Miriam Hospital, Providence, RI 02906.},
journal = {Medicine \& Science in Sports \& Exercise},
number = {11},
pages = {1400--1404},
pmid = {7837962},
publisher = {Lippincott Williams \& Wilkins},
title = {{The transtheoretical model: applications to exercise behavior.}},
url = {http://journals.lww.com/acsm-msse/Abstract/1994/11000/The\_transtheoretical\_model\_\_applications\_to.16.aspx},
volume = {26},
year = {1994}
}
@article{Gavalas2011,
author = {Gavalas, Damianos and Kenteris, Michael},
doi = {10.1007/s00779-011-0389-x},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gavalas, Kenteris - 2011 - A web-based pervasive recommendation system for mobile tourist guides.pdf:pdf},
issn = {1617-4909},
journal = {Personal and Ubiquitous Computing},
keywords = {awareness \'{a} collaborative filtering,location-awareness \'{a} context-,mobile,tourism \'{a} personalization \'{a},travel recommender systems \'{a},\'{a} clustering \'{a} wireless},
month = may,
number = {7},
pages = {759--770},
title = {{A web-based pervasive recommendation system for mobile tourist guides}},
url = {http://www.springerlink.com/index/10.1007/s00779-011-0389-x},
volume = {15},
year = {2011}
}
@book{Rogers1951,
address = {Boston},
author = {Rogers, Carl},
isbn = {0395053226},
publisher = {Houghton Mifflin Company},
title = {{Client-Centered Therapy: Its Current Practice, Implications, and Theory}},
year = {1951}
}
@inproceedings{Kay1984,
author = {Kay, M.},
booktitle = {Proceedings of the 10th International Conference on Computational Linguistics and 22nd annual meeting on Association for Computational Linguistics},
file = {:C$\backslash$:/Users/ugan/Desktop/papers/nabutalk/functional unification grammars-kay.pdf:pdf},
pages = {78},
publisher = {Association for Computational Linguistics},
title = {{Functional unification grammar: A formalism for machine translation}},
url = {http://dl.acm.org/citation.cfm?id=980509},
year = {1984}
}
@article{Manouselis2007,
author = {Manouselis, Nikos},
doi = {10.1007/s11280-007-0019-8},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Manouselis - 2007 - Analysis and classification of multi-criteria recommender systems.pdf:pdf},
journal = {World Wide Web},
keywords = {classification,mcdm,multi-criteria decision making,recommender systems},
pages = {415--441},
title = {{Analysis and classification of multi-criteria recommender systems}},
url = {http://www.springerlink.com/index/v703763243148332.pdf},
year = {2007}
}
@article{Ferguson2010,
abstract = {We describe design and prototyping efforts for a Personal Health Management Assistant for heart failure patients as part of Project HealthDesign. An assistant is more than simply an application. An assistant understands what its users need to do, interacts naturally with them, reacts to what they say and do, and is proactive in helping them manage their health. In this project, we focused on heart failure, which is not only a prevalent and economically significant disease, but also one that is very amenable to self-care. Working with patients, and building on our prior experience with conversational assistants, we designed and developed a prototype system that helps heart failure patients record objective and subjective observations using spoken natural language conversation. Our experience suggests that it is feasible to build such systems and that patients would use them. The system is designed to support rapid application to other self-care settings.},
author = {Ferguson, G and Quinn, J and Horwitz, C and Swift, M and Allen, J and Galescu, L},
doi = {10.1016/j.jbi.2010.05.014},
file = {:C$\backslash$:/Users/ugan/Desktop/2012 Spring/e-health/7 mart sunumum/Ferguson-PersonalHealthManagementAssistant-JBMI-2010.pdf:pdf},
issn = {1532-0480},
journal = {Journal of biomedical informatics},
keywords = {Decision Support Systems, Clinical,Health Records, Personal,Heart Failure,Heart Failure: therapy,Humans,Internet,Natural Language Processing,Patient Care Management,Patient Care Management: methods,Personal Health Services,Personal Health Services: methods,Self Care,Speech Recognition Software,Telemedicine,Telemedicine: methods,User-Computer Interface},
month = oct,
number = {5 Suppl},
pages = {S13--6},
pmid = {20937478},
title = {{Towards a Personal Health Management Assistant.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20937478},
volume = {43},
year = {2010}
}
@inproceedings{Aust1995,
author = {Aust, Harald and Martin, Oerder},
booktitle = {ESCA Workshop on Spoken Dialogue Systems},
file = {:C$\backslash$:/Users/ugan/Desktop/papers/spoken dialogue systems/sds5\_121.pdf:pdf},
pages = {121--124},
title = {{Dialogue control in automatic inquiry systems}},
year = {1995}
}
@article{Minami2011,
address = {New York, NY},
author = {Minami, Yasuhiro and Mori, Akira and Meguro, Toyomi and Higashinaka, Ryuichiro and Dohsaka, Kohji and Maeda, Eisaku},
doi = {10.1007/978-1-4419-7934-6},
editor = {Minker, Wolfgang and Lee, Gary Geunbae and Nakamura, Satoshi and Mariani, Joseph},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Minami et al. - 2011 - Spoken Dialogue Systems Technology and Design.pdf:pdf},
isbn = {978-1-4419-7933-9},
pages = {163--186},
publisher = {Springer New York},
title = {{Spoken Dialogue Systems Technology and Design}},
url = {http://www.springerlink.com/index/10.1007/978-1-4419-7934-6},
year = {2011}
}
@article{Spada2005,
author = {Spada, Marcantonio M. and Wells, Adrian},
doi = {10.1002/cpp.431},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Spada, Wells - 2005 - Metacognitions, emotion and alcohol use.pdf:pdf},
issn = {1063-3995},
journal = {Clinical Psychology \& Psychotherapy},
month = mar,
number = {2},
pages = {150--155},
title = {{Metacognitions, emotion and alcohol use}},
url = {http://doi.wiley.com/10.1002/cpp.431},
volume = {12},
year = {2005}
}
@book{Science2011,
author = {Science, Oregon},
file = {:C$\backslash$:/Users/ugan/Desktop/SIGDIAL2011-2011.pdf:pdf},
isbn = {9781937284107},
title = {{Proceedings of the SIGDIAL 2011 Conference The 12th Annual Meeting of the Special Interest Group on}},
year = {2011}
}
@article{Jokinen2010,
address = {Boston, MA},
author = {Jokinen, Kristiina},
doi = {10.1007/978-0-387-73819-2},
editor = {Chen, Fang},
file = {:C$\backslash$:/Users/ugan/Desktop/papers/spoken dialogue systems/fulltext (1).pdf:pdf},
isbn = {978-0-387-73818-5},
pages = {33--60},
publisher = {Springer US},
title = {{Speech Technology}},
url = {http://www.springerlink.com/index/10.1007/978-0-387-73819-2},
year = {2010}
}
@article{Curioso2007,
abstract = {Internet tools, cell phones, and other information and communication technologies are being used by HIV-positive people on their own initiative. Little is known about the perceptions of HIV-positive people towards these technologies in Peru. The purpose of this paper is to report on perceptions towards use of information and communication technologies as a means to support antiretroviral medication adherence and HIV transmission risk reduction.},
author = {Curioso, Walter H and Kurth, Ann E},
doi = {10.1186/1472-6947-7-24},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Curioso, Kurth - 2007 - Access, use and perceptions regarding Internet, cell phones and PDAs as a means for health promotion for people living with HIV in Peru.pdf:pdf},
isbn = {ISSN\~{}\~{}1472-6947},
issn = {14726947},
journal = {BMC Medical Informatics and Decision Making},
number = {1},
pages = {24},
pmid = {17850656},
title = {{Access, use and perceptions regarding Internet, cell phones and PDAs as a means for health promotion for people living with HIV in Peru.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2048945\&tool=pmcentrez\&rendertype=abstract},
volume = {7},
year = {2007}
}
@misc{Danisman2008,
address = {Aberdeen, UK},
author = {Danisman, Taner and Alpkocak, Adil},
publisher = {Society for the Study of Artificial Intelligence and the Simulation of Behaviour},
title = {{Feeler: Emotion Classification of Text Using Vector Space Model BT  - AISB 2008 Convention, Communication, Interaction and Social Intelligence}},
volume = {vol. 2},
year = {2008}
}
@article{Martin2005,
author = {Martin, Tim and Moyers, TB and Houck, Jon and Christopher, Paulette},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Martin et al. - Unknown - Motivational Interviewing Sequential Code for Observing Process Exchanges ( MI-SCOPE ) Coder ' s Manual.pdf:pdf},
journal = {Retrieved},
title = {{Motivational Interviewing Sequential Code for Observing Process Exchanges (MI-SCOPE) coder's manual}},
url = {http://casaa.unm.edu/download/scope.pdf},
year = {2005}
}
@article{Bird2008,
author = {Bird, Steven and Klein, Ewan and Loper, Edward and Baldridge, Jason},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bird et al. - 2008 - Multidisciplinary Instruction with the Natural Language Toolkit.pdf:pdf},
journal = {Computational Linguistics},
number = {June},
pages = {62--70},
title = {{Multidisciplinary Instruction with the Natural Language Toolkit}},
year = {2008}
}
@article{Muller2004,
abstract = {We have developed Textpresso, a new text-mining system for scientific literature whose capabilities go far beyond those of a simple keyword search engine. Textpresso's two major elements are a collection of the full text of scientific articles split into individual sentences, and the implementation of categories of terms for which a database of articles and individual sentences can be searched. The categories are classes of biological concepts (e.g., gene, allele, cell or cell group, phenotype, etc.) and classes that relate two objects (e.g., association, regulation, etc.) or describe one (e.g., biological process, etc.). Together they form a catalog of types of objects and concepts called an ontology. After this ontology is populated with terms, the whole corpus of articles and abstracts is marked up to identify terms of these categories. The current ontology comprises 33 categories of terms. A search engine enables the user to search for one or a combination of these tags and/or keywords within a sentence or document, and as the ontology allows word meaning to be queried, it is possible to formulate semantic queries. Full text access increases recall of biological data types from 45\% to 95\%. Extraction of particular biological facts, such as gene-gene interactions, can be accelerated significantly by ontologies, with Textpresso automatically performing nearly as well as expert curators to identify sentences; in searches for two uniquely named genes and an interaction term, the ontology confers a 3-fold increase of search efficiency. Textpresso currently focuses on Caenorhabditis elegans literature, with 3,800 full text articles and 16,000 abstracts. The lexicon of the ontology contains 14,500 entries, each of which includes all versions of a specific word or phrase, and it includes all categories of the Gene Ontology database. Textpresso is a useful curation tool, as well as search engine for researchers, and can readily be extended to other organism-specific corpora of text. Textpresso can be accessed at http://www.textpresso.org or via WormBase at http://www.wormbase.org.},
author = {M\"{u}ller, Hans-Michael and Kenny, Eimear E and Sternberg, Paul W},
doi = {10.1371/journal.pbio.0020309},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/M\"{u}ller, Kenny, Sternberg - 2004 - Textpresso an ontology-based information retrieval and extraction system for biological literature.pdf:pdf},
issn = {1545-7885},
journal = {PLoS biology},
keywords = {Abstracting and Indexing as Topic,Algorithms,Animals,Biology,Biology: methods,Caenorhabditis elegans,Caenorhabditis elegans Proteins,Caenorhabditis elegans Proteins: chemistry,Computational Biology,Computational Biology: methods,Databases, Bibliographic,Databases, Genetic,Information Services,Information Storage and Retrieval,Internet,Literature,MEDLINE,Medical Informatics,Natural Language Processing,PubMed,Software,Unified Medical Language System,User-Computer Interface},
month = nov,
number = {11},
pages = {e309},
pmid = {15383839},
title = {{Textpresso: an ontology-based information retrieval and extraction system for biological literature.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=517822\&tool=pmcentrez\&rendertype=abstract},
volume = {2},
year = {2004}
}
@article{Resnicow2001,
abstract = {This study reports on Eat for Life, a multicomponent intervention to increase fruit and vegetable consumption among African Americans that was delivered through Black churches.},
author = {Resnicow, K and Jackson, a and Wang, T and De, a K and McCarty, F and Dudley, W N and Baranowski, T},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Resnicow et al. - 2001 - A motivational interviewing intervention to increase fruit and vegetable intake through Black churches results of the Eat for Life trial.pdf:pdf},
issn = {0090-0036},
journal = {American journal of public health},
keywords = {African Americans,African Americans: psychology,Counseling,Diet,Diet: psychology,Female,Fruit,Fruit: therapeutic use,Humans,Intervention Studies,Interview, Psychological,Male,Motivation,Outcome Assessment (Health Care),Persuasive Communication,Phytotherapy,Religion and Psychology,Vegetables,Vegetables: therapeutic use},
month = oct,
number = {10},
pages = {1686--93},
pmid = {11574336},
title = {{A motivational interviewing intervention to increase fruit and vegetable intake through Black churches: results of the Eat for Life trial.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1446855\&tool=pmcentrez\&rendertype=abstract},
volume = {91},
year = {2001}
}
@article{Linden2003,
author = {Linden, Greg and Smith, Brent},
file = {:C$\backslash$:/Users/ugan/Downloads/Amazon-Recommendations.pdf:pdf},
journal = {Internet Computing, IEEE},
number = {February},
pages = {76--80},
title = {{Amazon. com recommendations: Item-to-item collaborative filtering}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1167344},
volume = {7},
year = {2003}
}
@article{Laveist2002,
abstract = {We examined a national sample of African American, white, Hispanic, and Asian American respondents to test the hypothesis that doctor-patient race concordance is predictive of patient satisfaction. Our analysis examined racial/ethnic differences in patient satisfaction among patients in multiple combinations of doctor-patient race/ethnicity pairs. Additionally, we outline the determinants of doctor-patient race concordance. The analysis used the 1994 Commonwealth Fund Minority Health Survey to construct a series of multivariate models. We found that for respondents in each race/ethnic group, patients who had a choice in the selection of their physician were more likely to be race concordant. Whites were more likely to be race concordant with their physician compared to African American, Hispanic, and Asian American respondents. Among each race/ethnic group, respondents who were race concordant reported greater satisfaction with their physician compared with respondents who were not race concordant. These findings suggest support for the continuation of efforts to increase the number of minority physicians, while placing greater emphasis on improving the ability of physicians to interact with patients who are not of their own race.},
author = {Laveist, Thomas a and Nuru-Jeter, Amani},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Laveist, Nuru-Jeter - 2002 - Is doctor-patient race concordance associated with greater satisfaction with care.pdf:pdf},
issn = {0022-1465},
journal = {Journal of health and social behavior},
keywords = {Adolescent,Adult,African Americans,African Americans: psychology,Aged,Aged, 80 and over,Asian Americans,Asian Americans: psychology,Cultural Diversity,Ethnic Groups,Ethnic Groups: classification,Ethnic Groups: psychology,European Continental Ancestry Group,European Continental Ancestry Group: psychology,Female,Hispanic Americans,Hispanic Americans: psychology,Humans,Male,Middle Aged,Outcome Assessment (Health Care),Patient Satisfaction,Patient Satisfaction: ethnology,Physician-Patient Relations,United States},
month = sep,
number = {3},
pages = {296--306},
pmid = {12467254},
title = {{Is doctor-patient race concordance associated with greater satisfaction with care?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12467254},
volume = {43},
year = {2002}
}
@article{VanDeemter2008,
author = {van Deemter, Kees and Krenn, Brigitte and Piwek, Paul and Klesen, Martin and Schr\"{o}der, Marc and Baumann, Stefan},
doi = {10.1016/j.artint.2008.02.002},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/van Deemter et al. - 2008 - Fully generated scripted dialogue for embodied agents.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {affective reasoning,body language,embodied conversational agents,emotion modelling,fully generated scripted dialogue,interfaces,multimodal,natural language generation,speech,synthesis},
month = jun,
number = {10},
pages = {1219--1244},
title = {{Fully generated scripted dialogue for embodied agents}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0004370208000234},
volume = {172},
year = {2008}
}
@article{Carberry2008,
author = {Carberry, Sandra and Rosis, Fiorella},
doi = {10.1007/s11257-007-9044-7},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Carberry, Rosis - 2008 - Introduction to special Issue on ‘Affective modeling and adaptation’(2).pdf:pdf},
issn = {0924-1868},
journal = {User Modeling and User-Adapted Interaction},
month = jan,
number = {1-2},
pages = {1--9},
title = {{Introduction to special Issue on ‘Affective modeling and adaptation’}},
url = {http://www.springerlink.com/index/10.1007/s11257-007-9044-7},
volume = {18},
year = {2008}
}

@Article{OnlineAlcoholInterventionRev2010,
author={White, Angela
and Kavanagh, David
and Stallman, Helen
and Klein, Britt
and Kay-Lambkin, Frances
and Proudfoot, Judy
and Drennan, Judy
and Connor, Jason
and Baker, Amanda
and Hines, Emily
and Young, Ross},
title={Online Alcohol Interventions: A Systematic Review},
journal={J Med Internet Res},
year={2010},
month={Dec},
day={19},
volume={12},
number={5},
pages={e62},
keywords={Alcohol},
keywords={drugs},
keywords={Internet},
keywords={physical health},
keywords={website interactivity},
keywords={online treatment},
keywords={online information},
abstract={Background:  There has been a significant increase in the availability of online programs for alcohol problems. A systematic review of the research evidence underpinning these programs is timely. Objectives:  Our objective was to review the efficacy of online interventions for alcohol misuse.     Systematic searches of Medline, PsycINFO, Web of Science, and Scopus were conducted for English abstracts (excluding dissertations) published from 1998 onward. Search terms were: (1) Internet, Web*; (2) online, computer*; (3) alcohol*; and (4) E{\backslash}effect*, trial*, random* (where * denotes a wildcard). Forward and backward searches from identified papers were also conducted. Articles were included if (1) the primary intervention was delivered and accessed via the Internet, (2) the intervention focused on moderating or stopping alcohol consumption, and (3) the study was a randomized controlled trial of an alcohol-related screen, assessment, or intervention. Results:  The literature search initially yielded 31 randomized controlled trials (RCTs), 17 of which met inclusion criteria. Of these 17 studies, 12 (70.6\%) were conducted with university students, and 11 (64.7\%) specifically focused on at-risk, heavy, or binge drinkers. Sample sizes ranged from 40 to 3216 (median 261), with 12 (70.6\%) studies predominantly involving brief personalized feedback interventions. Using published data, effect sizes could be extracted from 8 of the 17 studies. In relation to alcohol units per week or month and based on 5 RCTs where a measure of alcohol units per week or month could be extracted, differential effect sizes to posttreatment ranged from 0.02 to 0.81 (mean 0.42, median 0.54). Pre-post effect sizes for brief personalized feedback interventions ranged from 0.02 to 0.81, and in 2 multi-session modularized interventions, a pre-post effect size of 0.56 was obtained in both. Pre-post differential effect sizes for peak blood alcohol concentrations (BAC) ranged from 0.22 to 0.88, with a mean effect size of 0.66. Conclusions:  The available evidence suggests that users can benefit from online alcohol interventions and that this approach could be particularly useful for groups less likely to access traditional alcohol-related services, such as women, young people, and at-risk users. However, caution should be exercised given the limited number of studies allowing extraction of effect sizes, the heterogeneity of outcome measures and follow-up periods, and the large proportion of student-based studies. More extensive RCTs in community samples are required to better understand the efficacy of specific online alcohol approaches, program dosage, the additive effect of telephone or face-to-face interventions, and effective strategies for their dissemination and marketing. },
doi={10.2196/jmir.1479},
url={http://www.jmir.org/2010/5/e62/},
url={http://www.ncbi.nlm.nih.gov/pubmed/21169175}
}

@article{Dunn2012,
abstract = {Dropout is a frequent problem in face-to-face psychological interventions. However, little is known regarding dropout in computer-based interventions (CBIs). It is important to understand the extent to which children and adolescents drop out of CBIs, so we can ensure that more people complete the programmes to gain maximum benefit. A systematic review of current research on dropout from CBIs identified 15 studies. Dropout rate ranged from 0 per cent to 54 per cent with a median of 15 per cent. There is a need for more rigorous investigation of the extent of, and reasons for, dropout from CBIs with children and adolescents with chronic health conditions.},
author = {Dunn, Tamara L and Casey, Leanne M and Sheffield, Jeanie and Newcombe, Peter and Chang, Anne B},
doi = {10.1177/1359105311415558},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dunn et al. - 2012 - Dropout from computer-based interventions for children and adolescents with chronic health conditions.pdf:pdf},
issn = {1461-7277},
journal = {Journal of health psychology},
keywords = {Adolescent,Age Factors,Child,Chronic Disease,Chronic Disease: psychology,Chronic Disease: therapy,Female,Humans,Male,Patient Dropouts,Patient Dropouts: psychology,Severity of Illness Index,Sex Factors,Therapy, Computer-Assisted},
month = apr,
number = {3},
pages = {429--42},
pmid = {21890540},
title = {{Dropout from computer-based interventions for children and adolescents with chronic health conditions.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21890540},
volume = {17},
year = {2012}
}
@article{Park2007,
author = {Park, MH and Hong, JH},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Park, Hong - 2007 - Location-based recommendation system using Bayesian user's preference model in mobile devices.pdf:pdf},
journal = {Ubiquitous Intelligence and Computing},
pages = {1130--1139},
title = {{Location-based recommendation system using Bayesian user's preference model in mobile devices}},
url = {http://www.springerlink.com/index/j10232118932324j.pdf},
year = {2007}
}
@article{Farrar2008,
author = {Farrar, Scott},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Farrar, Moran - Unknown - The e-Linguistics Toolkit.pdf:pdf},
journal = {emerging discipline: Workshop in the},
title = {{The e-linguistics toolkit}},
url = {http://faculty.washington.edu/farrar/documents/inproceedings/FarrarMoran2008.pdf},
year = {2008}
}
@article{Singh1997,
author = {Singh, M and Barnett, James},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Singh, Barnett - 1997 - Automating spoken dialogue systems.pdf:pdf},
journal = {Foundations of Intelligent Systems},
title = {{Automating spoken dialogue systems}},
url = {http://www.springerlink.com/index/p51351q8153539l7.pdf},
year = {1997}
}
@article{Willett2002,
abstract = {Genetic and environmental factors, including diet and life-style, both contribute to cardiovascular disease, cancers, and other major causes of mortality, but various lines of evidence indicate that environmental factors are most important. Overly enthusiastic expectations regarding the benefits of genetic research for disease prevention have the potential to distort research priorities and spending for health. However, integration of new genetic information into epidemiologic studies can help clarify causal relations between both life-style and genetic factors and risks of disease. Thus, a balanced approach should provide the best data to make informed choices about the most effective means to prevent disease.},
author = {Willett, Walter C},
doi = {10.1126/science.1071055},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Willett - 2002 - Balancing life-style and genomics research for disease prevention.pdf:pdf},
issn = {1095-9203},
journal = {Science (New York, N.Y.)},
keywords = {Disease,Disease Susceptibility,Disease: etiology,Environment,Epidemiologic Studies,Genetic Predisposition to Disease,Genomics,Humans,Life Style,Mutation,Neoplasms,Neoplasms: etiology,Neoplasms: genetics,Neoplasms: prevention \& control,Polymorphism, Genetic,Preventive Medicine,Research,Risk Factors,Twin Studies as Topic},
month = apr,
number = {5568},
pages = {695--8},
pmid = {11976443},
title = {{Balancing life-style and genomics research for disease prevention.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11976443},
volume = {296},
year = {2002}
}
@article{Carberry2008c,
author = {Carberry, Sandra and Rosis, Fiorella},
doi = {10.1007/s11257-007-9044-7},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Carberry, Rosis - 2008 - Introduction to special Issue on ‘Affective modeling and adaptation’.pdf:pdf},
issn = {0924-1868},
journal = {User Modeling and User-Adapted Interaction},
month = jan,
number = {1-2},
pages = {1--9},
title = {{Introduction to special Issue on ‘Affective modeling and adaptation’}},
url = {http://www.springerlink.com/index/10.1007/s11257-007-9044-7},
volume = {18},
year = {2008}
}
@article{Krebs2010,
abstract = {Computer-tailored interventions have become increasingly common for facilitating improvement in behaviors related to chronic disease and health promotion. A sufficient number of outcome studies from these interventions are now available to facilitate the quantitative analysis of effect sizes, permitting moderator analyses that were not possible with previous systematic reviews.},
author = {Krebs, Paul and Prochaska, James O and Rossi, Joseph S},
doi = {10.1016/j.ypmed.2010.06.004},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Krebs, Prochaska, Rossi - 2010 - A meta-analysis of computer-tailored interventions for health behavior change.pdf:pdf},
issn = {1096-0260},
journal = {Preventive medicine},
keywords = {Decision Making, Computer-Assisted,Diet,Female,Health Behavior,Health Promotion,Health Promotion: methods,Humans,Male,Mammography,Motor Activity,Patient Compliance,Reminder Systems,Smoking Cessation,Smoking Cessation: methods},
number = {3-4},
pages = {214--21},
pmid = {20558196},
publisher = {Elsevier Inc.},
title = {{A meta-analysis of computer-tailored interventions for health behavior change.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2939185\&tool=pmcentrez\&rendertype=abstract},
volume = {51},
year = {2010}
}
@inproceedings{Nakano2000,
author = {Nakano, Mikio and Miyazaki, Noboru and Yasuda, Norihito and Sugiyama, Akira and Hirasawa, Jun-ichi and Dohsaka, Kohji and Aikawa, Kiyoaki},
booktitle = {Proceedings of the 1st SIGdial workshop on Discourse and dialogue-Volume 10},
file = {:C$\backslash$:/Users/ugan/Desktop/papers/spoken dialogue systems/nakano.pdf:pdf},
pages = {150--159},
publisher = {Association for Computational Linguistics},
title = {{WIT: A toolkit for building robust and real-time spoken dialogue systems}},
url = {http://dl.acm.org/citation.cfm?id=1117753},
year = {2000}
}
@article{Webb2010,
abstract = {Background: The Internet is increasingly used as a medium for the delivery of interventions designed to promote health behavior change. However, reviews of these interventions to date have not systematically identified intervention characteristics and linked these to effectiveness. Objectives: The present review sought to capitalize on recently published coding frames for assessing use of theory and behavior change techniques to investigate which characteristics of Internet-based interventions best promote health behavior change. In addition, we wanted to develop a novel coding scheme for assessing mode of delivery in Internet-based interventions and also to link different modes to effect sizes. Methods: We conducted a computerized search of the databases indexed by ISI Web of Knowledge (including BIOSIS Previews and Medline) between 2000 and 2008. Studies were included if (1) the primary components of the intervention were delivered via the Internet, (2) participants were randomly assigned to conditions, and (3) a measure of behavior related to health was taken after the intervention. Results: We found 85 studies that satisfied the inclusion criteria, providing a total sample size of 43,236 participants. On average, interventions had a statistically small but significant effect on health-related behavior (d+ = 0.16, 95\% CI 0.09 to 0.23). More extensive use of theory was associated with increases in effect size (P = .049), and, in particular, interventions based on the theory of planned behavior tended to have substantial effects on behavior (d+ = 0.36, 95\% CI 0.15 to 0.56). Interventions that incorporated more behavior change techniques also tended to have larger effects compared to interventions that incorporated fewer techniques (P < .001). Finally, the effectiveness of Internet-based interventions was enhanced by the use of additional methods of communicating with participants, especially the use of short message service (SMS), or text, messages. Conclusions: The review provides a framework for the development of a science of Internet-based interventions, and our findings provide a rationale for investing in more intensive theory-based interventions that incorporate multiple behavior change techniques and modes of delivery.},
author = {Webb, Thomas L and Joseph, Judith and Yardley, Lucy and Michie, Susan},
editor = {Eysenbach, Gunther},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Webb et al. - 2010 - Using the Internet to Promote Health Behavior Change A Systematic Review and Meta-analysis of the Impact of Theoretical Basis, Use of Behavior Change Technique.pdf:pdf},
institution = {Department of Psychology, University of Sheffield, Western Bank, Sheffield, UK. t.webb@sheffield.ac.uk},
journal = {Journal of Medical Internet Research},
keywords = {behavior control,behavior control methods,behavior control standards,health behavior,health promotion,health promotion methods,humans,internet,internet standards,models,program evaluation,psychological},
number = {1},
pages = {e4},
publisher = {Gunther Eysenbach},
title = {{Using the Internet to Promote Health Behavior Change: A Systematic Review and Meta-analysis of the Impact of Theoretical Basis, Use of Behavior Change Techniques, and Mode of Delivery on Efficacy}},
url = {http://eprints.soton.ac.uk/145595/1/HTML},
volume = {12},
year = {2010}
}
@article{Mairesse2010b,
author = {Mairesse, Fran\c{c}ois and Walker, Marilyn a.},
doi = {10.1007/s11257-010-9076-2},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mairesse, Walker - 2010 - Towards personality-based user adaptation psychologically informed stylistic language generation.pdf:pdf},
issn = {0924-1868},
journal = {User Modeling and User-Adapted Interaction},
keywords = {big five traits,dialogue,individual differences,linguistic style,natural language generation,personality,recommendation},
month = jul,
number = {3},
pages = {227--278},
title = {{Towards personality-based user adaptation: psychologically informed stylistic language generation}},
url = {http://www.springerlink.com/index/10.1007/s11257-010-9076-2},
volume = {20},
year = {2010}
}
@misc{woods1969,
address = {Cambridge},
author = {Woods, W. A.},
file = {:C$\backslash$:/Users/ugan/Documents/Papers/nlp/augmented transition networks.pdf:pdf},
title = {augmented transition networks for natural language analysis},
year = {1969}
}
@article{Miller1995a,
author = {Miller, George A.},
journal = {Communications of the ACM},
number = {11},
pages = {39--41},
title = {{WordNet: A Lexical Database for English}},
volume = {38},
year = {1995}
}
@article{ElKaliouby2006,
abstract = {This article highlights the overlapping and converging goals and challenges of autism research and affective computing. We propose that a collaboration between autism research and affective computing could lead to several mutually beneficial outcomes--from developing new tools to assist people with autism in understanding and operating in the socioemotional world around them, to developing new computational models and theories that will enable technology to be modified to provide an overall better socioemotional experience to all people who use it. This article describes work toward this convergence at the MIT Media Lab, and anticipates new research that might arise from the interaction between research into autism, technology, and human socioemotional intelligence.},
author = {el Kaliouby, Rana and Picard, Rosalind and Baron-Cohen, Simon},
doi = {10.1196/annals.1382.016},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/el Kaliouby, Picard, Baron-Cohen - 2006 - Affective computing and autism.pdf:pdf},
issn = {0077-8923},
journal = {Annals of the New York Academy of Sciences},
keywords = {Asperger Syndrome,Asperger Syndrome: psychology,Autistic Disorder,Autistic Disorder: psychology,Behavior,Computational Biology,Empathy,Humans,Interdisciplinary Communication},
month = dec,
number = {321},
pages = {228--48},
pmid = {17312261},
title = {{Affective computing and autism.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17312261},
volume = {1093},
year = {2006}
}
@article{Honka2010,
author = {Honka, Anita and Kaipainen, Kirsikka and Hietala, Henri and Saranummi, Niilo},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Honka et al. - 2011 - Rethinking Health ICT-Enabled Services to Empower People to Manage Their Health.pdf:pdf},
journal = {Studies Computational Intelligence},
pages = {139--149},
title = {{Rethinking Health : ICT-Enabled Services to Empower People to Manage Their Health}},
volume = {205},
year = {2010}
}
@article{Edinger1983a,
author = {Edinger, Joyce a. and Patterson, Miles L.},
doi = {10.1037//0033-2909.93.1.30},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Edinger, Patterson - 1983 - Nonverbal involvement and social control.pdf:pdf},
issn = {0033-2909},
journal = {Psychological Bulletin},
number = {1},
pages = {30--56},
title = {{Nonverbal involvement and social control.}},
url = {http://content.apa.org/journals/bul/93/1/30},
volume = {93},
year = {1983}
}
@article{Lisetti2012a,
author = {Lisetti, Christine and Yasavur, Ugan and Leon, Claudia De and Amini, Reza},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lisetti et al. - 2012 - Building an On-demand Avatar-based Health Intervention for Behavior Change(2).pdf:pdf},
journal = {Proceedings of the Twenty-Fifth International Florida Artificial Intelligence Research Society Conference},
title = {{Building an On-Demand Avatar-Based Health Intervention for Behavior Change}},
url = {http://www.aaai.org/ocs/index.php/FLAIRS/FLAIRS12/paper/download/4481/4789},
year = {2012}
}

@article{babor1992,
  title={Programme on Substance Abuse : project on identification and management of alcohol-related problems. Report on Phase II, an randomized clinical trial of brief interventions in primary health care},
  author={Babor, Thomas F and Grant, Marcus},
  year={1992},
  publisher={World Health Organization}
}

@article{miller2002mesa,
  title={Mesa Grande: a methodological analysis of clinical trials of treatments for alcohol use disorders},
  author={Miller, William R and Wilbourne, Paula L},
  journal={Addiction},
  volume={97},
  number={3},
  pages={265--277},
  year={2002},
  publisher={Wiley Online Library}
}

@article{Mokdad2004,
abstract = {Modifiable behavioral risk factors are leading causes of mortality in the United States. Quantifying these will provide insight into the effects of recent trends and the implications of missed prevention opportunities.},
author = {Mokdad, Ali H and Marks, James S and Stroup, Donna F and Gerberding, Julie L},
doi = {10.1001/jama.291.10.1238},
file = {:C$\backslash$:/Users/ugan/Downloads/JSC40095.pdf:pdf},
issn = {1538-3598},
journal = {JAMA : the journal of the American Medical Association},
keywords = {Accidents, Traffic,Accidents, Traffic: mortality,Alcohol Drinking,Cause of Death,Cause of Death: trends,Communicable Diseases,Communicable Diseases: mortality,Diet,Humans,Physical Fitness,Poisoning,Poisoning: mortality,Risk Factors,Sexual Behavior,Smoking,Smoking: mortality,Substance-Related Disorders,United States,United States: epidemiology,Wounds, Gunshot,Wounds, Gunshot: mortality},
month = mar,
number = {10},
pages = {1238--45},
pmid = {15010446},
title = {{Actual causes of death in the United States, 2000.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15657315},
volume = {291},
year = {2004}
}
@article{Boukricha2007,
abstract = {Addressing user’s emotions in human-computer interaction significantly enhances the believability and lifelikeness of virtual humans. Emotion recognition and interpretation is realized in our approach by integrating empathy as a designated process within the agent’s cognitive architecture. In this paper we describe this empathy process which comprises of two interconnected components: a belief-desire-intention (BDI) based cognitive component and an affective component based on the emotion simulation system of the virtual human Max.},
author = {Boukricha, Hana and Becker-Asano, Christian},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Boukricha, Becker-Asano - 2007 - Simulating empathy for the virtual human max(3).pdf:pdf},
journal = {on Emotion and Computing in conj},
title = {{Simulating empathy for the virtual human max}},
year = {2007}
}
@article{Glanz2010,
abstract = {Increasing evidence suggests that public health and health-promotion interventions that are based on social and behavioral science theories are more effective than those lacking a theoretical base. This article provides an overview of the state of the science of theory use for designing and conducting health-promotion interventions. Influential contemporary perspectives stress the multiple determinants and multiple levels of determinants of health and health behavior. We describe key types of theory and selected often-used theories and their key concepts, including the health belief model, the transtheoretical model, social cognitive theory, and the ecological model. This summary is followed by a review of the evidence about patterns and effects of theory use in health behavior intervention research. Examples of applied theories in three large public health programs illustrate the feasibility, utility, and challenges of using theory-based interventions. This review concludes by identifying cross-cutting themes and important future directions for bridging the divides between theory, practice, and research.},
author = {Glanz, Karen and Bishop, Donald B},
doi = {10.1146/annurev.publhealth.012809.103604},
file = {:C$\backslash$:/Users/ugan/Desktop/papers/spoken dialogue systems/T19-Glanz.pdf:pdf},
issn = {1545-2093},
journal = {Annual review of public health},
keywords = {Behavioral Sciences,Health Behavior,Humans,Models, Theoretical,Public Health Practice},
month = apr,
pages = {399--418},
pmid = {20070207},
title = {{The role of behavioral science theory in development and implementation of public health interventions.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20070207},
volume = {31},
year = {2010}
}
@article{Lu2011,
author = {Lu, Yue and Castellanos, M and Dayal, U and Zhai, CX},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lu et al. - 2011 - Automatic construction of a context-aware sentiment lexicon an optimization approach.pdf:pdf},
isbn = {9781450306324},
journal = {Proceedings of the 20th \ldots},
keywords = {opinion mining,opti-,sentiment analysis,sentiment lexicon},
pages = {347--356},
title = {{Automatic construction of a context-aware sentiment lexicon: an optimization approach}},
url = {http://dl.acm.org/citation.cfm?id=1963456},
year = {2011}
}
@article{Portnoy2008,
abstract = {The use of computers to promote healthy behavior is increasing. To evaluate the efficacy of these computer-delivered interventions, we conducted a meta-analysis of the published literature.},
author = {Portnoy, David B and Scott-Sheldon, Lori a J and Johnson, Blair T and Carey, Michael P},
doi = {10.1016/j.ypmed.2008.02.014},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Portnoy et al. - 2008 - Computer-delivered interventions for health promotion and behavioral risk reduction a meta-analysis of 75 randomized controlled trials, 1988-2007.pdf:pdf},
issn = {0091-7435},
journal = {Preventive medicine},
keywords = {Computers,Health Behavior,Health Education,Health Promotion,Humans,Randomized Controlled Trials as Topic,Risk Reduction Behavior},
month = jul,
number = {1},
pages = {3--16},
pmid = {18403003},
title = {{Computer-delivered interventions for health promotion and behavioral risk reduction: a meta-analysis of 75 randomized controlled trials, 1988-2007.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2572996\&tool=pmcentrez\&rendertype=abstract},
volume = {47},
year = {2008}
}
@inproceedings{Papangelis2012,
 author = {Papangelis, Alexandros and Kouroupas, Nikolaos and Karkaletsis, Vangelis and Makedon, Fillia},
 title = {An adaptive dialogue system with online dialogue policy learning},
 booktitle = {Proceedings of the 7th Hellenic conference on Artificial Intelligence: theories and applications},
 series = {SETN'12},
 year = {2012},
 isbn = {978-3-642-30447-7},
 location = {Lamia, Greece},
 pages = {323--330},
 numpages = {8},
 url = {http://dx.doi.org/10.1007/978-3-642-30448-4_41},
 doi = {10.1007/978-3-642-30448-4_41},
 acmid = {2366965},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
 keywords = {adaptive dialogue systems, reinforcement learning},
} 
@article{Bellotti2008,
address = {New York, New York, USA},
author = {Bellotti, Victoria and Price, Bob and Rasmussen, Paul and Roberts, Michael and Schiano, Diane J. and Walendowski, Alan and Begole, Bo and Chi, Ed H. and Ducheneaut, Nicolas and Fang, Ji and Isaacs, Ellen and King, Tracy and Newman, Mark W. and Partridge, Kurt},
doi = {10.1145/1357054.1357237},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bellotti et al. - 2008 - Activity-based serendipitous recommendations with the Magitti mobile leisure guide.pdf:pdf},
isbn = {9781605580111},
journal = {Proceeding of the twenty-sixth annual CHI conference on Human factors in computing systems - CHI '08},
pages = {1157},
publisher = {ACM Press},
title = {{Activity-based serendipitous recommendations with the Magitti mobile leisure guide}},
url = {http://portal.acm.org/citation.cfm?doid=1357054.1357237},
year = {2008}
}
@article{Rollnick1995,
author = {Rollnick, Stephen},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Rollnick - 1995 - What is motivational interviewing.pdf:pdf},
journal = {Behavioural and cognitive},
number = {1},
pages = {325--334},
title = {{What is motivational interviewing?}},
url = {http://journals.cambridge.org/production/action/cjoGetFulltext?fulltextid=5091440},
year = {1995}
}
@article{Galescu2009,
author = {Galescu, Lucian and Allen, James and Ferguson, George and Quinn, Jill and Swift, Mary},
doi = {10.1109/BIBMW.2009.5332111},
file = {:C$\backslash$:/Users/ugan/Desktop/2012 Spring/e-health/7 mart sunumum/Galescu-et-al-SpeechRecog-Health-bibm-2009.pdf:pdf},
isbn = {978-1-4244-5121-0},
journal = {2009 IEEE International Conference on Bioinformatics and Biomedicine Workshop},
keywords = {- dialog systems,chronic heart failure,data acquisition,george ferguson,james allen,jill quinn,language processing,mary swift,natural,patient self-management,speech recognition},
month = nov,
pages = {302--307},
publisher = {Ieee},
title = {{Speech recognition in a dialog system for patient health monitoring}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5332111},
year = {2009}
}
@article{Bickmore2005,
author = {Bickmore, T.W.},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bickmore, Picard - 2005 - Establishing and maintaining long-term human-computer relationships.pdf:pdf},
journal = {ACM Transactions on Computer-Human},
number = {2},
pages = {293--327},
publisher = {ACM},
title = {{Establishing and maintaining long-term human-computer relationships}},
url = {http://dl.acm.org/citation.cfm?id=1067860.1067867},
volume = {12},
year = {2005}
}
@article{White2005,
author = {White, HR and Jackson, Kristina},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/White, Jackson - 2005 - Social and psychological influences on emerging adult drinking behavior.pdf:pdf},
journal = {Alcohol Research \& Health},
number = {Arnett},
pages = {182--190},
title = {{Social and psychological influences on emerging adult drinking behavior.}},
url = {http://psycnet.apa.org/psycinfo/2006-01535-002},
volume = {28(4)},
year = {2005}
}
@article{Nadeau2007,
author = {Nadeau, David and Sekine, Satoshi},
file = {:C$\backslash$:/Users/ugan/Downloads/li07.pdf:pdf},
journal = {Lingvisticae Investigationes},
number = {1991},
pages = {1--20},
title = {{A survey of named entity recognition and classification}},
url = {http://www.ingentaconnect.com/content/jbp/li/2007/00000030/00000001/art00002},
year = {2007}
}
@article{Ohtake2011,
address = {New York, NY},
author = {Ohtake, Kiyonori and Misu, Teruhisa and Hori, Chiori and Kashioka, Hideki and Nakamura, Satoshi},
doi = {10.1007/978-1-4419-7934-6},
editor = {Minker, Wolfgang and Lee, Gary Geunbae and Nakamura, Satoshi and Mariani, Joseph},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ohtake et al. - 2011 - Spoken Dialogue Systems Technology and Design.pdf:pdf},
isbn = {978-1-4419-7933-9},
pages = {231--254},
publisher = {Springer New York},
title = {{Spoken Dialogue Systems Technology and Design}},
url = {http://www.springerlink.com/index/10.1007/978-1-4419-7934-6},
year = {2011}
}
@article{Mohammad2009,
author = {Mohammad, Saif and Dunne, Cody and Dorr, Bonnie},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mohammad, Dunne, Dorr - 2009 - Generating high-coverage semantic orientation lexicons from overtly marked words and a thesaurus.pdf:pdf},
journal = {\ldots of the 2009 Conference on Empirical \ldots},
number = {August},
pages = {599--608},
title = {{Generating high-coverage semantic orientation lexicons from overtly marked words and a thesaurus}},
url = {http://dl.acm.org/citation.cfm?id=1699591},
year = {2009}
}
@article{Cunningham2009,
abstract = {Misuse of alcohol imposes a major public health cost, yet few problem drinkers are willing to access in-person services for alcohol abuse. The development of brief, easily accessible ways to help problem drinkers who are unwilling or unable to seek traditional treatment services could therefore have significant public health benefit. The objective of this project is to conduct a randomized controlled evaluation of the internet-based Check Your Drinking (CYD) screener ( http://www.CheckYourDrinking.net).},
author = {Cunningham, John a and Wild, T Cameron and Cordingley, Joanne and van Mierlo, Trevor and Humphreys, Keith},
doi = {10.1111/j.1360-0443.2009.02726.x},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cunningham et al. - 2009 - A randomized controlled trial of an internet-based intervention for alcohol abusers.pdf:pdf},
issn = {1360-0443},
journal = {Addiction (Abingdon, England)},
keywords = {Adolescent,Adult,Aged,Aged, 80 and over,Alcohol Drinking,Alcohol Drinking: epidemiology,Alcohol Drinking: therapy,Alcoholism,Alcoholism: epidemiology,Alcoholism: rehabilitation,Female,Follow-Up Studies,Humans,Internet,Male,Middle Aged,Ontario,Ontario: epidemiology,Patient Education as Topic,Patient Education as Topic: methods,Questionnaires,Questionnaires: standards,Treatment Outcome,Young Adult},
month = dec,
number = {12},
pages = {2023--32},
pmid = {19922569},
title = {{A randomized controlled trial of an internet-based intervention for alcohol abusers.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2779998\&tool=pmcentrez\&rendertype=abstract},
volume = {104},
year = {2009}
}
@article{Brug1996,
author = {Brug, J. and Steenhuis, I. and {Van Assema}, P. and {De Vries}, H. and Others},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Brug et al. - 1996 - The impact of a computer-tailored nutrition intervention.pdf:pdf},
journal = {Preventive Medicine},
number = {3},
pages = {236--242},
publisher = {San Diego [etc.] Academic Press.},
title = {{The impact of a computer-tailored nutrition intervention}},
url = {http://knowledgetranslation.ca/sysrev/articles/project21/Burg J Prev Med 1996 May Jun 25 3 236 42-20090818114620.pdf},
volume = {25},
year = {1996}
}
@article{Weizenbaum1966,
author = {J., Weizenbaum},
doi = {10.1145/365719.366410},
file = {:C$\backslash$:/Users/ugan/Desktop/2012 Spring/p36-weizenabaum.pdf:pdf},
issn = {00010782},
journal = {Communications of the ACM},
keywords = {2,3,4,5,a discussion of some,and,capability for eliza,context,editing,generation of responses in,of appropriate transformations,psychologi-,scripts,the absence of key,the choice,the discovery of minimal,the provision of an,words},
month = jul,
number = {7},
pages = {479--480},
title = {{Eliza - a computer program for the study of natural language communication between man and machine}},
url = {http://portal.acm.org/citation.cfm?doid=365719.366410},
volume = {9},
year = {1966}
}
@article{Buhler2011,
address = {New York, NY},
author = {B\"{u}hler, Dirk and Minker, Wolfgang},
doi = {10.1007/978-1-4419-9728-9},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/B\"{u}hler, Minker - 2011 - Domain-Level Reasoning for Spoken Dialogue Systems.pdf:pdf},
isbn = {978-1-4419-9727-2},
publisher = {Springer New York},
title = {{Domain-Level Reasoning for Spoken Dialogue Systems}},
url = {http://www.springerlink.com/index/10.1007/978-1-4419-9728-9},
year = {2011}
}
@article{Larsson2000,
author = {Larsson, Staffan and Traum, David R.},
doi = {10.1017/S1351324900002539},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Larsson, Traum - 2000 - Information state and dialogue management in the TRINDI dialogue move engine toolkit.pdf:pdf},
isbn = {1351324900002},
issn = {13513249},
journal = {Natural Language Engineering},
month = sep,
number = {3\&4},
pages = {323--340},
title = {{Information state and dialogue management in the TRINDI dialogue move engine toolkit}},
url = {http://www.journals.cambridge.org/abstract\_S1351324900002539},
volume = {6},
year = {2000}
}
@article{Mairesse2010c,
author = {Mairesse, Fran\c{c}ois and Walker, Marilyn a.},
doi = {10.1007/s11257-010-9076-2},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mairesse, Walker - 2010 - Towards personality-based user adaptation psychologically informed stylistic language generation.pdf:pdf},
issn = {0924-1868},
journal = {User Modeling and User-Adapted Interaction},
keywords = {big five traits,dialogue,individual differences,linguistic style,natural language generation,personality,recommendation},
month = jul,
number = {3},
pages = {227--278},
title = {{Towards personality-based user adaptation: psychologically informed stylistic language generation}},
url = {http://www.springerlink.com/index/10.1007/s11257-010-9076-2},
volume = {20},
year = {2010}
}
@article{Miller2003,
author = {Miller, WR and Moyers, TB and Ernst, Denise},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Miller, Moyers, Ernst - 2003 - Manual for the motivational interviewing skill code (MISC).pdf:pdf},
journal = {World Wide Web Published Online},
keywords = {MISC 2.0},
title = {{Manual for the motivational interviewing skill code (MISC)}},
url = {http://casaa.unm.edu/tandc.html},
year = {2003}
}
@article{Ohman1998,
author = {Ohman, Arne and Soares, Joaquim J F},
journal = {Journal of Experimental Psychology: General},
number = {1},
pages = {69--82},
title = {{Emotional Conditioning to Masked Stimuli: Expectancies for Aversive Outcomes Following Nonrecognized Fear-Relevant Stimuli}},
volume = {127},
year = {1998}
}
@inproceedings{Duffy1972,
author = {Duffy, E},
pages = {577--622},
publisher = {Holt, Rinehart and Winston},
title = {{Activation BT  - Handbook of Psychophysiology}},
year = {1972}
}
@article{ElKaliouby2006,
author = {{El Kaliouby}, R and Picard, R and Baron-Cohen, S},
journal = {Annals New York Academy of Sciences},
pages = {228},
title = {{Affective computing and autism}},
volume = {1093},
year = {2006}
}
@article{Bailenson2008,
author = {Bailenson, J N and Pontikakis, E D and Mauss, I B and Gross, J J and Jabon, M E and Hutcherson, C A C and Nass, C and John, O},
journal = {International Journal of Human-Computer Studies},
number = {5},
pages = {303--317},
title = {{Real-time classification of evoked emotions using facial feature tracking and physiological responses}},
volume = {66},
year = {2008}
}
@article{Esposito2009,
address = {http://dx.doi.org/10.1007/978-1-84800-306-4\_12},
author = {Esposito, Anna},
journal = {Affective Information Processing},
pages = {203--226},
title = {{Affect in Multimodal Information}},
year = {2009}
}
@article{Ekman1992,
author = {Ekman, P},
journal = {Cognition \& Emotion},
number = {3-4},
pages = {169--200},
title = {{An Argument for Basic Emotions}},
url = {<Go to ISI>://A1992JD26200002 },
volume = {6},
year = {1992}
}
@article{Rozin2003,
author = {Rozin, P and Cohen, A},
journal = {Emotion},
pages = {68--75},
title = {{High frequency of facial expressions corresponding to confusion, concentration, and worry in an analysis of maturally occurring facial expressions of Americans}},
volume = {3},
year = {2003}
}
@article{Hancock2007,
address = {San Jose, California, USA},
author = {Hancock, J and Landrigan, C and Silver, C},
publisher = {ACM},
series = {Proceedings of the SIGCHI conference on Human factors in computing systems},
title = {{Expressing emotion in text-based communication}},
year = {2007}
}
@misc{Mota2003,
author = {Mota, S and Picard, R},
number = {5},
pages = {49},
title = {{Automated Posture Analysis for Detecting Learner's Interest Level BT  - Computer Vision and Pattern Recognition Workshop, 2003. CVPRW '03. Conference on}},
year = {2003}
}
@misc{Conati2009,
address = {Trento, Italy},
author = {Conati, C and Maclaren, H},
publisher = {Springer},
title = {{Modeling User Affect from Causes and Effects BT  - Proceedings of UMAP 2009, First and Seventeenth International Conference on User Modeling, Adaptation and Personalization}},
year = {2009}
}
@article{Brooks1991,
author = {Brooks, R A},
journal = {Artificial Intelligence},
number = {1-3},
pages = {139--159},
title = {{Intelligence without representation}},
volume = {47},
year = {1991}
}
@misc{Ma2005,
address = {Kagawa, Japan},
author = {Ma, C and Osherenko, A and Prendinger, H and Ishizuka, M},
pages = {546--548},
publisher = {IEEE},
title = {{A chat system based on emotion estimation from text and embodied conversational messengers BT  - Active Media Technology, 2005.(AMT 2005). Proceedings of the 2005 International Conference on}},
year = {2005}
}
@inproceedings{Liu2003,
address = {Miami, Florida, USA},
author = {Liu, H and Lieberman, H and Selker, S},
pages = {1132--1225},
publisher = {ACM},
title = {{A model of textual affect sensing using real-world knowledge BT  - Proceedings of the 8th international conference on Intelligent user interfaces}},
year = {2003}
}
@techreport{Bradley2007,
author = {Bradley, Margaret M and Lang, Peter J},
publisher = {University of Florida, Gainesville, Fl.},
title = {{Affective norms for English Text (ANET): Affective ratings of text and instruction manual.}},
year = {2007}
}
@article{Nasoz2004,
author = {Nasoz, F and Alvarez, K and Lisetti, C L and Finkelstein, N},
journal = {Cognition, Technology \& Work},
number = {1},
pages = {4--14},
title = {{Emotion recognition from physiological signals using wireless sensors for presence technologies}},
volume = {6},
year = {2004}
}
@book{Turkle1984,
address = {New York},
author = {Turkle, S},
publisher = {Simon \& Schuster},
title = {{The second self: computers and the human spirit}},
year = {1984}
}
@incollection{Gill,
address = {Washington, DC},
author = {Gill, A and French, R and Gergle, D and Oberlander, J},
editor = {Love, B C and McRae, K and Sloutsky, V M},
pages = {2237--2242},
publisher = {Cognitive Science Society},
title = {{Identifying emotional characteristics from short blog texts}}
}
@article{Valitutti2005,
address = {http://dx.doi.org/10.1007/11573548$\backslash$\_61},
author = {Valitutti, Alessandro and Strapparava, Carlo and Stock, Oliviero},
journal = {Affective Computing and Intelligent Interaction},
pages = {474--481},
title = {{Lexical Resources and Semantic Similarity for Affective Evaluative Expressions Generation}},
url = {10.1007/11573548$\backslash$\_61},
year = {2005}
}
@article{Russell2003,
author = {Russell, J A},
file = {::},
journal = {Psychological Review},
number = {1},
pages = {145--172},
title = {{Core affect and the psychological construction of emotion}},
volume = {110},
year = {2003}
}
@article{Smith1985,
author = {Smith, C and Ellsworth, P},
journal = {Journal of Personality and Social Psychology},
number = {4},
pages = {813--838},
title = {{Patterns of Cognitive Appraisal in Emotion}},
volume = {48},
year = {1985}
}
@book{Weintraub1989,
address = {New York},
author = {Weintraub, W},
publisher = {Springer},
title = {{Verbal behavior in everyday life}},
year = {1989}
}
@book{Ledoux1998,
address = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0684836599},
author = {Ledoux, Joseph},
publisher = {Simon \& Schuster},
title = {{The Emotional Brain: The mysterious underpinnings of emotional life}},
year = {1998}
}
@book{Scherera,
author = {Scherer, K R and B\"{a}nziger, T and EB, Roesch},
publisher = {Oxford University Press},
title = {{Blueprint for Affective Computing: a Sourcebook. }}
}
@article{Craig2004,
author = {Craig, S and Graesser, A and Sullins, J and Gholson, J},
journal = {Journal of Educational Media},
pages = {241--250},
title = {{Affect and learning: An exploratory look into the role of affect in learning}},
volume = {29},
year = {2004}
}
@article{Lewis2005,
author = {Lewis, M D},
journal = {Behavioral and Brain Sciences},
number = {2},
pages = {169--+},
title = {{Bridging emotion theory and neurobiology through dynamic systems modeling}},
volume = {28},
year = {2005}
}
@article{Anders2004,
address = {http://dx.doi.org/10.1002/hbm.20048},
author = {Anders, Silke and Lotze, Martin and Erb, Michael and Grodd, Wolfgang and Birbaumer, Niels},
journal = {Hum Brain Mapp},
number = {4},
pages = {200--209},
title = {{Brain activity underlying emotional valence and arousal: a response-related fMRI study.}},
url = {10.1002/hbm.20048},
volume = {23},
year = {2004}
}
@inproceedings{Averill1980,
address = {New York},
author = {Averill, J R},
pages = {305--339},
publisher = {Academic Press},
title = {{A constructivist view of emotion. In Emotion: Theory, Reseach and Experience BT  - Emotion: Theory, Reseach and Experience}},
year = {1980}
}
@article{Pantic2003,
author = {Pantic, M and Rothkrantz, L J M},
file = {::},
journal = {Proceedings of the IEEE},
number = {9},
pages = {1370--1390},
title = {{Toward an affect-sensitive multimodal human-computer interaction}},
volume = {91},
year = {2003}
}
@misc{Schuller2006,
author = {Schuller, B and Stadermann, J and Rigoll, G},
title = {{Affect-Robust Speech Recognition by Dynamic Emotional Adaptation BT  - Proceedings of Speech Prosody}},
year = {2006}
}
@article{Devillers2005,
author = {Devillers, L and Vidrascu, L and Lamel, L},
journal = {Neural Networks},
number = {4},
pages = {407--422},
title = {{Challenges in real-life emotion annotation and machine learning based detection}},
volume = {18},
year = {2005}
}
@incollection{Forbes-Riley,
address = {Amsterdam},
author = {Forbes-Riley, K and Litman, D},
editor = {Dimitrova, V and Mizoguchi, R and {Du Boulay}, B},
file = {::},
pages = {33--40},
publisher = {IOS Press},
title = {{Adapting to student uncertainty improves tutoring dialogues}}
}
@phdthesis{ElKaliouby2005,
abstract = {People express their mental states all the time, even when interacting with machines. These mental states shape the decisions that we make, govern how we communicate with others, and affect our performance. The ability to attribute mental states to others from their behaviour, and to use that knowledge to guide one’s own actions and predict those of others is known as theory of mind or mind-reading. The principal contribution of this dissertation is the real time inference of a wide range of mental states from head and facial displays in a video stream. In particular, the focus is on the inference of complex mental states: the affective and cognitive states of mind that are not part of the set of basic emotions. The automated mental state inference system is inspired by and draws on the fundamental role of mind-reading in communication and decision-making. The dissertation describes the design, implementation and validation of a computational model of mind-reading. The design is based on the results of a number of experiments that I have undertaken to analyse the facial signals and dynamics of complex mental states. The resulting model is a multi-level probabilistic graphical model that repre- sents the facial events in a raw video stream at different levels of spatial and temporal abstraction. Dynamic Bayesian Networks model observable head and facial displays, and corresponding hidden mental states over time. The automated mind-reading system implements the model by combining top-down predictions of mental state models with bottom-up vision-based processing of the face. To support intelligent human-computer interaction, the system meets three important criteria. These are: full automation so that no manual preprocessing or segmentation is required, real time execution, and the categorization of mental states early enough after their onset to ensure that the resulting knowledge is current and useful. The system is evaluated in terms of recognition accuracy, generalization and real time performance for six broad classes of complex mental states—agreeing, concentrating, disagreeing, interested, thinking and unsure, on two different corpora. The system successfully classiﬁes and generalizes to new examples of these classes with an accuracy and speed that are comparable to that of human recognition. The research I present here signiﬁcantly advances the nascent ability of machines to infer cognitive-affective mental states in real time from nonverbal expressions of people. By developing a real time system for the inference of a wide range of mental states beyond the basic emotions, I have widened the scope of human-computer interaction scenarios in which this technology can be integrated. This is an important step towards building socially and emotionally intelligent machines.},
author = {{El Kaliouby}, R},
pages = {185},
school = {The University of Cambridge},
title = {{Mind-reading machines: automated inference of complex mental states}},
url = {http://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-636.html},
year = {2005}
}
@book{Panksepp1998,
address = {New York},
author = {Panksepp, J},
publisher = {Oxford University Press},
title = {{Affective neuroscience: The foundations of human and animal emotion}},
year = {1998}
}
@article{Russell1994,
author = {Russell, J},
file = {::},
journal = {Psychological Bulletin},
pages = {102--141},
title = {{Is there universal recognition of emotion from facial expression?: A review of the cross-cultural studies}},
volume = {115},
year = {1994}
}
@article{Ekman1990,
author = {Ekman, P and Friesen, W and Davidson, R},
file = {::},
journal = {Journal of Personality and Social Psychology},
number = {2},
pages = {342--353},
title = {{The Duchenne Smile - Emotional Expression and Brain Physiology .2}},
volume = {58},
year = {1990}
}
@article{Bashashati2007,
address = {http://dx.doi.org/10.1088/1741-2560/4/2/R03},
author = {Bashashati, Ali and Fatourechi, Mehrdad and Ward, Rabab K and Birch, Gary E},
journal = {Journal of Neural Engineering},
number = {2},
pages = {R32--R57},
title = {{A survey of signal processing algorithms in brain-computer interfaces based on electrical brain signals.}},
url = {10.1088/1741-2560/4/2/R03},
volume = {4},
year = {2007}
}
@misc{Hoque2009,
address = {Amsterdam},
author = {Hoque, M E and el Kaliouby, R and Picard, R W},
title = {{When Human Coders (and Machines) Disagree on the Meaning of Facial Affect in Spontaneous Videos BT  - 9th International Conference on Intelligent Virtual Agents}},
year = {2009}
}
@misc{D'Mello2009,
address = {Berlin/Heidelberg},
author = {D'Mello, S and Craig, S and Fike, K and Graesser, A},
pages = {595--604},
title = {{Responding to learners' cognitive-affective states with supportive and shakeup dialogues BT  - Human-Computer Interaction. Ambient, Ubiquitous and Intelligent Interaction}},
year = {2009}
}
@book{Gibson1978,
address = {Boston},
author = {Gibson, J J},
publisher = {Houghton Mifflin},
title = {{The Ecological Approach to Visual Perception}},
year = {1978}
}
@article{Kim2004,
address = {http://dx.doi.org/10.1007/BF02344719},
author = {Kim, K and Bang, S and Kim, S},
journal = {Medical and Biological Engineering and Computing},
number = {3},
pages = {419--427},
title = {{Emotion recognition system using short-term monitoring of physiological signals}},
url = {10.1007/BF02344719},
volume = {42},
year = {2004}
}
@misc{Bartlett2006,
author = {Bartlett, M S and Littlewort, G and Frank, M and Lainscsek, C and Fasel, I and Movellan, Javier},
pages = {223--230},
title = {{Fully automatic facial action recognition in spontaneous behaviour. BT  - Int. Conf. on Automatic Face and Gesture Recognition}},
year = {2006}
}
@article{D'Mello2006,
author = {D'Mello, S K and Craig, S D and Sullins, J and Graesser, A C},
journal = {International Journal of Artificial Intelligence in Education},
number = {1},
pages = {3--28},
title = {{Predicting Affective States expressed through an Emote-Aloud Procedure from AutoTutor's Mixed-Initiative Dialogue}},
volume = {16},
year = {2006}
}
@misc{Lehman2008,
author = {Lehman, B and Matthews, M and D'Mello, S and Person, N},
pages = {50--59},
title = {{What are you feeling? Investigating student affective states during expert human tutoring sessions BT  - Proceedings of the 9th International Conference on Intelligent Tutoring Systems}},
year = {2008}
}
@book{Norman2005,
abstract = {Did you ever wonder why cheap wine tastes better in fancy glasses? Why sales of Macintosh computers soared when Apple introduced the colorful iMac? New research on emotion and cognition has shown that attractive things really do work better, as Donald Norman amply demonstrates in this fascinating book, which has garnered acclaim everywhere from Scientific American to The New Yorker. Emotional Design articulates the profound influence of the feelings that objects evoke, from our willingness to spend thousands of dollars on Gucci bags and Rolex watches, to the impact of emotion on the everyday objects of tomorrow. Norman draws on a wealth of examples and the latest scientific insights to present a bold exploration of the objects in our everyday world. Emotional Design will appeal not only to designers and manufacturers but also to managers, psychologists, and general readers who love to think about their stuff.},
address = {New York},
author = {Norman, Donald A},
keywords = {emotion hci},
pages = {Basic Books},
publisher = {Basic Books},
title = {{Emotional Design: Why We Love (or Hate) Everyday Things}},
url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20$\backslash$\&amp path=ASIN/0465051367},
year = {2005}
}
@book{Ortony,
address = {Cambridge, UK.},
author = {Ortony, Andrew and Clore, Gerald and Collins, Allan},
keywords = {emotion},
publisher = {Cambridge University Press},
title = {{No Title}},
url = {citeulike-article-id:2330286 http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp path=ASIN/0521353645 }
}
@book{Tomkins1962,
address = {London},
author = {Tomkins, Silvan S},
publisher = {Tavistock},
title = {{Affect Imagery Consciousness: Volume I, The Positive Affects}},
year = {1962}
}
@article{Petrantonakis2010,
author = {Petrantonakis, Panagiotis C and Hadjileontiadis, Leontios J},
journal = {IEEE Transactions on Information Technology in Biomedicine},
number = {2},
pages = {186--194},
title = {{Emotion Recognition From EEG Using Higher Order Crossings}},
volume = {14},
year = {2010}
}
@misc{Danisman2008a,
address = {Aberdeen, UK},
author = {Danisman, Taner and Alpkocak, Adil},
publisher = {Society for the Study of Artificial Intelligence and the Simulation of Behaviour},
title = {{Feeler: Emotion Classification of Text Using Vector Space Model BT  - AISB 2008 Convention, Communication, Interaction and Social Intelligence}},
volume = {vol. 2},
year = {2008}
}
@article{Immordino-Yang2007,
address = {http://dx.doi.org/10.1111/j.1751-228X.2007.00004.x},
author = {Immordino-Yang, Mary H and Damasio, Antonio},
journal = {Mind, Brain, and Education},
number = {1},
pages = {3--10},
title = {{We Feel, Therefore We Learn: The Relevance of Affective and Social Neuroscience to Education}},
url = {10.1111/j.1751-228X.2007.00004.x},
volume = {1},
year = {2007}
}
@article{Barrett2007,
address = {Boston Coll, Dept Psychol, Chestnut Hill, MA 02467 USA. Harvard Univ, Massachusetts Gen Hosp, Sch Med, Psychiat Neuroimaging Res Program, Charlestown, MA 02129 USA. Wake Forest Univ, Dept Psychol, Winston Salem, NC 27109 USA. Columbia Univ, Dept Psychol, },
author = {Barrett, L and Mesquita, B and Ochsner, K and Gross, J},
journal = {Annual Review of Psychology},
keywords = {emotion affect consciousness MEDIAL PREFRONTAL COR},
pages = {373--403},
title = {{The experience of emotion}},
url = {<Go to ISI>://000243900200015 },
volume = {58},
year = {2007}
}
@article{Schachter1962,
author = {Schachter, S and Singer, J E},
journal = {Psychological Review},
number = {5},
pages = {379--399},
title = {{Cognitive, Social, and Physiological Determinants of Emotional State}},
volume = {69},
year = {1962}
}
@misc{Robison2009,
address = {Amsterdam},
author = {Robison, J and McQuiggan, S and Lester, J},
pages = {37--42},
title = {{Evaluating the Consequences of Affective Feedback in Intelligent Tutoring Systems BT  - Proceedings of the International Conference on Affective Computing \& Intelligent Interaction}},
year = {2009}
}
@article{Zeng2009,
author = {Zeng, Z and Pantic, M and Roisman, G I and Huang, T S},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
pages = {39--58},
title = {{A survey of affect recognition methods: Audio, visual, and spontaneous expressions}},
year = {2009}
}
@book{Osgood1990,
author = {Osgood, C E},
publisher = {Praeger Publishers},
title = {{Language, meaning, and culture: The selected papers of CE Osgood}},
year = {1990}
}
@article{Baker2010,
author = {Baker, R and D'Mello, S and Rodrigo, M and Graesser, A},
journal = {International Journal of human-computer studies},
pages = {223--241},
title = {{Better to be frustrated than bored: The incidence and persistence of affect during interactions with three different computer-based learning environments}},
volume = {68 (4)},
year = {2010}
}
@article{Pantic2006,
author = {Pantic, M and Patras, I},
journal = {Systems, Man, and Cybernetics, Part B: Cybernetics, IEEE Transactions on},
number = {2},
pages = {433--449},
title = {{Dynamics of facial expression: recognition of facial actions and their temporal segments from face profile image sequences}},
url = {10.1109/TSMCB.2005.859075},
volume = {36},
year = {2006}
}
@misc{Alm2005,
address = {Vancouver, Canada},
author = {Alm, C O and Roth, D and Sproat, R},
pages = {347--354},
publisher = {Association for Computational Linguistics (ACL)},
title = {{Emotions from text: Machine learning for text-based emotion prediction BT  - Proceedings of HLT/EMNLP}},
volume = {2005},
year = {2005}
}
@article{Gratch2005,
author = {Gratch, Jonathan and Marsella, Stacy},
journal = {Journal of Autonomous Agents and Multiagent Systems},
number = {1},
pages = {23--43},
title = {{Evaluating a computational model of emotion}},
volume = {11},
year = {2005}
}
@article{Conati2009a,
author = {Conati, Cristina and Maclaren, Heather},
file = {::},
journal = {User Modeling and User-adapted Interaction},
number = {3},
pages = {267--303},
title = {{Empirically building and evaluating a probabilistic model of user affect}},
url = {http://dx.doi.org/10.1007/s11257-009-9062-8},
volume = {19},
year = {2009}
}
@misc{Dweck2002,
address = {Orlando, FL},
author = {Dweck, C},
pages = {61--87},
title = {{Messages that motivate: How praise molds students' beliefs, motivation, and performance (in surprising ways). BT  - Improving academic achievement: Impact of psychological factors on education}},
year = {2002}
}
@misc{Brick2009,
author = {Brick, T and Hunter, M and Cohn, J},
title = {{Get The FACS Fast: Automated FACS face analysis benefits from the addition of velocity BT  - Proceedings of 2009 International Conference on Affective Computing \& Intelligent Interaction}},
year = {2009}
}
@article{Shields2005,
author = {Shields, C G and Epstein, R M and Franks, P and Fiscella, K and Duberstein, P and McDaniel, S H and Meldrum, S},
journal = {Patient Education and Counseling},
number = {2},
pages = {232--238},
title = {{Emotion language in primary care encounters: Reliability and validity of an emotion word count coding system}},
url = {<Go to ISI>://000229808900013 },
volume = {57},
year = {2005}
}
@article{Liu2008,
author = {Liu, C and Conn, K and Sarkar, N and Stone, W},
journal = {International Journal of Human-Computer Studies},
number = {9},
pages = {662--677},
title = {{Physiology-based affect recognition for computer-assisted intervention of children with Autism Spectrum Disorder}},
volume = {66},
year = {2008}
}
@article{Heraz2007,
author = {Heraz, A and Frasson, C},
journal = {Proceedings of the World Academy of Science, Engineering and Technology},
pages = {323--329},
title = {{Predicting the Three Major Dimensions of the Learner's Emotions from Brainwaves}},
volume = {25},
year = {2007}
}
@inproceedings{Calvo2009,
address = {Melbourne, Australia},
author = {Calvo, Rafael A and Brown, Iain and Scheding, Steve},
booktitle = {BT-AI 2009: Advances in Artificial Intelligence, Proceedings of 22nd Australasian Joint Conference on Artificial Intelligence},
publisher = {Springer-Verlag},
title = {{Effect of Experimental Factors on the Recognition of Affective Mental States Through Physiological Measures}},
year = {2009}
}
@misc{Liscombe2005,
author = {Liscombe, J and Riccardi, G and Hakkani-T\"{u}r, D},
title = {{Using Context to Improve Emotion Detection in Spoken Dialog Systems}},
year = {2005}
}
@misc{Strapparava2008,
address = {New York, NY, USA},
author = {Strapparava, C and Mihalcea, R},
pages = {1556--1560},
publisher = {ACM},
title = {{Learning to identify emotions in text BT  - Proceedings of the 2008 ACM symposium on Applied computing}},
year = {2008}
}
@misc{D'Mello2007,
author = {D'Mello, S and Taylor, R S and Graesser, A},
title = {{Monitoring affective trajectories during complex learning BT  - Proceedings of the 29th Annual Meeting of the Cognitive Science Society}},
year = {2007}
}
@article{Castellano2008a,
author = {Castellano, G and Mortillaro, M and Camurri, A and Volpe, G and Scherer, K},
journal = {Music Perception},
number = {2},
pages = {103--119},
title = {{Automated Analysis of Body Movement in Emotionally Expressive Piano Performances}},
url = {<Go to ISI>://000261102700001 },
volume = {26},
year = {2008}
}
@article{Chuang2004,
author = {Chuang, Z J and Wu, C H},
journal = {International Journal of Computational Linguistics and Chinese Language Processing},
number = {2},
pages = {1--18},
title = {{Multi-modal emotion recognition from speech and text}},
volume = {9},
year = {2004}
}
@misc{Haag2004,
author = {Haag, Andreas and Goronzy, Silke and Schaich, Peter and Williams, Jason},
pages = {36--48},
title = {{Emotion Recognition Using Bio-sensors: First Steps towards an Automatic System BT  - Affective Dialogue Systems}},
year = {2004}
}
@article{Scherer1993,
author = {Scherer, K R},
journal = {Cognition and Emotion},
pages = {325--355},
title = {{Studying the emotion-antecedent appraisal process: an expert system approach}},
volume = {7},
year = {1993}
}
@article{Fernandez2003,
address = {http://www.sciencedirect.com/science/article/B6V1C-46RV6ST-7/2/aacc687778f7007a7d7e46953657a505},
author = {Fernandez, Raul and Picard, Rosalind W},
journal = {Speech Communication},
number = {1-2},
pages = {145--159},
title = {{Modeling drivers' speech under stress}},
url = {DOI: 10.1016/S0167-6393(02)00080-8},
volume = {40},
year = {2003}
}
@book{Osgood,
address = {Urbana},
author = {Osgood, C E and May, W H and Miron, M S},
publisher = {University of Illinois Press},
title = {{No Title}}
}
@article{Yerkes1908,
author = {Yerkes, R and Dodson, J},
journal = {Journal of Comparative Neurology and Psychology},
pages = {459--482},
title = {{The relation of strength of stimulus to rapidity of habit-formation}},
volume = {18},
year = {1908}
}
@book{Ekman2003,
address = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/1883536367},
author = {Ekman, Paul and Friesen, Wallace V},
publisher = {Malor Books},
title = {{Unmasking the Face}},
year = {2003}
}
@article{Jaimes2007,
author = {Jaimes, A and Sebe, N},
journal = {Computer Vision and Image Understanding},
number = {1-2},
pages = {116--134},
title = {{Multimodal human-computer interaction: A survey}},
volume = {108},
year = {2007}
}
@article{Bianchi-Berthouze2002,
address = {Bianchi-Berthouze, N Univ Aizu, Comp Software Dept, Aizu Wakamatsu, Fukushima, Japan Univ Aizu, Comp Software Dept, Fukushima, Japan Univ Cent Florida, Sch Comp Sci, Orlando, FL 32816 USA},
author = {Bianchi-Berthouze, N and Lisetti, C},
journal = {User Modeling and User-Adapted Interaction},
keywords = {affect embodiment emotion interaction perception s},
number = {1},
pages = {49--84},
title = {{Modeling multimodal expression of user's affective subjective experience}},
url = {<Go to ISI>://000172862500002},
volume = {12},
year = {2002}
}
@article{Russell2003a,
author = {Russell, J A and Bachorowski, J A and Fernandez-Dols, J M},
journal = {Annual Review of Psychology},
pages = {329--349},
title = {{Facial and vocal expressions of emotion}},
url = {<Go to ISI>://000181435000014 },
volume = {54},
year = {2003}
}
@article{Ekman1969,
author = {Ekman, P and Friesen, W},
journal = {Psychiatry},
number = {1},
pages = {88},
title = {{Nonverbal Leakage and Clues to Deception}},
volume = {32},
year = {1969}
}
@article{Cohn2004a,
author = {Cohn, J and Schmidt, K},
journal = {International Journal of Wavelets, Multiresolution and Information Processing},
pages = {1--12},
title = {{The timing of facial motion in posed and spontaneous smiles}},
volume = {2},
year = {2004}
}
@article{Kahn2007,
author = {Kahn, J and Tobin, R and Massey, A and Anderson, J},
journal = {American Journal of Psychology},
number = {2},
pages = {263--286},
title = {{Measuring emotional expression with the linguistic inquiry and word count}},
url = {<Go to ISI>://000247508900005 },
volume = {120},
year = {2007}
}
@article{Graesser2007,
author = {Graesser, A and Chipman, P and King, B and McDaniel, B and D'Mello, S K},
journal = {Frontiers in Artificial Intelligence and Applications},
pages = {569},
title = {{Emotions and Learning with Auto Tutor}},
volume = {158},
year = {2007}
}
@misc{Panksepp2000,
address = {New York},
author = {Panksepp, J},
pages = {137--156},
title = {{Emotions as natural kinds within the mammalian brain BT  - Handbook of emotions}},
year = {2000}
}
@article{Demeijer1989,
author = {Demeijer, M},
journal = {Journal of Nonverbal Behavior},
number = {4},
pages = {247--268},
title = {{The Contribution of General Features of Body Movement to the Attribution of Emotions}},
volume = {13},
year = {1989}
}
@inproceedings{Schuller2005,
author = {Schuller, B and Villar, R J and Rigoll, G and Lang, M},
title = {{Meta-classifiers in acoustic and linguistic feature fusion-based affect recognition BT  - IEEE International Conference on Acoustics, Speech, and Signal Processing, 2005. Proceedings.(ICASSP'05)}},
volume = {1},
year = {2005}
}
@misc{Strapparava2004,
author = {Strapparava, C and Valitutti, A},
pages = {1083--1086},
title = {{WordNet-Affect: an affective extension of WordNet BT  - Proceedings of LREC}},
volume = {4},
year = {2004}
}
@article{Akkaya2009,
address = {Singapore},
author = {Akkaya, C and Wiebe, J and Mihalcea, R},
publisher = {Association for Computational Linguistics},
series = {Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1 - Volume 1},
title = {{Subjectivity word sense disambiguation}},
year = {2009}
}
@article{Wagner2005,
address = {http://dx.doi.org/http://doi.ieeecomputersociety.org/10.1109/ICME.2005.1521579},
author = {Wagner, J and Kim, Null J and Andre, E},
journal = {Multimedia and Expo, IEEE International Conference on},
pages = {940--943},
title = {{From Physiological Signals to Emotions: Implementing and Comparing Selected Methods for Feature Extraction and Classification}},
url = {http://doi.ieeecomputersociety.org/10.1109/ICME.2005.1521579},
year = {2005}
}
@article{Zajonc1984,
author = {Zajonc, R},
journal = {American Psychologist},
number = {2},
pages = {117--123},
title = {{On the primacy of affect}},
volume = {39},
year = {1984}
}
@misc{Zeng2006,
author = {Zeng, Z and Hu, Y and Roisman, G and Wen, Z and Fu, Y and Huang, T},
pages = {139--145},
title = {{Audio-visual emotion recognition in adult attachment interview BT  - International Conference on Multimodal Interfaces}},
year = {2006}
}
@misc{McDaniel2007,
author = {McDaniel, Bethany and D'Mello, Sidney and King, Brandon and Chipman, Patrick and Tapp, Kristy and Graesser, Art},
title = {{Facial Features for Affective State Detection in Learning Environments BT  - Proceedings of the 29th Annual Meeting of the Cognitive Science Society}},
year = {2007}
}
@article{Lund1996,
author = {Lund, K and Burgess, C},
journal = {Behavior Research Methods Instruments \& Computers},
pages = {203--208},
title = {{Producing high-dimensional semantic spaces from lexical co-occurrence}},
volume = {28},
year = {1996}
}
@inproceedings{Malmo1962,
address = {New York},
author = {Malmo, R B},
pages = {386--422},
publisher = {Basic Books},
title = {{Activation BT  - Experimental foundations of clinical psychology}},
year = {1962}
}
@book{Dalgleish1999,
address = {Sussex},
author = {Dalgleish, T and Power, M},
publisher = {John Wiley \& Sons Ltd.},
title = {{Handbook of cognition and emotion}},
year = {1999}
}
@misc{Arroyo2009,
address = {Brighton, UK},
author = {Arroyo, Ivon and Cooper, David G and Burleson, Winslow and Woolf, Beverly Park and Muldner, Kasia and Christopherson, Robert},
pages = {17--24},
publisher = {IOS Press},
title = {{Emotion Sensors go to School BT  - 14th Conference on Artificial Intelligence in Education}},
year = {2009}
}
@misc{Asthana2009,
author = {Asthana, A and Saragih, J and Wagner, M and Goecke, R},
title = {{Evaluating AAM Fitting Methods for Facial Expression Recognition BT  - Proceedings of 2009 International Conference on Affective Computing \& Intelligent Interaction}},
year = {2009}
}
@article{DMello2009,
author = {D’Mello, S and Graesser, A},
journal = {Applied Artificial Intelligence},
number = {2},
pages = {123--150},
title = {{Automatic Detection of Learner's Affect From Gross Body Language}},
volume = {23},
year = {2009}
}
@book{Izard1971,
address = {New York},
author = {Izard, C},
publisher = {Appleton-Century-Crofts},
title = {{The face of emotion}},
year = {1971}
}
@article{Lotte2007,
author = {Lotte, F and Congedo, M and L\'{e}cuyer, A and Lamarche, F and Arnaldi, B},
journal = {Journal of Neural Engineering},
title = {{A review of classification algorithms for EEG-based brain-computer interfaces}},
volume = {4},
year = {2007}
}
@article{Bestgen1994,
author = {Bestgen, Y},
journal = {Cognition \& Emotion},
number = {1},
pages = {21--36},
title = {{Can emotional valence in stories be determined from words}},
url = {<Go to ISI>://A1994MU77100002 },
volume = {8},
year = {1994}
}
@article{Cowie2001,
author = {Cowie, R and Douglas-Cowie, E and Tsapatsoulis, N and Votsis, G and Kollias, S and Fellenz, W and Taylor, J G},
journal = {IEEE Signal processing magazine},
number = {1},
pages = {32--80},
title = {{Emotion recognition in human-computer interaction}},
volume = {18},
year = {2001}
}
@article{Pang2008,
author = {Pang, B and Lee, L},
journal = {Foundations and Trends in Information Retrieval},
number = {1-2},
pages = {1--135},
title = {{Opinion mining and sentiment analysis}},
volume = {2},
year = {2008}
}
@misc{Villon2006,
address = {Hatfield, United Kingdom},
author = {Villon, Oliver and Lisetti, Christine},
pages = {269--276},
publisher = {IEEE},
title = {{A User-Modeling Approach to Build User's Psycho-Physiological Maps of Emotions using Bio-Sensors BT  - proceedings of IEEE RO-MAN 2006, The 15th IEEE International Symposium on Robot and Human Interactive Communication, Session Emotional Cues in Human-Rob}},
year = {2006}
}
@book{Landauer2007,
address = {Mahwah, NJ},
author = {Landauer, T and McNamara, D and Dennis, S and Kintsch, W},
publisher = {Erlbaum},
title = {{Handbook of Latent Semantic Analysis}},
year = {2007}
}
@article{Burleson2007,
address = {http://dx.doi.org/http://doi.ieeecomputersociety.org/10.1109/MIS.2007.69},
author = {Burleson, Winslow and Picard, Rosalind W},
journal = {IEEE Intelligent Systems},
number = {4},
pages = {62--69},
title = {{Gender-Specific Approaches to Developing Emotionally Intelligent Learning Companions}},
url = {http://doi.ieeecomputersociety.org/10.1109/MIS.2007.69},
volume = {22},
year = {2007}
}
@article{Miller1990,
author = {Miller, G and Beckwith, R and Fellbaum, C and Gross, D and Miller, K},
journal = {Journal of Lexicography},
pages = {235--244},
title = {{Introduction to wordnet: An on-line lexical database}},
volume = {3},
year = {1990}
}
@misc{Dragon2008,
author = {Dragon, Toby and Arroyo, Ivon and Woolf, Beverly and Burleson, Winslow and Kaliouby, Rana E and Eydgahi, Hoda},
pages = {29--39},
title = {{Viewing Student Affect and Learning through Classroom Observation and Physical Sensors BT  - Intelligent Tutoring Systems}},
year = {2008}
}
@inproceedings{Sebe2005,
author = {Sebe, N and Cohen, I and Huang, T S},
publisher = {World Scientific},
title = {{Multimodal Emotion Recognition BT  - Handbook of Pattern Recognition and Computer Vision}},
year = {2005}
}
@article{Izard1994,
author = {Izard, C},
journal = {Psychological Bulletin},
number = {2},
pages = {288--299},
title = {{Innate and universal facial expressions: Evidence from developmental and cross-cultural research}},
volume = {115},
year = {1994}
}
@misc{Tao2005,
address = {Heidelberg, Germany},
author = {Tao, J and Tan, T},
publisher = {Springer-Verlag},
title = {{Affective Computing: A Review}},
year = {2005}
}
@article{Breck2007,
address = {Hyderabad, India},
author = {Breck, E and Choi, Y and Cardie, C},
publisher = {Morgan Kaufmann Publishers Inc.},
series = {Proceedings of the 20th international joint conference on Artificial intelligence},
title = {{Identifying expressions of opinion in context}},
year = {2007}
}
@article{Shaikh2008,
author = {Shaikh, M and Prendinger, H and Ishizuka, M},
journal = {Applied Artificial Intelligence},
number = {6},
pages = {558--601},
title = {{Sentiment assessment of text by analyzing linguistic features and contextual valence assignment}},
url = {<Go to ISI>://000258005000004 },
volume = {22},
year = {2008}
}
@misc{Busso2004,
address = {Pennsylvania, USA},
author = {Busso, C and Deng, Z and Yildirim, S and Bulut, M and Lee, C M and et Al.},
publisher = {ACM},
title = {{Analysis of Emotion Recognition using Facial Expressions, Speech and Multimodal Information BT  - Int. Conf. Multimodal Interfaces}},
year = {2004}
}
@misc{Glenberg,
address = {Cambridge},
author = {Glenberg, A and Havas, D and Becker, R and Rinck, M},
title = {{Grounding Language in Bodily States: The Case for Emotion BT  - The Grounding Of Cognition: The Role Of Perception And Action In Memory, Language, And Thinking}}
}
@book{Gratch,
author = {Gratch, J and Marsella, S},
publisher = {Oxford University Press},
title = {{Social emotions in nature and artifact: emotions in human and human-computer interaction}}
}
@article{Donato1999,
author = {Donato, G and Bartlett, M S and Hager, J C and Ekman, P and Sejnowski, T J},
journal = {IEEE Pattern Analysis and Mach. Intelligence},
number = {October},
pages = {974--989},
title = {{Classifying facial actions}},
volume = {21},
year = {1999}
}
@misc{D'Mello2008,
author = {D'Mello, Sidney and Craig, Scotty D and Witherspoon, Amy and McDaniel, Bethany and Graesser, Arthur},
publisher = {Springer-Verlag},
title = {{Automatic Detection of Learner's Affect from Conversational Cues BT  - User Modeling and User-adapted Interaction}},
year = {2008}
}
@article{Ekman1983,
author = {Ekman, P and Levenson, R W and Friesen, W V},
journal = {Science},
number = {4616},
pages = {1208--1210},
title = {{Autonomic nervous system activity distinguishes among emotions}},
volume = {221},
year = {1983}
}
@misc{Vyzas1999,
address = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.51.206},
author = {Vyzas, E and Picard, R},
title = {{Offline and online recognition of emotion expression from physiological data}},
year = {1999}
}
@techreport{Bradley1999,
address = {The Center for Research in Psychophysiology},
author = {Bradley, M M and Lang, P J},
publisher = {University of Florida},
title = {{Affective norms for English words (ANEW): Instruction manual and affective ratings}},
year = {1999}
}
@article{Graesser2004,
author = {Graesser, A and Lu, S L and Jackson, G and Mitchell, H and Ventura, M and Olney, A and Louwerse, M},
file = {::},
journal = {Behavioral Research Methods, Instruments, and Computers},
pages = {180--193},
title = {{AutoTutor: A tutor with dialogue in natural language}},
volume = {36},
year = {2004}
}
@misc{ElKaliouby2004,
author = {{El Kaliouby}, R and Robinson, P},
file = {::},
title = {{Real-time inference of complex mental states from facial expressions and head gestures}},
year = {2004}
}
@misc{Devillers2006,
author = {Devillers, L and Vidrascu, L},
title = {{Real-life emotions detection with lexical and paralinguistic cues on human-human call center dialogs BT  - Ninth International Conference on Spoken Language Processing}},
year = {2006}
}
@article{Croyle1983,
author = {Croyle, R T and Cooper, J},
journal = {Journal of Personality and Social Psychology},
number = {4},
pages = {782},
title = {{Dissonance arousal: physiological evidence.}},
volume = {45},
year = {1983}
}
@article{Picard2001,
author = {Picard, R W and Vyzas, E and Healey, J},
journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
number = {10},
pages = {1175--1191},
title = {{Toward machine emotional intelligence: analysis of affective physiological state}},
volume = {23},
year = {2001}
}
@article{Ortony1990,
author = {Ortony, A and Turner, T},
journal = {Psychological Review},
number = {3},
pages = {315--331},
title = {{Whats Basic About Basic Emotions}},
url = {<Go to ISI>://A1990DN33800001 },
volume = {97},
year = {1990}
}
@misc{Chen1998,
author = {Chen, L and Huang, T and Miyasato, T and Nakatsu, R},
pages = {366--371},
title = {{Multimodal human emotion/expression recognition BT  - Third IEEE International Conference on Automatic Face and Gesture Recognition}},
year = {1998}
}
@misc{Johnstone2000,
address = {New York},
author = {Johnstone, T and Scherer, K},
pages = {220--235},
title = {{Vocal communication of emotion BT  - Handbook of Emotions}},
year = {2000}
}
@article{Dawson2007,
author = {Dawson, Michael E and Rissling, Anthony J and Schell, Anne M and Wilcox, Rand},
journal = {Emotion},
number = {4},
pages = {755--766},
title = {{Under What Conditions Can Human Affective Conditioning Occur Without Contingency Awareness?: Test of the Evaluative Conditioning Paradigm.}},
volume = {7},
year = {2007}
}
@article{Frijda1987,
author = {Frijda, N},
journal = {Cognition and Emotion},
pages = {115--143},
title = {{Emotion, cognitive structure, and action tendency.}},
volume = {1},
year = {1987}
}
@article{Gunes2007,
address = {http://www.sciencedirect.com/science/article/B6WKB-4MC14YD-2/2/383a7d6e8f109ed40a34d679cf07abde},
author = {Gunes, Hatice and Piccardi, Massimo},
journal = {Journal of Network and Computer Applications},
number = {4},
pages = {1334--1345},
title = {{Bi-modal emotion recognition from expressive face and body gestures}},
url = {DOI: 10.1016/j.jnca.2006.09.007},
volume = {30},
year = {2007}
}
@article{James1884,
author = {James, William},
journal = {Mind},
pages = {188--205},
title = {{What is an Emotion?}},
year = {1884}
}
@article{Kapoor2007,
author = {Kapoor, A and Burleson, B and Picard, R},
journal = {International Journal of human-computer studies},
number = {8},
pages = {724--736},
title = {{Automatic prediction of frustration}},
volume = {65},
year = {2007}
}
@misc{Yoshitomi2000,
author = {Yoshitomi, Y and Sung-Ill, K and Kawano, T and Kilazoe, T},
pages = {178--183},
title = {{Effect of sensor fusion for recognition of emotional states using voice, face image and thermal image of face}},
year = {2000}
}
@article{Kort2001,
address = {http://dx.doi.org/http://doi.ieeecomputersociety.org/10.1109/ICALT.2001.943850},
author = {Kort, Barry and Reilly, Rob and Picard, Rosalind W},
journal = {Advanced Learning Technologies, IEEE International Conference on},
pages = {43},
title = {{An Affective Model of Interplay between Emotions and Learning: Reengineering Educational Pedagogy-Building a Learning Companion}},
url = {http://doi.ieeecomputersociety.org/10.1109/ICALT.2001.943850},
volume = {0},
year = {2001}
}
@misc{ElKaliouby2005,
author = {{El Kaliouby}, R and Robinson, P},
title = {{Generalization of a vision-based computational model of mind-reading}},
year = {2005}
}
@article{Lutz1986,
author = {Lutz, C and White, G M},
journal = {Annual Review of anthropology},
number = {1},
pages = {405--436},
title = {{The anthropology of emotions}},
volume = {15},
year = {1986}
}
@misc{Castellano2008,
address = {Heidelberg},
author = {Castellano, G and Kessous, L and Caridakis, G},
pages = {92--103},
title = {{Emotion recognition through multiple modalities: face, body gesture, speech BT  - Affect and Emotion in Human-Computer Interaction (LNCS, vol. 4868)}},
year = {2008}
}
@article{Pennebaker2003,
address = {Univ Texas, Dept Psychol, Austin, TX 78712 USA. Pennebaker, JW, Univ Texas, Dept Psychol, Austin, TX 78712 USA.},
author = {Pennebaker, J and Mehl, M and Niederhoffer, K},
journal = {Annual Review of Psychology},
keywords = {LIWC text analysis artificial intelligence discour},
pages = {547--577},
title = {{Psychological aspects of natural language use: Our words, our selves}},
volume = {54},
year = {2003}
}
@book{Pinel2004,
author = {Pinel, J P},
publisher = {Allyn and Bacon},
title = {{Biopsychology}},
year = {2004}
}
@article{Stevenson2007,
author = {Stevenson, R A and Mikels, J A and James, T W},
journal = {Behavior Research Methods},
number = {4},
pages = {1020},
title = {{Characterization of the Affective Norms for English Words by discrete emotional categories}},
volume = {39},
year = {2007}
}
@book{Lewis2008,
address = {New York},
author = {Lewis, M and Haviland-Jones, J and Barrett, L},
publisher = {Guilford Press ET  - 3rd},
title = {{Handbook of emotions}},
year = {2008}
}
@article{Caridakis2006,
address = {Banff, Alberta, Canada },
author = {Caridakis, G and Malatesta, L and Kessous, L and Amir, N and Paouzaiou, A and Karpouzis, K},
series = {International Conference on Multimodal Interfaces},
title = {{Modeling Naturalistic Affective States via Facial and Vocal Expression Recognition}},
year = {2006}
}
@article{Montepare1999,
author = {Montepare, J and Koff, E and Zaitchik, D and Albert, M},
journal = {Journal of Nonverbal Behavior},
number = {2},
pages = {133--152},
title = {{The use of body movements and gestures as cues to emotions in younger and older adults}},
volume = {23},
year = {1999}
}
@article{Banse1996,
author = {Banse, R and Scherer, K R},
journal = {Journal of Personality and Social Psychology},
number = {3},
pages = {614--636},
title = {{Acoustic profiles in Vocal Emotion Expression}},
volume = {70},
year = {1996}
}
@misc{Vyzas1998,
address = {Orlando, Florida},
author = {Vyzas, Elias and Picard, Rosalind W},
pages = {176--182},
title = {{Affective Pattern Classification BT  - AAAI Fall Symposium Series: Emotional and Intelligent: The Tangled Knot of Cognition}},
year = {1998}
}
@misc{Ekman1978,
author = {Ekman, P and Friesen, W},
publisher = {Palo Alto: Consulting Psychologists Pr},
title = {{Facial action coding system: A technique for the measurement of facial movement: Investigator's guide 2 parts}},
year = {1978}
}
@misc{Maat2006,
author = {Maat, L and Pantic, M},
pages = {171--178},
title = {{GazeX: Adaptive affective multimodal interface for single-user office scenarios BT  - Proceedings ACM International Conference in Multimodal Interfaces}},
year = {2006}
}
@article{Sharma1998,
author = {Sharma, R and Pavlovic, V I and Huang, T S},
journal = {Proceedings of the IEEE},
number = {5},
pages = {853--869},
title = {{Toward multimodal human-computer interface}},
volume = {86},
year = {1998}
}
@article{Davidson1990,
author = {Davidson, R J and Ekman, P and Saron, C D and Senulis, J A and Friesen, W V},
journal = {Journal of Personality and Social Psychology},
number = {2},
pages = {330--341},
title = {{Approach-Withdrawal and Cerebral Asymmetry: Emotional Expression and Brain Physiology I}},
volume = {58},
year = {1990}
}
@article{Barrett2006,
author = {Barrett, L},
journal = {Perspectives on Psychological Science},
pages = {28--58},
title = {{Are Emotions Natural Kinds?}},
volume = {1},
year = {2006}
}
@article{Zajonc1980,
author = {Zajonc, R},
journal = {American Psychologist},
number = {2},
pages = {151--175},
title = {{Feeling and thinking: Preferences need no inferences,}},
volume = {33},
year = {1980}
}
@article{Conati2005,
author = {Conati, C and Maclaren, H},
journal = {Lecture Notes in Computer Science},
pages = {40},
title = {{Data-Driven Refinement of a Probabilistic Model of User Affect}},
volume = {3538},
year = {2005}
}
@book{Pennebaker,
address = {Mahwah NJ},
author = {Pennebaker, J and Francis, M and Booth, R},
publisher = {Erlbaum Publishers},
title = {{No Title}}
}
@incollection{Ekman,
address = {Hillsdale, NJ},
author = {Ekman, P},
editor = {Scherer, K and Ekman, P},
pages = {319--344},
publisher = {Erlbaum},
title = {{Expression and the nature of emotion}}
}
@misc{Ang2002,
address = {Denver, CO.},
author = {Ang, J and Dhillon, R and Krupski, A and Shriberg, E and Stolcke, A},
pages = {2037--2039},
title = {{Prosody-based automatic detection of annoyance and frustration in human-computer dialog BT  - International Conference on Spoken Language Processing}},
year = {2002}
}
@article{Lee2005,
author = {Lee, C M and Narayanan, S S},
journal = {IEEE Tran. Speech and Audio Processing},
number = {2},
pages = {293--303},
title = {{Toward detecting emotions in spoken dialogs}},
volume = {13},
year = {2005}
}
@article{Walk1988,
author = {Walk, R and Walters, K},
journal = {Bulletin of the Psychonomic Society},
number = {6},
pages = {510},
title = {{Perception of the Smile and Other Emotions of the Body and Face at Different Distances}},
volume = {26},
year = {1988}
}
@article{Cohn2004,
author = {Cohn, M A and Mehl, M R and Pennebaker, J W},
journal = {Psychological Science},
number = {10},
pages = {687--693},
title = {{Linguistic markers of psychological change surrounding September 11, 2001}},
url = {<Go to ISI>://000225021500008 },
volume = {15},
year = {2004}
}
@article{D'MelloN.andGraesserA.2009,
address = {Brighton. UK},
author = {{D'Mello  N. and Graesser, A.}, S and Dowell},
publisher = {IOS Press},
series = {Proceeding of the 2009 conference on Artificial Intelligence in Education: Building Learning Systems that Care: From Knowledge Representation to Affective Modelling},
title = {{Cohesion Relationships in Tutorial Dialogue as Predictors of Affective States}},
year = {2009}
}
@inproceedings{Juslin2005,
address = {Oxford, UK},
author = {Juslin, P N and Scherer, K R},
publisher = {Oxford University Press},
title = {{Vocal expression of affect BT  - The New Handbook of Methods in Nonverbal Behavior Research}},
year = {2005}
}
@article{Dasarathy1997,
author = {Dasarathy, B},
journal = {Proceedings IEEE},
pages = {24--38},
title = {{Sensor fusion potential exploitation: Innovative architectures and illustrative approaches}},
volume = {85},
year = {1997}
}
@misc{Lin2006,
address = {New York},
author = {Lin, W H and Wilson, T and Wiebe, J and Hauptmann, A},
publisher = {Association for Computational Linguistics},
title = {{Which side are you on? identifying perspectives at the document and sentence levels BT  - Proceedings of Tenth Conference on Natural Language Learning (CoNLL)}},
year = {2006}
}
@article{D'Mello2007a,
author = {D'Mello, S and Picard, R and Graesser, A},
journal = {Intelligent Systems, IEEE},
keywords = {intelligent tutoring systems natural language inte},
number = {4},
pages = {53--61},
title = {{Towards an affect-sensitive AutoTutor}},
volume = {22},
year = {2007}
}
@article{Calvo2007,
author = {Calvo, Manuel G and Nummenmaa, Lauri},
journal = {Journal of Experimental Psychology: General},
number = {3},
pages = {347--369},
title = {{Processing of Unattended Emotional Visual Scenes.}},
volume = {136},
year = {2007}
}
@incollection{Robison,
author = {Robison, J and McQuiggan, S and Lester, J},
pages = {37--42},
title = {{Evaluating the Consequences of Affective Feedback in Intelligent Tutoring Systems}}
}
@article{Aviezer2008,
author = {Aviezer, H and Hassin, R and Ryan, J and Grady, C and Susskind, J and Anderson, A and Moscovitch, M and Bentin, S},
journal = {Psychological Science},
number = {7},
pages = {724--732},
title = {{Angry, disgusted, or afraid? Studies on the malleability of emotion perception}},
volume = {19},
year = {2008}
}
@incollection{Salovey,
address = {New York},
author = {Salovey, Peter},
editor = {Davidson, Richard J and Scherer, Klaus R and Goldsmith, H Hill},
publisher = {Oxford University Press},
title = {{Introduction: Emotion and Social Processes}}
}
@article{Olofsson2008,
address = {http://dx.doi.org/10.1016/j.biopsycho.2007.11.006},
author = {Olofsson, Jonas K and Nordin, Steven and Sequeira, Henrique and Polich, John},
journal = {Biol Psychol},
number = {3},
pages = {247--265},
title = {{Affective picture processing: an integrative review of ERP findings.}},
url = {10.1016/j.biopsycho.2007.11.006},
volume = {77},
year = {2008}
}
@book{Parkinson1995,
address = {London},
author = {Parkinson, Brian},
publisher = {Routledge},
title = {{Ideas and realities of emotion}},
year = {1995}
}
@article{Baenziger2009,
author = {Baenziger, T and Grandjean, D and Scherer, K R},
journal = {Emotion},
number = {5},
pages = {691--704},
title = {{Emotion recognition from expressions in face, voice, and body. The Multimodal Emotion Recognition Test (MERT)}},
volume = {9},
year = {2009}
}
@article{Keltner2003,
author = {Keltner, D and Shiota, M},
journal = {Emotion},
pages = {86--91},
title = {{New displays and new emotions: a commentary on Rozin and Cohen (2003)}},
volume = {3},
year = {2003}
}
@article{Scherer2007,
author = {Scherer, K and Ellgring, H},
file = {::},
journal = {Emotion},
number = {1},
pages = {158--171},
title = {{Multimodal expression of emotion: Affect programs or componential appraisal patterns?}},
volume = {7},
year = {2007}
}
@article{Meyer2006,
author = {Meyer, D and Turner, J},
journal = {Educational Psychology Review},
number = {4},
pages = {377--390},
title = {{Re-conceptualizing emotion and motivation to learn in classroom contexts}},
volume = {18},
year = {2006}
}
@misc{Samsonovich2006,
author = {Samsonovich, A V and Ascoli, G A},
title = {{Cognitive map dimensions of the human value system extracted from natural language}},
year = {2006}
}
@book{Mehrabian1972,
address = {Chicago, Illinois},
author = {Mehrabian, A},
publisher = {Aldine-Atherton},
title = {{Nonverbal communication}},
year = {1972}
}
@misc{Linnenbrink2002,
address = {Dordretch, Netherlands},
author = {Linnenbrink, E and Pintrich, P},
pages = {115--135},
title = {{The Role Of Motivational Beliefs In Conceptual Change BT  - Reconsidering conceptual change: Issues in theory and practice}},
year = {2002}
}
@article{Coulson2004,
author = {Coulson, M},
journal = {Journal of Nonverbal Behavior},
number = {2},
pages = {117--139},
title = {{Attributing emotion to static body postures: Recognition accuracy, confusions, and viewpoint dependence}},
volume = {28},
year = {2004}
}
@book{Lazarus1991,
address = {New York},
author = {Lazarus, R},
publisher = {Oxford University Press},
title = {{Lazarus, R.}},
year = {1991}
}
@inproceedings{Roseman1984,
address = {Beverly Hills, CA},
author = {Roseman, I J},
pages = {11--36},
publisher = {Sage},
title = {{Cognitive determiniants of Emotion. In Emotions, Relationships and Health}},
volume = {5},
year = {1984}
}
@inproceedings{Litman2004,
address = {Barcelona, Spain},
author = {Litman, D and Forbes-Riley, K},
pages = {Association for Computational Linguistics--359},
title = {{Predicting student emotions in computer-human tutoring dialogues BT  - Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics}},
year = {2004}
}
@article{Parkinson2008,
author = {Parkinson, Brian},
journal = {Computers in Human Behavior},
pages = {510--1529},
title = {{Emotions in direct and remote social interaction: Getting through the spaces between us }},
volume = {24},
year = {2008}
}
@article{Dalgleish2009,
author = {Dalgleish, T and Dunn, B and Mobbs, D},
journal = {Emotion Review},
number = {4},
pages = {355--368},
title = {{Affective Neuroscience: Past, Present, and Future}},
volume = {1},
year = {2009}
}
@misc{Boehner2005,
address = {New York, NY, USA},
author = {Boehner, K and DePaula, R and Dourish, P and Sengers, P},
publisher = {ACM Press},
title = {{Affect: from information to interaction}},
year = {2005}
}
@misc{Afzal2009,
author = {Afzal, S and Robinson, P},
pages = {1--7},
title = {{Natural affect data: Collection \& annotation in a learning context BT  - Affective Computing and Intelligent Interaction and Workshops, 2009. ACII 2009. 3rd International Conference on}},
url = {10.1109/ACII.2009.5349537},
year = {2009}
}
@article{Conati2002,
address = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.16.944},
author = {Conati, C},
journal = {Journal of Applied Artificial Intelligence, special issue on "Merging Cognition and Affect in HCI"},
number = {7-8},
pages = {555--575},
title = {{Probabilistic Assessment of User's Emotions During the Interaction with Educational Games}},
volume = {16},
year = {2002}
}
@article{Russell1980,
author = {Russell, J},
journal = {Journal of Personality and Social Psychology},
pages = {1161--1178},
title = {{A circumplex model of affect}},
volume = {39},
year = {1980}
}
@misc{Kapoor2005,
address = {Singapore},
author = {Kapoor, A and Picard, R W},
file = {::},
publisher = {ACM},
title = {{Multimodal affect recognition in learning environments}},
year = {2005}
}
@article{Roseman1990,
author = {Roseman, I J and Spindel, M S and P.E., Jose},
journal = {Journal of Personality and Social Psychology},
pages = {899--915},
title = {{Appraisals of Emotion Eliciting Events: Testing a Theory of Discrete Emotions}},
volume = {59},
year = {1990}
}
@book{Scherer,
address = {New York},
author = {Scherer, K and Schorr, A and Johnstone, T},
publisher = {Oxford University Press},
series = {Series in Affective Science},
title = {{No Title}}
}
@inproceedings{Gordon1985,
address = {Baguio, Philippines},
annote = {Three ways to improve empathetic listening are to 
1.      Avoid judgment: the empathetic communicator must avoid making comparisons or passing moral judgments. 
2.      Give the speaker time to speak without interruption 
3.      Focus on the speaker: the empathetic communicator needs to focus his or her attention on the speaker, and not distract from this focus by verbally calling undue attention to oneself or one’s own situation [14]. },
author = {Gordon, Ronald D.},
booktitle = {International COnference of the World Communication Association},
pages = {1--16},
title = {{Empathy: The State of the Art and Science}},
year = {1985}
}
@article{Klein2002,
abstract = {Use of technology often has unpleasant side effects, which may include strong, negative emotional states that arise during interaction with computers. Frustration, confusion, anger, anxiety and similar emotional states can affect not only the interaction itself, but also productivity, learning, social relationships, and overall well-being. This paper suggests a new solution to this problem: designing human–computer interaction systems to actively support users in their ability to manage and recover from negative emotional states. An interactive affect–support agent was designed and built to test the proposed solution in a situation where users were feeling frustration. The agent, which used only text and buttons in a graphical user interface for its interaction, demonstrated components of active listening, empathy, and sympathy in an effort to support users in their ability to recover from frustration. The agent's effectiveness was evaluated against two control conditions, which were also text-based interactions: (1) users’ emotions were ignored, and (2) users were able to report problems and ‘vent’ their feelings and concerns to the computer. Behavioral results showed that users chose to continue to interact with the system that had caused their frustration significantly longer after interacting with the affect–support agent, in comparison with the two controls. These results support the prediction that the computer can undo some of the negative feelings it causes by helping a user manage his or her emotional state.},
author = {Klein, J and Moon, Y and {Rosalind W. Picard}},
doi = {http://dx.doi.org/10.1016/S0953-5438(01)00053-4},
file = {::},
journal = {Interacting with computers},
keywords = {affect,affective computing,empathetic interface,frustration,human-centred design,social interface,user emotion},
number = {2},
pages = {119--140},
publisher = {Elsevier Science Ltd},
title = {{This computer responds to user frustration: Theory, design, and results}},
url = {http://www.sciencedirect.com/science/article/pii/S0953543801000534},
volume = {14},
year = {2002}
}
@article{Ondersma2007,
abstract = {Drug use among parenting women is a significant risk factor for a range of negative child outcomes, including exposure to violence, child maltreatment, and child behavior problems. Implementation of brief interventions with this population may be greatly facilitated by computer-based interventions.},
author = {Ondersma, Steven J and Svikis, Dace S and Schuster, Charles R},
doi = {10.1016/j.amepre.2006.11.003},
issn = {0749-3797},
journal = {American journal of preventive medicine},
keywords = {Adult,African Americans,African Americans: psychology,Computers,Female,Health Promotion,Health Promotion: methods,Humans,Marijuana Abuse,Marijuana Abuse: ethnology,Marijuana Abuse: prevention \& control,Mothers,Mothers: psychology,Motivation,Postpartum Period,Prospective Studies,Risk Factors,Self Disclosure,Self Efficacy,Street Drugs,Substance-Related Disorders,Substance-Related Disorders: ethnology,Substance-Related Disorders: prevention \& control,United States},
month = mar,
number = {3},
pages = {231--8},
pmid = {17236741},
title = {{Computer-based brief intervention a randomized trial with postpartum women.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1858656\&tool=pmcentrez\&rendertype=abstract},
volume = {32},
year = {2007}
}
@inproceedings{Liu2003,
abstract = {This paper presents a novel way for assessing the affective quali- ties of natural language and a scenario for its use. Previous ap- proaches to textual affect sensing have employed keyword spot- ting, lexical affinity, statistical methods, and hand-crafted models. This paper demonstrates a new approach, using large-scale real- world knowledge about the inherent affective nature of everyday situations (such as “getting into a car accident”) to classify sen- tences into “basic” emotion categories. This commonsense ap- proach has new robustness implications. Open Mind Commonsense was used as a real world corpus of 400,000 facts about the everyday world. Four linguistic models are combined for robustness as a society of commonsense-based affect recognition. These models cooperate and compete to clas- sify the affect of text. Such a system that analyzes affective qualities sentence by sen- tence is of practical value when people want to evaluate the text they are writing. As such, the system is tested in an email writing application. The results suggest that the approach is robust enough to enable plausible affective text user interfaces.},
address = {New York, New York, USA},
author = {Liu, Hugo and Lieberman, Henry and Selker, Ted},
booktitle = {Proceedings of the 8th international conference on Intelligent user interfaces - IUI '03},
doi = {10.1145/604050.604067},
file = {::},
isbn = {1581135866},
keywords = {Affective computing,Open Mind Commonsense,affective UI,commonsense reasoning,emotions,story understanding},
pages = {125},
publisher = {ACM Press},
title = {{A model of textual affect sensing using real-world knowledge}},
url = {http://portal.acm.org/citation.cfm?doid=604045.604067},
year = {2003}
}
@article{Suchman1997,
abstract = {To formulate an empirically derived model of empathic communication in medical interviews by describing the specific behaviors and patterns of interaction associated with verbal expressions of emotion.},
author = {Suchman, a L and Markakis, K and Beckman, H B and Frankel, R},
file = {::},
issn = {0098-7484},
journal = {JAMA : the journal of the American Medical Association},
keywords = {Communication,Empathy,Humans,Interviews as Topic,Models,Physician-Patient Relations,Psychological},
month = feb,
number = {8},
pages = {678--82},
pmid = {9039890},
title = {{A model of empathic communication in the medical interview.}},
volume = {277},
year = {1997}
}
@article{Shamay-Tsoory2011,
abstract = {Human empathy relies on the ability to share emotions as well as the ability to understand the other's thoughts, desires, and feelings. Recent evidence points to 2 separate systems for empathy: an emotional system that supports our ability to empathize emotionally and a cognitive system that involves cognitive understanding of the other's perspective. A neural network that includes the inferior frontal gyrus and the inferior parietal lobule is necessary for emotion recognition and emotional contagion. Although the emotional and cognitive systems appear to work independently, every empathic response may still evoke both components to some extent, depending on the social context.},
annote = {Difference between cognitive empathy and emotional empathy is explained in this paper. Also they talk about the active brain parts in each empathy type.},
author = {Shamay-Tsoory, Simone G},
doi = {10.1177/1073858410379268},
file = {::},
issn = {1089-4098},
journal = {The Neuroscientist : a review journal bringing neurobiology, neurology and psychiatry},
keywords = {Brain,Brain: physiology,Empathy,Empathy: physiology,Humans,Neural Pathways,Neural Pathways: physiology},
month = feb,
number = {1},
pages = {18--24},
pmid = {21071616},
title = {{The neural bases for empathy.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21071616},
volume = {17},
year = {2011}
}
@article{Jaques2007,
abstract = {In this article we describe the use of mental states approach, more specifically the belief-desire-intention (BDI) model, to implement the process of affective diagnosis in an educational environment. We use the psychological OCC model, which is based on the cognitive theory of emotions and is possible to be imple- mented computationally, in order to infer the learners emotions from his actions in the system interface. In our work we profit from the reasoning capacity of the BDI model in order to infer the students appraisal (a cognitive evaluation of a person that elicits an emotion), which allows us to deduce students emotions. The system reasons about an emotion-generating situation and tries to infer the users emotion by using the OCC model. Besides, the BDI model is very adequate to infer and also model students affective states since the emotions have a dynamic nature.},
author = {Jaques, Patricia Augustin and Vicari, Rosa Maria},
doi = {10.1016/j.compedu.2005.09.002},
file = {::},
issn = {03601315},
journal = {Computers \& Education},
keywords = {architectures for educational technology,computer,distance education and telelearning,human,intelligent tutoring systems,interactive learning environments,interface,media in education,system},
month = sep,
number = {2},
pages = {360--384},
title = {{A BDI approach to infer student’s emotions in an intelligent learning environment}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0360131505001302},
volume = {49},
year = {2007}
}
@misc{TheMendeleySupportTeam2011,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/The Mendeley Support Team - 2011 - Getting Started with Mendeley(4).pdf:pdf},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@article{Cooper2000,
author = {Cooper, Bridget and Brna, Paul and Martins, Alex},
file = {::},
journal = {Affective interactions},
pages = {21--34},
publisher = {Springer},
title = {{Effective affective in intelligent systems–building on evidence of empathy in teaching and learning}},
url = {http://www.springerlink.com/index/j8v0l230t3503367.pdf},
year = {2000}
}
@article{Roesch2010,
abstract = {To investigate the perception of emotional facial expressions, researchers rely on shared sets of photos or videos, most often generated by actor portrayals. The drawback of such standardized material is a lack of flexibility and controllability, as it does not allow the systematic parametric manipulation of specific features of facial expressions on the one hand, and of more general properties of the facial identity (age, ethnicity, gender) on the other. To remedy this problem, we developed FACSGen: a novel tool that allows the creation of realistic synthetic 3D facial stimuli, both static and dynamic, based on the Facial Action Coding System. FACSGen provides researchers with total control over facial action units, and corresponding informational cues in 3D synthetic faces. We present four studies validating both the software and the general methodology of systematically generating controlled facial expression patterns for stimulus presentation.},
author = {Roesch, Etienne B. and Tamarit, Lucas and Reveret, Lionel and Grandjean, Didier and Sander, David and Scherer, Klaus R.},
doi = {10.1007/s10919-010-0095-9},
file = {::},
issn = {0191-5886},
journal = {Journal of Nonverbal Behavior},
keywords = {Emotion,FACS,Facial action coding system,Facial expression,Research material,Software},
month = nov,
number = {1},
pages = {1--16},
title = {{FACSGen: A Tool to Synthesize Emotional Facial Expressions Through Systematic Manipulation of Facial Action Units}},
url = {http://www.springerlink.com/index/10.1007/s10919-010-0095-9},
volume = {35},
year = {2010}
}
@article{Fagerstrom1990,
author = {Fagerstrom, K O and Heatherton, T F and Kozlowski, L T},
institution = {Department of Psychology, Harvard University.},
journal = {Ear nose throat journal},
keywords = {*adverse effects,*diagnosis,*nicotine,*standards,alcoholism,complications,etiology,human,ph,prevention \& control,psyc,questionnaires,smoking,substance related disorders},
number = {11},
pages = {763--765},
pmid = {2276350},
title = {{Nicotine addiction and its assessment.}},
volume = {69},
year = {1990}
}
@inproceedings{Nguyen2009c,
author = {Nguyen, H. and Masthoff, Judith},
booktitle = {Proceedings of the 4th International Conference on Persuasive Technology},
file = {::},
isbn = {9781605583761},
keywords = {affective computing,design,experimentation,human factors},
pages = {7},
publisher = {ACM},
title = {{Designing empathic computers: the effect of multimodal empathic feedback using animated agent}},
url = {http://dl.acm.org/citation.cfm?id=1541958},
year = {2009}
}
@article{Hess1998,
author = {Hess, Ursula and Philippot, Pierre and Blairy, Sylvie},
doi = {10.1080/026999398379547},
file = {::},
issn = {0269-9931},
journal = {Cognition \& Emotion},
month = jul,
number = {4},
pages = {509--531},
title = {{Facial Reactions to Emotional Facial Expressions: Affect or Cognition?}},
url = {http://www.tandfonline.com/doi/abs/10.1080/026999398379547},
volume = {12},
year = {1998}
}
@inproceedings{Kang2008a,
author = {Kang, Sin-hwa and Gratch, Jonathan and Wang, Ning and Watt, J.},
booktitle = {Intelligent Virtual Agents},
file = {::},
keywords = {evaluation,nonverbal feedback,personality,rapport,virtual agents},
pages = {253--261},
publisher = {Springer},
title = {{Agreeable people like agreeable virtual humans}},
url = {http://www.springerlink.com/index/DT61V8556710VW13.pdf},
year = {2008}
}
@article{Heimgartner2011,
author = {Heimg\"{a}rtner, R\"{u}diger and Tiede, L.W. and Windl, Helmut},
file = {::},
journal = {Design, User Experience, and Usability. Theory, Methods, Tools and Practice},
keywords = {1 problems in hci,communication,cultural differences,culture,design caused by cultural,designing the functionality and,differences,empathy,intercultural communication,intercultural hci design,much cultural background has,to be considered when,understanding},
pages = {557--566},
publisher = {Springer},
title = {{Empathy as Key Factor for Successful Intercultural HCI Design}},
url = {http://www.springerlink.com/index/FG03081276H7K042.pdf},
year = {2011}
}
@book{Fussell2002,
author = {Fussell, Susan R.},
editor = {Fussell, Susan R.},
file = {::},
isbn = {9780805836905},
pages = {294},
publisher = {Lawrence Erlbaum Associates},
title = {{The verbal communication of emotions: Interdisciplinary perspectives}},
url = {http://books.google.com/books?id=MHea6DYYfEgC},
year = {2002}
}
@article{Peter2003,
author = {Sonnby-borgstr\"{o}m, Marianne and Jonsson, Peter and Svensson, Owe},
file = {::},
journal = {Journal of Nonverbal},
keywords = {emg,emotional contagion,empathy,facial expressions,facial mim-,icry,mirror neurons},
number = {1},
pages = {3--23},
title = {{Emotional empathy as related to mimicry reactions at different levels of information processing}},
url = {http://www.springerlink.com/index/P81X69QTH751V836.pdf},
volume = {27},
year = {2003}
}
@article{Bickmore2005,
abstract = {This research investigates the meaning of “human-computer relationship” and presents techniques for constructing, maintaining, and evaluating such relationships, based on research in social psychology, sociolinguistics, communication and other social sciences. Contexts in which relationships are particularly important are described, together with specific benefits (like trust) and task outcomes (like improved learning) known to be associated with relationship quality. We especially consider the problem of designing for long-term interaction, and define relational agents as computational artifacts designed to establish and maintain long-term social-emotional relationships with their users. We construct the first such agent, and evaluate it in a controlled experiment with 101 users who were asked to interact daily with an exercise adoption system for a month. Compared to an equivalent task-oriented agent without any deliberate social-emotional or relationship-building skills, the relational agent was respected more, liked more, and trusted more, even after four weeks of interaction. Additionally, users expressed a significantly greater desire to continue working with the relational agent after the termination of the study. We conclude by discussing future directions for this research together with ethical and other ramifications of this work for HCI designers.},
author = {Bickmore, Timothy W. and {Rosalind W. Picard}},
doi = {10.1145/1067860.1067867},
file = {::},
journal = {ACM Transactions on Computer-Human Interaction (TOCHI)},
keywords = {Human-computer interaction,embodied conversational agent,relational agent,social interface},
number = {2},
pages = {617--638},
title = {{Establishing and maintaining long-term human-computer relationships}},
url = {http://dl.acm.org/citation.cfm?id=1067860.1067867},
volume = {12},
year = {2005}
}
@inproceedings{Nor2010,
author = {Nor, R.M. and Muhlberger, Ralf},
booktitle = {User Science and Engineering (i-USEr), 2010 International Conference on},
file = {::},
isbn = {9781424490493},
keywords = {-component,community,empathy,emphatic communication,user experience},
pages = {7--10},
publisher = {IEEE},
title = {{Designing to support empathy: Understanding user experience by using a model of interaction in meeting human needs}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5716713},
year = {2010}
}
@misc{Mota2003,
abstract = {This paper presents a system for recognizing naturally occurring postures and associated affective states related to a child's interest level while performing a learning task on a computer. Postures are gathered using two matrices of pressure sensors mounted on the seat and back of a chair. Subsequently, posture features are extracted using a mixture of four gaussians, and input to a 3-layer feed-forward neural network. The neural network classifies nine postures in real time and achieves an overall accuracy of 87.6\&amp;x025; when tested with postures coming from new subjects. A set of independent Hidden Markov Models (HMMs) is used to analyze temporal patterns among these posture sequences in order to determine three categories related to a child's level of interest, as rated by human observers. The system reaches an overall performance of 82.3\&amp;x025; with posture sequences coming from known subjects and 76.5\&amp;x025; with unknown subjects.},
author = {Mota, Selene and Picard, Rosalind W},
booktitle = {2003 Conference on Computer Vision and Pattern Recognition Workshop},
doi = {10.1109/CVPRW.2003.10047},
institution = {IEEE},
isbn = {0769519008},
issn = {10636919},
pages = {49--49},
publisher = {Ieee},
title = {{Automated Posture Analysis for Detecting Learner's Interest Level}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4624309},
volume = {5},
year = {2003}
}
@inproceedings{Mateas2003,
abstract = {In this paper we discuss our research and development towards creating an architecture, and a story design using this architecture, that integrates a broad and shallow approach to natural language processing, a novel character authoring language and a novel drama manager, in order to build an interactive drama about human relationships.},
address = {San Jose, CA, UA},
author = {Mateas, Michael and Stern, Andrew},
booktitle = {Game Developers Conference Game Design track},
file = {::},
publisher = {Citeseer},
title = {{Fa\c{c}ade: An experiment in building a fully-realized interactive drama}},
url = {http://www.mendeley.com/research/faade-an-experiment-in-building-a-fullyrealized-interactive-drama/},
volume = {2},
year = {2003}
}
@incollection{Chung2007,
abstract = {The present paper focuses on the influence of avatar creation in a video game. More specifically, this study investigates the effects of avatar creation on attitude towards avatar, empathy, presence, and para-social interaction of female non-game users. As a cyber-self, an avatar is a graphic character representing a user in cyberspace. Avatars are primarily used in the entertainment industry as high-tech novelties, controlled by game users, for high-end video games. Some games provide game characters by default that users cannot change, but other games provide various options gamers can choose. What if game users can create their own avatars? Do they have more psychological closeness with their avatars as their cyber-selves? This study tested the differences of attitude, empathy, presence, and para-social interaction of female non-game users between an avatar creation group and a non-avatar creation group and resulted in no difference.},
author = {Chung, Donghun and DeBuys, Brahm and Nam, Chang},
booktitle = {Human-Computer Interaction. Interaction Design and Usability},
doi = {10.1007/978-3-540-73105-4\_78},
file = {::},
isbn = {978-3-540-73104-7},
keywords = {Avatar - Attitude - Empathy - Presence - Para-Soci},
pages = {711--720},
publisher = {Springer Berlin / Heidelberg},
title = {{Influence of avatar creation on attitude, empathy, presence, and para-social interaction}},
url = {http://www.springerlink.com/index/9518116J51670433.pdf},
year = {2007}
}
@article{Kang2011,
author = {Kang, Sin-hwa and Sidner, Candy and Gratch, Jonathan and Artstein, Ron and Huang, Lixing and Morency, Louis-philippe},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kang et al. - Unknown - Modeling Nonverbal Behavior of a Virtual Counselor during Intimate Self-Disclosure.pdf:pdf},
journal = {New York},
number = {0},
pages = {2--3},
title = {{Modeling Nonverbal Behavior of a Virtual Counselor during Intimate Self-Disclosure}},
year = {2011}
}
@article{Liu2010,
abstract = {Emotions accompany everyone in the daily life, playing a key role in non-verbal communication, and they are essential to the understanding of human behavior. Emotion recognition could be done from the text, speech, facial expression or gesture. In this paper, we concentrate on recognition of “inner” emotions from electroencephalogram (EEG) signals as humans could control their facial expressions or vocal intonation. The need and importance of the automatic emotion recognition from EEG signals has grown with increasing role of brain computer interface applications and development of new forms of human-centric and humandriven interaction with digital media. We propose fractal dimension based algorithm of quantification of basic emotions and describe its implementation as a feedback in 3D virtual environments. The user emotions are recognized and visualized in real time on his/her avatar adding one more so-called “emotion dimension” to human computer interfaces.},
author = {Liu, Yisi and Sourina, Olga and Nguyen, Minh Khoa},
doi = {10.1109/CW.2010.37},
file = {::},
isbn = {978-1-4244-8301-3},
journal = {2010 International Conference on Cyberworlds},
keywords = {BCI,EEG,HCI,emotion recognition,emotion visualization,fractal dimension},
month = oct,
pages = {262--269},
publisher = {Ieee},
title = {{Real-Time EEG-Based Human Emotion Recognition and Visualization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5656346},
year = {2010}
}
@article{Oatley1987,
abstract = {A theory is proposed that emotions are cognitively based states which co-ordinate quasi-autonomous processes in the nervous system. Emotions provide a biological solution to certain problems of transition between plans, in systems with multiple goals. Their function is to accomplish and maintain these transitions, and to communicate them to ourselves and others. Transitions occur at significant junctures of plans when the evaluation of success in a plan changes. Complex emotions are derived from a small number of basic emotions and arise at junctures of social plans.},
author = {Oatley, Keith and Johnson-laird, P N},
doi = {10.1080/02699938708408362},
isbn = {0269993114640600},
issn = {02699931},
journal = {Cognition \& Emotion},
number = {1},
pages = {29--50},
publisher = {Psychology Press},
title = {{Towards a Cognitive Theory of Emotions}},
url = {http://www.tandfonline.com/doi/abs/10.1080/02699938708408362?journalCode=pcem20},
volume = {1},
year = {1987}
}
@article{Orozco2010,
author = {Orozco, H. and Thalmann, Daniel and Ramos, F.},
file = {::},
journal = {Proceedings of 11th Computer Graphics International, CGI},
title = {{Making empathetic virtual humans in human–computer interaction scenarios}},
url = {http://cgi2010.miralab.unige.ch/short/SP09/SP09.pdf},
volume = {10},
year = {2010}
}
@article{Greenson1960,
author = {Greenson, Ralph R},
journal = {International Journal of PsychoAnalysis},
pages = {418--424},
title = {{Empathy and its vicissitudes}},
volume = {41},
year = {1960}
}
@article{D&39;Mello2006,
author = {Mello, Sidney D' and Graesser, Art},
file = {::},
journal = {Intelligent Virtual Agents},
pages = {54--67},
title = {{Affect detection from human-computer dialogue with an intelligent tutoring system}},
url = {http://www.springerlink.com/index/b574kpu6nl719408.pdf},
year = {2006}
}
@techreport{Miller1981,
abstract = {Thirty-one self-referred problem drinkers were randomly assigned to one of two modalities for behavioral self-control training with a goal of moderation: (1) minimal therapist contact, in which clients worked only with a self-help manual; and (2) therapist directed training, in which clients received self-help materials plus 10 individual treatment sessions. Both groups showed significant reductions in alcohol consumption and peak blood alcohol concentration. Contrary to expectations, there were no significant differences on outcome measures between groups. Results are interpreted within a self-control framework.},
author = {Miller, William R. and Gribskov, C J and Mortell, R L},
booktitle = {The International journal of the addictions},
number = {7},
pages = {1247--1254},
pmid = {7327785},
publisher = {Informa UK Ltd UK},
title = {{Effectiveness of a self-control manual for problem drinkers with and without therapist contact.}},
url = {http://informahealthcare.com/doi/abs/10.3109/10826088109039178},
volume = {16},
year = {1981}
}
@inproceedings{Gonsior2011,
abstract = {In this paper, the impact of facial expressions on HRI is explored. To determine their influence on empathy of a human towards a robot and perceived subjective performance, an experimental setup is created, in which participants engage in a dialog with the robot head EDDIE. The web-based gaming application “Akinator” serves as a backbone for the dialog structure. In this game, the robot tries to guess a thought-of person chosen by the human by asking various questions about the person. In our experimental evaluation, the robot reacts in various ways to the human's facial expressions, either ignoring them, mirroring them, or displaying its own facial expression based on a psychological model for social awareness. In which way this robot behavior influences human perception of the interaction is investigated by a questionnaire. Our results support the hypothesis that the robot behavior during interaction heavily influences the extent of empathy by a human towards a robot and perceived subjective task-performance, with the adaptive modes clearly leading compared to the non-adaptive mode.},
address = {Atlanta, GA, USA},
author = {Gonsior, Barbara and Sosnowski, Stefan and Mayer, Christoph and Blume, Jiirgen and Radig, B. and Wollherr, D. and Kuhnlenz, K.},
booktitle = {RO-MAN, 20th IEEE International Symposium on Robot and Human Interactive Communication},
doi = {10.1109/ROMAN.2011.6005294},
file = {::},
isbn = {9781457715730},
pages = {350--356},
publisher = {IEEE},
title = {{Improving aspects of empathy and subjective performance for HRI through mirroring facial expressions}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6005294},
year = {2011}
}
@book{Dennett1987,
author = {Dennett, D C},
booktitle = {Technology},
publisher = {MIT Press},
title = {{The Intentional Stance}},
year = {1987}
}
@article{Saerbeck2010,
abstract = {Teaching is inherently a social interaction between teacher and student. Despite this knowledge, many educational tools, such as vocabulary training programs, still model the interaction in a tutoring scenario as unidirectional knowledge transfer rather than a social dialog. Therefore, ongoing research aims to develop virtual agents as more appropriate media in education. Virtual agents can induce the perception of a life-like social interaction partner that communicates through natural modalities such as speech, gestures and emotional expressions. This effect can be additionally enhanced with a physical robotic embodiment. This paper presents the development of social supportive behaviors for a robotic tutor to be used in a language learning application. The effect of these behaviors on the learning performance of students was evaluated. The results support that employing social supportive behavior increases learning efficiency of students.},
author = {Saerbeck, Martin and Schut, Tom and Bartneck, Christoph and Janse, Maddy D},
institution = {ACM},
issn = {0379864X},
journal = {Human Factors},
keywords = {education,human rob,social interaction,tutoring},
number = {1},
pages = {1613--1622},
publisher = {ACM},
series = {CHI '10},
title = {{Expressive Robots in Education Varying the Degree of Social Supportive Behavior of a Robotic Tutor}},
url = {http://portal.acm.org/citation.cfm?doid=1753326.1753567},
volume = {30},
year = {2010}
}
@article{Pelachaud2009,
abstract = {Over the past few years we have been developing an expressive embodied conversational agent system. In particular, we have developed a model of multimodal behaviours that includes dynamism and complex facial expressions. The first feature refers to the qualitative execution of behaviours. Our model is based on perceptual studies and encompasses several parameters that modulate multimodal behaviours. The second feature, the model of complex expressions, follows a componential approach where a new expression is obtained by combining facial areas of other expressions. Lately we have been working on adding temporal dynamism to expressions. So far they have been designed statically, typically at their apex. Only full-blown expressions could be modelled. To overcome this limitation, we have defined a representation scheme that describes the temporal evolution of the expression of an emotion. It is no longer represented by a static definition but by a temporally ordered sequence of multimodal signals.},
author = {Pelachaud, Catherine},
doi = {10.1098/rstb.2009.0186},
file = {::},
issn = {1471-2970},
journal = {Philosophical transactions of the Royal Society of London. Series B, Biological sciences},
keywords = {Computer Simulation,Emotions,Emotions: physiology,Facial Expression,Humans,Models, Psychological,Social Behavior},
month = dec,
number = {1535},
pages = {3539--48},
pmid = {19884148},
title = {{Modelling multimodal expression of emotion in a virtual agent.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2781894\&tool=pmcentrez\&rendertype=abstract},
volume = {364},
year = {2009}
}
@article{Picard2001,
author = {Picard, Rosalind W and Vyzas, E. and Healey, J.},
doi = {10.1109/34.954607},
file = {::},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {10},
pages = {1175--1191},
title = {{Toward machine emotional intelligence: analysis of affective physiological state}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=954607},
volume = {23},
year = {2001}
}
@incollection{Gratch2006a,
author = {Gratch, Jonathan and Mao, W and Marsella, Stacy},
booktitle = {Cognition and Multi-Agent Interaction: From Cognitive Modeling to Social Simulation},
chapter = {9},
doi = {http://dx.doi.org/10.1017/CBO9780511610721.010},
editor = {Sun, Ron},
file = {::;::},
isbn = {9780511610721},
pages = {219--251},
publisher = {Cambridge University Press},
title = {{Modeling social emotions and social attributions}},
year = {2006}
}
@inproceedings{Ishii2010,
abstract = {In face-to-face conversations, speakers are continuously checking whether the listener is engaged in the conversation by monitoring the partner’s eye-gaze behaviors. In this study, focusing on eye-gaze as information of estimating user’s conversational engagement, Wizard-of-Oz experiment first, we to collect the user’s conduct a gaze behaviors as well as the user’s subjective reports and an observer’s judgment concerning the user’s engagement in the conversation. Then, by analyzing the user’s gaze behaviors, variables and factors for estimating the user’s engagement are identified. Based on the analysis, we propose four types of engagement estimation methods based on gaze duration information and gaze transition 3- gram patterns. As the results of comparing the performance of these methods, it is revealed that a method which takes account of the individual differences in gaze transition patterns performs the best and can predict the user’s conversational engagement quite well.},
address = {Hong Kong},
author = {Ishii, Ryo and Yukiko, I. Nakano},
booktitle = {EGIHMI '10 Proceedings of the 2010 workshop on Eye gaze in intelligent human machine interaction},
file = {::},
isbn = {9781605589992},
keywords = {Empirical study,Wizard-of-Oz experiment,conversational engagement},
pages = {33--40},
publisher = {ACM},
title = {{An Empirical Study of Eye-gaze Behaviors : Towards the Estimation of Conversational Engagement in Human-Agent Communication}},
year = {2010}
}
@article{Dada2006,
abstract = {Images: p1372-a:},
author = {Dada, Michael},
journal = {Journal of the National Medical Association},
number = {8},
pages = {1372},
publisher = {Motivate Healthy Habits},
title = {{Motivational Practice: Promoting Healthy Habits and Self-Care of Chronic Diseases}},
volume = {98},
year = {2006}
}
@inproceedings{Lisetti2008,
abstract = {In this article, we explore how Embodied Conversational Agents (ECAs) or avatars could be used as social orthotics defined as therapeutic computer- based social companions aimed at promoting healthy behaviors. We review some of the latest related progress and identify specific features of ECAs that are important – if not necessary – to include in the design of social orthotic systems.},
author = {Lisetti, Christine L},
booktitle = {Proceedings of the CHI 2008 Conference Workshop on Technology in Mental Health},
file = {::},
keywords = {affective computing,agents,avatars,embodied conversational,psychotherapy,social orthotics},
pages = {1--12},
publisher = {ACM},
title = {{Embodied Conversational Agents for Psychotherapy}},
year = {2008}
}
@incollection{Chung2007,
abstract = {The present paper focuses on the influence of avatar creation in a video game. More specifically, this study investigates the effects of avatar creation on attitude towards avatar, empathy, presence, and para-social interaction of female non-game users. As a cyber-self, an avatar is a graphic character representing a user in cyberspace. Avatars are primarily used in the entertainment industry as high-tech novelties, controlled by game users, for high-end video games. Some games provide game characters by default that users cannot change, but other games provide various options gamers can choose. What if game users can create their own avatars? Do they have more psychological closeness with their avatars as their cyber-selves? This study tested the differences of attitude, empathy, presence, and para-social interaction of female non-game users between an avatar creation group and a non-avatar creation group and resulted in no difference.},
author = {Chung, Donghun and DeBuys, Brahm and Nam, Chang},
booktitle = {Human-Computer Interaction. Interaction Design and Usability},
doi = {10.1007/978-3-540-73105-4\_78},
file = {::},
isbn = {978-3-540-73104-7},
keywords = {Avatar - Attitude - Empathy - Presence - Para-Soci},
pages = {711--720},
publisher = {Springer Berlin / Heidelberg},
title = {{Influence of avatar creation on attitude, empathy, presence, and para-social interaction}},
url = {http://www.springerlink.com/index/9518116J51670433.pdf},
year = {2007}
}
@inproceedings{Lisetti2008a,
author = {Lisetti, Christine L and Wagner, Eric},
booktitle = {Proceedings of the AAAI Spring Symposium on Emotion, Personality and Social Behavior},
file = {::},
keywords = {Technical Report SS-08-04},
title = {{Mental Health Promotion with Animated Characters : Exploring Issues and Potential}},
year = {2008}
}
@article{Robison2010,
abstract = {affective interventions can both positively and negatively influence learning experiences. In this paper we investigate the role of student personality, including goal orienta- tion and empathetic tendencies, in estimating confidence in the benefits of an affective intervention strategy. The results indicate that student personality profiles can serve as a powerful tool for informing affective feedback models.},
annote = {We can use the same way of menu base self-report affective state recognition (in addition to automatic) and text-base empathic feedback. Then after each feedback we can evaluate the feedback with another user self-report.},
author = {Robison, Jennifer and McQuiggan, Scott W and Lester, James and Carolina, North},
keywords = {affect,affective computing,pedagogical agents},
pages = {285--295},
title = {{Developing Empirically Based Student Personality Profiles for Affective Feedback Models}},
year = {2010}
}
@phdthesis{Becker-Asano2008,
author = {Becker-Asano, Christian},
file = {::},
keywords = {Emotion,Empathy,PhD Thesis,Secondary Emotions,primary Emotions},
mendeley-tags = {PhD Thesis},
pages = {186},
publisher = {IOS Press},
school = {University of Bielefeld},
title = {{WASABI: Affect simulation for agents with believable interactivity}},
type = {PhD Dissertation, IOS Press (DISKI 319)},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=8ABvlwHBCQIC\&amp;oi=fnd\&amp;pg=PA1\&amp;dq=WASABI+:+Affect+Simulation+for+Agents+with+Believable+Interactivity\&amp;ots=m6MhCZ6IzD\&amp;sig=IcDYrCYofbGlJ8E1szs\_wltd18k},
volume = {319},
year = {2008}
}
@article{Cogger1982,
author = {Cogger, J W},
journal = {The Personnel journal},
number = {11},
pages = {840--843},
pmid = {10258019},
title = {{Are you a skilled interviewer?}},
volume = {61},
year = {1982}
}
@article{Dautenhahn2002,
author = {Dautenhahn, Kerstin and Bond, Alan},
file = {::},
journal = {Socially Intelligent},
pages = {1--20},
publisher = {Springer},
title = {{Socially intelligent agents}},
url = {http://www.springerlink.com/index/V38H434X220766G8.pdf},
year = {2002}
}
@article{Fuchs1987,
abstract = {The impact of examiner/examinee familiarity and rapport on psychological test performance is reviewed. Drawing upon research involving hundreds of young handicapped and nonhandicapped children, it was found that certain handicapped children obtain higher scores when tested by familiar examiners. Implications for practice, theory, and personnel preparation are discussed.},
author = {Fuchs, Douglas},
journal = {Topics in Early Childhood Special Education},
number = {3},
pages = {90--104},
title = {{Examiner Familiarity Effects on Test Performance: Implications for Training and Practice}},
volume = {7},
year = {1987}
}
@article{Larimer2009,
abstract = {It is well established that college students have high rates of alcohol use and misuse and suffer the negative consequences of this behavior. Research evaluating the results of brief interventions with high-risk college students has shown these approaches to be successful in reducing alcohol con- sumption and/or related consequences. Several screening tools have been developed to detect the presence of problematic alcohol use and associated disorders, and some are designed specifically for use in a college student population. College campuses offer several opportunities to implement screening and interventions, including universal or large-scale assessments; health services, counsel- ing centers, or local emergency rooms; or via established judicial or grievance systems set up to deal with students who violate campus alcohol policies. Issues to consider when implementing screening and brief interventions in college populations include who should deliver the interventions—peer or professional counselors—and how students should be encouraged to participate in the interventions. Regardless of how the measures are implemented, the content and process of the brief interventions should be based on the available scientific evidence regarding established efficacious interventions.},
author = {Larimer, Mary E and Cronce, Jessica M and Lee, Christine M and Kilmer, Jason R},
file = {::},
journal = {Alcohol Research \& Health},
keywords = {AODD (alcohol and other drug use disorder),CAGE Questionnaire,Michigan Alcoholism Screening Test (MAST),Young Adult Alcohol Problems Screening Test (YAAPS,alcohol abuse,binge drinking,brief intervention,heavy drinking,identification and screening,interview,literature review,motivational interviewing,peer counseling,professional counseling,undergraduate student},
pages = {94--104},
title = {{Brief Intervention in College Settings}},
url = {?http://pubs.niaaa.nih.gov/publications/arh28 ?2/94?104 .htm},
volume = {28},
year = {2004}
}
@article{Archer1977,
author = {Archer, Dane and Akert, Robin M},
journal = {Journal of Personality and Social Psychology},
number = {6},
pages = {443--449},
title = {{Words and everything else: Verbal and nonverbal cues in social interpretation}},
volume = {35},
year = {1977}
}
@article{Noller1985,
abstract = {This paper reviews the literature on the complex question of the relative importance of the verbal, visual and vocal channels in various types of judgments. It is noted that a wide variety of methodologies are used in such research with studies differing in terms of the type of stimuli used (varying on the dimension of stylised to naturally occurring), the task required of the subjects (particularly varying on the cognitive-affective dimension) and the method used to assess the relative importance of the channels. An attempt is made to assess the important variables which affect the way the various channels are used by decoders, including whether deception is involved or expected, whether the message is discrepant, the particular judgment being made and the dimension on which the stimulus varies, the sex of the encoder and the decoder and the relationship between them, and the age of the decoder. The possibility of other related variables also acting as moderators is discussed.},
author = {Noller, Patricia},
doi = {10.1007/BF00987557},
issn = {01915886},
journal = {Journal of Nonverbal Behavior},
number = {1},
pages = {28--47},
publisher = {Springer Netherlands},
title = {{Video primacy? A further look}},
url = {http://www.springerlink.com/index/10.1007/BF00987557},
volume = {9},
year = {1985}
}
@article{Gerdes2009,
abstract = {This article presents a social work model of empathy that reflects the latest interdisciplinary research findings on empathy. The model reflects the social work commitment to social justice. The three model components are: 1) the affective response to another’s emotions and actions; 2) the cognitive processing of one’s affective response and the other person’s perspective; and 3) the conscious decision-making to take empathic action. Mirrored affective responses are involuntary, while cognitive processing and conscious decision-making are voluntary. The affective component requires healthy, neural pathways to function appropriately and accurately. The cognitive aspects of perspective-taking, self-awareness, and emotion regulation can be practiced and cultivated, particularly through the use of mindfulness techniques. Empathic action requires that we move beyond affective responses and cognitive processing toward utilizing social work values and knowledge to inform our actions. By introducing the proposed model of empathy, we hope it will serve as a catalyst for discussion and future research and development of the model.},
author = {Gerdes, Karen E. and Segal, Elizabeth A.},
file = {::},
journal = {Advances in Social Work},
keywords = {empathy,social cognitive neuroscience,social empathy},
number = {2},
pages = {114--127},
title = {{A social work model of empathy}},
url = {https://advancesinsocialwork.iupui.edu/index.php/advancesinsocialwork/article/viewArticle/235 http://journals.iupui.edu/index.php/advancesinsocialwork/article/view/235/215},
volume = {10},
year = {2009}
}
@article{Wasfy2004,
abstract = {An intelligent virtual environment is described for training users in the operation of complex engineering systems. The environment combines an intelligent agent facility, for tutoring, guiding and/or supervising the training; an object-oriented virtual environment engine, for displaying the engineering system; and a simulator, for simulating the system controls. The intelligent agent facility includes: (a) a hierarchical process knowledge base, (b) a rule-based expert system for natural language understanding, and (c) a human-like virtual characters engine. Three types of objects are used for representing the process knowledge, namely, processes, steps, and constraints. An application of the environment to the interactive training for operating a NASA wind tunnel is described. Two agents in the environment can perform several functions, including conducting an interactive virtual tour of the facility; guiding and supervising the training, as well as certifying the trainee.},
author = {Wasfy, Ayman and Wasfy, Tamer and Noor, Ahmed},
doi = {10.1016/j.advengsoft.2004.04.005},
file = {::},
issn = {09659978},
journal = {Advances in Engineering Software},
keywords = {intelligent agents,natural language processing,virtual reality,virtual training environments},
month = jun,
number = {6},
pages = {337--355},
title = {{Intelligent virtual environment for process training}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0965997804000390},
volume = {35},
year = {2004}
}
@article{Gerdes2009,
abstract = {This article presents a social work model of empathy that reflects the latest interdisciplinary research findings on empathy. The model reflects the social work commitment to social justice. The three model components are: 1) the affective response to another’s emotions and actions; 2) the cognitive processing of one’s affective response and the other person’s perspective; and 3) the conscious decision-making to take empathic action. Mirrored affective responses are involuntary, while cognitive processing and conscious decision-making are voluntary. The affective component requires healthy, neural pathways to function appropriately and accurately. The cognitive aspects of perspective-taking, self-awareness, and emotion regulation can be practiced and cultivated, particularly through the use of mindfulness techniques. Empathic action requires that we move beyond affective responses and cognitive processing toward utilizing social work values and knowledge to inform our actions. By introducing the proposed model of empathy, we hope it will serve as a catalyst for discussion and future research and development of the model.},
author = {Gerdes, Karen E. and Segal, Elizabeth A.},
file = {::},
journal = {Advances in Social Work},
keywords = {empathy,social cognitive neuroscience,social empathy},
number = {2},
pages = {114--127},
title = {{A social work model of empathy}},
url = {https://advancesinsocialwork.iupui.edu/index.php/advancesinsocialwork/article/viewArticle/235 http://journals.iupui.edu/index.php/advancesinsocialwork/article/view/235/215},
volume = {10},
year = {2009}
}
@inproceedings{Polajnar2011,
author = {Polajnar, Jernej and Dalvandi, B. and Polajnar, D.},
booktitle = {Cognitive Informatics \& Cognitive Computing (ICCI'CC'11), 2011 10th IEEE International Conference on},
file = {::},
isbn = {9781457716973},
pages = {96--102},
publisher = {IEEE},
title = {{Does empathy between artificial agents improve agent teamwork?}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6016126},
year = {2011}
}
@article{Lakin2003a,
abstract = {The “chameleon effect” refers to the tendency to adopt the postures, gestures, and mannerisms of interaction partners (Chartrand \& Bargh, 1999). This type of mimicry occurs outside of conscious awareness, and without any intent to mimic or imitate. Empirical evidence suggests a bi-directional relationship between nonconscious mimicry on the one hand, and liking, rapport, and affiliation on the other. That is, nonconscious mimicry creates affiliation, and affiliation can be expressed through nonconscious mimicry. We argue that mimicry played an important role in human evolution. Initially, mimicry may have had survival value by helping humans communicate. We propose that the purpose of mimicry has now evolved to serve a social function. Nonconscious behavioral mimicry increases affiliation, which serves to foster relationships with others.},
annote = {nonconscious mimicry creates affiliation, and affiliation can be expressed through nonconscious mimicry.
Initially, mimicry may have had survival value by helping humans communicate. The purpose of mimicry has now evolved to serve a social function. Nonconscious behavioral mimicry increases affiliation, which serves to foster relationships with others.
Empathic individuals mimic people more that people low in empathy.},
author = {Lakin, JL and Jefferis, VE and Cheng, CM},
file = {::},
journal = {Journal of nonverbal},
keywords = {1994,1999,2000,2001a,affiliation,and sometimes from,animals,aronson,caporael,chameleon effect,dusk to dawn,ehrlich,from dawn to dusk,human beings are social,human evolution,mimicry,our lives are filled,we talk to signif-,with social interactions,wright},
number = {3},
pages = {145--162},
title = {{The chameleon effect as social glue: Evidence for the evolutionary significance of nonconscious mimicry}},
url = {http://www.springerlink.com/index/R16K6T278246H656.pdf},
volume = {27},
year = {2003}
}
@book{Widmark1981,
address = {Davis, California},
author = {Widmark, Erik Matteo Prochet},
isbn = {0931890071, 9780931890079},
pages = {163},
publisher = {Biomedical Publications},
title = {{Principles and Applications of Medicolegal Alcohol Determination}},
year = {1981}
}
@article{Cichosz2007,
author = {Cichosz, Jarosław},
file = {::},
journal = {Doctoral Consortium. ACII},
keywords = {emotion recognition,speech analysis},
pages = {1--8},
title = {{Emotion recognition in speech signal using emotion-extracting binary decision trees}},
url = {http://www.di.uniba.it/intint/DC-ACII07/Chicosz.pdf},
year = {2007}
}
@article{Kaliouby2005,
author = {Kaliouby, R. and Robinson, Peter},
file = {::},
journal = {Real-time vision for human-computer interaction},
pages = {181--200},
publisher = {Springer},
title = {{Real-time inference of complex mental states from facial expressions and head gestures}},
url = {http://www.springerlink.com/index/K822871338R66039.pdf},
year = {2005}
}
@book{Andreassi2009,
author = {Andreassi, John L.},
edition = {5},
isbn = {978-0805828337},
pages = {488},
publisher = {Taylor \& Francis},
title = {{Psychophysiology: Human Behavior and Physiological Response}},
year = {2009}
}
@misc{Ostermann1998,
abstract = {MPEG-4 is the first international standard that standardizes true multimedia communication-including natural and synthetic audio, natural and synthetic video, as well as 3D graphics. Integrated into this standard is the capability to define and animate virtual humans consisting of synthetic heads and bodies. For the head, more than 70 model-independent animation parameters defining low-level actions like \&amp;ldquo;move left mouth corner\&amp;rdquo; up to high-level parameters like facial expressions and visemes are standardized In a communication application. The encoder can define the face model using MPEG-4 BIFS (BInary Format for Scenes) and transmit it to the decoder. Alternatively, the encoder can rely on a face model that is available at the decoder. The animation parameters are quantized, predictively encoded using an arithmetic encoder or a DCT. The decoder receives the model and the animation parameters in order to animate the model. Since MPEG-4 defines the minimum MPEG-4 terminal capabilities in profiles and levels, the encoder knows the quality of the animation at the decoder},
author = {Ostermann, J},
booktitle = {Proceedings Computer Animation 98 Cat No98EX169},
doi = {10.1109/CA.1998.681907},
isbn = {0818685417},
issn = {10874844},
keywords = {facial animation,fap,mpeg4,synthetic faces},
pages = {49--51},
title = {{Animation of synthetic faces in MPEG-4}},
year = {1998}
}
@article{Scherer2007,
abstract = {In earlier work, the authors analyzed emotion portrayals by professional actors separately for facial expression, vocal expression, gestures, and body movements. In a secondary analysis of the combined data set for all these modalities, the authors now examine to what extent actors use prototypical multimodal configurations of expressive actions to portray different emotions, as predicted by basic emotion theories claiming that expressions are produced by fixed neuromotor affect programs. Although several coherent unimodal clusters are identified, the results show only 3 multimodal clusters: agitation, resignation, and joyful surprise, with only the latter being specific to a particular emotion. Finding variable expressions rather than prototypical patterns seems consistent with the notion that emotional expression is differentially driven by the results of sequential appraisal checks, as postulated by componential appraisal theories.},
author = {Scherer, Klaus R and Ellgring, Heiner},
doi = {10.1037/1528-3542.7.1.158},
file = {::},
issn = {1528-3542},
journal = {Emotion (Washington, D.C.)},
keywords = {Adult,Affect,Facial Expression,Female,Gestures,Humans,Judgment,Male,Psychomotor Performance,Speech Acoustics,Voice},
month = feb,
number = {1},
pages = {158--71},
pmid = {17352571},
title = {{Multimodal expression of emotion: affect programs or componential appraisal patterns?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17352571},
volume = {7},
year = {2007}
}
@incollection{Catucci2006,
abstract = {Empathy is a distributed environment for the generation of emotions and other related affective phenomena like moods and temperaments. Empathy has been conceived as an object-oriented reusable framework entirely written in Java and realized for the purpose of studying the direct influences of emotions on behaviors and on decision-making processes of autonomous agents, interacting in complex or real environments. It allows for the realization of custom emotional agents, usable in several different domains, from the educational applications (e.g. entertainment, video games, intelligent tutoring systems.) to control systems in autonomous robots.},
author = {Catucci, Graziano and Abbattista, Fabio and Gadaleta, R. and Guaccero, Domenico and Semeraro, Giovanni},
booktitle = {Applied Soft Computing Technologies: The Challenge of Complexity},
doi = {10.1007/3-540-31662-0\_21},
file = {::},
isbn = {978-3-540-31649-7},
keywords = {autonomous agents,emotional agents,synthetic characters},
pages = {265--277},
publisher = {Springer Berlin / Heidelberg},
title = {{Empathy: A computational framework for emotion generation}},
url = {http://www.springerlink.com/index/LJ26L065L0072722.pdf http://dx.doi.org/10.1007/3-540-31662-0\_21},
year = {2006}
}
@article{Brave2005,
abstract = {Embodied computer agents are becoming an increasingly popular human-computer interaction technique. Often, these agents are programmed with the capacity for emotional expression. This paper investigates the psychological effects of emotion in agents upon users. In particular, two types of emotion were evaluated: self-oriented emotion and other-oriented, empathic emotion. In a 2 (self-oriented emotion: absent vs. present) by 2 (empathic emotion: absent vs. present) by 2 (gender dyad: male vs. female) between-subjects experiment (N = 96), empathic emotion was found to lead to more positive ratings of the agent by users, including greater likeability and trustworthiness, as well as greater perceived caring and felt support. No such effect was found for the presence of self-oriented emotion. Implications for the design of embodied computer agents are discussed and directions for future research suggested.},
author = {Brave, Scott and Nass, Clifford and Hutchinson, Kevin},
doi = {10.1016/j.ijhcs.2004.11.002},
file = {::},
issn = {10715819},
journal = {International Journal of Human-Computer Studies - Special issue: Subtle expressivity for characters and robots},
keywords = {affective computing,characters,embodied agents,emotion,empathy,social interfaces},
month = feb,
number = {2},
pages = {161--178},
title = {{Computers that care: investigating the effects of orientation of emotion exhibited by an embodied computer agent}},
url = {http://www.sciencedirect.com/science/article/pii/S1071581904001284},
volume = {62},
year = {2005}
}
@book{Ekman2002,
author = {Ekman, Paul and Freisen, Wallace V. and Hager, Joseph C},
booktitle = {A Human Face},
institution = {Consulting Psychologists},
isbn = {0931835011},
number = {4},
pages = {4--5},
publisher = {A Human Face},
title = {{Facial Action Coding System}},
volume = {160},
year = {2002}
}
@article{Kiesler2008,
author = {Kiesler, Sara and Powers, Aaron and Fussell, Susan R. and Torrey, Cristen},
doi = {10.1521/soco.2008.26.2.169},
file = {::},
issn = {0278-016X},
journal = {Social Cognition},
month = apr,
number = {2},
pages = {169--181},
title = {{Anthropomorphic Interactions with a Robot and Robot–like Agent}},
url = {http://guilfordjournals.com/doi/abs/10.1521/soco.2008.26.2.169},
volume = {26},
year = {2008}
}
@article{Prochaska1997,
abstract = {The transtheoretical model posits that health behavior change involves progress through six stages of change: precontemplation, contemplation, preparation, action, maintenance, and termination. Ten processes of change have been identified for producing progress along with decisional balance, self-efficacy, and temptations. Basic research has generated a rule of thumb for at-risk populations: 40\% in precontemplation, 40\% in contemplation, and 20\% in preparation. Across 12 health behaviors, consistent patterns have been found between the pros and cons of changing and the stages of change. Applied research has demonstrated dramatic improvements in recruitment, retention, and progress using stage-matched interventions and proactive recruitment procedures. The most promising outcomes to data have been found with computer-based individualized and interactive interventions. The most promising enhancement to the computer-based programs are personalized counselors. One of the most striking results to date for stage-matched programs is the similarity between participants reactively recruited who reached us for help and those proactively recruited who we reached out to help. If results with stage-matched interventions continue to be replicated, health promotion programs will be able to produce unprecedented impacts on entire at-risk populations.},
author = {Prochaska, J O and Velicer, W F},
chapter = {5},
doi = {10.4278/0890-1171-12.1.38},
editor = {Shumaker, S A and Schron, E B},
institution = {Cancer Prevention Research Center, University of Rhode Island, Kingston 02881-0808, USA. JOP@URIACC.URI.EDU},
issn = {08901171},
journal = {American Journal Of Health Promotion},
number = {1},
pages = {38--48},
publisher = {American Journal of Health Promotion P.O. Box 1897, 810 East 10th Street, Lawrence, KS 66044-8897},
title = {{The transtheoretical model of health behavior change}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10170434},
volume = {12},
year = {1997}
}

@inproceedings{CatizoneDPW08,
  author    = {Roberta Catizone and
               Alexiei Dingli and
               Hugo Pinto and
               Yorick Wilks},
  title     = {Information Extraction Tools and Methods for Understanding
               Dialogue in a Companion},
  booktitle = {LREC},
  year      = {2008},
  ee        = {http://www.lrec-conf.org/proceedings/lrec2008/summaries/819.html},
  crossref  = {DBLP:conf/lrec/2008},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@article{Prendinger2005,
abstract = {In this paper, we report on our efforts in developing affective character-based interfaces, i.e., interfaces that recognize and measure affective information of the user and address user affect by employing embodied characters. In particular, we describe the Empathic Companion, an ani- mated interface agent that accompanies the user in the setting of a virtual job interview. This inter- face application takes physiological data (skin conductance and electromyography) of a user in realtime, interprets them as emotions, and addresses the user’s affective states in the form of empathic feedback. The Empathic Companion is conceived as an educational agent that supports job seekers preparing for a job interview. We also present results from an exploratory study that aims to evaluate the impact of the Empathic Companion by measuring users’ skin conductance and heart rate. While an overall positive effect of the Empathic Companion could not be shown, the outcome of the experiment suggests that empathic feedback has a positive effect on the interviewee’s stress level while hearing the interviewer question.},
annote = {They take physiological data (skin conductance and electromyography) of a user in real-time, interpret them as emotions, and address the user’s affective states by empathic feedback. A decision making agent relates these signals and the user’s answer to arousal and valence to infer the user’s emotional state by applying the model of Lang (1995) (Lang claims that all emotions can be characterized in terms of valence (pleasant or unpleasant) and arousal (calm or aroused)). Then it selects empathetic actions that maximize some utility function. They use text-based empathetic actions in addition to a small full body character.We can use the decision-theoretic agent aspect in our empathy model.
The empathy is mainly expressed in a text-base fashion in their job. The embodied agent that they have is so small and no facial expressions are used. There are some gestural expressions.
As shown in this paper and many other ones, text-base empathy expression can be effective. So we can use that too.
      },
author = {Prendinger, Helmut and Ishizuka, M.},
doi = {10.1080/08839510590910174},
file = {::;::},
journal = {Applied Artificial Intelligence},
keywords = {electromyography,physiological signals,skin conductance},
number = {3-4},
pages = {267--286},
publisher = {Citeseer},
title = {{The Empathic Companion - A Character-based Interface that Addresses Users’ Affective States}},
volume = {19},
year = {2005}
}
@inproceedings{Gama2011,
abstract = {Over the last decade extensive research has been conducted in the area of conversational agents focusing in many different aspects of these agents. In this research, and aiming at building agents that maintain a social connection with users, empathy has been one of those areas, as it plays a leading role in the establishment of social relationships. In this paper we present a relationship model of empathy that takes advantage of Social Penetration Theory's concepts for relationship building. This model has been implemented into an agent that attempts to establish a relationship with the user, expressing empathy both verbally and visually. The visual expression of empathy consists of facial expression and physical proximity representation. The user tests performed showed that while users were able to develop a simple relationship with the agents, they however developed stronger relationships with a version of the agent that is most visually expressive and takes advantage of the proximity element, confirming the significance of our model based on social penetration theory may have and, consequently, the importance of the visual representation of empathic responses.},
address = {Memphis, TN, USA},
author = {Gama, Sandra and Barata, Gabriel and Gon\c{c}alves, D. and Prada, R. and Paiva, Ana},
booktitle = {ACII'11 Proceedings of the 4th international conference on Affective computing and intelligent interaction - Volume Part I},
doi = {10.1007/978-3-642-24600-5\_54},
editor = {{D'Mello, Sidney K. and Graesser, Arthur C. and Schuller, Bj\"{o}rn and Martin}, Jean-Claude},
file = {::},
keywords = {affective computing,conversational agent,empathic agent},
pages = {507--516},
publisher = {Springer Berlin / Heidelberg},
title = {{SARA: social affective relational agent: a study on the role of empathy in artificial social agents}},
url = {http://www.springerlink.com/content/g0433kx744258w62/},
year = {2011}
}
@inproceedings{Schulman2011,
abstract = {We present a conversational agent designed as a virtual counselor for health behavior change. The incorporates techniques drawn from agent Motivational Interviewing to enhance client motivation and confidence to change; these techniques are modeled and implemented based on a domain-specific taxonomy of dialogue acts. We discuss the design and preliminary evaluation of the agent.},
author = {Schulman, Daniel and Bickmore, Timothy W. and Sidner, Candace L},
booktitle = {Association for the Advancement of Artificial Intelligence (AAAI) Spring Symposium Series},
file = {::},
pages = {61--64},
publisher = {Association for the Advancement of Artificial Intelligence (www.aaai.org)},
title = {{An Intelligent Conversational Agent for Promoting Long-Term Health Behavior Change using Motivational Interviewing}},
year = {2011}
}
@article{James1884,
abstract = {The physiologists who , during the past few years , have been so industriously exploring the functions of the brain , have limited their attempts at explanation to its cognitive and volitional per- formances . Dividing the brain into sensorial and motor centers , they have found their division to be exactly paralleled by the analysis made by empirical psychology , of the perceptive and volitional parts of the mind into their simplest elements . But the aesthetic sphere of the mind , its longings , its pleasures and pains , and its emotions , have been so ignored in all these researches that one is tempted to suppose that if either Dr . Ferrier or Dr . Munk were asked for a theory in brain-terms of the latter mental facts , they might both reply , either that they had as yet bestowed no thought upon the subject , or that they had found it so difficult to make distinct hypotheses , that the matter lay for them among the problems of the future , only to be taken up after the simpler ones of the present should have been definitely solved . And yet it is even now certain that of two things concerning the emotions , one must be true . Either separate and special centers affected to them alone , are their brain-seat , or else they correspond to processes occurring in the motor and sensory centers , already assigned , or in others like them , not yet mapped out . If the for- mer be the case we must deny the current view , and hold the cortex to be something more than the surface of projection for every sensitive spot and every muscle in the body . If the latter be the case , we must ask whether the emotional process in the sensory or motor center be an altogether peculiar one , or whether it resembles the ordinary perceptive processes of which those centers are already recognized to be the seat . The purpose of the following pages is to show that the last alternative comes nearest to the truth , and that the emotional brain-processes not only},
author = {James, William},
chapter = {188},
issn = {00264423},
journal = {Mind},
number = {34},
pages = {188--205},
publisher = {JSTOR},
title = {{What is an Emotion?}},
url = {http://www.jstor.org/stable/2246769},
volume = {9},
year = {1884}
}
@misc{TheMendeleySupportTeam2011,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/The Mendeley Support Team - 2011 - Getting Started with Mendeley(4).pdf:pdf},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@article{Rodrigues2009,
author = {Rodrigues, SH and Mascarenhas, SF},
file = {::},
isbn = {9781424447992},
journal = {and Workshops, 2009},
title = {{“ I can feel it too !”: Emergent empathic reactions between synthetic characters}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5349570},
year = {2009}
}
@article{Feshbach1968,
author = {Feshbach, N D and Roe, K},
journal = {Child Development},
number = {1},
pages = {133--145},
pmid = {5645790},
title = {{Empathy in six- and seven-year-olds.}},
volume = {39},
year = {1968}
}
@article{McQuiggan2008a,
abstract = {Humans continuously assess one another’s situational context, modify their own affective state, and then respond based on these outcomes through empathetic expression. Virtual agents should be capable of similarly empathizing with users in interactive environments. A key challenge posed by empathetic reasoning in virtual agents is determining whether to respond with parallel or reactive empathy. Parallel empathy refers to mere replication of another’s affective state, whereas reactive empathy exhibits greater cognitive awareness and may lead to incongruent emotional responses (i.e., emotions different from the recipient’s and perhaps intended to alter negative affect). This paper proposes a unified inductive framework for modeling parallel and reactive empathy. Empathy models are used to drive runtime situation-appropriate empathetic behaviors by selecting suitable parallel or reactive empathetic expressions.},
author = {McQuiggan, SW and Robison, JL and Phillips, Robert},
file = {::},
journal = {on Autonomous agents},
number = {Aamas},
pages = {167--174},
title = {{Modeling parallel and reactive empathy in virtual agents: An inductive approach}},
url = {http://portal.acm.org/citation.cfm?id=1402411},
year = {2008}
}
@inproceedings{Courgeon2008,
address = {Estoril, Portugal},
annote = {The user reports his/her affective state in real-time with changing the position of a 3D point in PAD space using a joystick. The system captures the position of that point and maps it to a blend of 8 selected emotions. },
author = {Courgeon, Matthieu and Martin, Jean-claude and Jacquemin, Christian},
booktitle = {Proc. of 7th Int. Conf. on Autonomous Agents and Multiagent Systems (AAMAS 2008)},
file = {::},
number = {Aamas},
pages = {1237--1240},
title = {{User ’ s Gestural Exploration of Different Virtual Agents ’ Expressive Profiles ( Short Paper )}},
year = {2008}
}
@incollection{WeinerBGraham1984,
address = {New York},
author = {{Weiner B Graham}, S},
booktitle = {Emotions, cognition, and behavior},
editor = {Izard, Carroll E and Kagan, J and Zajonc, Robert B},
pages = {167--191},
publisher = {Cambridge University Press},
title = {{An attributional approach to emotional development}},
year = {1984}
}
@inproceedings{Bickmore2007,
abstract = {Interactions in which computer agents comfort users through expressed empathy have been shown to be important in alleviating user frustration and increasing user liking of the agent, and may have important healthcare applications. Given the current state of technology, designers of these systems are forced to choose between (a) allowing users to freely express their feelings, but having the agents provide imperfect empathic responses, or (b) greatly restricting how users can express themselves, but having the agents provide very accurate empathic feedback. This study investigates which of these options leads to better outcomes, in terms of comforting users and increasing user-agent social bonds. Results, on almost all measures, indicate that empathic accuracy is more important than user expressivity.},
address = {San Jose, California, USA},
author = {Bickmore, Timothy W. and Schulman, Daniel},
booktitle = {Preceeding of ACM CHI 2007 Conference on Human Factors in Computing Systems},
doi = {10.1145/1240866.1240996},
file = {::},
isbn = {9781595936424},
keywords = {affective computing,caring,comforting,embodied conversational agent,relational agent,social interface},
pages = {2291--2296},
publisher = {ACM},
title = {{Practical approaches to comforting users with relational agents}},
url = {http://dl.acm.org/citation.cfm?id=1240996},
year = {2007}
}
@inproceedings{DeCarolis2002,
abstract = {Developing an embodied conversational agent that is able to exhibit a human-like behavior while communicating with other virtual or human agents requires enriching a typical NLG architecture. The purpose of this paper is to describe our efforts in this direction and to illustrate our approach to the generation of an Agent that intelligence shows a personality, a social and is able to react emotionally to events occurring in the environment, consistently with her goals and with the context in which the conversation takes place.},
address = {New York, USA},
author = {{De Carolis}, Berardina and Carofiglio, Valeria and Pelachaud, Catherine},
booktitle = {Proceedings of the 2nd International Conference on Natural Language Generation (INLG 2002)},
file = {::},
title = {{From discourse plans to believable behavior generation}},
url = {http://www.cs.rutgers.edu/~mdstone/inlg02/154.pdf},
year = {2002}
}
@book{Ekman1978,
author = {Ekman, Paul and Freisen, Wallace V.},
booktitle = {Consulting Psychologists Press 1978},
editor = {Press, Consulting Psychologists},
publisher = {Consulting Psychologists Press},
title = {{Facial Action Coding System: A Technique for the Measurement of Facial Movement}},
year = {1978}
}
@article{Mehrabian1967,
author = {Mehrabian, Albert and Ferris, S R},
journal = {Journal of Consulting Psychology},
keywords = {attitude,communication,facial expression,female,humans,verbal behavior},
number = {3},
pages = {248--252},
pmid = {6046577},
title = {{Inference of attitudes from nonverbal communication in two channels.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/6046577},
volume = {31},
year = {1967}
}
@inproceedings{Wang2010,
address = {Atlanta, GA, USA},
author = {Wang, Ning and Gratch, Jonathan},
booktitle = {CHI},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - p1241-wang.pdf(6).pdf:pdf},
pages = {1241--1249},
title = {{Don't just stare at me.pdf}},
year = {2010}
}
@article{Caridakis2008,
abstract = {As input they consider the image sequence of the recorded human behavior. Computer vision and image processing techniques are incorporated in order to detect cues needed for expressivity features extraction. Using multimodalities, the virtual agent mimics the human expressions. The multimodality of the approach lies in the fact that both facial and gestural aspects of the user’s behavior are analyzed and processed. The mimicry consists of perception, interpretation, planning and animation of the expressions shown by the human, resulting not in an exact duplicate rather than an expressive model of the user’s original behavior.},
annote = {They use both facial and gestural aspects of the user’s behavior to mimic the user’s expressions. The introductory information and references about the psychological background of the mimicry in the paper are useful. But because most of the work is image processing, other sections would not be useful for our job.
Their system does not work in real time because they use a recorded video or sequence of images (limitation).},
author = {Caridakis, George and Raouzaiou, Amaryllis and Bevacqua, Elisabetta and Mancini, Maurizio and Karpouzis, Kostas and Malatesta, Lori and Pelachaud, Catherine},
doi = {10.1007/s10579-007-9057-1},
file = {::},
issn = {1574-020X},
journal = {International Language Resources and Evaluation Journal: Special issue on Multimodal Corpora For Modelling Human Multimodal Behavior},
keywords = {facial,gesture,mimicry,multimodal,virtual agent},
month = jan,
number = {3-4},
pages = {367--388},
title = {{Virtual agent multimodal mimicry of humans}},
volume = {41},
year = {2008}
}
@inproceedings{Panagiotis2009,
abstract = {Emotion identification is beginning to be considered as an essential feature in human-computer interaction. However, most of the studies are mainly focused on facial expression classifications and speech recognition and not much attention has been paid until recently to physiological pattern recognition. In this paper, an integrative approach is proposed to emotional interaction by fusing multi-modal signals. Subjects are exposed to pictures selected from the International Affective Picture System (IAPS). A feature extraction procedure is used to discriminate between four affective states by means of a Mahalanobis distance classifier. The average classifications rate (74.11\%) was encouraging. Thus, the induced affective state is mirrored through an avatar by changing its facial characteristics and generating a voice message sympathising with the user’s mood. It is argued that multi-physiological patterning in combination with anthropomorphic avatars may contribute to the enhancement of affective multi-modal interfaces and the advancement of machine emotional intelligence.},
address = {San Diego, CA, USA},
author = {Panagiotis, D and Christos, A and Evdokimos, I and Manousos, A},
booktitle = {Ambient, Ubiquitous and Intelligent Interaction. 13th International Conference on Human-Computer Interaction},
doi = {10.1007/978-3-642-02580-8},
file = {::},
isbn = {9783642025808},
keywords = {Affective Computing,Avatar,EEG,Emotion,Mahalanobis,Skin Conductance,classifier},
number = {July},
pages = {565--574},
publisher = {Springer},
title = {{An integrated approach to emotion recognition for advanced emotional intelligence}},
year = {2009}
}
@article{Mehrabian1996,
author = {Mehrabian, Albert},
file = {::},
journal = {Current Psychology},
number = {4},
pages = {261--292},
title = {{Pleasure-arousal-dominance: A general framework for describing and measuring individual differences in temperament}},
volume = {14},
year = {1996}
}
@article{Bryant1982,
abstract = {56 1st, 115 4th, and 87 7th graders were administered a newly devised index of empathy partly based on A. Mehrabian and N. Epstein's (see record 1973-23075-001) measure. Item means, item-total correlations, testretest reliabilities, correlations of empathy with aggressiveness and acceptance of individual differences, and correlations with other existing measures of empathy as well as to social desirability response set and reading achievement formed the basis of internal, discriminant, convergent, and general construct validation. The measure demonstrated satisfactory reliability and preliminary construct validity. The study of developmental aspects of empathic arousal toward peers of different sexes is indicated. (38 ref) (PsycINFO Database Record (c) 2010 APA, all rights reserved)},
author = {Bryant, Brenda K},
doi = {10.2307/1128984},
issn = {00093920},
journal = {Child Development},
number = {2},
pages = {413--425},
publisher = {Blackwell Publishing on behalf of the Society for Research in Child Development},
title = {{An Index of Empathy for Children and Adolescents}},
volume = {53},
year = {1982}
}
@article{Grynberg2010,
abstract = {Alexithymia and empathy have been related but very little is known on shared variance between their respective affective and cognitive dimensions. We examined this question with correlations, as well as both exploratory and confirmatory analyses, and controlled for anxiety and depression. The responses of 645 young adults to self-report questionnaires of alexithymia (TAS-20), empathy (IRI), anxiety (STAI-T) and depression (BDI-13) were examined. We observed associations between the proposed cog- nitive components of alexithymia (externally-oriented thinking) and that of empathy (perspective taking, fantasy) as well as empathic concern, which were insensitive to anxiety or depression. In contrast, asso- ciations between the proposed affective components of alexithymia (difficulty identifying feelings, diffi- culty describing feelings) and empathy (personal distress) were largely due to shared covariance with anxiety. A model encompassing an affective and a cognitive (including empathic concern) latent factors emerged, even after controlling for dysphoric affects. These findings suggest specific associations between cognitive and affective components of both constructs that were dissimilarly affected by anxiety and depression. The allocation of empathic concern to the cognitive factor is also discussed.},
author = {Grynberg, Delphine and Luminet, Olivier and Corneille, Olivier and Gr\`{e}zes, Julie and Berthoz, Sylvie},
doi = {10.1016/j.paid.2010.07.013},
file = {::},
issn = {01918869},
journal = {Personality and Individual Differences},
keywords = {Alexithymia,Anxiety,Depression,Empathy,IRI,TAS-20},
mendeley-tags = {Alexithymia,Anxiety,Depression,Empathy,IRI,TAS-20},
month = dec,
number = {8},
pages = {845--850},
publisher = {Elsevier Ltd},
title = {{Alexithymia in the interpersonal domain: A general deficit of empathy?}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S019188691000365X},
volume = {49},
year = {2010}
}
@article{Maurer1983,
author = {Maurer, R.E. and Tindall, J.H.},
file = {::},
journal = {Journal of Counseling Psychology},
number = {2},
pages = {158},
publisher = {American Psychological Association},
title = {{Effect of postural congruence on client's perception of counselor empathy.}},
volume = {30},
year = {1983}
}
@article{Pereira2011,
abstract = {For robots to become our personal companions in the future, they need to know how to socially interact with us. One defining charac- teristic of human social behaviour is empathy. In this paper, we present a robot that acts as a social companion expressing different kinds of empathic behaviours through its facial expressions and utterances. The robot comments the moves of two subjects playing a chess game against each other, being empathic to one of them and neutral towards the other. The results of a pilot study suggest that users to whom the robot was empathic perceived the robot more as a friend.},
author = {Pereira, A. and Leite, Iolanda and Mascarenhas, Samuel and Martinho, Carlos and Paiva, Ana},
file = {::},
journal = {Human-Robot Personal Relationships},
keywords = {companionship,empathy,human-robot interaction},
pages = {130--138},
publisher = {Springer},
title = {{Using empathy to improve human-robot relationships}},
url = {http://www.springerlink.com/index/R468X62581620V62.pdf},
volume = {LNICST 59},
year = {2011}
}
@misc{Ekman1980,
author = {Ekman, Paul and Freisen, Wallace V. and Ancoli, Sonia},
booktitle = {Journal of Personality and Social Psychology},
doi = {10.1037/h0077722},
file = {::},
issn = {0022-3514},
number = {6},
pages = {1125--1134},
title = {{Facial signs of emotional experience.}},
url = {http://content.apa.org/journals/psp/39/6/1125},
volume = {39},
year = {1980}
}

@article{Lemon2009,
author = {Lemon, Oliver},
file = {:C$\backslash$:/Users/uyasa001/Downloads/LemonKonstasEACL09.pdf:pdf},
journal = {Proceedings of the 12th Conference of the European \ldots},
number = {1},
title = {{User simulations for context-sensitive speech recognition in spoken dialogue systems}},
url = {http://dl.acm.org/citation.cfm?id=1609067.1609123},
year = {2009}
}

@article{young2010POMDP,
  title={The hidden information state model: A practical framework for POMDP-based spoken dialogue management},
  author={Young, Steve and Ga{\v{s}}i{\'c}, Milica and Keizer, Simon and Mairesse, Fran{\c{c}}ois and Schatzmann, Jost and Thomson, Blaise and Yu, Kai},
  journal={Computer Speech \& Language},
  volume={24},
  number={2},
  pages={150--174},
  year={2010},
  publisher={Elsevier}
}

@inproceedings{paek2005markov,
  title={The markov assumption in spoken dialogue management},
  author={Paek, Tim and Chickering, David Maxwell},
  booktitle={6th SIGDIAL Workshop on Discourse and Dialogue},
  year={2005}
}

@inproceedings{Tetreault2006,
    author = {Tetreault, Joel R. and Litman, Diane J.},
    booktitle = {Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics},
    citeulike-article-id = {12214290},
    keywords = {features, goodness, learning, measure, policy, reinforcement, utility},
    organization = {Association for Computational Linguistics},
    pages = {272--279},
    posted-at = {2013-03-27 01:45:47},
    priority = {2},
    title = {{Comparing the utility of state features in spoken dialogue using reinforcement learning}},
    year = {2006}
}

@inproceedings{frampton2006learning,
  title={Learning more effective dialogue strategies using limited dialogue move features},
  author={Frampton, Matthew and Lemon, Oliver},
  booktitle={Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics},
  pages={185--192},
  year={2006},
  organization={Association for Computational Linguistics}
}

@inproceedings{georgila2005automatic,
  title={Automatic annotation of COMMUNICATOR dialogue data for learning dialogue strategies and user simulations},
  author={Georgila, Kallirroi and Lemon, Oliver and Henderson, James},
  booktitle={Ninth Workshop on the Semantics and Pragmatics of Dialogue (SEMDIAL: DIALOR)},
  year={2005},
  organization={Citeseer}
}

@article{frampton2009,
  title={Recent research advances in reinforcement learning in spoken dialogue systems},
  author={Frampton, Matthew and Lemon, Oliver},
  journal={Knowledge Engineering Review},
  volume={24},
  number={4},
  pages={375--408},
  year={2009},
  publisher={Cambridge Univ Press}
}

@inproceedings{CommunicatorWalker2001,
 author = {Walker, Marilyn A. and Passonneau, Rebecca and Boland, Julie E.},
 title = {Quantitative and qualitative evaluation of DARPA Communicator spoken dialogue systems},
 booktitle = {Proceedings of the 39th Annual Meeting on Association for Computational Linguistics},
 series = {ACL '01},
 year = {2001},
 location = {Toulouse, France},
 pages = {515--522},
 numpages = {8},
 url = {http://dx.doi.org/10.3115/1073012.1073078},
 doi = {10.3115/1073012.1073078},
 acmid = {1073078},
 publisher = {Association for Computational Linguistics},
 address = {Stroudsburg, PA, USA},
} 


@inproceedings{Lemon2006Talk,
 author = {Lemon, Oliver and Georgila, Kallirroi and Henderson, James and Stuttle, Matthew},
 title = {An ISU dialogue system exhibiting reinforcement learning of dialogue policies: generic slot-filling in the TALK in-car system},
 booktitle = {Proceedings of the Eleventh Conference of the European Chapter of the Association for Computational Linguistics: Posters \&\#38; Demonstrations},
 series = {EACL '06},
 year = {2006},
 location = {Trento, Italy},
 pages = {119--122},
 numpages = {4},
 url = {http://dl.acm.org/citation.cfm?id=1608974.1608986},
 acmid = {1608986},
 publisher = {Association for Computational Linguistics},
 address = {Stroudsburg, PA, USA},
} 

@inproceedings{putois2010,
  title={Enhanced monitoring tools and online dialogue optimisation merged into a new spoken dialogue system design experience},
  author={Putois, Ghislain and Lannion, France and Laroche, Romain and Issy-les-Moulineaux, France and Bretier, Philippe},
  booktitle={Proceedings of the SIGDIAL 2010 Conference},
  pages={185--192},
  year={2010}
}

@inproceedings{Rieser2010,
 author = {Rieser, Verena and Lemon, Oliver and Liu, Xingkun},
 title = {Optimising information presentation for spoken dialogue systems},
 booktitle = {Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics},
 series = {ACL '10},
 year = {2010},
 location = {Uppsala, Sweden},
 pages = {1009--1018},
 numpages = {10},
 url = {http://dl.acm.org/citation.cfm?id=1858681.1858784},
 acmid = {1858784},
 publisher = {Association for Computational Linguistics},
 address = {Stroudsburg, PA, USA},
} 

@incollection{Predinger2008,
year={2008},
isbn={978-3-540-85482-1},
booktitle={Intelligent Virtual Agents},
volume={5208},
series={Lecture Notes in Computer Science},
editor={Prendinger, Helmut and Lester, James and Ishizuka, Mitsuru},
doi={10.1007/978-3-540-85483-8_15},
title={Integrating Planning and Dialogue in a Lifestyle Agent},
url={http://dx.doi.org/10.1007/978-3-540-85483-8_15},
publisher={Springer Berlin Heidelberg},
keywords={Multimodal interaction with intelligent virtual agents; Embodied Cognitive Modelling; Conversational and non-verbal behavior},
author={Smith, Cameron and Cavazza, Marc and Charlton, Daniel and Zhang, Li and Turunen, Markku and Hakulinen, Jaakko},
pages={146-153}
}


@article{miller2009ten,
  title={Ten things that motivational interviewing is not},
  author={Miller, William R and Rollnick, Stephen and others},
  journal={Behavioural and Cognitive Psychotherapy},
  volume={37},
  number={2},
  pages={129},
  year={2009},
  publisher={Cambridge Univ Press}
}

@book{Miller2002,
abstract = {This bestselling work has introduced hundreds of thousands of professionals and students to motivational interviewing (MI), a proven approach to helping people overcome ambivalence that gets in the way of change. William R. Miller and Stephen Rollnick explain current thinking on the process of behavior change, present the principles of MI, and provide detailed guidelines for putting it into practice. Case examples illustrate key points and demonstrate the benefits of MI in addictions treatment and other clinical contexts. The authors also discuss the process of learning MI. Chapters contributed by other leading experts address such special topics as MI and the stages-of-change model; applications in medical, public health, and criminal justice settings; and using the approach with groups, couples, and adolescents.},
address = {New York},
author = {Miller, William R. and Rollnick, Stephen},
booktitle = {Zeitschrift f\"{u}r Klinische Psychologie und Psychotherapie},
chapter = {428},
doi = {10.1026/1616-3443.34.1.66},
edition = {2nd},
isbn = {1572305630},
issn = {16163443},
number = {1},
pages = {428},
pmid = {12538308},
publisher = {Guilford Press},
title = {{Motivational Interviewing: Preparing People for Change}},
url = {http://books.google.com/books?id=r\_CuyHwdz7EC\&pgis=1},
volume = {2nd},
year = {2002}
}
@inproceedings{Boukricha2011c,
abstract = {Empathy is believed to play a prominent role in contributing to an efficient and satisfying cooperative social interaction by adjusting one's own behavior to that of others. Thus, endowing virtual humans with the ability to empathize not only enhances their cooperative social skills, but also makes them more likeable, trustworthy, and caring. Supported by psychological models of empathy, we propose an approach to model empathy for EMMA - an Empathic MultiModal Agent - based on three processing steps: First, the Empathy Mechanism consists of an internal simulation of perceived emotional facial expressions and results in an internal emotional feedback that represents the empathic emotion. Second, the Empathy Modulation consists of modulating the empathic emotion through different predefined modulation factors. Third, the Expression of Empathy consists of triggering EMMA's multiple modalities like facial and verbal behaviors. In a conversational agent scenario involving the virtual humans MAX and EMMA, we illustrate our proposed model of empathy and we introduce a planned empirical evaluation of EMMA's empathic behavior.},
address = {Paris, France},
author = {Boukricha, Hana and Wachsmuth, Ipke},
booktitle = {Proceedings of the IEEE SSCI2011 - Symposium Series on Computational Intelligence, Workshop on Affective Computational Intelligence (WACI)},
doi = {10.1109/WACI.2011.5953146},
file = {::},
isbn = {9781612840840},
pages = {30 -- 37},
publisher = {IEEE},
title = {{Mechanism, modulation, and expression of empathy in a virtual human}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5953146},
year = {2011}
}
@inproceedings{Whitehill2008,
author = {Whitehill, Jacob and Bartlett, Marian and Movellan, Javier R},
booktitle = {Intelligent Tutoring Systems},
file = {::},
pages = {668--670},
publisher = {Springer},
title = {{Measuring the perceived difficulty of a lecture using automatic facial expression recognition}},
year = {2008}
}
@article{Riek2009,
author = {Riek, Laurel D. and Paul, Philip C. and Robinson, Peter},
doi = {10.1007/s12193-009-0028-2},
file = {::},
issn = {1783-7677},
journal = {Journal on Multimodal User Interfaces},
keywords = {19,affective computing,emotionally conveying,empathy,expressions,facial,forms of expressive empathy,human-robot interaction,is known as,of the most basic,one,social robotics,understand what others are},
month = nov,
number = {1-2},
pages = {99--108},
title = {{When my robot smiles at me: Enabling human-robot rapport via real-time head gesture mimicry}},
url = {http://www.springerlink.com/index/10.1007/s12193-009-0028-2},
volume = {3},
year = {2009}
}
@book{Stokes2003,
author = {{Maura E. Stokes} and Davis, Charles S. and Koch, Gary G.},
edition = {2nd},
file = {::},
isbn = {1-58025-710-0},
pages = {1--86},
publisher = {SAS Institute and Wiley},
title = {{Categorical Data Analysis Using the SAS System}},
year = {2003}
}
@inproceedings{Kenny2007,
abstract = {Virtual humans offer an exciting and powerful potential for rich interactive experiences. Fully embodied virtual humans are growing in capability, ease, and utility. As a result, they present an opportunity for expanding research into burgeoning virtual patient medical applications. In this paper we consider the ways in which one may go about building and applying virtual human technology to the virtual patient domain. Specifically we aim to show that virtual human technology may be used to help develop the interviewing and diagnostics skills of developing clinicians. Herein we proffer a description of our iterative design process and preliminary results to show that virtual patients may be a useful adjunct to psychotherapy education.},
author = {Kenny, Patrick and Parsons, T and Gratch, Jonathan and Leuski, Anton and Rizzo, A},
booktitle = {Intelligent Virtual Agents (IVA'07)},
editor = {et Al., C. Pelachaud},
file = {::},
keywords = {psychopathology,virtual humans,virtual patients},
pages = {197--210},
publisher = {Springer-Verlag Berlin Heidelberg},
title = {{Virtual patients for clinical therapist skills training}},
url = {http://www.springerlink.com/index/J76642WV61N3R017.pdf},
year = {2007}
}
@article{Yacoub2003,
author = {Yacoub, Sherif and Simske, Steve and Lin, Xiaofan and Burns, John},
file = {::},
journal = {8th European Conference on Speech Communication and Technology},
number = {September},
pages = {1--4},
title = {{Recognition of emotions in interactive voice response systems}},
url = {http://www.isca-speech.org/archive/eurospeech\_2003/e03\_0729.html},
year = {2003}
}
@article{Nasoz2006,
author = {Nasoz, Fatma and Lisetti, Christine L.},
doi = {10.1016/j.jvlc.2006.05.001},
file = {::},
issn = {1045926X},
journal = {Journal of Visual Languages \& Computing},
keywords = {1,affective intelligent user interfaces,considered an independent channel,emotion recognition,emphasized,face in human,human communication has been,in various studies,introduction and motivation,of communica-,the human face is,the importance of human},
month = oct,
number = {5},
pages = {430--444},
title = {{MAUI avatars: Mirroring the user's sensed emotions via expressive multi-ethnic facial avatars}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1045926X06000309},
volume = {17},
year = {2006}
}
@article{Lafrance1976,
author = {Lafrance, Marianne and Broadbent, M.},
doi = {10.1177/105960117600100307},
file = {::},
isbn = {1059601176},
issn = {1059-6011},
journal = {Group \& Organization Management},
month = sep,
number = {3},
pages = {328--333},
title = {{Group Rapport: Posture Sharing as a Nonverbal Indicator}},
volume = {1},
year = {1976}
}
@inproceedings{Dinda2007,
abstract = {Experimental computer systems research typically ignores the end-user, modeling him, if at all, in overly simple ways. We argue that this (1) results in inadequate performance evaluation of the systems, and (2) ignores opportunities. We summarize our experiences with (a) directly evaluating user satisfaction and (b) incorporating user feedback in different areas of client/server computing, and use our experiences to motivate principles for that domain. Specifically, we report on user studies to measure user satisfaction with resource borrowing and with different clock frequencies in desktop computing, the development and evaluation of user interfaces to integrate user feedback into scheduling and clock frequency decisions in this context, and results in predicting user action and system response in a remote display system. We also present initial results on extending our work to user control of scheduling and mapping of virtual machines in a virtualization-based distributed computing environment. We then generalize (a) and (b) as recommendations for incorporating the user into experimental computer systems research.},
address = {New York, USA},
author = {Dinda, Peter A and Dick, Robert P and Rossoff, Samuel},
booktitle = {ExpCS '07 Proceedings of the 2007 workshop on Experimental computer science ACM},
doi = {10.1145/1281700.1281710},
file = {::},
isbn = {9781595937513},
keywords = {Autonomic Systems,Design,Experimentation,Human Directed Adaptation,Human Factors,Measurement,Performance,Speculative Remote Display,User Comfort With Resource Borrowing,User-driven Power Management,User-driven Scheduling},
number = {June},
pages = {1--12},
title = {{The User In Experimental Computer Systems Research}},
url = {http://dl.acm.org/citation.cfm?id=1281710},
year = {2007}
}
@article{LaFrance1982,
abstract = {The relationship between client-perceived rapport (as measured from a standardized client) and physical mirroring and the standard counsellor posture was investigated with interviews performed by 59 post-graduate students (47 females and 12 males, aged 21-60 yrs) in counselling psychology. Videotaped recordings were used to code counsellor posture in the categories of: total postural mirroring, mirroring of the hands and arms, mirroring of the legs, mirroring of the torso, and the frequency of the standard counsellor posture across each minute of the interviews. These minutes were classified as 'high' in rapport or 'low' in rapport as measured by the standardized client. Results indicated that there was significantly more postural mirroring of the torso during high versus low minutes, but that the counsellor standard posture occurred significantly more frequently during low rapport minutes than in high rapport minutes. However, when examined over the entire length of the interviews, these data were able to be understood in terms of counsellor 'flexibility' of response rather than simply whether these postural behaviors were present or not. Implications for counsellor training are discussed. (PsycINFO Database Record (c) 2009 APA},
author = {Lafrance, Marianne},
doi = {10.1080/09515070110088843},
issn = {09515070},
journal = {Counselling Psychology Quarterly},
number = {4},
pages = {267--280},
publisher = {Human Sciences Press},
title = {{Posture mirroring and rapport}},
volume = {14},
year = {1982}
}
@inproceedings{McQuiggan2008,
abstract = {Humans continuously assess one another’s situational context, modify their own affective state, and then respond based on these outcomes through empathetic expression. Virtual agents should be capable of similarly empathizing with users in interactive environments. A key challenge posed by empathetic reasoning in virtual agents is determining whether to respond with parallel or reactive empathy. Parallel empathy refers to mere replication of another’s affective state, whereas reactive empathy exhibits greater cognitive awareness and may lead to incongruent emotional responses (i.e., emotions different from the recipient’s and perhaps intended to alter negative affect). This paper proposes a unified inductive framework for modeling parallel and reactive empathy. Empathy models are used to drive runtime situation-appropriate empathetic behaviors by selecting suitable parallel or reactive empathetic expressions.},
annote = {- No automatic affect detection
- agent demographics are not taken into account.},
author = {McQuiggan, Scott W and Robison, Jennifer and Phillips, Robert},
booktitle = {on Autonomous agents},
file = {::},
number = {Aamas},
pages = {167--174},
title = {{Modeling parallel and reactive empathy in virtual agents: An inductive approach}},
year = {2008}
}
@article{Szymanski2007,
abstract = {The first step towards creating avatars with human-like artificial minds is to give them human-like memory structures with an access to general knowledge about the world. This type of knowledge is stored in semantic memory. Although many approaches to modeling of semantic memories have been proposed they are not very useful in real life applications because they lack knowledge comparable to the common sense that humans have, and they cannot be implemented in a computationally efficient way. The most drastic simplification of semantic memory leading to the simplest knowledge representation that is sufficient for many applications is based on the Concept Description Vectors (CDVs) that store, for each concept, an information whether a given property is applicable to this concept or not. Unfortunately even such simple information about real objects or concepts is not available. Experiments with automatic creation of concept description vectors from various sources, including ontologies, dictionaries, encyclopedias and unstructured text sources are described. Haptek-based talking head that has an access to this memory has been created as an example of a humanized interface (HIT) that can interact with web pages and exchange information in a natural way. A few examples of applications of an avatar with semantic memory are given, including the twenty questions game and automatic creation of word puzzles.},
author = {Szymanski, Julian and Sarnatowicz, Tomasz and Duch, Wlodzislaw},
file = {::},
journal = {Journal of Ubiquitous Computing and Intelligence},
keywords = {avatars,cyberspace,dialogue systems,natural language processing,semantic memory,word games},
title = {{Towards Avatars with Artificial Minds : Role of Semantic Memory}},
url = {http://cogprints.org/5357/},
year = {2007}
}
@article{Pereira2011,
author = {Pereira, A. and Leite, Iolanda and Mascarenhas, Samuel and Martinho, Carlos and Paiva, Ana},
file = {::},
journal = {Human-Robot Personal Relationships},
keywords = {companionship,empathy,human-robot interaction},
pages = {130--138},
publisher = {Springer},
title = {{Using empathy to improve human-robot relationships}},
url = {http://www.springerlink.com/index/R468X62581620V62.pdf},
year = {2011}
}
@article{Orozco2010,
author = {Orozco, H. and Thalmann, Daniel and Ramos, F.},
file = {::},
journal = {Proceedings of 11th Computer Graphics International, CGI},
title = {{Making empathetic virtual humans in human–computer interaction scenarios}},
url = {http://cgi2010.miralab.unige.ch/short/SP09/SP09.pdf},
volume = {10},
year = {2010}
}
@article{Heimendinger2007,
abstract = {The purpose of this article is to report the process outcomes of a coaching methodology used in a study designed to increase fruit and vegetable consumption and physical activity in families. Eighty-eight families with second graders were recruited from a rural, biethnic community in Colorado and randomized to intervention and delayed intervention conditions. This article reports on the 27 families in the delayed intervention group. Families received up to 10 home visits over 10 months from a family advisor and completed activities to improve their dietary and physical activity behaviors. Coaching conversations took place during each home visit. Coaching process outcomes were evaluated by analysis of visit documentation, participant survey, and qualitative interviews. Results indicated that coaching, in conjunction with family activities, engaged families in the process of change and facilitated movement toward the achievement of their weekly nutrition or physical activity goals. Coaching methodology may be particularly useful for participatory research.},
author = {Heimendinger, Jerianne and Uyeki, Terry and Andhara, Aurielle and Marshall, Julie A and Scarbro, Sharon and Belansky, Elaine and Crane, Lori},
institution = {Jerianneb@earthlink.net},
journal = {Health education behavior the official publication of the Society for Public Health Education},
keywords = {colorado,diet,exercise,fruit,health promotion,humans,interviews topic,professional family relations,vegetables},
number = {1},
pages = {71--89},
pmid = {16740515},
title = {{Coaching process outcomes of a family visit nutrition and physical activity intervention.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16740515},
volume = {34},
year = {2007}
}
@article{Cowell2005,
author = {Cowell, Andrew J. and Stanney, Kay M.},
doi = {10.1016/j.ijhcs.2004.11.008},
file = {::},
issn = {10715819},
journal = {International Journal of Human-Computer Studies},
month = feb,
number = {2},
pages = {281--306},
title = {{Manipulation of non-verbal interaction style and demographic embodiment to increase anthropomorphic computer character credibility}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1071581904001260},
volume = {62},
year = {2005}
}
@book{Hoffman2000,
author = {Hoffman, Martin L},
booktitle = {Development},
isbn = {052158034X},
pages = {2},
publisher = {Cambridge University Press},
title = {{Empathy and Moral Development: Implications for Caring and Justice}},
year = {2000}
}
@misc{TheMendeleySupportTeam2011,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/The Mendeley Support Team - 2011 - Getting Started with Mendeley(4).pdf:pdf},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@article{Paiva2000,
author = {Paiva, Ana},
file = {::},
journal = {Affective interactions},
pages = {1--8},
title = {{Affective interactions: toward a new generation of computer interfaces?}},
url = {http://www.springerlink.com/index/826w110p65762167.pdf},
year = {2000}
}
@article{Rebolledo-Mendez2009,
author = {Rebolledo-Mendez, Genaro and Freitas, Sara De and Gaona, Alma Rosa Garcia},
doi = {10.1109/VS-GAMES.2009.33},
file = {::},
isbn = {978-0-7695-3588-3},
journal = {2009 Conference in Games and Virtual Worlds for Serious Applications},
keywords = {- empathy,alma rosa garcia gaona,facultad de inform\'{a}tica,motivation,serious games,universidad veracruzana},
month = mar,
pages = {5--11},
publisher = {Ieee},
title = {{A Model of Motivation Based on Empathy for AI-Driven Avatars in Virtual Worlds}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5116547},
year = {2009}
}
@article{Hatfield2009,
author = {Hatfield, Elaine and Rapson, Richard L. and Le, Yen-Chi L.},
file = {::},
journal = {The social neuroscience of empathy},
pages = {1--20},
title = {{Emotional Contagion and Empathy}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=KLvJKTN\_nDoC\&amp;oi=fnd\&amp;pg=PA19\&amp;dq=Emotional+Contagion+and+Empathy\&amp;ots=gC929Xij3X\&amp;sig=IFpRxpx1igOlZl86Jr837oVgfhY},
year = {2009}
}
@article{Becker2008,
author = {Becker-Asano, Christian and Prendinger, H and Ishizuka, M.},
file = {::},
isbn = {0780390350},
journal = {Data Processing},
keywords = {embodied conversational agents,empa-},
title = {{Empathy for Max}},
url = {http://www.techfak.uni-bielefeld.de/~cbecker/becker-helmut-amt05.pdf},
year = {2008}
}
@article{Pereira2011,
abstract = {For robots to become our personal companions in the future, they need to know how to socially interact with us. One defining charac- teristic of human social behaviour is empathy. In this paper, we present a robot that acts as a social companion expressing different kinds of empathic behaviours through its facial expressions and utterances. The robot comments the moves of two subjects playing a chess game against each other, being empathic to one of them and neutral towards the other. The results of a pilot study suggest that users to whom the robot was empathic perceived the robot more as a friend.},
author = {Pereira, A. and Leite, Iolanda and Mascarenhas, Samuel and Martinho, Carlos and Paiva, Ana},
file = {::},
journal = {Human-Robot Personal Relationships},
keywords = {companionship,empathy,human-robot interaction},
pages = {130--138},
publisher = {Springer},
title = {{Using empathy to improve human-robot relationships}},
url = {http://www.springerlink.com/index/R468X62581620V62.pdf},
volume = {LNICST 59},
year = {2011}
}
@article{Paiva2000,
author = {Paiva, Ana},
file = {::},
journal = {Affective interactions},
pages = {1--8},
title = {{Affective interactions: toward a new generation of computer interfaces?}},
url = {http://www.springerlink.com/index/826w110p65762167.pdf},
year = {2000}
}
@article{Silverman2001,
abstract = {The goal of this research is to determine whether a computer based training game (HEART-SENSE) can improve recognition of heart attack symptoms and shift behavioral issues so as to reduce pre-hospitalization delay in seeking treatment. Since treatment delay correlates with adverse outcomes, this research could reduce myocardial infarction mortality and morbidity. In Phase I we created and evaluated a prototype virtual village in which users encounter and help convince synthetic personas to deal appropriately with a variety of heart attack scenarios and delay issues. Innovations made here are: (1) a design for a generic simulator package for promoting health behavior shifts, and (2) algorithms for animated pedagogical agents to reason about how their emotional state ties to patient condition and user progress. Initial results show that users of the game exhibit a significant shift in intention to call 9-1-1 and avoid delay, that multi-media versions of the game foster vividness and memory retention as well as a better understanding of both symptoms and of the need to manage time during a heart attack event. Also, results provide insight into areas where emotive pedagogical agents help and hinder user performance. Finally, we conclude with next steps that will help improve the game and the field of pedagogical agents and tools for simulated worlds for healthcare education and promotion.},
author = {Silverman, B G and Holmes, J and Kimmel, S and Branas, C and Ivins, D and Weaver, R and Chen, Y},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Silverman et al. - 2001 - Modeling emotion and behavior in animated personas to facilitate human behavior change the case of the HEART-SENSE game(4).pdf:pdf},
issn = {1386-9620},
journal = {Health care management science},
keywords = {Algorithms,Behavior Therapy,Computer Simulation,Computer-Assisted Instruction,Emotions,Experimental,Games,Humans,Models,Myocardial Infarction,Myocardial Infarction: diagnosis,Myocardial Infarction: physiopathology,Myocardial Infarction: psychology,Patient Acceptance of Health Care,Patient Acceptance of Health Care: psychology,Psychological,Software,United States},
month = sep,
number = {3},
pages = {213--28},
pmid = {11519847},
title = {{Modeling emotion and behavior in animated personas to facilitate human behavior change: the case of the HEART-SENSE game.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11519847},
volume = {4},
year = {2001}
}
@book{Halliday1977,
author = {Halliday, Michael Alexander Kirkwood},
publisher = {Elsevier North-Holland},
title = {{Explorations in the functions of language}},
year = {1977}
}
@inproceedings{Vertegaal2003,
abstract = {GAZE-2 is a novel group video conferencing system that uses eye-controlled camera direction to ensure parallax- free transmission of eye contact. To convey eye contact, GAZE-2 employs a video tunnel that allows placement of cameras behind participant images on the screen. To avoid parallax, GAZE-2 automatically directs the cameras in this video tunnel using an eye tracker, selecting a single camera closest to where the user is looking for broadcast. Images of users are displayed in a virtual meeting room, and rotated towards the participant each user looks at. This way, eye contact can be conveyed to any number of users with only a single video stream per user. We empirically evaluated whether eye contact perception is affected by automated camera direction, which causes angular shifts in the transmitted images. Findings suggest camera shifts do not affect eye contact perception, and are not considered highly distractive.},
address = {Fort Lauderdale, Florida, USA},
author = {Vertegaal, Roel and Weevers, Ivo and Sohn, Changuk and Cheung, Chris},
booktitle = {SIGCHI Conference on Human Factors in Computing Systems (CHI'03)},
file = {::},
isbn = {1581136307},
keywords = {attentive user interfaces,conferencing,eye contact,eye tracking,gaze,multiparty video},
number = {5},
pages = {521--528},
publisher = {ACM Press},
title = {{GAZE-2: conveying eye contact in group video conferencing using eye-controlled camera direction}},
url = {http://dl.acm.org/citation.cfm?id=642702},
year = {2003}
}
@article{Stockwell1983,
author = {Stockwell, T and Murphy, D and Hodgson, R},
journal = {British journal of addiction},
number = {2},
pages = {145--155},
pmid = {6135435},
title = {{The severity of alcohol dependence questionnaire: its use, reliability and validity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/6135435},
volume = {78},
year = {1983}
}
@article{Davidson1986,
author = {Davidson, R and Raistrick, D},
journal = {British journal of addiction},
keywords = {adolescent,adult,age factors,aged,alcoholism,humans,middle aged,questionnaires,self disclosure},
number = {2},
pages = {217--222},
pmid = {3458489},
title = {{The validity of the Short Alcohol Dependence Data (SADD) Questionnaire: a short self-report questionnaire for the assessment of alcohol dependence.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/3458489},
volume = {81},
year = {1986}
}
@inproceedings{Broek2005,
abstract = {A new view on empathic agents is introduced, named: Empathic Agent Technology (EAT). It incorporates a speech analysis, which provides an indication for the amount of tension present in people. It is founded on an indirect physiological measure for the amount of experienced stress, defined as the variability of the fundamental frequency of the human voice. A thorough review of literature is provided on which the EAT is founded. In addition, the complete processing line of this measure is introduced. Hence, the first generally applicable, completely automated technique is introduced that enables the development of truly empathic agents.},
address = {Utrecht – The Netherlands},
author = {van den Broek, E. L.},
booktitle = {Proceedings of the AAMAS-05 Agent-Based Systems for Human Learning workshop (ABSHL 2005)},
editor = {Johnson, L. and Richards, D. and Sklar, E. and Wilensky, U.},
file = {::},
keywords = {affect,agents,emotion,empathy,fundamental frequency,pitch,speech,stress},
pages = {59--67},
publisher = {Brooklyn College},
title = {{Empathic agent technology}},
url = {http://eprints.eemcs.utwente.nl/21142/},
year = {2005}
}
@article{Jacob2011,
author = {Jacob, Pierre},
doi = {10.1007/s13164-011-0065-0},
file = {::},
issn = {1878-5158},
journal = {Review of Philosophy and Psychology},
month = aug,
number = {August},
pages = {519--540},
title = {{The Direct-Perception Model of Empathy: a Critique}},
url = {http://www.springerlink.com/index/10.1007/s13164-011-0065-0},
year = {2011}
}
@article{Ward2000,
abstract = {Back-channel feedback, responses such as uh-uh from a listener, is a pervasive feature of conversation. It has long been thought that the production of back-channel feedback depends to a large extent on the actions of the other conversation partner, not just on the volition of the one who produces them. In particular, prosodic cues from the speaker have long been thought to play a role, but have so far eluded identification. We have earlier suggested that an important prosodic cue involved, in both English and Japanese, is a region of low pitch late in an utterance (Ward, 1996). This paper discusses issues in the definition of back-channel feedback, presents evidence for our claim, surveys other factors which elicit or inhibit back-channel responses, and mentions a few related phenomena and theoretical issues. (C) 2000 Elsevier Science B.V. All rights reserved.},
author = {Ward, Nigel and Tsukahara, Wataru},
doi = {10.1016/S0378-2166(99)00109-5},
issn = {03782166},
journal = {Journal of Pragmatics},
number = {8},
pages = {1177--1207},
publisher = {Elsevier},
title = {{Prosodic features which cue back-channel responses in English and Japanese}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0378216699001095},
volume = {32},
year = {2000}
}
@article{Deehan1998,
abstract = {The appropriateness of the primary care setting to undertake the health promotional activities needed to meet 'Health of the Nation' alcohol targets has been acknowledged in UK government policy and the scientific literature. However, the latest data suggest these targets are not being met. A 20\% random sample of all general practitioners in England and Wales were surveyed by postal questionnaire to examine their work in detecting alcohol misuse and their attitudes towards the work. Four mailing waves produced a 44\% response rate. GPs had identified a mean of 3.2 patients per month drinking above recommended 'sensible' guidelines. These patients were mostly male (73\%) and above 40 years of age (45\%), with nearly half (45\%) already dependent drinkers. Most GPs perceived alcohol misuse patients as a difficult group with whom to work. None the less, over half the respondents believed general practice was an appropriate setting for the detection of the problem. However, most did not feel trained or supported in this area of their work. More emphasis needs to be placed on the valuable contribution GPs can make with the larger number of patients who are drinking regularly above 'sensible' levels but not yet suffering adverse affects. Our findings point towards not an unwilling profession, but a profession lacking confidence. The provision of support and basic training are major factors in how GPs perceive alcohol misusers and their own role in this work. Twenty years after the Maudsley Alcohol Pilot Project research it is disappointing that, despite greater recognition by GPs of their potential impact, lack of training and lack of support are still so central to their continued low levels of therapeutic commitment.},
author = {Deehan, A and Templeton, L and Taylor, C and Drummond, C and Strang, J},
journal = {Drug and Alcohol Review},
number = {3},
pages = {249--258},
title = {{Low detection rates, negative attitudes and the failure to meet the "Health of the Nation" alcohol targets: findings from a national survey of GPs in England and Wales}},
volume = {17},
year = {1998}
}
@article{Hogan1969,
author = {Hogan, R},
file = {::},
issn = {0022-006X},
journal = {Journal of consulting and clinical psychology},
keywords = {Emotions,Humans,MMPI,Morals,Personality Assessment,Personality Inventory,Social Behavior,Social Perception,Social Values,Socialization},
month = jun,
number = {3},
pages = {307--16},
pmid = {4389335},
title = {{Development of an empathy scale.}},
volume = {33},
year = {1969}
}
@incollection{Creed2008,
abstract = {Why do computers need emotional intelligence? Science fiction often portrays emotional computers as dangerous and frightening, and as a serious threat to human life. One of the most famous examples is HAL, the supercomputer onboard the spaceship Discovery, in the movie 2001: A Space Odyssey. HAL could express, recognize and respond to human emotion, and generally had strong emotional skills — the consequences of which were catastrophic. However, since the movie’s release almost 40 years ago, the traditional view of emotions as contributing to irrational and unpredictable behavior has changed. Recent research has suggested that emotions play an essential role in important areas such as learning, memory, motivation, attention, creativity, and decision making. These findings have prompted a large number of research groups around the world to start examining the role of emotions and emotional intelligence in human-computer interaction (HCI). For almost half a century, computer scientists have been attempting to build machines that can interact intelligently with us, and despite initial optimism, they are still struggling to do so. For much of this time, the role of emotion in developing intelligent computers was largely overlooked, and it is only recently that interest in this area has risen dramatically. This increased interest can largely be attributed to the work of [6] and [85] who were amongst the first to bring emotion to the attention of computer scientists. The former highlighted emotion as a fundamental component required in building believable agents, while the latter further raised the awareness of emotion and its potential importance in HCI. Since these publications, the literature on emotions and computing has grown considerably with progress being made on a number of different fronts.},
author = {Creed, Chris and Beale, Russell},
booktitle = {Computational Intelligence: A Compendium},
doi = {10.1007/978-3-540-78293-3},
editor = {Fulcher, John and Jain, L. C.},
file = {::},
isbn = {978-3-540-78292-6},
pages = {185--230},
publisher = {Springer Berlin / Heidelberg},
title = {{Emotional Intelligence: Giving Computers Effective Emotional Skills to Aid Interaction}},
url = {http://www.springerlink.com/index/U2231064587Q8V07.pdf},
volume = {230},
year = {2008}
}
@inproceedings{Gratch2007,
abstract = {Emotional bonds don’t arise from a simple exchange of facial displays, but often emerge through the dynamic give and take of face-to-face interactions. This article explores the phenome- non of rapport, a feeling of connectedness that seems to arise from rapid and contingent positive feedback between partners and is often associated with socio-emotional processes. Rapport has been argued to lead to communicative efficiency, better learning outcomes, improved acceptance of medical advice and successful negotiations. We provide experimental evidence that a simple vir- tual character that provides positive listening feedback can induce stronger rapport-like effects than face-to-face communication between human partners. Specifically, this interaction can be more en- gaging to storytellers than speaking to a human audience, as measured by the length and content of their stories.},
annote = {They explore the rapport, a feeling of connectedness that arises from rapid and contingent positive feedback between partners and is often associated with socio-emotional processes. Rapport can lead to communicative efficiency, better learning outcomes, improved acceptance of medical advice and successful negotiations.
They experimentally proved that a simple virtual character with positive listening feedback can induce stronger rapport-like effects than face-to-face communication between human partners.},
author = {Gratch, Jonathan and Wang, Ning and Okhmatovskaia, Anna},
booktitle = {12th International Conference on Human-Computer Interaction},
file = {::},
keywords = {ECA,engagement,virtual human},
publisher = {Springer},
title = {{Can virtual humans be more engaging than real ones?}},
url = {http://dl.acm.org/citation.cfm?id=1769622},
year = {2007}
}
@article{Straalen2009,
author = {Straalen, Bart Van and Heylen, Dirk and Theune, Mari\"{e}t},
file = {::},
journal = {Agents for Games and},
keywords = {bad news con-,embodied conversational agents,empathy,social agents,tutoring,versations},
pages = {95--106},
title = {{Enhancing Embodied Conversational Agents with Social and Emotional Capabilities}},
url = {http://www.springerlink.com/index/3612181747K5L570.pdf},
year = {2009}
}
@book{Hojat2007,
author = {Hojat, M.},
booktitle = {Patient Care},
file = {::},
isbn = {9780387336077},
publisher = {Springer Verlag},
title = {{Empathy in patient care: antecedents, development, measurement, and outcomes}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=OZT1sypBp5EC\&amp;oi=fnd\&amp;pg=PR7\&amp;dq=Empathy+In+Patient+Care:+Antecedents,+Development,+Measurements,+and+Outcomes\&amp;ots=8aQbxTclHN\&amp;sig=HFiEPtCVpFvXI6HU3rprIwvHGXc},
year = {2007}
}
@article{Campbell2005,
author = {Campbell, K.S.},
doi = {10.1109/IPCC.2005.1494206},
file = {::},
isbn = {0-7803-9027-X},
journal = {IPCC 2005. Proceedings. International Professional Communication Conference, 2005.},
keywords = {communication,face-to-face interaction,health,medical interviews,sociolinguistics,verbal communication},
pages = {422--432},
publisher = {Ieee},
title = {{The rapport management model: how physicians build relationships with patients}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1494206},
year = {2005}
}
@article{Termine1988,
author = {Termine, NT},
file = {::},
journal = {Developmental Psychology},
number = {2},
pages = {223--229},
title = {{Infants' responses to their mothers'; expressions of joy and sadness}},
volume = {24},
year = {1988}
}
@article{Creed2008,
author = {Creed, Chris and Beale, Russell},
file = {::},
journal = {Computational Intelligence: A Compendium},
pages = {185--230},
publisher = {Springer},
title = {{Emotional Intelligence: Giving Computers Effective Emotional Skills to Aid Interaction}},
url = {http://www.springerlink.com/index/U2231064587Q8V07.pdf},
volume = {230},
year = {2008}
}
@article{Poh2010,
author = {Poh, MZ and McDuff, DJ},
file = {::},
journal = {Optics Express},
number = {10},
pages = {10762--10774},
title = {{Non-contact, automated cardiac pulse measurements using video imaging and blind source separation}},
volume = {18},
year = {2010}
}
@inproceedings{Legaspi2008,
author = {Legaspi, Roberto and Kurihara, Satoshi and Fukui, K.I. and Moriyama, Koichi and Numao, Masayuki},
booktitle = {Human system interactions, 2008 conference on},
file = {::},
isbn = {1424415438},
keywords = {empathic computing,interfaces,machine learning,user modeling and user-adaptive},
pages = {209--214},
publisher = {IEEE},
title = {{An empathy learning problem for HSI: To be empathic, self-improving and ambient}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4581435},
year = {2008}
}
@article{Drolet2000,
abstract = {We propose that face-to-face contact fosters the development of rapport and thereby helps negotiators coordinate on mutually beneficial settlements in mixed-motive conflicts. Specifically, we investigate whether, in a cooperative climate, negotiators visual access to each others nonverbal behavior fosters a dyadic state of rapport that facilitates mutual cooperation. Experiment 1 manipulated whether negotiators stood face-to-face or side-by- side (unable to see each other) in a simulated strike negotiation. Face-to-face dyads were more likely to coordinate on a settlement early in the strike, resulting in higher joint gains. An alternative interpretation in terms of an anticipatory effect of face-to-face contact was not supported. Experiment 2 manipulated whether previously unacquainted negotiators conversed face-to-face or by telephone before separating to play a conflict game with the structure of a Prisoners Dilemma game. Face-to-face dyads were more likely to coordinate on high joint gain outcomes. The facilitatory effect of face-to-face contact was statistically mediated by ameasure of dyadic rapport. Results did not support alternative interpretations based on individual-level positive affect or expectations about opponents. We conclude with a discussion of the role of affective and dyad-level processes in social psychological models of conflict resolution.},
author = {Drolet, Aimee L and Morris, Michael W},
doi = {10.1006/jesp.1999.1395},
issn = {00221031},
journal = {Journal of Experimental Social Psychology},
number = {1},
pages = {26--50},
publisher = {ACADEMIC PRESS INC},
title = {{Rapport in Conflict Resolution: Accounting for How Face-to-Face Contact Fosters Mutual Cooperation in Mixed-Motive Conflicts}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0022103199913951},
volume = {36},
year = {2000}
}
@inproceedings{Nguyen2009,
abstract = {Experiencing emotional distress is the number one reason why people who are undergoing behaviour modification (e.g. quitting smoking, dieting) suffer from relapses. Providing emotional support is an effective way to help them overcome the unpleasant effects of negative affect and adhere to their regimen. Building computers with such ability has grabbed the attention of the HCI community in recent years. This paper presents the results of a 2 (modality: animated vs. no visual) by 3 (intervention: non-empathy vs. empathy vs. empathy and expressivity) between-subjects study that investigates the impact of two important factors and their interaction in the design of such systems: (1) different ways of expressing empathy, and (2) the modality of delivering such content.},
annote = {They investigate: 
1-      Different ways of expressing empathy 
2-      Modality of delivering such content. 
        
They define empathy as the ability to detect what others feel and to experience that emotion ourselves (seems like mimicry).
        
Empirical evidence indicates that expressing accurate empathy can lead to positive psychological, physical and health outcomes.
        
Their results show: 
1. The positive attitude of the users toward active support (active empathy). 
2.  The positive outcome of an empathic system regardless of its representation. 
3.  A system represented by a human-like representation is expected to be empathic.
        
they believe, adding a mechanism to allow the users to freely express themselves does not improve the effectiveness or liking of an empathic system.
      },
author = {Nguyen, H. and Masthoff, Judith},
booktitle = {Proceedings of the 4th International Conference on Persuasive Technology},
file = {::},
isbn = {9781605583761},
keywords = {affective computing,design,experimentation,human factors},
pages = {7},
publisher = {ACM},
title = {{Designing empathic computers: the effect of multimodal empathic feedback using animated agent}},
url = {http://portal.acm.org/citation.cfm?id=1541958},
year = {2009}
}
@article{McClave2000,
abstract = {Speaker head movements pattern predictably and have semantic, discourse, and communicative functions. Some head movements convey propositional content, while others carry semantic meanings beyond affirmation and negation. Side-to-side shakes correlate with expressions of inclusivity and intensification. Lateral movements also co-occur with uncertain statements and lexical repairs. In narration, head movements serve to locate referents in abstract space. A change in head posture marks switches between direct and indirect discourse, and speaker head nods function as backchannel requests to which listeners are extraordinarily sensitive. These findings are based on the microanalysis of videotaped conversations between native speakers of American English.},
author = {McClave, Evelyn Z},
doi = {10.1016/S0378-2166(99)00079-X},
issn = {03782166},
journal = {Journal of Pragmatics},
keywords = {ameri,backchannel,gesture,head movements,kinesic,nonverbal,speech},
number = {7},
pages = {855--878},
publisher = {Elsevier},
title = {{Linguistic functions of head movements in the context of speech}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S037821669900079X},
volume = {32},
year = {2000}
}
@article{Meng2009,
author = {Meng, Qinggang and Lee, Mark},
doi = {10.1109/CASE.2009.156},
file = {::},
isbn = {978-0-7695-3728-3},
journal = {2009 IITA International Conference on Control, Automation and Systems Engineering (case 2009)},
keywords = {-home service robots,human-robot interaction},
month = jul,
pages = {220--224},
publisher = {Ieee},
title = {{Empathy between Human and Home Service Robots}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5194430},
year = {2009}
}
@book{Miller1995,
author = {Miller, WR and Tonigan, JS},
booktitle = {Project MATCH Monograph Series},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Miller, Tonigan - 1995 - The drinker inventory of consequences (DrInC).pdf:pdf},
keywords = {National Institutes of Health},
mendeley-tags = {National Institutes of Health},
title = {{The drinker inventory of consequences (DrInC)}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:the+drinker+inventory+of+consequences+DrInC\#1},
year = {1995}
}
@inproceedings{Fabri2007,
abstract = {We present our work on emotionally expressive avatars, animated virtual characters that can express emotions via facial expressions. Because these avatars are highly distinctive and easily recognizable, they may be used in a range of applications. In the first part of the paper we present their use in computer mediated communication where two or more people meet in virtual space, each represented by an avatar. Study results suggest that social interaction behavior from the real-world is readily transferred to the virtual world. Empathy is identified as a key component for creating a more enjoyable experience and greater harmony between users. In the second part of the paper we discuss the use of avatars as an assistive, educational and therapeutic technology for people with autism. Based on the results of a preliminary study, we provide pointers regarding how people with autism may overcome some of the limitations that characterize their condition.},
address = {Beijing, China},
author = {Fabri, Marc and Elzouki, SYA},
booktitle = {Human-Computer Interaction, HCI Intelligent Multimodal Interaction Environments 12th International Conference},
doi = {10.1007/978-3-540-73110-8},
editor = {Jacko, Julie A.},
file = {::},
keywords = {Emotion,autism,avatar,education,empathy,facial messaging,therapeutic intervention,virtual reality},
pages = {275--285},
publisher = {Springer Berlin / Heidelberg},
title = {{Emotionally expressive avatars for chatting, learning and therapeutic intervention}},
url = {http://dl.acm.org/citation.cfm?id=1769621 http://www.springerlink.com/content/7gju6n38605hp3h2/},
year = {2007}
}
@inproceedings{Pulman2010,
abstract = {We describe a ‘How was your day?’ (HWYD) Companion whose purpose is to establish a comforting and supportive rela- tionship with a user via a conversation on a variety of work-related topics. The sys- tem has several fairly novel features aimed at increasing the naturalness of the interac- tion: a rapid ‘short loop’ response primed by the results of acoustic emotion anal- ysis, and an ‘interruption manager’, en- abling the user to interrupt lengthy or ap- parently inappropriate system responses, prompting a replanning of behaviour on the part of the system. The ‘long loop’ also takes into account the emotional state of the user, but using more conventional dialogue management and planning tech- niques. We describe the architecture and components of the implemented prototype HWYD system.},
address = {Uppsala, Sweden},
author = {Pulman, S G and Boye, J and Cavazza, M and Smith, C},
booktitle = {Proceedings of the 2010 Workshop on Companionable Dialogue Systems, ACL 2010},
file = {::},
number = {July},
pages = {37--42},
publisher = {Association for Computational Linguistics},
title = {{‘ How was your day ?’}},
year = {2010}
}
@article{Niewiadomski2008,
author = {Niewiadomski, Radoslaw and Ochs, Magalie},
file = {::},
journal = {Intelligent Virtual Agents},
keywords = {eca,empathy,facial expressions},
pages = {37--44},
title = {{Expressions of empathy in ECAs}},
url = {http://www.springerlink.com/index/618982507263X720.pdf},
year = {2008}
}
@article{Scherer2005,
abstract = {Defining emotion is a notorious problem. Without consensual conceptualization and operationalization of exactly what phenomenon is to be studied, progress in theory and research is difficult to achieve and fruitless debates are likely to proliferate. A particularly unfortunate example is William Jamess asking the question What is an emotion? when he really meant feeling, a misnomer that started a debate which is still ongoing, more than a century later. This contribution attempts to sensitize researchers in the social and behavioral sciences to the importance of definitional issues and their consequences for distinguishing related but fundamentally different affective processes, states, and traits. Links between scientific and folk concepts of emotion are explored and ways to measure emotion and its components are discussed.},
author = {Scherer, Klaus R.},
doi = {10.1177/0539018405058216},
issn = {05390184},
journal = {Social Science Information},
keywords = {affective processes,emotion,feeling,folk concepts emotion,measurement emotion,scientific concepts emotion},
number = {4},
pages = {695--729},
publisher = {Sage Publications},
title = {{What are emotions? And how can they be measured?}},
url = {http://ssi.sagepub.com/cgi/doi/10.1177/0539018405058216},
volume = {44},
year = {2005}
}
@article{Taigman2011,
archivePrefix = {arXiv},
arxivId = {arXiv:1108.1122v1},
author = {Taigman, Yaniv and Wolf, Lior},
eprint = {arXiv:1108.1122v1},
file = {::},
journal = {Arxiv preprint arXiv:1108.1122},
number = {view 2},
pages = {1--7},
title = {{Leveraging Billions of Faces to Overcome Performance Barriers in Unconstrained Face Recognition}},
volume = {1},
year = {2011}
}
@article{Albrecht2005,
abstract = {We present an algorithm for generating facial expressions for a continuum of pure and mixed emotions of varying intensity. Based on the observation that in natural interaction among humans, shades of emotion are much more frequently encountered than expressions of basic emotions, a method to generate more than Ekman's six basic emotions (joy, anger, fear, sadness, disgust and surprise) is required. To this end, we have adapted the algorithm proposed by Tsapatsoulis et al. [1] to be applicable to a physics-based facial animation system and a single, integrated emotion model. A physics-based facial animation system was combined with an equally flexible and expressive text-to-speech synthesis system, based upon the same emotion model, to form a talking head capable of expressing non-basic emotions of varying intensities. With a variety of life-like intermediate facial expressions captured as snapshots from the system we demonstrate the appropriateness of our approach.},
author = {Albrecht, Irene and Schr\"{o}der, Marc and Haber, J\"{o}rg and Seidel, Hans-Peter},
doi = {10.1007/s10055-005-0153-5},
file = {::},
issn = {1359-4338},
journal = {Virtual Reality},
keywords = {continuous emotions \ae emotional,speech,synthesis \ae facial animation},
month = aug,
number = {4},
pages = {201--212},
title = {{Mixed feelings: expression of non-basic emotions in a muscle-based talking head}},
url = {http://www.springerlink.com/index/10.1007/s10055-005-0153-5},
volume = {8},
year = {2005}
}
@article{Saunier2010,
author = {Saunier, Julien and Jones, Hazael and Lourdeaux, Domitile},
doi = {10.1109/WI-IAT.2010.255},
file = {::},
isbn = {978-1-4244-8482-9},
journal = {2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology},
keywords = {emotions,empathy,multi-agent architecture,personality,placebo},
month = aug,
pages = {277--282},
publisher = {Ieee},
title = {{Empathy and Placebo for Autonomous Agents}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5616059},
year = {2010}
}
@article{Lien1998,
author = {Lien, James J and Cohn, Jeffrey F and Kanade, Takeo and Li, Ching-Chung},
file = {::},
journal = {IEEE Proceedings of FG'98},
title = {{Automated Facial Expression Recognition Based on FACS Action Units University of Pittsburgh Takeo Kanade Vision and Autonomous Systems Center Ching-Chung Li}},
year = {1998}
}
@article{Hine2009,
author = {Hine, Michael J. and Murphy, Steven a. and Weber, Michael and Kersten, Gregory},
doi = {10.1007/s10726-008-9151-9},
file = {::},
issn = {0926-2644},
journal = {Group Decision and Negotiation},
keywords = {computer mediated communication,electronic negotiation,emotion,logistic regression},
month = jan,
number = {3},
pages = {193--211},
title = {{The Role of Emotion and Language in Dyadic E-negotiations}},
url = {http://www.springerlink.com/index/10.1007/s10726-008-9151-9},
volume = {18},
year = {2009}
}
@article{Russell2003,
abstract = {A flurry of theoretical and empirical work concerning the production of and response to facial and vocal expressions has occurred in the past decade. That emotional expressions express emotions is a tautology but may not be a fact. Debates have centered on universality, the nature of emotion, and the link between emotions and expressions. Modern evolutionary theory is informing more models, emphasizing that expressions are directed at a receiver, that the interests of sender and receiver can conflict, that there are many determinants of sending an expression in addition to emotion, that expressions influence the receiver in a variety of ways, and that the receiver's response is more than simply decoding a message.},
author = {Russell, James a and Bachorowski, Jo-Anne and Fernandez-Dols, Jose-Miguel},
doi = {10.1146/annurev.psych.54.101601.145102},
file = {::},
issn = {0066-4308},
journal = {Annual review of psychology},
keywords = {Emotions,Expressed Emotion,Facial Expression,Humans,Interpersonal Relations,Nonverbal Communication,Personal Construct Theory,Social Perception,Speech Acoustics},
month = jan,
pages = {329--49},
pmid = {12415074},
title = {{Facial and vocal expressions of emotion.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12415074},
volume = {54},
year = {2003}
}
@incollection{Ekman1979,
author = {Ekman, Paul},
booktitle = {Human Ethology},
chapter = {3},
editor = {Cranach, M. Von and Foppa, K. and Lepenies, W. and Ploog, D.},
file = {::},
pages = {169--249},
publisher = {Cambridge University Press},
title = {{About-Brows-Emotional-And-Conversational-Signals.pdf}},
year = {1979}
}
@book{Prendinger2004,
author = {Prendinger, Helmut and Ishizuka, M.},
editor = {Prendinger, Helmut and Ishizuka, M.},
publisher = {Springer Berlin / Heidelberg},
title = {{Life-Like Characters. Cognitive Technologies}},
year = {2004}
}
@inproceedings{Neviarouskaya2007,
abstract = {In this paper, we address the tasks of recognition and interpretation of affect communicated through text messaging. The evolving nature of language in online conversations is a main issue in affect sensing from this media type, since sentence parsing might fail while syntactical structure analysis. The developed Affect Analysis Model was designed to handle not only correctly written text, but also informal messages written in abbreviated or expressive manner. The proposed rule-based approach processes each sentence in sequential stages, including symbolic cue processing, detection and transformation of abbreviations, sentence parsing, and word/phrase/sentence-level analyses. In a study based on 160 sentences, the system result agrees with at least two out of three human annotators in 70\% of the cases. In order to reflect the detected affective information and social behaviour, an avatar was created.},
address = {Lisbon, Portugal},
author = {Neviarouskaya, Alena and Prendinger, Helmut and Ishizuka, Mitsuru},
booktitle = {2nd International Conference in Affective Computing and Intelligent Interaction (ACII)},
editor = {Paiva, Ana and Prada, R. and Picard, Rosalind W},
file = {::},
keywords = {affective sensing from text,affective user interface,avatar,emotions,language parsing and understanding,online communication,text analysis},
pages = {220--231},
publisher = {Springer-Verlag Berlin Heidelber},
title = {{Textual Affect Sensing for Sociable and Expressive Online Communication}},
year = {2007}
}
@article{Chung,
author = {Chung, Donghun and DeBuys, B. and Nam, C.},
file = {::},
journal = {Human-Computer Interaction. Interaction Design and Usability},
keywords = {attitude,avatar,empathy,para-social interaction,presence,wii},
pages = {711--720},
publisher = {Springer},
title = {{Influence of avatar creation on attitude, empathy, presence, and para-social interaction}},
url = {http://www.springerlink.com/index/9518116J51670433.pdf},
year = {2007}
}
@inproceedings{Mulder2004,
abstract = {In this paper we report about our research towards the use of affect in language wherein we have attempted to formalise the affective functionality at word and grammatical level for a fraction of Dutch and English. These formalisations have been demonstrated in a pilot experiment. The empirical background of the formalisation, and the results of the experiment constitute the basis for further research on a lexical, grammatical implementation of affect.},
author = {Mulder, Matthijs and Nijholt, Anton and {Den Uyl}, Marten and Terpstra, Peter},
booktitle = {Proceedings of the 7th International Conference Text Speech and Dialogue TSD04},
pages = {171--178},
publisher = {Springer-Verlag},
series = {Lecture Notes in Computer Science},
title = {{A Lexical Grammatical Implementation of Affect}},
url = {http://wwwhome.cs.utwente.nl/~anijholt/artikelen/tsd2004.pdf},
volume = {3206},
year = {2004}
}
@misc{TheMendeleySupportTeam2011,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/The Mendeley Support Team - 2011 - Getting Started with Mendeley(4).pdf:pdf},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@inproceedings{Kang2008a,
author = {Kang, Sin-hwa and Gratch, Jonathan and Wang, Ning and Watt, J.},
booktitle = {Intelligent Virtual Agents},
file = {::},
keywords = {evaluation,nonverbal feedback,personality,rapport,virtual agents},
pages = {253--261},
publisher = {Springer},
title = {{Agreeable people like agreeable virtual humans}},
url = {http://www.springerlink.com/index/DT61V8556710VW13.pdf},
year = {2008}
}
@article{Hess1998,
author = {Hess, Ursula and Philippot, Pierre and Blairy, Sylvie},
doi = {10.1080/026999398379547},
file = {::},
issn = {0269-9931},
journal = {Cognition \& Emotion},
month = jul,
number = {4},
pages = {509--531},
title = {{Facial Reactions to Emotional Facial Expressions: Affect or Cognition?}},
url = {http://www.tandfonline.com/doi/abs/10.1080/026999398379547},
volume = {12},
year = {1998}
}
@article{Grahe1999,
author = {Grahe, JE},
file = {::},
journal = {Journal of Nonverbal behavior},
number = {4},
pages = {253--269},
title = {{The importance of nonverbal cues in judging rapport}},
url = {http://www.springerlink.com/index/V8U30855W38M4673.pdf},
volume = {23},
year = {1999}
}
@inproceedings{Nguyen2009,
abstract = {Experiencing emotional distress is the number one reason why people who are undergoing behaviour modification (e.g. quitting smoking, dieting) suffer from relapses. Providing emotional support is an effective way to help them overcome the unpleasant effects of negative affect and adhere to their regimen. Building computers with such ability has grabbed the attention of the HCI community in recent years. This paper presents the results of a 2 (modality: animated vs. no visual) by 3 (intervention: non-empathy vs. empathy vs. empathy and expressivity) between-subjects study that investigates the impact of two important factors and their interaction in the design of such systems: (1) different ways of expressing empathy, and (2) the modality of delivering such content.},
annote = {They investigate: 
1-      Different ways of expressing empathy 
2-      Modality of delivering such content. 
        
They define empathy as the ability to detect what others feel and to experience that emotion ourselves (seems like mimicry).
        
Empirical evidence indicates that expressing accurate empathy can lead to positive psychological, physical and health outcomes.
        
Their results show: 
1. The positive attitude of the users toward active support (active empathy). 
2.  The positive outcome of an empathic system regardless of its representation. 
3.  A system represented by a human-like representation is expected to be empathic.
        
they believe, adding a mechanism to allow the users to freely express themselves does not improve the effectiveness or liking of an empathic system.
      },
author = {Nguyen, H. and Masthoff, Judith},
booktitle = {Proceedings of the 4th International Conference on Persuasive Technology},
file = {::},
isbn = {9781605583761},
keywords = {affective computing,design,experimentation,human factors},
publisher = {ACM},
title = {{Designing empathic computers: the effect of multimodal empathic feedback using animated agent}},
year = {2009}
}
@article{Bickmore2005,
abstract = {This research investigates the meaning of “human-computer relationship” and presents techniques for constructing, maintaining, and evaluating such relationships, based on research in social psychology, sociolinguistics, communication and other social sciences. Contexts in which relationships are particularly important are described, together with specific benefits (like trust) and task outcomes (like improved learning) known to be associated with relationship quality. We especially consider the problem of designing for long-term interaction, and define relational agents as computational artifacts designed to establish and maintain long-term social-emotional relationships with their users. We construct the first such agent, and evaluate it in a controlled experiment with 101 users who were asked to interact daily with an exercise adoption system for a month. Compared to an equivalent task-oriented agent without any deliberate social-emotional or relationship-building skills, the relational agent was respected more, liked more, and trusted more, even after four weeks of interaction. Additionally, users expressed a significantly greater desire to continue working with the relational agent after the termination of the study. We conclude by discussing future directions for this research together with ethical and other ramifications of this work for HCI designers.},
author = {Bickmore, Timothy W. and {Rosalind W. Picard}},
doi = {10.1145/1067860.1067867},
file = {::},
journal = {ACM Transactions on Computer-Human Interaction (TOCHI)},
keywords = {Human-computer interaction,embodied conversational agent,relational agent,social interface},
number = {2},
pages = {617--638},
title = {{Establishing and maintaining long-term human-computer relationships}},
url = {http://dl.acm.org/citation.cfm?id=1067860.1067867},
volume = {12},
year = {2005}
}
@article{Dada2006,
abstract = {Images: p1372-a:},
author = {Dada, Michael},
journal = {Journal of the National Medical Association},
number = {8},
pages = {1372},
publisher = {Motivate Healthy Habits},
title = {{Motivational Practice: Promoting Healthy Habits and Self-Care of Chronic Diseases}},
volume = {98},
year = {2006}
}
@article{Blairy1999,
abstract = {Lipps (1907) presented a model of empathy which had an important influence on later formulations. According to Lipps, individuals tend to mimic an interaction partner's behavior, and this nonverbal mimicry induces—via a feedback process—the corresponding affective state in the observer. The resulting shared affect is believed to foster the understanding of the observed person's self. The present study tested this model in the context of judgments of emotional facial expressions. The results confirm that individuals mimic emotional facial expressions, and that the decoding of facial expressions is accompanied by shared affect. However, no evidence that emotion recognition accuracy or shared affect are mediated by mimicry was found. Yet, voluntary mimicry was found to have some limited influence on observer' s assessment of the observed person's personality. The implications of these results with regard to Lipps' original hypothesis are discussed.},
author = {Blairy, Sylvie and Herrera, Pedro and Hess, Ursula},
doi = {10.1023/A:1021370825283},
file = {::},
journal = {Journal of Nonverbal Behavior},
number = {1},
pages = {5--41},
title = {{Mimicry and the Judgment of Emotional Facial Expressions}},
url = {http://www.springerlink.com/content/unx02r46695w7651/ http://dx.doi.org/10.1023/A:1021370825283},
volume = {23},
year = {1999}
}
@book{Leigh2006,
author = {Leigh, R. John and Zee, David S.},
edition = {4},
isbn = {0195300904, 9780195300901},
publisher = {Oxford University Press},
title = {{The neurology of eye movements}},
year = {2006}
}
@article{Jacob2011,
author = {Jacob, Pierre},
doi = {10.1007/s13164-011-0065-0},
file = {::},
issn = {1878-5158},
journal = {Review of Philosophy and Psychology},
month = aug,
number = {August},
pages = {519--540},
title = {{The Direct-Perception Model of Empathy: a Critique}},
url = {http://www.springerlink.com/index/10.1007/s13164-011-0065-0},
year = {2011}
}
@inproceedings{Ullrich2008,
address = {Yokohama, Japan},
author = {Ullrich, Sebastian and Prendinger, Helmut and Ishizuka, Mitsuru},
booktitle = {2008 International Conference on Advances in Computer Entertainment Technology (ACE '08)},
doi = {10.1145/1501750.1501781},
pages = {134--137},
publisher = {ACM},
title = {{MPML3D: agent authoring language for virtual worlds}},
year = {2008}
}
@phdthesis{Li2007,
author = {Li, Xi},
booktitle = {Interface},
file = {::},
school = {Marquette University},
title = {{SPEech Feature Toolbox (SPEFT) Design and Emotional Speech Feature Extraction}},
url = {http://speechlab.eece.mu.edu/johnson/papers/li\_thesis.pdf},
year = {2007}
}
@article{Spurgeon2010,
abstract = {There has been a recent acceleration in the development and testing of programs for computer-assisted cognitive-behavioral therapy (CCBT). Programs are now available for treatment of depression, anxiety disorders, and other psychiatric conditions. Technology for delivery of CCBT includes multimedia programs, virtual reality, and handheld devices. Research on CCBT generally has supported the efficacy of computer-assisted therapy and has shown patient acceptance of computer tools for psychotherapy. Completion rates and treatment efficacy typically have been higher when clinicians prescribe and support the use of psychotherapeutic computer programs than when programs are delivered in a self-help format without clinician involvement. CCBT seems to have the potential to improve access to evidence-based therapies while reducing the demand for clinician time.},
author = {Spurgeon, Joyce a and Wright, Jesse H},
doi = {10.1007/s11920-010-0152-4},
file = {::},
isbn = {1192001001},
issn = {1535-1645},
journal = {Current psychiatry reports},
keywords = {Anxiety Disorders,Anxiety Disorders: therapy,Cognitive Therapy,Depressive Disorder,Depressive Disorder: therapy,Humans,Therapy, Computer-Assisted,Treatment Outcome},
month = dec,
number = {6},
pages = {547--52},
pmid = {20872100},
title = {{Computer-assisted cognitive-behavioral therapy.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20872100},
volume = {12},
year = {2010}
}
@article{Bickmore2005,
author = {Bickmore, TW},
file = {::},
journal = {ACM Transactions on Computer-Human},
pages = {617--638},
title = {{Establishing and maintaining long-term human-computer relationships}},
url = {http://dl.acm.org/citation.cfm?id=1067860.1067867},
year = {2005}
}
@article{XinLuo2007,
abstract = {The present study investigated the ability of normal-hearing listeners and cochlear implant users to recognize vocal emotions. Sentences were produced by 1 male and 1 female talker according to 5 target emotions: angry, anxious, happy, sad, and neutral. Overall amplitude differences between the stimuli were either preserved or normalized. In experiment 1, vocal emotion recognition was measured in normal-hearing and cochlear implant listeners; cochlear implant subjects were tested using their clinically assigned processors. When overall amplitude cues were preserved, normal-hearing listeners achieved near-perfect performance, whereas listeners with cochlear implant recognized less than half of the target emotions. Removing the overall amplitude cues significantly worsened mean normal-hearing and cochlear implant performance. In experiment 2, vocal emotion recognition was measured in listeners with cochlear implant as a function of the number of channels (from 1 to 8) and envelope filter cutoff frequency (50 vs 400 Hz) in experimental speech processors. In experiment 3, vocal emotion recognition was measured in normal-hearing listeners as a function of the number of channels (from 1 to 16) and envelope filter cutoff frequency (50 vs 500 Hz) in acoustic cochlear implant simulations. Results from experiments 2 and 3 showed that both cochlear implant and normal-hearing performance significantly improved as the number of channels or the envelope filter cutoff frequency was increased. The results suggest that spectral, temporal, and overall amplitude cues each contribute to vocal emotion recognition. The poorer cochlear implant performance is most likely attributable to the lack of salient pitch cues and the limited functional spectral resolution.},
author = {{Xin Luo} and Fu, Qian-Jie and Galvin, John J},
doi = {10.1177/1084713807305301},
file = {::},
issn = {1084-7138},
journal = {Trends in amplification},
keywords = {Aged,Auditory Perception,Cochlear Implants,Cues,Emotions,Female,Hearing Disorders,Hearing Disorders: psychology,Hearing Disorders: surgery,Hearing Impaired Persons,Humans,Male,Middle Aged,Pitch Perception,Rehabilitation of Hearing Impaired,Speech Acoustics,Speech Perception,Time Factors},
month = dec,
number = {4},
pages = {301--15},
pmid = {18003871},
title = {{Vocal emotion recognition by normal-hearing listeners and cochlear implant users.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3210149\&tool=pmcentrez\&rendertype=abstract},
volume = {11},
year = {2007}
}
@book{Ekman2002,
address = {Salt Lake City, UT},
author = {Ekman, Paul and Freisen, Wallace V. and Hager, Joseph C},
booktitle = {A Human Face},
edition = {2nd},
institution = {Consulting Psychologists},
isbn = {0931835011},
number = {4},
pages = {4--5},
publisher = {Research Nexus eBook},
title = {{Facial Action Coding System}},
volume = {160},
year = {2002}
}
@article{Spurgeon2010,
abstract = {There has been a recent acceleration in the development and testing of programs for computer-assisted cognitive-behavioral therapy (CCBT). Programs are now available for treatment of depression, anxiety disorders, and other psychiatric conditions. Technology for delivery of CCBT includes multimedia programs, virtual reality, and handheld devices. Research on CCBT generally has supported the efficacy of computer-assisted therapy and has shown patient acceptance of computer tools for psychotherapy. Completion rates and treatment efficacy typically have been higher when clinicians prescribe and support the use of psychotherapeutic computer programs than when programs are delivered in a self-help format without clinician involvement. CCBT seems to have the potential to improve access to evidence-based therapies while reducing the demand for clinician time.},
author = {Spurgeon, Joyce a and Wright, Jesse H},
doi = {10.1007/s11920-010-0152-4},
file = {::},
isbn = {1192001001},
issn = {1535-1645},
journal = {Current psychiatry reports},
keywords = {Anxiety Disorders,Anxiety Disorders: therapy,Cognitive Therapy,Depressive Disorder,Depressive Disorder: therapy,Humans,Therapy, Computer-Assisted,Treatment Outcome},
month = dec,
number = {6},
pages = {547--52},
pmid = {20872100},
title = {{Computer-assisted cognitive-behavioral therapy.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20872100},
volume = {12},
year = {2010}
}
@article{Robbins1994,
abstract = {To date, cognitive and affective influences on performance evaluations have been addressed separately, although it is likely that affect may influence ratings indirectly through its impact on the cognitive processing involved in the evaluation. 83 management students participated in a study of the influence of affect on the cognitive processing of performance information. Results suggest that an affect-consistency bias influences ratings even though the cognitive processes that require some judgment indicated a bias toward both affect-consistent and affect-inconsistent performance. Additional findings suggest that the practical utility of affect as something distinct from past performance perceptions may be limited in field settings. Job-related affect, past performance perceptions, and social affect had similar influences on the cognitive process and ratings in performance evaluations. (PsycINFO Database Record (c) 2003 APA, all rights reserved)},
author = {Robbins, Tina L and DeNisi, Angelo S},
doi = {10.1037//0021-9010.79.3.341},
issn = {00219010},
journal = {Journal of Applied Psychology},
number = {3},
pages = {341--353},
publisher = {Elsevier},
title = {{A closer look at interpersonal affect as a distinct influence on cognitive processing in performance evaluations}},
url = {http://www.apa.org},
volume = {79},
year = {1994}
}
@inproceedings{Whitehill2008,
author = {Whitehill, Jacob and Bartlett, Marian and Movellan, Javier R},
booktitle = {Intelligent Tutoring Systems},
file = {::},
pages = {668--670},
publisher = {Springer},
title = {{Measuring the perceived difficulty of a lecture using automatic facial expression recognition}},
year = {2008}
}
@article{Pardas2002,
abstract = {The video analysis system described in this paper aims at facial expression recognition consistent with the MPEG4 standardized parameters for facial animation, FAP. For this reason, two levels of analysis are necessary: low level analysis to extract the MPEG4 compliant parameters and high level analysis to estimate the expression of the sequence using these low level parameters. The low level analysis is based on an improved active contour algorithm that uses high level information based on Principal Component Analysis to locate the most significant contours of the face (eyebrows and mouth), and on motion estimation to track them. The high level analysis takes as input the FAP produced by the low level analysis tool and, by means of a Hidden Markov Model classifier, detects the expression of the sequence.},
author = {Pard\`{a}s, Montse and Bonafonte, Antonio},
doi = {10.1016/S0923-5965(02)00078-4},
file = {::},
issn = {09235965},
journal = {Signal Processing: Image Communication},
month = oct,
number = {9},
pages = {675--688},
title = {{Facial animation parameters extraction and expression recognition using Hidden Markov Models}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0923596502000784},
volume = {17},
year = {2002}
}
@article{Lazarus1991,
abstract = {The 2 main tasks of this article are 1st, to examine what a theory of emotion must do and basic issues that it must address. These include definitional issues, whether or not physiological activity should be a defining attribute, categorical versus dimensional strategies, the reconciliation of biological universals with sociocultural sources of variability, and a classification of the emotions. The 2nd main task is to apply an analysis of appraisal patterns and the core relational themes that they produce to a number of commonly identified emotions. Anger, anxiety, sadness, and pride (to include 1 positive emotion) are used as illustrations. The purpose is to show the capability of a cognitive-motivational-relational theory to explain and predict the emotions. The role of coping in emotion is also discussed, and the article ends with a response to criticisms of a phenomenological, folk-theory outlook.},
author = {Lazarus, Richard S.},
doi = {10.1037/0003-066X.46.8.819},
file = {::},
issn = {0003-066X},
journal = {The American psychologist},
keywords = {Cognition,Emotions,Humans,Interpersonal Relations,Motivation,Psychological Theory},
month = aug,
number = {8},
pages = {819--834},
pmid = {1928936},
title = {{Progress on a cognitive-motivational-relational theory of emotion}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/1928936},
volume = {46},
year = {1991}
}
@article{Hess1998,
author = {Hess, Ursula and Philippot, Pierre and Blairy, Sylvie},
doi = {10.1080/026999398379547},
file = {::},
issn = {0269-9931},
journal = {Cognition \& Emotion},
month = jul,
number = {4},
pages = {509--531},
title = {{Facial Reactions to Emotional Facial Expressions: Affect or Cognition?}},
url = {http://www.tandfonline.com/doi/abs/10.1080/026999398379547},
volume = {12},
year = {1998}
}
@article{Cichosz2007,
author = {Cichosz, Jarosław},
file = {::},
journal = {Doctoral Consortium. ACII},
keywords = {emotion recognition,speech analysis},
pages = {1--8},
title = {{Emotion recognition in speech signal using emotion-extracting binary decision trees}},
url = {http://www.di.uniba.it/intint/DC-ACII07/Chicosz.pdf},
year = {2007}
}
@article{Lakin2003,
abstract = {The “chameleon effect” refers to the tendency to adopt the postures, gestures, and mannerisms of interaction partners (Chartrand \& Bargh, 1999). This type of mimicry occurs outside of conscious awareness, and without any intent to mimic or imitate. Empirical evidence suggests a bi-directional relationship between nonconscious mimicry on the one hand, and liking, rapport, and affiliation on the other. That is, nonconscious mimicry creates affiliation, and affiliation can be ex- pressed through nonconscious mimicry. We argue that mimicry played an impor- tant role in human evolution. Initially, mimicry may have had survival value by helping humans communicate. We propose that the purpose of mimicry has now evolved to serve a social function. Nonconscious behavioral mimicry increases af- filiation, which serves to foster relationships with others. We review current re- search in light of this proposed framework and suggest future areas of research.},
annote = {nonconscious mimicry creates affiliation, and affiliation can be expressed through nonconscious mimicry.
Initially, mimicry may have had survival value by helping humans communicate. The purpose of mimicry has now evolved to serve a social function. Nonconscious behavioral mimicry increases affiliation, which serves to foster relationships with others.
Empathic individuals mimic people more that people low in empathy.},
author = {Lakin, J. L. and Jefferis, VE and Cheng, CM},
file = {::},
journal = {Journal of nonverbal Behavior},
keywords = {affiliation,chameleon effect,human evolution,mimicry},
number = {3},
pages = {145--162},
title = {{The chameleon effect as social glue: Evidence for the evolutionary significance of nonconscious mimicry}},
volume = {27},
year = {2003}
}
@article{Hojat2003,
author = {Hojat, Mohammadreza and Gonnella, J S and Mangione, Salvatore and Nasca, Thomas J and Magee, Mike},
journal = {Seminars in Integrative Medicine},
publisher = {Seminars in Integrative Medicine},
title = {{Pshysician empathy in medical education practice experience with the jefferson scale of physician empathy}},
year = {2003}
}
@article{Matthews1993,
abstract = {Healers must try to understand what the illness means to the patient and create a therapeutic sense of connection in the patient-clinician relationship. A favorable climate for "connexional" experiences can be created through the use of various interviewing techniques. Attending to rapport, silencing internal talk, accessing unconscious processes, and communicating understanding can help clinicians enhance their sensitivity to the subtle clues on which issues of meaning and connection often depend. Several risks are associated with the establishment of closer patient-clinician relationships, including dependence and power issues, sexual attraction, and deeper exposure of the clinician to the patient's pain. Prepared with an awareness of these risks and techniques to address them, clinicians are encouraged to deepen their level of dialogue with patients, to compare their experiences with those of other clinicians, and to thereby develop a more systematic understanding of therapeutic relationships.},
author = {Matthews, D A and Suchman, A L and Branch, W T},
institution = {National Center for Chronic Fatigue, Arlington, Virginia.},
journal = {Annals of Internal Medicine},
keywords = {professional patient relationship},
number = {12},
pages = {973--977},
pmid = {8489112},
title = {{Making "connexions": enhancing the therapeutic potential of patient-clinician relationships.}},
volume = {118},
year = {1993}
}
@article{Boukricha2011,
author = {Boukricha, Hana and Wachsmuth, Ipke},
doi = {10.1007/s13218-011-0109-8},
file = {::},
issn = {0933-1875},
journal = {KI - K\"{u}nstliche Intelligenz},
keywords = {agent-agent interaction,empathic virtual humans,human-agent,internal simulation},
month = may,
number = {3},
pages = {195--204},
title = {{Empathy-Based Emotional Alignment for a Virtual Human: A Three-Step Approach}},
volume = {25},
year = {2011}
}
@article{Valitutti2005,
abstract = {This paper presents resources and functionalities for the selection of affective evaluative terms. An affective hierarchy as an extension of the WordNet-Affect lexical database was developed in the first place. The second phase was the development of a semantic similarity function, acquired automatically in an unsupervised way from a large corpus of texts that allows us to put into relation concepts and emotional categories. The integration of the two components is a key element for several applications.},
author = {Valitutti, Alessandro and Strapparava, Carlo and Stock, Oliviero},
doi = {10.1007/11573548\_61},
journal = {Affective Computing and Intelligent Interaction},
pages = {474--481},
title = {{Lexical Resources and Semantic Similarity for Affective Evaluative Expressions Generation}},
url = {http://dx.doi.org/10.1007/11573548\_61},
year = {2005}
}
@inproceedings{Boukricha2011b,
abstract = {Empathy is believed to play a major role as a basis for humans’ cooperative behavior. Recent research shows that humans empathize with each other to different degrees depending on several modulation factors including, among others, their social relationships, their mood, and the situational context. In human spatial interaction, partners share and sustain a space that is equally and exclusively reachable to them, the so-called interaction space. In a cooperative interaction scenario of relocating objects in interaction space, we introduce an approach for triggering and modulating a virtual humans cooperative spatial behavior by its degree of empathy with its interaction partner. That is, spatial distances like object distances as well as distances of arm and body movements while relocating objects in interaction space are modulated by the virtual human’s degree of empathy. In this scenario, the virtual human’s empathic emotion is generated as a hypothesis about the partner’s emotional state as related to the physical effort needed to perform a goal directed spatial behavior.},
address = {Berlin, Heidelberg},
author = {Boukricha, Hana and Nguyen, H.},
booktitle = {Proceedings of the 10th international conference on Intelligent virtual agents IVA'11},
doi = {10.1007/978-3-642-23974-8\_38},
editor = {Kopp, Stefan and Marsella, Stacy and Thorisson, Kristinn and Vilhjalmsson, Hannes},
file = {::},
pages = {350--362},
publisher = {Springer-Verlag},
title = {{Sharing Emotions and Space – Empathy as a Basis for Cooperative Spatial Interaction}},
url = {http://www.springerlink.com/content/q22784632u008337/},
year = {2011}
}
@article{Sarrafzadeh2006,
author = {Sarrafzadeh, Abdolhossein and Alexander, Samuel and Dadgostar, Farhad and Fan, Chao and Bigdeli, Abbas},
doi = {10.1109/INNOVATIONS.2006.301981},
file = {::},
isbn = {1-4244-0673-0},
journal = {2006 Innovations in Information Technology},
keywords = {affective,affective computing,affective tutoring systems,agents,emotion detection,human computer,interaction,lifelike,new type of its,proposed by the authors},
month = nov,
pages = {1--5},
publisher = {Ieee},
title = {{See Me, Teach Me: Facial Expression and Gesture Recognition for Intelligent Tutoring Systems}},
year = {2006}
}
@incollection{Cooper2000,
abstract = {This paper considers how research into empathy in teaching and learning can inform the research into intelligent systems and intelligent agents embedded in educational applications. It also relates this research to some analysis of classroom practice completed as part of the EU funded NIMIS project. The project is developing three applications, one of which aims to support writing development with young children aged 5-6 years based on a cartoon format. The NIMIS classroom as a whole is designed to enhance and augment existing classroom practices and to foster collaboration by non-intrusive hardware and intuitive hardware and software interfaces. To this end it seeks to enhance both human and electronic communication in the classroom. Empathy is central to ensuring the quality of human communication and personal development. This paper suggests that intelligent systems that can consider more carefully the processes and feelings involved in human interactions in teaching and learning, may promote higher quality support for students in classrooms.},
author = {Cooper, Bridget and Brna, Paul and Martins, Alex},
booktitle = {Affective Interactions Towards a New Generation of Computer Interfaces},
doi = {10.1007/10720296\_3},
editor = {Paiva, Ana},
file = {::},
isbn = {978-3-540-41520-6},
pages = {21--34},
publisher = {Springer Berlin / Heidelberg},
title = {{Effective affective in intelligent systems–building on evidence of empathy in teaching and learning}},
url = {http://www.springerlink.com/index/j8v0l230t3503367.pdf},
volume = {1814/2000},
year = {2000}
}
@article{Bickmore2002,
author = {Bickmore, Timothy W and Sidner, Candace L},
journal = {Artificial Intelligence},
pages = {14--18},
title = {{Towards Plan-based Health Behavior Change Counseling Systems}},
year = {2002}
}
@article{Meng2009,
author = {Meng, Qinggang and Lee, Mark},
doi = {10.1109/CASE.2009.156},
file = {::},
isbn = {978-0-7695-3728-3},
journal = {2009 IITA International Conference on Control, Automation and Systems Engineering (case 2009)},
keywords = {-home service robots,human-robot interaction},
month = jul,
pages = {220--224},
publisher = {Ieee},
title = {{Empathy between Human and Home Service Robots}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5194430},
year = {2009}
}
@phdthesis{Sidorova2007,
author = {Sidorova, Julia},
booktitle = {Speech communication},
file = {::},
school = {Universitat Pompeu Fabra},
title = {{Speech emotion recognition using hidden Markov models}},
year = {2007}
}
@article{Ekman1974,
author = {Ekman, Paul and Freisen, Wallace V.},
file = {::},
journal = {Journal of Personality and Social Psychology},
number = {3},
pages = {288--298},
title = {{Detecting Deception From The Body Or Face}},
volume = {29},
year = {1974}
}
@article{Miller1990,
abstract = {WordNet is an on-line lexical reference system whose design is inspired by current psycholinguistic theories of human lexical memory. English nouns, verbs, and adjectives are organized into synonym sets, each representing one underlying lexical concept. Different relations link the synonym sets.},
author = {Miller, George A and Beckwith, Richard and Fellbaum, Christiane and Gross, Derek and Miller, Katherine J},
doi = {10.1093/ijl/3.4.235},
isbn = {0950384614774577},
issn = {09503846},
journal = {International Journal of Lexicography},
number = {4},
pages = {235--244},
pmid = {15102489},
publisher = {Oxford Univ Press},
title = {{Introduction to WordNet: An On-line Lexical Database}},
url = {http://ijl.oxfordjournals.org/cgi/doi/10.1093/ijl/3.4.235},
volume = {3},
year = {1990}
}
@inproceedings{Caridakis2006,
author = {Caridakis, George and Malatesta, Lori and Kessous, Loic and Amir, Noam and Raouzaiou, Amaryllis and Karpouzis, Kostas},
booktitle = {Proceedings of the 8th international conference on Multimodal interfaces},
file = {::},
pages = {146--154},
publisher = {ACM},
title = {{Modeling naturalistic affective states via facial and vocal expressions recognition}},
year = {2006}
}
@inproceedings{Cramer2010,
abstract = {Empathy has great potential in human-robot interaction. However, the challenging nature of assessing the user's emotional state points to the importance of also understanding the effects of empathic behaviours incongruent with users' affective experience. A 3x2 between-subject video-based survey experiment (N=133) was conducted with empathic robot behaviour (empathically accurate, neutral, inaccurate) and valence of the situation (positive, negative) as dimensions. Trust decreased when empathic responses were incongruent with the affective state of the user. However, in the negative valence condition, reported perceived empathic abilities were greater when the robot responded as if the situation were positive.},
author = {Cramer, Henriette and Goddijn, Jorrit and Wielinga, Bob and Evers, Vanessa},
booktitle = {HRI '10 Proceedings of the 5th ACM/IEEE international conference on Human-robot interaction},
doi = {10.1145/1734454.1734513},
file = {::},
isbn = {9781424448937},
pages = {141--142},
publisher = {ACM},
title = {{Effects of (in) accurate empathy and situational valence on attitudes towards robots}},
url = {http://dl.acm.org/citation.cfm?id=1734513},
year = {2010}
}
@inproceedings{Hyun2007,
author = {Hyun, KH and Kim, EH},
booktitle = {16th IEEE International Conference on Robot \& Human Interactive Communication},
file = {::},
isbn = {9781424416356},
pages = {802--806},
title = {{Emotional feature extraction based on phoneme information for speech emotion recognition}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4415195},
year = {2007}
}
@article{Banziger2009,
abstract = {Emotion recognition ability has been identified as a central component of emotional competence. We describe the development of an instrument that objectively measures this ability on the basis of actor portrayals of dynamic expressions of 10 emotions (2 variants each for 5 emotion families), operationalized as recognition accuracy in 4 presentation modes combining the visual and auditory sense modalities (audio/video, audio only, video only, still picture). Data from a large validation study, including construct validation using related tests (Profile of Nonverbal Sensitivity; Rosenthal, Hall, DiMatteo, Rogers, \& Archer, 1979; Japanese and Caucasian Facial Expressions of Emotion; Biehl et al., 1997; Diagnostic Analysis of Nonverbal Accuracy; Nowicki \& Duke, 1994; Emotion Recognition Index; Scherer \& Scherer, 2008), are reported. The results show the utility of a test designed to measure both coarse and fine-grained emotion differentiation and modality-specific skills. Factor analysis of the data suggests 2 separate abilities, visual and auditory recognition, which seem to be largely independent of personality dispositions.},
author = {B\"{a}nziger, Tanja and Grandjean, Didier and Scherer, Klaus R},
doi = {10.1037/a0017088},
file = {::},
issn = {1931-1516},
journal = {Emotion (Washington, D.C.)},
keywords = {Adolescent,Adult,Discrimination (Psychology),Emotional Intelligence,Emotions,Facial Expression,Female,Humans,Male,Nonverbal Communication,Pattern Recognition, Visual,Personality Inventory,Personality Inventory: statistics \& numerical data,Psychometrics,Psychometrics: statistics \& numerical data,Recognition (Psychology),Reproducibility of Results,Social Adjustment,Voice Quality,Young Adult},
month = oct,
number = {5},
pages = {691--704},
pmid = {19803591},
title = {{Emotion recognition from expressions in face, voice, and body: the Multimodal Emotion Recognition Test (MERT).}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19803591},
volume = {9},
year = {2009}
}
@inproceedings{Bartneck2008,
author = {Bartneck, Christoph and Kulic, Dana and Croft, Elizabeth},
booktitle = {Metrics for HRI Workshop, Technical Report},
file = {::},
pages = {37--44},
title = {{Measuring the anthropomorphism, animacy, likeability, perceived intelligence and perceived safety of robots}},
url = {http://ece.uwaterloo.ca/~dkulic/pubs/bartneckKulicCroft.pdf},
volume = {471},
year = {2008}
}
@article{Ekman1983,
author = {Ekman, Paul and Levenson, Robert W and Freisen, Wallace V.},
file = {::},
journal = {Science},
number = {4616},
pages = {1208--1210},
title = {{Autonomic Nervous System Activity Distinguishes among Emotions}},
volume = {221},
year = {1983}
}
@article{Larsen1992,
abstract = {TOC The structural bases of emotional behavior James R. Averill - Promises and problems with the circumplex model of emotion Randy J. Larsen and Edward Diener - The complexity of intensity Nico H. Frijda, Andrew Ortony, Joep Sonnemans, and Gerald L. Clore - The behavioral ecology and sociality of human faces Alan J. Firdlund - Appraisal as a cause of emotion Brian Parkinson and A.S.R. Manstead - Affective dynamics Robert Mauro - Cross-cultural similarities and differences in emotion and its representation Phillip R. Shaver, Shelley Wu, and Judith C. Schwartz - The process of emotional experience James D. Laird and Charles Bresler - Inhibitory effects of awareness on affective responding Robert F. Bornstein - A functional analysis of the role of mood in affective systems William N. Morris - Differentiating affect, mood, and emotion C. Daniel Batson, Laura L. Shaw, and Kathryn C. Oleson},
author = {Larsen, Randy J and Diener, Edward},
chapter = {2},
editor = {Clark, Margaret S},
isbn = {0803946139},
journal = {Review of Personality and Social Psychology},
number = {13},
pages = {25--59},
publisher = {Sage},
series = {Review of personality and social psychology; No. 13; 0270-1987},
title = {{Promises and problems with the circumplex model of emotion}},
url = {http://psycnet.apa.org/psycinfo/1992-97396-002},
volume = {13},
year = {1992}
}
@inproceedings{Schrammel2007,
abstract = {This paper describes the results of three studies investigating an embodied agent that supports its interaction with the user by gazing at corresponding objects within its close environment. Three experiments were conducted in order to research whether users can detect an agent’s line of sight, whether the agent’s gaze direction can help to guide the users' attention towards designated locations and whether such a setup can be used to improve realistic interaction situations. The results show that a) users can detect the agent’s gaze direction quickly (within 200 ms) but not very exactly, b) the use of the agent’s gaze direction can speed up but also slow down the detection of objects in dependence on their location and c) that the agent’s gaze towards corresponding objects during the interaction can have counterproductive effects in realistic settings.},
address = {San Jose, California, USA.},
author = {Schrammel, Johann and Sefelin, Reinhard and Tscheligi, Manfred},
booktitle = {CHI 2007 Proceedings of People, Looking at People April},
file = {::},
isbn = {9781595935939},
keywords = {Computer Vision,Embodied Agent,Gaze Direction},
pages = {1187--1190},
publisher = {ACM},
title = {{“ Look !” – Using the Gaze Direction of Embodied Agents}},
year = {2007}
}
@article{Dinda2007,
author = {Dinda, Peter A and Dick, Robert P and Rossoff, Samuel},
file = {::},
isbn = {9781595937513},
journal = {ACM},
number = {June},
title = {{The User In Experimental Computer Systems Research Categories and Subject Descriptors}},
year = {2007}
}
@inproceedings{Ishii2010,
abstract = {In face-to-face conversations, speakers are continuously checking whether the listener is engaged in the conversation by monitoring the partner’s eye-gaze behaviors. In this study, focusing on eye-gaze as information of estimating user’s conversational engagement, Wizard-of-Oz experiment first, we to collect the user’s conduct a gaze behaviors as well as the user’s subjective reports and an observer’s judgment concerning the user’s engagement in the conversation. Then, by analyzing the user’s gaze behaviors, variables and factors for estimating the user’s engagement are identified. Based on the analysis, we propose four types of engagement estimation methods based on gaze duration information and gaze transition 3- gram patterns. As the results of comparing the performance of these methods, it is revealed that a method which takes account of the individual differences in gaze transition patterns performs the best and can predict the user’s conversational engagement quite well.},
address = {Hong Kong},
author = {Ishii, Ryo and Yukiko, I. Nakano},
booktitle = {EGIHMI '10 Proceedings of the 2010 workshop on Eye gaze in intelligent human machine interaction},
file = {::},
isbn = {9781605589992},
keywords = {Empirical study,Wizard-of-Oz experiment,conversational engagement},
pages = {33--40},
publisher = {ACM},
title = {{An Empirical Study of Eye-gaze Behaviors : Towards the Estimation of Conversational Engagement in Human-Agent Communication}},
year = {2010}
}
@article{Prendinger2006,
abstract = {This paper presents a novel method for evaluating the impact of animated interface agents with affective and empathic behavior. While previous studies relied on question- naires in order to assess the user’s overall experience with the interface agent, we will analyze users’ physiological response (skin conductance and electromyography), which allows us to estimate affect-related user experiences on a moment-by-moment basis with- out interfering with the primary interaction task. As an interaction scenario, a card game has been implemented where the user plays against a virtual opponent. The findings of our study indicate that within a competitive gaming scenario, (i) the absence of the agent’s display of negative emotions is conceived as arousing or stress-inducing, and (ii) the valence of users’ emotional response is congruent with the valence of the emotion expressed by the agent. Our results for skin conductance could also be reproduced by assuming a local rather than a global baseline.},
annote = {they have tested 4 different empathic behaviours in a competitive card game.
1- Non-Emotional2- Self-Centered Emotional
3- Negative Empathic 
4- Positive Empathic 
They found out that:
 - absence of the agent's display of negative emotions is arousing for the user and highers his/her stress.
 - valence of users' emotional response is congruent with the valence of the emotion expressed by the agent.},
author = {Prendinger, Helmut and Becker-Asano, Christian},
file = {::},
journal = {International Journal of Humanoid},
keywords = {affective behavior,empathy,evaluation,life-like characters,physiological user information},
number = {3},
pages = {371--391},
title = {{A Study in User's Physiological Response to an Empathic Interface Agent}},
volume = {3},
year = {2006}
}
@article{Wasfy2004a,
abstract = {An interrogative visualization environment is described for the interactive display and querying of large datasets. The environment combines a web-based intelligent agent facility with a visualization engine. The intelligent agent facility (IAF) incorporates a rule-based expert system for natural-language understanding, voice and text input facilities, a hierarchical clickable command list, an interface for multimodal devices such as menu-based wireless handheld devices and gesture recognition devices, and human-like avatars acting as virtual assistants. The IAF interacts with, and controls, the visualization engine through a TCP/IP network socket interface. The environment enables multiple users using a variety of interaction modes and devices to effectively browse through large amounts of data, focus on and query interesting features, and more easily comprehend and make use of the data. Application of the environment to the visualization of engineering simulations is described.},
author = {Wasfy, Hatem M. and Wasfy, Tamer M. and Noor, Ahmed K.},
doi = {10.1016/j.advengsoft.2004.06.015},
file = {::},
issn = {09659978},
journal = {Advances in Engineering Software},
keywords = {expert system,intelligent software agent,interface,multimodal,natural language,visualization},
month = dec,
number = {12},
pages = {805--813},
title = {{An interrogative visualization environment for large-scale engineering simulations}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0965997804001310},
volume = {35},
year = {2004}
}
@article{Aviezer2008,
abstract = {Current theories of emotion perception posit that basic facial expressions signal categorically discrete emotions or affective dimensions of valence and arousal. In both cases, the information is thought to be directly "read out" from the face in a way that is largely immune to context. In contrast, the three studies reported here demonstrated that identical facial configurations convey strikingly different emotions and dimensional values depending on the affective context in which they are embedded. This effect is modulated by the similarity between the target facial expression and the facial expression typically associated with the context. Moreover, by monitoring eye movements, we demonstrated that characteristic fixation patterns previously thought to be determined solely by the facial expression are systematically modulated by emotional context already at very early stages of visual processing, even by the first time the face is fixated. Our results indicate that the perception of basic facial expressions is not context invariant and can be categorically altered by context at early perceptual levels.},
author = {Aviezer, Hillel and Hassin, Ran R and Ryan, Jennifer and Grady, Cheryl and Susskind, Josh and Anderson, Adam and Moscovitch, Morris and Bentin, Shlomo},
institution = {Department of Psychology, Hebrew University of Jerusalem, Jerusalem 91905, Israel. hillel.aviezer@mail.huji.ac.il},
journal = {Psychological Science},
keywords = {adolescent,affect,anger,facial expression,fear,female,humans,male,social perception,visual perception,young adult},
number = {7},
pages = {724--732},
pmid = {18727789},
publisher = {Blackwell Publishing},
title = {{Angry, disgusted, or afraid? Studies on the malleability of emotion perception.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18727789},
volume = {19},
year = {2008}
}
@article{Robison2010a,
abstract = {affective interventions can both positively and negatively influence learning experiences. In this paper we investigate the role of student personality, including goal orienta- tion and empathetic tendencies, in estimating confidence in the benefits of an affective intervention strategy. The results indicate that student personality profiles can serve as a powerful tool for informing affective feedback models.},
annote = {We can use the same way of menu base self-report affective state recognition (in addition to automatic) and text-base empathic feedback. Then after each feedback we can evaluate the feedback with another user self-report.},
author = {Robison, Jennifer and Mcquiggan, Scott and Lester, James and Carolina, North},
file = {::},
keywords = {affect,affective computing,pedagogical agents},
pages = {285--295},
title = {{Developing Empirically Based Student Personality Profiles for Affective Feedback Models}},
year = {2010}
}
@article{Boukricha2011,
abstract = {Allowing virtual humans to align to others’ perceived emotions is believed to enhance their cooperative and communicative social skills. In our work, emotional alignment is realized by endowing a virtual human with the ability to empathize. Recent research shows that humans empathize with each other to different degrees depending on several factors including, among others, their mood, their personality, and their social relationships. Although providing virtual humans with features like affect, personality, and the ability to build social relationships, little attention has been devoted to the role of such features as factors modulating their empathic behavior. Supported by psychological models of empathy, we propose an approach to model empathy for the virtual human EMMA—an Empathic MultiModal Agent—consisting of three processing steps: First, the Empathy Mechanism by which an empathic emotion is produced. Second, the Empathy Modulation by which the empathic emotion is modulated. Third, the Expression of Empathy by which EMMA’s multiple modalities are triggered through the modulated empathic emotion. The proposed model of empathy is illustrated in a conversational agent scenario involving the virtual humans MAX and EMMA.},
author = {Boukricha, Hana and Wachsmuth, Ipke},
doi = {10.1007/s13218-011-0109-8},
file = {::},
issn = {0933-1875},
journal = {KI - K\"{u}nstliche Intelligenz},
keywords = {agent-agent interaction,empathic virtual humans,human-agent,internal simulation},
month = may,
number = {3},
pages = {195--204},
title = {{Empathy-Based Emotional Alignment for a Virtual Human: A Three-Step Approach}},
url = {http://www.springerlink.com/content/9322738p4101p94w/},
volume = {25},
year = {2011}
}
@article{Cai2006,
author = {Cai, Yang},
file = {::},
journal = {Ambient Intelligence in Everyday Life},
pages = {67--85},
publisher = {Springer},
title = {{Empathic computing}},
url = {http://www.springerlink.com/index/l482m128476w5043.pdf},
year = {2006}
}
@article{Shimoda2000,
author = {Shimoda, H. and Kunihiro, T. and Yang, D. and Yoshikawa, H.},
doi = {10.1109/IECON.2000.972406},
file = {::},
isbn = {0-7803-6456-2},
journal = {2000 26th Annual Conference of the IEEE Industrial Electronics Society. IECON 2000. 2000 IEEE International Conference on Industrial Electronics, Control and Instrumentation. 21st Century Technologies and Industrial Opportunities (Cat. No.00CH37141)},
pages = {2589--2594},
publisher = {Ieee},
title = {{Design of affective interface for realizing human-machine empathy}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=972406},
volume = {4},
year = {2000}
}
@article{Happ2011,
author = {Happ, Christian and Melzer, Andr\'{e}},
file = {::},
journal = {Ifip International Federation For Information Processing},
keywords = {1,1 prosocial and antisocial,aggression,anderson and his colleagues,confirmed that video game,effects of video games,empathy,furthermore,in a recent overview,prosocial behavior,related to indicators of,video games,violence exposure is positively},
pages = {371--374},
title = {{Bringing Empathy into Play: On the Effects of Empathy in Violent and Nonviolent Video Games}},
url = {http://www.springerlink.com/index/P76556V1HN316RK6.pdf},
year = {2011}
}
@article{Fabri2007,
author = {Fabri, Marc and Elzouki, SYA},
file = {::},
journal = {of the 12th international conference on},
keywords = {autism,avatar,education,emotion,empathy,facial expression,instant,messaging,therapeutic intervention,virtual reality},
pages = {275--285},
title = {{Emotionally expressive avatars for chatting, learning and therapeutic intervention}},
url = {http://dl.acm.org/citation.cfm?id=1769621},
year = {2007}
}
@article{Hess1998,
author = {Hess, Ursula and Philippot, Pierre and Blairy, Sylvie},
doi = {10.1080/026999398379547},
file = {::},
issn = {0269-9931},
journal = {Cognition \& Emotion},
month = jul,
number = {4},
pages = {509--531},
title = {{Facial Reactions to Emotional Facial Expressions: Affect or Cognition?}},
url = {http://www.tandfonline.com/doi/abs/10.1080/026999398379547},
volume = {12},
year = {1998}
}
@article{Hanna2007,
abstract = {This article describes how an object-oriented approach can be applied to the architectural design of a spoken language dialog system with the aim of facilitating the modification, extension, and reuse of discourse-related expertise. The architecture of the developed system is described and a functionally similar VoiceXML system is used to provide a comparative baseline across a range of modification and reuse scenarios. It is shown that the use of an object-oriented dialog manager can provide a capable means of reusing existing discourse expertise in a manner that limits the degree of structural decay associated with system change.},
author = {Hanna, Philip and O'neill, Ian and Wootton, Craig and Mctear, Michael},
doi = {10.1145/1255171.1255173},
file = {::},
issn = {15504875},
journal = {ACM Transactions on Speech and Language Processing},
keywords = {Design,Human Factors,Human-computer interaction,dialog management,speech and language processing,spoken dialog systems},
mendeley-tags = {Design,Human Factors},
month = jul,
number = {3},
pages = {Article 7 (July 2007), 39 pages},
title = {{Promoting extension and reuse in a spoken dialog manager}},
url = {http://portal.acm.org/citation.cfm?doid=1255171.1255173},
volume = {4},
year = {2007}
}
@misc{TheMendeleySupportTeam2011,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/The Mendeley Support Team - 2011 - Getting Started with Mendeley(4).pdf:pdf},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@article{Cowell2005a,
abstract = {For years, people have sought more natural means of communicating with their computers. Many have suggested that interaction with a computer should be as easy as interacting with other people, taking advantage of the multimodal nature of human communication. While users should, in theory, gravitate to such anthropomorphic embodiments, quite the contrary has been experienced; users generally have been dissatisfied and abandoned their use. This suggests a disconnect between factors that make human-human communication engaging and those used by designers to support human-agent interaction. This paper discusses a set of empirical studies that attempted to replicate human-human non-verbal behavior. The focus revolved around behaviors that portray a credible fa\c{c}ade, thereby helping embodied conversational agents (ECAs) to form a successful cooperative dyad with users. Based on a review of the non-verbal literature, a framework was created that identified trustworthy and credible non-verbal behaviors across five areas and formed design guidelines for character interaction. The design suggestions for those areas emanating from the facial region were experimentally supported but there was no concordant increase in perceived trust when bodily regions (posture, gesture) were added. In addition, in examining the importance of demographic elements in embodiment, it was found that users prefer to interact with characters that match their ethnicity and are young looking. There was no significant preference for gender. The implications of these results, as well as other interesting consequences are discussed.},
author = {Cowell, Andrew J. and Stanney, Kay M.},
doi = {10.1016/j.ijhcs.2004.11.008},
file = {::},
issn = {10715819},
journal = {International Journal of Human-Computer Studies},
month = feb,
number = {2},
pages = {281--306},
title = {{Manipulation of non-verbal interaction style and demographic embodiment to increase anthropomorphic computer character credibility}},
url = {http://ocw.tudelft.nl/fileadmin/ocw/opener/Manipulation\_of\_non-verbal\_interaction\_style\_and\_demographic\_embodiment\_to\_increase\_anthropomorphic\_computer\_character\_credibility.pdf},
volume = {62},
year = {2005}
}
@book{Ekman2002,
address = {Salt Lake City, UT},
author = {Ekman, Paul and Freisen, Wallace V. and Hager, Joseph C},
booktitle = {A Human Face},
edition = {2nd},
institution = {Consulting Psychologists},
isbn = {0931835011},
number = {4},
pages = {4--5},
publisher = {Research Nexus eBook},
title = {{Facial Action Coding System}},
volume = {160},
year = {2002}
}
@article{Shimoda2000,
author = {Shimoda, H. and Kunihiro, T. and Yang, D. and Yoshikawa, H.},
doi = {10.1109/IECON.2000.972406},
file = {::},
isbn = {0-7803-6456-2},
journal = {2000 26th Annual Conference of the IEEE Industrial Electronics Society. IECON 2000. 2000 IEEE International Conference on Industrial Electronics, Control and Instrumentation. 21st Century Technologies and Industrial Opportunities (Cat. No.00CH37141)},
pages = {2589--2594},
publisher = {Ieee},
title = {{Design of affective interface for realizing human-machine empathy}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=972406},
volume = {4},
year = {2000}
}
@inproceedings{Bransky2011,
abstract = {To understand the role that memory plays we have collected data from three online experimental sessions in which participants inter- act with our virtual real-estate agent in both a recall and forget mode. We found that partial forgetting and even total loss of recall of an item, whether domain or social-based, was more believable and less frustrating than incorrect recall.},
author = {Bransky, Karla and Richards, Debbie},
booktitle = {Intelligent Virtual Agents 10th International Conference (IVA 2011)},
doi = {10.1007/978-3-642-23974-8\_49},
file = {::},
keywords = {forget-,intelligent virtual agents,memory,remembering},
pages = {433--434},
publisher = {Springer-Verlag Berlin Heidelberg},
title = {{Users ’ s Expectations of IVA Recall and Forgetting}},
year = {2011}
}
@article{Devoldre2010,
abstract = {Social support researchers and clinicians have repeatedly expressed the need to identify the antecedents of social support provision within close relationships. The aim of the present study is to investigate the extent to which individual differences in cognitive empathy (perspective taking) and affective empathy (empathic concern and personal distress) are predictive of social support provision in couples. Study 1 involved 83 female participants in a relatively young relationship; Study 2 involved 128 married couples. The authors used self-report measures in both studies to assess individual differences in empathy and participants' support provision behaviors. The main findings suggest a significant contribution of the different components of empathy with rather different pictures for each of these components. The authors discuss the present findings in light of existing theory and research on social support in relationships.},
author = {Devoldre, Inge and Davis, Mark H. and Verhofstadt, Lesley L and Buysse, Ann},
doi = {10.1080/00223981003648294},
file = {::},
issn = {0022-3980},
journal = {The Journal of psychology},
keywords = {80 and over,Adolescent,Adult,Affect,Aged,Empathy,Family Characteristics,Female,Humans,Individuality,Male,Middle Aged,Personal Construct Theory,Personality Inventory,Personality Inventory: statistics \& numerical data,Psychometrics,Social Support,Young Adult},
number = {3},
pages = {259--284},
pmid = {20461931},
title = {{Empathy and social support provision in couples: social support and the need to study the underlying processes.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21506454},
volume = {144},
year = {2010}
}
@article{Cliffordson2002,
abstract = {The purpose of the present study was to examine the structure of empathy using a hierarchical approach, and to compare the dimensions of empathy with measures of social functioning, in order to contribute to the understanding of the nature of empathy. The dimensionality of the Interpersonal Reactivity Index, which comprises four subscales (empathic concern, perspective taking, fantasy and personal distress) was examined using confirmatory factor analysis. Relations with the Social Skills Inventory were also investigated. A sample of 127 applicants for places on nursing and social work undergraduate programs participated in the study. The study findings indicate that empathy is hierarchically organized, with one general dimension at the apex. The general factor is identical to empathic concern and this dimension overlaps to a great extent with perspective taking and fantasy. The findings also indicate that the general dimension constitutes an integrated entirety, with its main emphasis on emotional reactivity by also involving cognitive processes.},
author = {Cliffordson, Christina},
doi = {10.1111/1467-9450.00268},
file = {::},
issn = {0036-5564},
journal = {Scandinavian journal of psychology},
keywords = {Empathy,Factor Analysis,Humans,Social Behavior,Statistical},
month = feb,
number = {1},
pages = {49--59},
pmid = {11885760},
title = {{The hierarchical structure of empathy: dimensional organization and relations to social functioning}},
url = {http://onlinelibrary.wiley.com/doi/10.1111/1467-9450.00268/abstract},
volume = {43},
year = {2002}
}
@incollection{Preston2007,
author = {Preston, SD},
booktitle = {Empathy in mental illness},
chapter = {23},
editor = {Farrow, T. and Woodruff, P.},
file = {::},
isbn = {0521847346},
pages = {428--446},
publisher = {Cambridge University Press},
title = {{A perception-action model for empathy}},
url = {http://www-personal.umich.edu/~prestos/Downloads/Preston2007\_MI.pdf},
year = {2007}
}
@article{Bailenson2005,
abstract = {Previous research demonstrated social influence resulting from mimicry (the chameleon effect); a confederate who mimicked participants was more highly regarded than a confederate who did not, despite the fact that participants did not explicitly notice the mimicry. In the current study, participants interacted with an embodied artificial intelligence agent in immersive virtual reality. The agent either mimicked a participant's head movements at a 4-s delay or utilized prerecorded movements of another participant as it verbally presented an argument. Mimicking agents were more persuasive and received more positive trait ratings than nonmimickers, despite participants' inability to explicitly detect the mimicry. These data are uniquely powerful because they demonstrate the ability to use automatic, indiscriminate mimicking (i.e., a computer algorithm blindly applied to all movements) to gain social influence. Furthermore, this is the first study to demonstrate social influence effects with a nonhuman, nonverbal mimicker.},
author = {Bailenson, Jeremy N and Yee, Nick},
file = {::},
journal = {Psychological Science},
number = {10},
pages = {814--819},
title = {{Digital Chameleons: Automatic Assimilation of Nonverbal Gestures in Immersive Virtual Environments}},
volume = {16},
year = {2005}
}
@inproceedings{Kang2008,
author = {Kang, Sin-hwa and Gratch, Jonathan and Wang, Ning and Watt, J.H.},
booktitle = {Proceedings of the 7th international joint conference on Autonomous agents and multiagent systems-Volume 1},
file = {::},
keywords = {agents,contingency of nonverbal feedback,evaluation,rapport,social anxiety,virtual humans},
number = {Aamas},
pages = {120--127},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
title = {{Does the contingency of agents' nonverbal feedback affect users' social anxiety?}},
url = {http://dl.acm.org/citation.cfm?id=1402405},
year = {2008}
}
@inproceedings{Stoyanchev2011,
author = {Stoyanchev, Svetlana and Piwek, Paul and Prendinger, Helmut},
booktitle = {Intelligent Virtual Agents},
file = {::},
pages = {377--383},
publisher = {Springer},
title = {{Comparing modes of information presentation: text versus ECA and single versus two ECAs}},
url = {http://www.springerlink.com/index/H72521305G072173.pdf},
year = {2011}
}
@inproceedings{Paiva2004,
address = {Washington, DC, USA},
author = {Paiva, Ana and Dias, J. and Sobral, Daniel and Aylett, Ruth},
booktitle = {AAMAS '04 Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems},
doi = {10.1109/AAMAS.2004.82},
file = {::},
isbn = {1581138644},
pages = {194--201},
publisher = {IEEE Computer Society},
title = {{Caring for agents and agents that care: Building empathic relations with synthetic agents}},
url = {http://dl.acm.org/citation.cfm?id=1018754 http://dx.doi.org/10.1109/AAMAS.2004.82},
year = {2004}
}
@article{ArthurJ.Clark2010,
abstract = {Expanding on a framework introduced by Carl Rogers, an integral model of empathy in counseling uses empathic understanding through 3 ways of knowing: Subjective empathy enables a counselor to momentarily experience what it is like to be a client, interpersonal empathy relates to understanding a client's phenomenological experiencing, and objective empathy uses reputable knowledge sources outside of a client's frame of reference. Across the counseling process, empathy is integral to treatment strategies and interventions.},
author = {{Arthur J. Clark}},
file = {::},
journal = {Journal of Counseling \& Development},
keywords = {Counseling,Counseling Techniques,Counselor Client Relationship,Empathy,Models},
number = {3},
pages = {348 -- 356},
title = {{Empathy: An integral model in the counseling process}},
url = {http://aca.metapress.com/link.asp?id=075658qt56l20466 },
volume = {88},
year = {2010}
}
@inproceedings{Lisetti2012,
address = {Miami, FLorida},
author = {Lisetti, Christine L},
booktitle = {IHI2012 International Health Informatics Sysmposium},
file = {::},
title = {{10 Advantages of using Avatars in Patient-Centered Computer-based Interventions for Behavior Change}},
year = {2012}
}
@article{Brug1999,
abstract = {Computer-tailored nutrition education may be more effective than general nutrition education because messages are tailored to individual behavior, needs and beliefs of subjects. Therefore, the messages are likely to be of more personal relevance and may have stronger motivational effects. Computer-generated nutrition education has been studied for different dietary behaviors, in different target populations, and in different settings. In recent years, eight studies have been published that assessed the impact of comprehensive computer-generated nutrition interventions that were based on behavior change theory. In this article, the process of providing people with computer-tailored nutrition education is described and the studies on the impact of computer-tailored nutrition education are reviewed. The results point to the conclusion that computer-tailored nutrition education is more likely to be read, remembered, and experienced as personally relevant compared to standard materials. Furthermore, computer-tailored nutrition education also appears to have a greater impact in motivating people to change their diet, their fat intake in particular, although at present no definite conclusions can be drawn.},
author = {Brug, J and Campbell, M and van Assema, P},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Brug, Campbell, van Assema - 1999 - The application and impact of computer-generated personalized nutrition education a review of the literature.pdf:pdf},
issn = {0738-3991},
journal = {Patient education and counseling},
keywords = {Attitude to Health,Computer-Assisted Instruction,Computer-Assisted Instruction: methods,Feedback,Health Education,Health Education: methods,Health Knowledge, Attitudes, Practice,Humans,Motivation,Needs Assessment,Nutrition Assessment,Nutritional Sciences,Nutritional Sciences: education,Patient Care Planning,Self Efficacy,Treatment Outcome},
month = feb,
number = {2},
pages = {145--56},
pmid = {10223019},
title = {{The application and impact of computer-generated personalized nutrition education: a review of the literature.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10223019},
volume = {36},
year = {1999}
}
@article{Ekman1974,
author = {Ekman, Paul and Freisen, Wallace V.},
file = {::},
journal = {Journal of Personality and Social Psychology},
number = {3},
pages = {288--298},
title = {{Detecting Deception From The Body Or Face}},
volume = {29},
year = {1974}
}
@article{Bartneck2003,
abstract = {A salient feature of the ambient intelligent home of the future will be the natural interaction between the home and its inhabitants through speech. An embodied home character is necessary to ensure a natural dialogue by continuously providing intuitive feedback in the form of conversational and emotional body language. This study experimentally investigates the influence of the characters embodiment (screen character and robotic character) and its emotional expressiveness on the enjoyability of the interaction. The presence of emotional expressions significantly increased the enjoyability of the interaction with the robotic character. The embodiment had no significant influence on the enjoyability. However, in the robotic character condition a social facilitation effect and a high forgiveness for speech recognition errors was observed.},
author = {Bartneck, Christoph},
journal = {Proceedings of the 2003 international conference on Designing pleasurable products and interfaces DPPI 03},
keywords = {ambient intelligent home,character,embodied,emotion,enjoyability,robot},
pages = {55},
publisher = {ACM Press},
title = {{Interacting with an embodied emotional character}},
url = {http://portal.acm.org/citation.cfm?doid=782896.782911},
year = {2003}
}
@inproceedings{Jiang2007,
author = {Jiang, Hong and Vidal, J.M. and Huhns, M.N.},
booktitle = {Proceedings of the 6th international joint conference on Autonomous agents and multiagent systems},
file = {::},
keywords = {agent architecture,belief-desire-intention,emotional agent},
pages = {11},
publisher = {ACM},
title = {{EBDI: an architecture for emotional agents}},
url = {http://dl.acm.org/citation.cfm?id=1329139},
year = {2007}
}
@book{Dimeff1999,
abstract = {(from the cover) This manual presents a pragmatic and clinically proven approach to the prevention and treatment of undergraduate alcohol abuse. The Brief Alcohol Screening and Intervention for College Students (BASICS) model is a nonconfrontational, harm reduction approach that helps students reduce their alcohol consumption and decrease the behavioral and health risks associated with heavy drinking. Including reproducible handouts and assessment forms, the book takes readers step-by-step through conducting BASICS assessment and feedback sessions. Special topics covered include the use of Diagnostic and Statistical Manual of Mental Disorders-IV (DSM-IV) criteria to evaluate alcohol abuse, ways to counter defensiveness about drinking and how to help students who continue to drink in a hazardous fashion. (PsycINFO Database Record (c) 2010 APA, all rights reserved) (cover)},
author = {Dimeff, Linda A and Baer, John S and Kivlahan, Daniel R and Marlatt, G Alan},
booktitle = {The Journal of Psychiatry Law},
isbn = {1572303921},
pages = {1929--1945},
publisher = {Guilford Press},
title = {{Brief alcohol screening and intervention for college students (BASICS): A harm reduction approach}},
url = {http://search.ebscohost.com/login.aspx?direct=true\&db=psyh\&AN=1999-02125-000\&lang=fr\&site=ehost-live},
volume = {30},
year = {1999}
}
@article{Jaques2007,
abstract = {In this article we describe the use of mental states approach, more specifically the belief-desire-intention (BDI) model, to implement the process of affective diagnosis in an educational environment. We use the psychological OCC model, which is based on the cognitive theory of emotions and is possible to be imple- mented computationally, in order to infer the learners emotions from his actions in the system interface. In our work we profit from the reasoning capacity of the BDI model in order to infer the students appraisal (a cognitive evaluation of a person that elicits an emotion), which allows us to deduce students emotions. The system reasons about an emotion-generating situation and tries to infer the users emotion by using the OCC model. Besides, the BDI model is very adequate to infer and also model students affective states since the emotions have a dynamic nature.},
author = {Jaques, Patricia Augustin and Vicari, Rosa Maria},
doi = {10.1016/j.compedu.2005.09.002},
file = {::},
issn = {03601315},
journal = {Computers \& Education},
keywords = {architectures for educational technology,computer,distance education and telelearning,human,intelligent tutoring systems,interactive learning environments,interface,media in education,system},
month = sep,
number = {2},
pages = {360--384},
title = {{A BDI approach to infer student’s emotions in an intelligent learning environment}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0360131505001302},
volume = {49},
year = {2007}
}
@article{Lisetti2003,
abstract = {Accountingfor a patient’s emotional state is integral in medical care. Tele-health research attests to the challenge clinicians must overcome in assessing patient emotional state when modalities are limited (J. Adv. Nurs. 36(5) 668). The extra effort involved in addressingthis challenge requires attention, skill, and time. Large caseloads may not afford tele-home health- care (tele-HHC) clinicians the time and focus necessary to accurately assess emotional states and trends. Unstructured interviews with experienced tele-HHC providers support the introduction of objective indicators of patients’ emotional status in a useful form to enhance patient care. We discuss our contribution to addressingthis challenge, which involves building user models not only of the physical characteristics of users—in our case patients—but also models of their emotions. We explain our research in progress on Affective Computing for tele-HHC applications, which includes: developinga system architecture for monitoringand respondingto human multimodal affect and emotions via multimedia and empathetic avatars; mapping of physiological signals to emotions and synthesizing the patient’s affective information for the health-care provider. Our results usinga wireless non-invasive wearable computer to collect physiological signals and mapping these to emotional states show the feasibility of our approach, for which we lastly discuss the future research issues that we have identified.},
author = {Lisetti, Christine L and Nasoz, F. and LeRouge, C. and Ozyer, O. and Alvarez, K.},
doi = {10.1016/S1071-5819(03)00051-X},
issn = {10715819},
journal = {International Journal of Human-Computer Studies},
keywords = {Affective computing,Emotions,Human factors of multimedia systems,Intelligent user interfaces,Tele-health,Tele-home health care,User modeling},
month = jul,
number = {1-2},
pages = {245--255},
title = {{Developing multimodal intelligent affective interfaces for tele-home health care}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S107158190300051X},
volume = {59},
year = {2003}
}
@article{Barnett2007,
abstract = {The purpose of this study was to evaluate the efficacy of two brief interventions and the inclusion of a 1-month booster session with college students who were referred to attend alcohol education following an alcohol-related incident. Participants (N=225; 48.9\% male) were randomly assigned to receive one session of a Brief Motivational Interview (BMI) or computer-delivered intervention (CDI) with the Alcohol 101 CD-ROM. Participants were also randomly assigned to booster/no booster. At 3-month follow up, participants in BMI reported greater help seeking and use of behavioral strategies to moderate drinking. At 12-month follow up, BMI participants were drinking more frequently and CDI participants were consuming a greater number of drinks per occasion than at baseline. Mediation analyses showed that the use of specific behavioral strategies mediated the effect of the BMI condition on drinking volume. There was no intervention effect on alcohol problems, and the booster condition did not significantly affect outcomes. Promoting specific behaviors in the context of in-person brief interventions may be a promising approach to reducing drinking volume among identified at-risk students.},
author = {Barnett, Nancy P and Murphy, James G and Colby, Suzanne M and Monti, Peter M},
doi = {10.1016/j.addbeh.2007.06.017},
issn = {0306-4603},
journal = {Addictive behaviors},
keywords = {Alcohol Drinking,Alcohol Drinking: epidemiology,Alcohol Drinking: prevention \& control,Alcohol Drinking: psychology,Computer-Assisted Instruction,Computer-Assisted Instruction: methods,Directive Counseling,Directive Counseling: methods,Female,Follow-Up Studies,Humans,Male,Mandatory Programs,Motivation,Psychotherapy, Brief,Students,Treatment Outcome},
month = dec,
number = {11},
pages = {2529--48},
pmid = {17707594},
title = {{Efficacy of counselor vs. computer-delivered intervention with mandated college students.}},
url = {http://dx.doi.org/10.1016/j.addbeh.2007.06.017},
volume = {32},
year = {2007}
}
@inproceedings{Wright2008,
author = {Wright, Peter and McCarthy, J.},
booktitle = {Proceeding of the twenty-sixth annual SIGCHI conference on Human factors in computing systems},
file = {::},
isbn = {9781605580111},
pages = {637--646},
publisher = {ACM},
title = {{Empathy and experience in HCI}},
url = {http://dl.acm.org/citation.cfm?id=1357156},
year = {2008}
}
@article{Vannini2010,
abstract = {Bullying is widespread in European schools, despite multiple intervention strategies having been proposed over the years. The present study investigates the effects of a novel virtual learning strategy (“FearNot!”) to tackle bullying in both UK and German samples. The approach is intended primarily for victims to increase their coping skills and further to heighten empathy and defence of victims by non-involved bystanders. This paper focuses on the defender role. Applying quantitative as well as qualitative methodology, the present study found that “FearNot!” helped non-involved children to become defenders in the German sub-sample while it had no such effect in the UK sub-sample. German “New Defenders” (children who are initially uninvolved but are nominated as defenders by their peers after the intervention period) were found to be significantly more popular at baseline, and to show more cognitive empathy (Theory of Mind) for the virtual victims as compared to permanently non-involved pupils. Moreover, gender interacts with becoming a defender in its effects on affective empathy, with emotional contagion being particularly associated with New Defender status among girls. The findings are discussed in relation to previous research on anti-bullying intervention strategies and cultural differences in bullying prevalence rates and intervention outcomes.},
author = {Vannini, Natalie and Enz, Sibylle and Sapouna, Maria and Wolke, Dieter and Watson, Scott and Woods, Sarah and Dautenhahn, Kerstin and Hall, Lynne and Paiva, Ana and Andr\'{e}, Elizabeth and Aylett, Ruth and Schneider, Wolfgang},
doi = {10.1007/s10212-010-0035-4},
file = {::},
issn = {0256-2928},
journal = {European Journal of Psychology of Education},
month = jun,
number = {1},
pages = {21--44},
title = {{“FearNot!”: a computer-based anti-bullying-programme designed to foster peer intervention}},
url = {http://www.springerlink.com/index/10.1007/s10212-010-0035-4 http://dx.doi.org/10.1007/s10212-010-0035-4},
volume = {26},
year = {2010}
}
@article{Cappella1990,
author = {Cappella, Joseph N.},
doi = {10.1207/s15327965pli0104\_5},
file = {::},
issn = {1047-840X},
journal = {Psychological Inquiry},
month = oct,
number = {4},
pages = {303--305},
title = {{On Defining Conversational Coordination and Rapport}},
url = {http://www.tandfonline.com/doi/abs/10.1207/s15327965pli0104\_5},
volume = {1},
year = {1990}
}
@incollection{Plutchik1980,
address = {New York},
author = {Plutchik, R},
booktitle = {Emotion: Theory, research, and experience},
chapter = {Theories o},
editor = {Plutchik, R and Kellerman, H},
number = {3},
pages = {3--33},
publisher = {Academic Press},
series = {Emotion: Theory, research, and experience: Vol. 1. Theories of emotion},
title = {{A general psychoevolutionary theory of emotion}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:A+general+psychoevolutionary+theory+of+emotion\#0},
volume = {1},
year = {1980}
}
@inproceedings{Morency2008,
abstract = {During face-to-face interactions, listeners use backchannel feedback such as head nods as a signal to the speaker that the communication is working and that they should continue speaking. Predicting these backchannel opportunities is an important milestone for building engaging and natural virtual humans. In this paper we show how sequential probabilistic models (e.g., Hidden Markov Model or Conditional Random Fields) can automatically learn from a database of human-to-human interactions to predict listener backchannels using the speaker multimodal output features (e.g., prosody, spoken words and eye gaze). The main challenges addressed in this paper are automatic selection of the relevant features and optimal feature representation for probabilistic models. For prediction of visual backchannel cues (i.e., head nods), our prediction model shows a statistically significant improvement over a previously published approach based on hand-crafted rules.},
address = {Tokyo, Japan},
author = {Morency, LP and Kok, Iwan De and Gratch, Jonathan},
booktitle = {8th International Conference (IVA'08},
doi = {10.1007/978-3-540-85483-8\_18},
file = {::},
pages = {176--190},
publisher = {Springer Berlin Heidelberg},
title = {{Predicting listener backchannels: A probabilistic multimodal approach}},
url = {http://www.springerlink.com/index/180267KR7P8PT321.pdf},
year = {2008}
}
@article{Niewiadomski2008,
author = {Niewiadomski, Radoslaw and Ochs, Magalie},
file = {::},
journal = {Intelligent Virtual Agents},
keywords = {eca,empathy,facial expressions},
pages = {37--44},
title = {{Expressions of empathy in ECAs}},
url = {http://www.springerlink.com/index/618982507263X720.pdf},
year = {2008}
}
@article{Wu2008,
author = {Wu, Siew-Rong},
doi = {10.1109/DIGITEL.2008.27},
file = {::},
isbn = {978-0-7695-3409-1},
journal = {2008 Second IEEE International Conference on Digital Game and Intelligent Toy Enhanced Learning},
pages = {213--214},
publisher = {Ieee},
title = {{Humor and Empathy: Developing Students' Empathy through Teaching Robots to Tell English Jokes}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4700764},
year = {2008}
}
@inproceedings{Dahlberg2008,
abstract = {Research experiences for undergraduates are considered an effective means for increasing student retention and encouraging undergraduate students to continue on to graduate school. However, managing a cohort of undergraduate researchers, with varying skill levels, can be daunting for faculty advisors. We have developed a program to engage students in research and outreach in visualization, virtual reality, networked robotics, and interactive games. Our program immerses students into the life of a lab, employing a situated learning approach that includes tiered mentoring and collaboration to enable students at all levels to contribute to research. Students work in research comprised of other undergraduates, graduate students and faculty, and participate in professional development and social gatherings within the larger cohort. Results from our first two years indicate this approach is manageable and effective for increasing students’ ability and desire to conduct research.},
address = {New York, New York, USA},
author = {Dahlberg, Teresa and Barnes, Tiffany and Rorrer, Audrey and Powell, Eve and Cairco, Lauren},
booktitle = {Proceedings of the 39th SIGCSE technical symposium on Computer science education - SIGCSE '08},
doi = {10.1145/1352135.1352293},
file = {::},
isbn = {9781595937995},
keywords = {education,undergraduate research},
pages = {466},
publisher = {ACM Press},
title = {{Improving retention and graduate recruitment through immersive research experiences for undergraduates}},
url = {http://portal.acm.org/citation.cfm?doid=1352135.1352293},
year = {2008}
}
@article{Creed2008,
author = {Creed, Chris and Beale, Russell},
file = {::},
journal = {Computational Intelligence: A Compendium},
pages = {185--230},
publisher = {Springer},
title = {{Emotional Intelligence: Giving Computers Effective Emotional Skills to Aid Interaction}},
url = {http://www.springerlink.com/index/U2231064587Q8V07.pdf},
volume = {230},
year = {2008}
}
@inproceedings{Gordon1985,
address = {Baguio, Philippines},
annote = {Three ways to improve empathetic listening are to 
1.      Avoid judgment: the empathetic communicator must avoid making comparisons or passing moral judgments. 
2.      Give the speaker time to speak without interruption 
3.      Focus on the speaker: the empathetic communicator needs to focus his or her attention on the speaker, and not distract from this focus by verbally calling undue attention to oneself or one’s own situation [14]. },
author = {Gordon, Ronald D.},
booktitle = {International COnference of the World Communication Association},
file = {::},
pages = {1--16},
title = {{Empathy: The State of the Art and Science}},
year = {1985}
}
@article{Prendinger2005,
abstract = {They designed an animated interface agent that accompanies the user in the setting of a virtual job interview. This interface application takes physiological data (skin conductance and electromyography) of a user in realtime, interprets them as emotions, and addresses the user’s affective states in the form of empathic feedback by employing embodied characters.},
annote = {They take physiological data (skin conductance and electromyography) of a user in real-time, interpret them as emotions, and address the user’s affective states by empathic feedback. A decision making agent relates these signals and the user’s answer to arousal and valence to infer the user’s emotional state by applying the model of Lang (1995) (Lang claims that all emotions can be characterized in terms of valence (pleasant or unpleasant) and arousal (calm or aroused)). Then it selects empathetic actions that maximize some utility function. They use text-based empathetic actions in addition to a small full body character.We can use the decision-theoretic agent aspect in our empathy model.
The empathy is mainly expressed in a text-base fashion in their job. The embodied agent that they have is so small and no facial expressions are used. There are some gestural expressions.
As shown in this paper and many other ones, text-base empathy expression can be effective. So we can use that too.
      },
author = {Prendinger, Helmut and Ishizuka, M.},
file = {::;::},
journal = {Applied Artificial Intelligence},
keywords = {electromyography,physiological signals,skin conductance},
number = {3-4},
pages = {267--286},
publisher = {Citeseer},
title = {{The Empathic Companion - A Character-based Interface that Addresses Users’ Affective States}},
url = {citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.79.4710\&rep=rep1\&type=pdf},
volume = {19},
year = {2005}
}
@article{Ekman1983,
author = {Ekman, Paul and Levenson, Robert W and Freisen, Wallace V.},
file = {::},
journal = {Science},
number = {4616},
pages = {1208--1210},
title = {{Autonomic Nervous System Activity Distinguishes among Emotions}},
volume = {221},
year = {1983}
}
@article{Kiesler2008,
author = {Kiesler, Sara and Powers, Aaron and Fussell, Susan R. and Torrey, Cristen},
doi = {10.1521/soco.2008.26.2.169},
file = {::},
issn = {0278-016X},
journal = {Social Cognition},
month = apr,
number = {2},
pages = {169--181},
title = {{Anthropomorphic Interactions with a Robot and Robot–like Agent}},
url = {http://guilfordjournals.com/doi/abs/10.1521/soco.2008.26.2.169},
volume = {26},
year = {2008}
}
@article{Schneier2011,
author = {Schneier, B.},
file = {::},
journal = {Security \& Privacy, IEEE},
number = {5},
pages = {88--88},
publisher = {IEEE},
title = {{Empathy and Security}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6029366},
volume = {9},
year = {2011}
}
@article{Prevost1994,
abstract = {This paper presents a theory and a computational implementation for generating prosodically appropriate synthetic speech in response to database queries. Proper distinctions of contrast and emphasis are expressed in an intonation contour that is synthesized by rule under the control of a grammar, a discourse model, and a knowledge base. The theory is based on Combinatory Categorial Grammar, a formalism which easily integrates the notions of syntactic constituency, semantics, prosodic phrasing and information structure. Results from our current implementation demonstrate the system's ability to generate a variety of intonational possibilities for a given sentence depending on the discourse context.},
author = {Prevost, Scott and Steedman, Mark},
file = {::},
journal = {Speech Communication},
number = {1-2},
pages = {18},
publisher = {Citeseer},
title = {{Specifying Intonation from Context for Speech Synthesis}},
url = {http://arxiv.org/abs/cmp-lg/9407015},
volume = {15},
year = {1994}
}
@article{Decety2004,
abstract = {Empathy accounts for the naturally occurring subjective experience of similarity between the feelings expressed by self and others without loosing sight of whose feelings belong to whom. Empathy involves not only the affective experience of the other person's actual or inferred emotional state but also some minimal recognition and understanding of another's emotional state. In light of multiple levels of analysis ranging from developmental psychology, social psychology, cognitive neuroscience, and clinical neuropsychology, this article proposes a model of empathy that involves parallel and distributed processing in a number of dissociable computational mechanisms. Shared neural representations, self-awareness, mental flexibility, and emotion regulation constitute the basic macrocomponents of empathy, which are underpinned by specific neural systems. This functional model may be used to make specific predictions about the various empathy deficits that can be encountered in different forms of social and neurological disorders.},
author = {Decety, Jean and Jackson, Philip L},
doi = {10.1177/1534582304267187},
file = {::},
isbn = {1534582304267},
issn = {1534-5823},
journal = {Behavioral and cognitive neuroscience reviews},
keywords = {affective sharing,emotion regulation,executive inhibition,intersubjectivity,perspective taking,self-awareness,shared representations},
month = jun,
number = {2},
pages = {71--100},
pmid = {15537986},
title = {{The functional architecture of human empathy}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15537986},
volume = {3},
year = {2004}
}
@article{Caridakis2008,
abstract = {As input they consider the image sequence of the recorded human behavior. Computer vision and image processing techniques are incorporated in order to detect cues needed for expressivity features extraction. Using multimodalities, the virtual agent mimics the human expressions. The multimodality of the approach lies in the fact that both facial and gestural aspects of the user’s behavior are analyzed and processed. The mimicry consists of perception, interpretation, planning and animation of the expressions shown by the human, resulting not in an exact duplicate rather than an expressive model of the user’s original behavior.},
annote = {They use both facial and gestural aspects of the user’s behavior to mimic the user’s expressions. The introductory information and references about the psychological background of the mimicry in the paper are useful. But because most of the work is image processing, other sections would not be useful for our job.
Their system does not work in real time because they use a recorded video or sequence of images (limitation).},
author = {Caridakis, George and Raouzaiou, Amaryllis and Bevacqua, Elisabetta and Mancini, Maurizio and Karpouzis, Kostas and Malatesta, Lori and Pelachaud, Catherine},
doi = {10.1007/s10579-007-9057-1},
file = {::},
issn = {1574-020X},
journal = {Language Resources and Evaluation},
keywords = {facial,gesture,mimicry,multimodal,virtual agent},
month = jan,
number = {3-4},
pages = {367--388},
title = {{Virtual agent multimodal mimicry of humans}},
volume = {41},
year = {2008}
}
@article{McQuiggan2008b,
abstract = {Humans continuously assess one another’s situational context, modify their own affective state, and then respond based on these outcomes through empathetic expression. Virtual agents should be capable of similarly empathizing with users in interactive environments. A key challenge posed by empathetic reasoning in virtual agents is determining whether to respond with parallel or reactive empathy. Parallel empathy refers to mere replication of another’s affective state, whereas reactive empathy exhibits greater cognitive awareness and may lead to incongruent emotional responses (i.e., emotions different from the recipient’s and perhaps intended to alter negative affect). This paper proposes a unified inductive framework for modeling parallel and reactive empathy. Empathy models are used to drive runtime situation-appropriate empathetic behaviors by selecting suitable parallel or reactive empathetic expressions.},
author = {McQuiggan, SW and Robison, JL and Phillips, Robert},
file = {::},
journal = {on Autonomous agents},
number = {Aamas},
pages = {167--174},
title = {{Modeling parallel and reactive empathy in virtual agents: An inductive approach}},
url = {http://portal.acm.org/citation.cfm?id=1402411},
year = {2008}
}
@article{Drapeau2009,
abstract = {Persons with dementia of the Alzheimer type (DAT) are impaired in recognizing emotions from face and voice. Yet clinical practitioners use these mediums to communicate with DAT patients. Music is also used in clinical practice, but little is known about emotional processing from music in DAT. This study aims to assess emotional recognition in mild DAT. Seven patients with DAT and 16 healthy elderly adults were given three tasks of emotional recognition for face, prosody, and music. DAT participants were only impaired in the emotional recognition from the face. These preliminary results suggest that dynamic auditory emotions are preserved in DAT.},
author = {Drapeau, Joanie and Gosselin, Nathalie and Gagnon, Lise and Peretz, Isabelle and Lorrain, Dominique},
doi = {10.1111/j.1749-6632.2009.04768.x},
file = {::},
issn = {1749-6632},
journal = {Annals of the New York Academy of Sciences},
keywords = {Aged,Alzheimer Disease,Alzheimer Disease: physiopathology,Alzheimer Disease: psychology,Emotions,Face,Female,Humans,Male,Music,Recognition (Psychology),Recognition (Psychology): physiology,Voice},
month = jul,
pages = {342--5},
pmid = {19673804},
title = {{Emotional recognition from face, voice, and music in dementia of the Alzheimer type.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19673804},
volume = {1169},
year = {2009}
}
@article{DeRosis2003,
abstract = {This paper describes the results of a research project aimed at implementing a 'realistic' 3D Embodied Agent that can be animated in real-time and is 'believable and expressive': that is, able to coherently communicate complex information through the combination and the tight synchronisation of verbal and nonverbal signals. We describe, in particular, how we 'animate' this Agent (that we called Greta) so as to enable her to manifest the affective states that are dynamically activated and de-activated in her mind during the dialog with the user. The system is made up of three tightly interrelated components: A representation of the Agent Mind: this includes long and short-term affective components (personality and emotions) and simulates how emotions are triggered and decay over time according to the Agent's personality and to the context, and how several emotions may overlap. Dynamic belief networks with weighting of goals is the formalism we employ to this purpose. A mark-up language to denote the communicative meanings that may be associated with dialog moves performed by the Agent. A translation of the Agent's tagged move into a face expression, that combines appropriately the available channels (gaze direction, eyebrow shape, head direction and movement etc). The final output is a 3-D facial model that respects the MPEG-4 standard and uses MPEG-4 Facial Animation Parameters to produce facial expressions. Throughout the paper, we illustrate the results obtained, with an example of dialog in the domain of 'Advice about eating disorders'. The paper concludes with an analysis of advantages of our cognitive model of emotion triggering and of the problems found in testing it. Although we did not yet complete a formal evaluation of our system, we briefly describe how we plan to assess the agent's believability in terms of consistency of its communicative behaviour. (C) 2003 Elsevier Science Ltd. All rights reserved.},
author = {{De Rosis}, F and Pelachaud, Catherine and Poggi, Isabella and Carofiglio, V and {De Carolis}, Berardina},
doi = {10.1016/S1071-5819(03)00020-X},
issn = {10715819},
journal = {International Journal of Human-Computer Studies},
number = {1-2},
pages = {81--118},
title = {{From Greta's mind to her face: modelling the dynamics of affective states in a conversational embodied agent}},
volume = {59},
year = {2003}
}
@techreport{Pereira2006,
abstract = {In this report we present the Emotional-BDI architecture, an extension to the BDI architecture supporting Artificial Emotions and including internal representations for agent’s Capabilities and Resources. The architecture we present here, is conceptual, defining which components should exist so that Emotional- BDI agents can use Effective Capabilities as well as Effective Resources in order to better cope with highly dynamic environments.},
address = {Porto, Portugal},
author = {Pereira, David and Oliveira, Eugenio and Moreira, Nelma},
file = {::},
institution = {Universidade do Porto},
keywords = {Artificial Emotions,BDI Agents},
title = {{Towards an Architecture for Emotional BDI Agents}},
year = {2006}
}
@inproceedings{DeCarolis2010,
abstract = {As far as interaction is concerned Ambient Intelligence (AmI) research emphasizes the need of natural and friendly interfaces for accessing services provided by the environment. In this paper we present the result of an experimental study aiming at understanding whether Embodied Conversational Agents (ECAs) and Social Robots may improve the naturalness and effectiveness of interaction by playing different roles when acting as interface between users and smart environment services. Results obtained so far show that ECAs seem to have a better evaluation than robots for information related tasks. On the other side, Social Robots are preferred for welcoming people and for guiding them in the smart environment, due to their possibility to move and to the perceived sense of presence. Moreover, the robot seems to elicit a more positive evaluation in terms of user experience.},
address = {New York, New York, USA},
author = {{De Carolis}, Berardina and Mazzotta, Irene and Novielli, Nicole and Pizzutilo, Sebastiano},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces - AVI '10},
doi = {10.1145/1842993.1843041},
file = {::},
isbn = {9781450300766},
keywords = {animated interfaces,interface evaluation},
pages = {275--278},
publisher = {ACM Press},
title = {{Social robots and ECAs for accessing smart environments services}},
url = {http://portal.acm.org/citation.cfm?doid=1842993.1843041},
year = {2010}
}
@article{Maurer1983,
author = {Maurer, R.E. and Tindall, J.H.},
file = {::},
journal = {Journal of Counseling Psychology},
number = {2},
pages = {158},
publisher = {American Psychological Association},
title = {{Effect of postural congruence on client's perception of counselor empathy.}},
volume = {30},
year = {1983}
}
@inproceedings{Courgeon2008,
address = {Estoril, Portugal},
annote = {The user reports his/her affective state in real-time with changing the position of a 3D point in PAD space using a joystick. The system captures the position of that point and maps it to a blend of 8 selected emotions. },
author = {Courgeon, Matthieu and Martin, Jean-claude and Jacquemin, Christian},
booktitle = {Proc. of 7th Int. Conf. on Autonomous Agents and Multiagent Systems (AAMAS 2008)},
file = {::},
number = {Aamas},
pages = {1237--1240},
title = {{User ’ s Gestural Exploration of Different Virtual Agents ’ Expressive Profiles ( Short Paper )}},
year = {2008}
}
@article{Wolf2010,
abstract = {Computer Vision and Biometrics systems have demonstrated considerable improvement in recognizing and verifying faces in digital images. Still, recognizing faces appearing in unconstrained, natural conditions remains a challenging task. In this paper we present a face-image, pair-matching approach primarily developed and tested on the "Labeled Faces in the Wild" (LFW) benchmark that reflect the challenges of face recognition from unconstrained images. The approach we propose makes the following contributions. (a) We present a family of novel face-image descriptors designed to capture statistics of local patch similarities. (b) We demonstrate how semi-labeled background samples may be used to better evaluate image similarities. To this end we describe a number of novel, effective similarity measures. (c) We show how labeled background samples, when available, may further improve classification performance, by employing a unique pair-matching pipeline. We present state-of-the-art results on the LFW pair-matching benchmarks. In addition, we show our system to be well suited for multi-label face classification (recognition) problems. We perform recognition tests on LFW images as well images from the laboratory controlled multiPIE database.},
author = {Wolf, Lior and Hassner, Tal and Taigman, Yaniv},
doi = {10.1109/TPAMI.2010.230},
file = {::},
issn = {1939-3539},
journal = {IEEE transactions on pattern analysis and machine intelligence},
month = dec,
number = {X},
pages = {1--13},
pmid = {21173442},
title = {{Effective Unconstrained Face Recognition by Combining Multiple Descriptors and Learned Background Statistics.}},
volume = {33},
year = {2010}
}
@inproceedings{Arapakis2009,
abstract = {Recommender systems have been systematically applied in industry and academia to help users cope with information uncertainty. However, given the multiplicity of the pref- erences and needs it has been shown that no approach is suitable for all users in all situations. Thus, it is believed that an effective recommender system should incorporate a variety of techniques and features to offer valuable recom- mendations and enhance the search experience. In this pa- per we propose a novel video search interface that employs a multimodal recommender system, which can predict top- ical relevance. The multimodal recommender accounts for interaction data, contextual information, as well as users’ af- fective responses, and exploits these information channels to provide meaningful recommendations of unseen videos. Our experiment shows that the multimodal interaction feature is a promising way to improve the performance of recommen- dation.},
address = {New York, New York, USA},
author = {Arapakis, Ioannis and Moshfeghi, Yashar and Joho, Hideo and Ren, Reede and Hannah, David and Jose, Joemon M.},
booktitle = {Proceeding of the ACM International Conference on Image and Video Retrieval - CIVR '09},
doi = {10.1145/1646396.1646433},
file = {::},
isbn = {9781605584805},
keywords = {Affective feedback,facial expression analysis,multimedia re- trieval,recommender systems,user profilin},
publisher = {ACM Press},
title = {{Enriching user profiling with affective features for the improvement of a multimodal recommender system}},
url = {http://portal.acm.org/citation.cfm?doid=1646396.1646433},
year = {2009}
}
@article{Breazeal2005,
author = {Breazeal, Cynthia and Buchsbaum, Daphna and Gray, Jesse and Gatenby, David and Blumberg, Bruce},
file = {::},
journal = {Artificial Life},
number = {1-2},
pages = {31--62},
publisher = {MIT Press},
title = {{Learning from and about others: Towards using imitation to bootstrap the social understanding of others by robots}},
volume = {11},
year = {2005}
}
@inproceedings{Sourina2011a,
abstract = {To make human computer interfaces more immersive and intuitive, a new dimension could be added. Real-time brain state recognition from EEG in- cluding emotion recognition and level of concentration recognition would make an access to information more adaptive and personalized. Modern EEG tech- niques give us an easy and portable way to monitor brain activities by using suitable signal processing and classification methods and algorithms. We pro- posed a new subject-dependent fractal-based approach to brain state recognition and innovative applications based on EEG-enable user’s interaction. The algo- rithms of the “inner” brain state quantification including emotion recognition would advance research on human computer interaction bringing the proposed novel objective quantification methods and algorithms as new tools in medical, entertainment, and even digital art methodology applications, and allowing us an integration of the brain state quantification algorithms in the human com- puter interfaces. In this paper, we describe our fractal-based approach to the brain state recognition and its EEG-enable applications such as serious games, emotional avatar, music therapy, music player, and storytelling.},
author = {Sourina, Olga and Liu, Yisi and Wang, Qiang and Nguyen, Minh Khoa},
booktitle = {Proceedings of the 6th international conference on Universal access in human-computer interaction: users diversity - Volume Part II (UAHCI'11)},
file = {::},
keywords = {BCI,HCI,emotion recognition,fractal dimension,music therapy,serious game,storytelling.},
pages = {591--599},
publisher = {Springer-Verlag Berlin, Heidelberg},
title = {{EEG-Based Personalized Digital Experience}},
year = {2011}
}
@article{Bavelas1986,
author = {Bavelas, Janet Beavin and Black, Alex and Lemery, Charles R. and {Jennifer Muller}},
file = {::},
journal = {Journal of Personality and Social Psychology},
number = {2},
pages = {322--329},
title = {{"I show how you feel" - Motor mimicry as a communicative act}},
volume = {50},
year = {1986}
}
@inproceedings{Legaspi2008,
author = {Legaspi, Roberto and Kurihara, Satoshi and Fukui, K.I. and Moriyama, Koichi and Numao, Masayuki},
booktitle = {Human system interactions, 2008 conference on},
file = {::},
isbn = {1424415438},
keywords = {empathic computing,interfaces,machine learning,user modeling and user-adaptive},
pages = {209--214},
publisher = {IEEE},
title = {{An empathy learning problem for HSI: To be empathic, self-improving and ambient}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4581435},
year = {2008}
}
@article{DeRosis2003,
abstract = {This paper describes the results of a research project aimed at implementing a 'realistic' 3D Embodied Agent that can be animated in real-time and is 'believable and expressive': that is, able to coherently communicate complex information through the combination and the tight synchronisation of verbal and nonverbal signals. We describe, in particular, how we 'animate' this Agent (that we called Greta) so as to enable her to manifest the affective states that are dynamically activated and de-activated in her mind during the dialog with the user. The system is made up of three tightly interrelated components: A representation of the Agent Mind: this includes long and short-term affective components (personality and emotions) and simulates how emotions are triggered and decay over time according to the Agent's personality and to the context, and how several emotions may overlap. Dynamic belief networks with weighting of goals is the formalism we employ to this purpose. A mark-up language to denote the communicative meanings that may be associated with dialog moves performed by the Agent. A translation of the Agent's tagged move into a face expression, that combines appropriately the available channels (gaze direction, eyebrow shape, head direction and movement etc). The final output is a 3-D facial model that respects the MPEG-4 standard and uses MPEG-4 Facial Animation Parameters to produce facial expressions. Throughout the paper, we illustrate the results obtained, with an example of dialog in the domain of 'Advice about eating disorders'. The paper concludes with an analysis of advantages of our cognitive model of emotion triggering and of the problems found in testing it. Although we did not yet complete a formal evaluation of our system, we briefly describe how we plan to assess the agent's believability in terms of consistency of its communicative behaviour. (C) 2003 Elsevier Science Ltd. All rights reserved.},
author = {{De Rosis}, F and Pelachaud, Catherine and Poggi, I and Carofiglio, V and {De Carolis}, B},
doi = {10.1016/S1071-5819(03)00020-X},
issn = {10715819},
journal = {International Journal of Human-Computer Studies},
number = {1-2},
pages = {81--118},
title = {{From Greta's mind to her face: modelling the dynamics of affective states in a conversational embodied agent}},
volume = {59},
year = {2003}
}
@inproceedings{Adam2006,
abstract = {Nowadays, more and more artificial agents integrate emotional abil- ities, for different purposes: expressivity, adaptability, believability... Designers mainly use Ortony et al.’s typology of emotions, that provides a formalization of twenty-two emotions based on psychological theories. But most of them restrain their agents to a fewemotions among these twenty-two ones, and are more or less faithful to their definition. In this paper we propose to extend standard BDI (be- lief, desire, intention) logics to account formore emotions while trying to respect their definitions as exactly as possible.},
author = {Adam, Carole and Gaudou, Benoit and Herzig, Andreas and Longin, Dominique},
booktitle = {The 12th International Conference on Artificial Intelligence: Methodology, Systems, Applications},
editor = {Euzenat, J. and Domingue, J.},
file = {::},
pages = {24--32},
publisher = {Springer-Verlag},
title = {{OCC's emotions: a formalization in a BDI logic}},
url = {http://www.springerlink.com/index/F45K737M44J10840.pdf},
volume = {9},
year = {2006}
}
@article{Boukricha2007,
abstract = {Addressing user’s emotions in human-computer interaction significantly enhances the believability and lifelikeness of virtual humans. Emotion recognition and interpretation is realized in our approach by integrating empathy as a designated process within the agent’s cognitive architecture. In this paper we describe this empathy process which comprises of two interconnected components: a belief-desire-intention (BDI) based cognitive component and an affective component based on the emotion simulation system of the virtual human Max.},
author = {Boukricha, Hana and Becker-Asano, Christian},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Boukricha, Becker-Asano - 2007 - Simulating empathy for the virtual human max(3).pdf:pdf},
journal = {on Emotion and Computing in conj},
title = {{Simulating empathy for the virtual human max}},
year = {2007}
}
@inproceedings{Adam2006,
abstract = {Nowadays, more and more artificial agents integrate emotional abil- ities, for different purposes: expressivity, adaptability, believability... Designers mainly use Ortony et al.’s typology of emotions, that provides a formalization of twenty-two emotions based on psychological theories. But most of them restrain their agents to a fewemotions among these twenty-two ones, and are more or less faithful to their definition. In this paper we propose to extend standard BDI (be- lief, desire, intention) logics to account formore emotions while trying to respect their definitions as exactly as possible.},
author = {Adam, Carole and Gaudou, Benoit and Herzig, Andreas and Longin, Dominique},
booktitle = {The 12th International Conference on Artificial Intelligence: Methodology, Systems, Applications},
editor = {Euzenat, J. and Domingue, J.},
file = {::},
pages = {24--32},
publisher = {Springer-Verlag},
title = {{OCC's emotions: a formalization in a BDI logic}},
url = {http://www.springerlink.com/index/F45K737M44J10840.pdf},
volume = {9},
year = {2006}
}
@article{Barkham2001,
abstract = {To complement the evidence-based practice paradigm, the authors argued for a core outcome measure to provide practice-based evidence for the psychological therapies. Utility requires instruments that are acceptable scientifically, as well as to service users, and a coordinated implementation of the measure at a national level. The development of the Clinical Outcomes in Routine Evaluation-Outcome Measure (CORE-OM) is summarized. Data are presented across 39 secondary-care services (n = 2,710) and within an intensively evaluated single service (n = 1,455). Results suggest that the CORE-OM is a valid and reliable measure for multiple settings and is acceptable to users and clinicians as well as policy makers. Baseline data levels of patient presenting problem severity, including risk, are reported in addition to outcome benchmarks that use the concept of reliable and clinically significant change. Basic quality improvement in outcomes for a single service is considered.},
author = {Barkham, M and Margison, F and Leach, C and Lucock, M and Mellor-Clark, J and Evans, C and Benson, L and Connell, J and Audin, K and McGrath, G},
issn = {0022006X},
journal = {Journal of Consulting and Clinical Psychology},
number = {2},
pages = {184--96},
title = {{Service profiling and outcomes benchmarking using the CORE-OM: toward practice-based evidence in the psychological therapies. Clinical Outcomes in Routine Evaluation-Outcome Measures}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11393596?ordinalpos=17\&itool=EntrezSystem2.PEntrez.Pubmed.Pubmed\_ResultsPanel.Pubmed\_RVDocSum},
volume = {69},
year = {2001}
}
@article{Zahn-waxler1992,
author = {Zahn-Waxler, Carolyn and Robinson, JoAnn L. and Emde, Robert N.},
doi = {10.1037//0012-1649.28.6.1038},
file = {::},
issn = {0012-1649},
journal = {Developmental Psychology},
number = {6},
pages = {1038--1047},
title = {{The development of empathy in twins.}},
volume = {28},
year = {1992}
}
@article{Decety2004,
abstract = {Empathy accounts for the naturally occurring subjective experience of similarity between the feelings expressed by self and others without loosing sight of whose feelings belong to whom. Empathy involves not only the affective experience of the other person's actual or inferred emotional state but also some minimal recognition and understanding of another's emotional state. In light of multiple levels of analysis ranging from developmental psychology, social psychology, cognitive neuroscience, and clinical neuropsychology, this article proposes a model of empathy that involves parallel and distributed processing in a number of dissociable computational mechanisms. Shared neural representations, self-awareness, mental flexibility, and emotion regulation constitute the basic macrocomponents of empathy, which are underpinned by specific neural systems. This functional model may be used to make specific predictions about the various empathy deficits that can be encountered in different forms of social and neurological disorders.},
author = {Decety, Jean and Jackson, Philip L},
doi = {10.1177/1534582304267187},
file = {::},
isbn = {1534582304267},
issn = {1534-5823},
journal = {Behavioral and cognitive neuroscience reviews},
keywords = {Adaptation, Psychological,Adolescent,Adult,Awareness,Awareness: physiology,Cerebral Cortex,Cerebral Cortex: physiology,Child,Child, Preschool,Emotions,Emotions: physiology,Empathy,Humans,Infant,Models, Neurological,Models, Psychological,Perception,Perception: physiology,Self Concept,Social Behavior},
month = jun,
number = {2},
pages = {71--100},
pmid = {15537986},
title = {{The functional architecture of human empathy.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15537986},
volume = {3},
year = {2004}
}
@article{Hess2001,
author = {Hess, Ursula and Blairy, Sylvie},
file = {::},
journal = {International Journal of Psychophysiology},
keywords = {emotion recognition,emotional contagion,facial mimicry},
pages = {129--141},
title = {{Facial mimicry and emotional contagion to dynamic emotional facial expressions and their influence on decoding accuracy}},
volume = {40},
year = {2001}
}
@inproceedings{DeCarolis2010,
abstract = {As far as interaction is concerned Ambient Intelligence (AmI) research emphasizes the need of natural and friendly interfaces for accessing services provided by the environment. In this paper we present the result of an experimental study aiming at understanding whether Embodied Conversational Agents (ECAs) and Social Robots may improve the naturalness and effectiveness of interaction by playing different roles when acting as interface between users and smart environment services. Results obtained so far show that ECAs seem to have a better evaluation than robots for information related tasks. On the other side, Social Robots are preferred for welcoming people and for guiding them in the smart environment, due to their possibility to move and to the perceived sense of presence. Moreover, the robot seems to elicit a more positive evaluation in terms of user experience.},
address = {New York, New York, USA},
author = {{De Carolis}, Berardina and Mazzotta, Irene and Novielli, Nicole and Pizzutilo, Sebastiano},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces - AVI '10},
doi = {10.1145/1842993.1843041},
file = {::},
isbn = {9781450300766},
keywords = {animated interfaces,interface evaluation},
pages = {275--278},
publisher = {ACM Press},
title = {{Social robots and ECAs for accessing smart environments services}},
url = {http://portal.acm.org/citation.cfm?doid=1842993.1843041},
year = {2010}
}
@article{Straalen2009,
author = {Straalen, Bart Van and Heylen, Dirk and Theune, Mari\"{e}t},
file = {::},
journal = {Agents for Games and},
keywords = {bad news con-,embodied conversational agents,empathy,social agents,tutoring,versations},
pages = {95--106},
title = {{Enhancing Embodied Conversational Agents with Social and Emotional Capabilities}},
url = {http://www.springerlink.com/index/3612181747K5L570.pdf},
year = {2009}
}
@article{Russell2003,
abstract = {A flurry of theoretical and empirical work concerning the production of and response to facial and vocal expressions has occurred in the past decade. That emotional expressions express emotions is a tautology but may not be a fact. Debates have centered on universality, the nature of emotion, and the link between emotions and expressions. Modern evolutionary theory is informing more models, emphasizing that expressions are directed at a receiver, that the interests of sender and receiver can conflict, that there are many determinants of sending an expression in addition to emotion, that expressions influence the receiver in a variety of ways, and that the receiver's response is more than simply decoding a message.},
author = {Russell, James a and Bachorowski, Jo-Anne and Fernandez-Dols, Jose-Miguel},
doi = {10.1146/annurev.psych.54.101601.145102},
file = {::},
issn = {0066-4308},
journal = {Annual review of psychology},
keywords = {Emotions,Expressed Emotion,Facial Expression,Humans,Interpersonal Relations,Nonverbal Communication,Personal Construct Theory,Social Perception,Speech Acoustics},
month = jan,
pages = {329--49},
pmid = {12415074},
title = {{Facial and vocal expressions of emotion.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12415074},
volume = {54},
year = {2003}
}
@inproceedings{Nakano2010,
abstract = {In face-to-face conversations, speakers are continuously checking whether the listener is engaged in the conversation and change the conversational strategy if the listener is not fully engaged in the conversation. With the goal of building a conversational agent that can adaptively control conversations with the user, this study analyzes the user’s gaze behaviors and proposes a method for estimating whether the user is engaged in the conversation based on gaze transition 3-gram patterns. First, we conduct a Wizard- of-Oz experiment to collect Based on the analysis of the gaze data, we propose an engagement estimation method that the user’s gaze behaviors. detects the user’s disengagement gaze patterns. The algorithm is implemented as a real-time engagement-judgment mechanism and is incorporated into a multimodal dialogue manager in a conversational agent. The agent estimates the user’s conversational engagement and generates probing questions when the user is distracted from the conversation. Finally, we conduct an evaluation experiment using the proposed engagement-sensitive agent and demonstrate that engagement the estimation function improves the user’s impression of the agent and the interaction with the agent. In addition, probing performed with proper timing was also found to have a positive effect on user’s verbal/nonverbal behaviors in communication with the conversational agent.},
address = {Hong Kong, China},
author = {Nakano, I and Ishii, Ryo},
booktitle = {IUI '10 Proceedings of the 15th international conference on Intelligent user interfaces},
editor = {ACM},
file = {::},
isbn = {9781605585154},
keywords = {conversational agent,conversational engagement,dialogue management.,eye-gaze},
pages = {139--148},
title = {{Estimating User ’ s Engagement from Eye-gaze Behaviors in Human-Agent Conversations}},
year = {2010}
}
@article{D&39;Mello2006,
author = {Mello, Sidney D' and Graesser, Art},
file = {::},
journal = {Intelligent Virtual Agents},
pages = {54--67},
title = {{Affect detection from human-computer dialogue with an intelligent tutoring system}},
url = {http://www.springerlink.com/index/b574kpu6nl719408.pdf},
year = {2006}
}
@phdthesis{Becker-Asano2008,
author = {Becker-Asano, Christian},
file = {::},
keywords = {Emotion,Empathy,PhD Thesis,Secondary Emotions,primary Emotions},
mendeley-tags = {PhD Thesis},
pages = {186},
publisher = {IOS Press},
school = {University of Bielefeld},
title = {{WASABI: Affect simulation for agents with believable interactivity}},
type = {PhD Dissertation, IOS Press (DISKI 319)},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=8ABvlwHBCQIC\&amp;oi=fnd\&amp;pg=PA1\&amp;dq=WASABI+:+Affect+Simulation+for+Agents+with+Believable+Interactivity\&amp;ots=m6MhCZ6IzD\&amp;sig=IcDYrCYofbGlJ8E1szs\_wltd18k},
volume = {319},
year = {2008}
}
@book{Widmark1981,
address = {Davis, California},
author = {Widmark, Erik Matteo Prochet},
isbn = {0931890071, 9780931890079},
pages = {163},
publisher = {Biomedical Publications},
title = {{Principles and Applications of Medicolegal Alcohol Determination}},
year = {1981}
}
@article{Mendelson1999,
author = {Mendelson, M.J. and Aboud, F.E.},
file = {::},
journal = {Canadian Journal of Behavioural Science/Revue canadienne des sciences du comportement},
number = {2},
pages = {130},
publisher = {Canadian Psychological Association},
title = {{Measuring friendship quality in late adolescents and young adults: McGill Friendship Questionnaires.}},
url = {http://psycnet.apa.org/journals/cbs/31/2/130/},
volume = {31},
year = {1999}
}
@inproceedings{Arrington2011,
abstract = {One of the many factors that contribute to the decline in Computer Science retention is poor performance in foundation programming courses. In the Introduction to Programming course here at UNC Charlotte, it has been observed that poor assessment performance is often attributed to students feeling they understand material when they often don’t. This iteration of the Dr. Chestr Show seeks to overcome this disconnection by assisting in the guidance of review based on routine lecture quiz performance. The Dr. Chestr show presents users with questions about the C++ programming language based on topics covered during lecture. This paper describes the design and implementation of the Dr. Chestr virtual human and his game show environment.},
address = {New York, New York, USA},
author = {Arrington, Carl and Wilson, Dale-Marie and Lehmann, Lorrie},
booktitle = {Proceedings of the 49th Annual Southeast Regional Conference on - ACM-SE '11},
doi = {10.1145/2016039.2016127},
file = {::},
isbn = {9781450306867},
keywords = {Design,Human Factors.},
pages = {320},
publisher = {ACM Press},
title = {{Improving performance and retention in computer science courses using a virtual game show}},
url = {http://dl.acm.org/citation.cfm?doid=2016039.2016127},
year = {2011}
}
@article{Dautenhahn2002,
author = {Dautenhahn, Kerstin and Bond, Alan},
file = {::},
journal = {Socially Intelligent},
pages = {1--20},
publisher = {Springer},
title = {{Socially intelligent agents}},
url = {http://www.springerlink.com/index/V38H434X220766G8.pdf},
year = {2002}
}
@article{Becker2006,
author = {Becker, Christian},
file = {::},
journal = {International Journal of Humanoid Robotics},
keywords = {1,affective behavior,becoming ever,empathy,evaluation,introduction and motivation,life-like characters,or agents,physiological user information,while life-like characters,with affective behavior are},
number = {3},
pages = {371--391},
title = {{A STUDY IN USERS ’ PHYSIOLOGICAL RESPONSE TO AN EMPATHIC INTERFACE AGENT}},
volume = {3},
year = {2006}
}
@inproceedings{Hegel2006,
author = {Hegel, Frank and Spexard, Torsten and Wrede, Britta and Horstmann, G. and Vogt, T.},
booktitle = {Humanoid Robots, 2006 6th IEEE-RAS International Conference on},
file = {::},
isbn = {142440200X},
pages = {56--61},
publisher = {IEEE},
title = {{Playing a different imitation game: Interaction with an Empathic Android Robot}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4115580},
year = {2006}
}
@article{Archer1977,
author = {Archer, Dane and Akert, Robin M},
journal = {Journal of Personality and Social Psychology},
number = {6},
pages = {443--449},
title = {{Words and everything else: Verbal and nonverbal cues in social interpretation}},
volume = {35},
year = {1977}
}
@article{Cowell2005a,
abstract = {For years, people have sought more natural means of communicating with their computers. Many have suggested that interaction with a computer should be as easy as interacting with other people, taking advantage of the multimodal nature of human communication. While users should, in theory, gravitate to such anthropomorphic embodiments, quite the contrary has been experienced; users generally have been dissatisfied and abandoned their use. This suggests a disconnect between factors that make human-human communication engaging and those used by designers to support human-agent interaction. This paper discusses a set of empirical studies that attempted to replicate human-human non-verbal behavior. The focus revolved around behaviors that portray a credible fa\c{c}ade, thereby helping embodied conversational agents (ECAs) to form a successful cooperative dyad with users. Based on a review of the non-verbal literature, a framework was created that identified trustworthy and credible non-verbal behaviors across five areas and formed design guidelines for character interaction. The design suggestions for those areas emanating from the facial region were experimentally supported but there was no concordant increase in perceived trust when bodily regions (posture, gesture) were added. In addition, in examining the importance of demographic elements in embodiment, it was found that users prefer to interact with characters that match their ethnicity and are young looking. There was no significant preference for gender. The implications of these results, as well as other interesting consequences are discussed.},
author = {Cowell, Andrew J. and Stanney, Kay M.},
doi = {10.1016/j.ijhcs.2004.11.008},
file = {::},
issn = {10715819},
journal = {International Journal of Human-Computer Studies},
month = feb,
number = {2},
pages = {281--306},
title = {{Manipulation of non-verbal interaction style and demographic embodiment to increase anthropomorphic computer character credibility}},
url = {http://ocw.tudelft.nl/fileadmin/ocw/opener/Manipulation\_of\_non-verbal\_interaction\_style\_and\_demographic\_embodiment\_to\_increase\_anthropomorphic\_computer\_character\_credibility.pdf},
volume = {62},
year = {2005}
}
@misc{Twitter,
title = {{Twitter}},
url = {https://twitter.com/}
}
@article{Straalen2009,
author = {Straalen, Bart Van and Heylen, Dirk and Theune, Mari\"{e}t},
file = {::},
journal = {Agents for Games and},
keywords = {bad news con-,embodied conversational agents,empathy,social agents,tutoring,versations},
pages = {95--106},
title = {{Enhancing Embodied Conversational Agents with Social and Emotional Capabilities}},
url = {http://www.springerlink.com/index/3612181747K5L570.pdf},
year = {2009}
}
@article{Sharma1998,
author = {Sharma, R. and Pavlovic, V.I. and Huang, Thomas S.},
file = {::},
journal = {Proceedings of the IEEE},
keywords = {computer interface,human,multimodality,sensor},
number = {5},
pages = {853--869},
publisher = {IEEE},
title = {{Toward multimodal human-computer interface}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=664275},
volume = {86},
year = {1998}
}
@article{Gratch2006,
author = {Gratch, Jonathan and Okhmatovskaia, Anna and Lamothe, Francois},
file = {::},
journal = {Intelligent Virtual},
title = {{Virtual rapport}},
url = {http://www.springerlink.com/index/k720537752657m81.pdf},
year = {2006}
}
@article{Hand2008,
author = {Hand, Stacey and Varan, Duane},
file = {::},
journal = {Changing Television Environments},
pages = {11--19},
publisher = {Springer},
title = {{Interactive Narratives: Exploring the Links between Empathy, Interactivity and Structure}},
url = {http://www.springerlink.com/index/15385726247gu863.pdf},
year = {2008}
}
@inproceedings{Zwann2012,
abstract = {[1] J. M. van der Zwaan, V. Dignum, and C. M. Jonker, “A BDI Dialogue Agent for Social Support : Specification of Verbal Support Types ( Extended Abstract ) Categories and Subject Descriptors,” pp. 1183–1184.},
address = {Valencia, Spain},
author = {van der Zwaan, J.M. and Dignum, V. and Jonker, C.M.},
booktitle = {Proceedings of the 11th International Conference on Autonomous Agents and Multiagent Systems (AAMAS2012)},
file = {::},
keywords = {behavior,conversational agents,modeling cognition and socio-cultural,verbal and non-verbal expression},
pages = {1183--1184},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org)},
title = {{A BDI Dialogue Agent for Social Support : Specification of Verbal Support Types ( Extended Abstract ) Categories and Subject Descriptors}},
year = {2012}
}
@book{Picard1997,
address = {Cambridge, Massachusetts},
author = {Picard, Rosalind W},
isbn = {0-262-16170-2},
publisher = {The MIT Press},
title = {{Affective Computing}},
year = {1997}
}
@article{Clayman2001,
abstract = {This article provides an overview of the dynamics of answering and resisting or evading questions in broadcast news interviews. After a preliminary examination of the practices through which answers are recognizably constructed, the analysis turns to the practices through which interviewees manage responses that resist the agenda of an interviewer's question. When resisting overtly, interviewees engage in various forms of damage control. When resisting covertly, interviewees take steps to render the resistance less conspicuous. Both sets of practices facilitate resistant responses by reducing the negative consequences that might otherwise follow. Such practices demonstrate that, although interviewees have developed practices for resisting questions, the norm of answering remains a salient feature of the contemporary broadcast news interview.},
author = {Clayman, Steven E},
journal = {Language in Society},
number = {03},
pages = {403--442},
title = {{Answers and evasions}},
volume = {30},
year = {2001}
}
@article{Niewiadomski2008,
author = {Niewiadomski, Radoslaw and Ochs, Magalie},
file = {::},
journal = {Intelligent Virtual Agents},
keywords = {eca,empathy,facial expressions},
pages = {37--44},
title = {{Expressions of empathy in ECAs}},
url = {http://www.springerlink.com/index/618982507263X720.pdf},
year = {2008}
}
@article{Kaliouby2005,
author = {Kaliouby, R. and Robinson, Peter},
file = {::},
journal = {Real-time vision for human-computer interaction},
pages = {181--200},
publisher = {Springer},
title = {{Real-time inference of complex mental states from facial expressions and head gestures}},
url = {http://www.springerlink.com/index/K822871338R66039.pdf},
year = {2005}
}
@inproceedings{Hernandez2007,
abstract = {In this paper we explore the possibilities that conversational agent technology offers for the improvement of the quality of hu- man-machine interaction in a concrete area of application: the multimodal biometric authentication system. Our approach looks at the user perception effects related to the system interface rather than to the perform- ance of the biometric technology itself. For this purpose we have created a multibio- metric user test environment with two dif- ferent interfaces or interaction metaphors: one with an embodied conversational agent and the other with on-screen text messages only. We present the results of an explora- tory experiment that reveals interesting ef- fects, related to the presence of a conversa- tional agent, on the user’s perception of pa- rameters such as privacy, ease of use, inva- siveness or system security.},
address = {Prague, Czech Republic},
author = {Hern\'{a}ndez, \'{A}lvaro and L\'{o}pez, Beatriz and D\'{\i}az, David and Fern\'{a}ndez, Rub\'{e}n and Hern\'{a}ndez, Luis and Caminero, Javier},
booktitle = {Proceedings of the Workshop on Embodied Language Processing},
file = {::},
pages = {33--40},
publisher = {Association for Computational Linguistics},
title = {{A “ person ” in the interface : effects on user perceptions of multibiometrics}},
year = {2007}
}
@article{Ekman1993,
abstract = {Cross-cultural research on facial expression and the developments of methods to measure facial expression are briefly summarized. What has been learned about emotion from this work on the face is then elucidated. Four questions about facial expression and emotion are discussed: What information does an expression typically convey? Can there be emotion without facial expression? Can there be a facial expression of emotion without emotion? How do individuals differ in their facial expressions of emotion?},
author = {Ekman, Paul},
institution = {Human Interaction Laboratory, University of California, San Francisco 94143.},
journal = {American Psychologist},
number = {4},
pages = {384--392},
pmid = {8512154},
publisher = {American Psychological Association},
title = {{Facial expression and emotion.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8512154},
volume = {48},
year = {1993}
}
@article{Decety2004,
abstract = {Empathy accounts for the naturally occurring subjective experience of similarity between the feelings expressed by self and others without loosing sight of whose feelings belong to whom. Empathy involves not only the affective experience of the other person's actual or inferred emotional state but also some minimal recognition and understanding of another's emotional state. In light of multiple levels of analysis ranging from developmental psychology, social psychology, cognitive neuroscience, and clinical neuropsychology, this article proposes a model of empathy that involves parallel and distributed processing in a number of dissociable computational mechanisms. Shared neural representations, self-awareness, mental flexibility, and emotion regulation constitute the basic macrocomponents of empathy, which are underpinned by specific neural systems. This functional model may be used to make specific predictions about the various empathy deficits that can be encountered in different forms of social and neurological disorders.},
author = {Decety, Jean and Jackson, Philip L},
doi = {10.1177/1534582304267187},
file = {::},
isbn = {1534582304267},
issn = {1534-5823},
journal = {Behavioral and cognitive neuroscience reviews},
keywords = {Adaptation, Psychological,Adolescent,Adult,Awareness,Awareness: physiology,Cerebral Cortex,Cerebral Cortex: physiology,Child,Child, Preschool,Emotions,Emotions: physiology,Empathy,Humans,Infant,Models, Neurological,Models, Psychological,Perception,Perception: physiology,Self Concept,Social Behavior},
month = jun,
number = {2},
pages = {71--100},
pmid = {15537986},
title = {{The functional architecture of human empathy.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15537986},
volume = {3},
year = {2004}
}
@inproceedings{Boukricha2009,
abstract = {a system for simulating emotional facial expressions for a virtual human has been evolved. This system consists of two parts: (1) a control ar- chitecture for simulating emotional facial expressions with respect to Pleasure, Arousal, and Dominance (PAD) val- ues, (2) an expressive output component for animating the virtual human’s facial muscle actions called Action Units (AUs), modeled following the Facial Action Coding Sys- tem (FACS). A large face repertoire of about 6000 faces arranged in PAD-space with respect to two dominance val- ues (dominant vs. submissive) is obtained as a result of the empirical study. Using the face repertoire an approach to- wards realizing facial mimicry for a virtual human based on backward mapping AUs displaying an emotional facial expression on PAD-values is outlined.},
address = {Amsterdam},
annote = {- For automatic recognition, the mapping of AUs to PAD may be only useful once you can identify the active AUs and their intensity on the face (which you won't be able with image processing teckniques).
- For the expression, if you have an avatar which has control on the AUs, you don’t need to map the AUs to PAD. But, if you have an avatar which expresses based on PAD, then this mapping is useful. 
- Mapping of AUs to PAD is helpful when you want to fuse multiple modalities where other modalities are in PAD values. },
author = {Boukricha, Hana and Wachsmuth, Ipke and Hofstatter, A. and Grammer, Karl},
booktitle = {Interaction and Workshops of 3rd International Conference on Affective Computing and Intelligent ACII2009},
doi = {10.1109/ACII.2009.5349579},
file = {::},
isbn = {9781424447992},
pages = {1--7},
publisher = {IEEE},
title = {{Pleasure-arousal-dominance driven facial expression simulation}},
url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=5349579},
year = {2009}
}
@article{O'Keefe1988,
abstract = {Offers models of 3 alternative message design logics and describes a general method of message analysis based on these models. The method of analysis is exemplified in a study of messages used in addressing a regulative communication task. 92 undergraduates were asked to provide messages they would address to a subordinate who failed to complete assigned work; these messages were classified in terms of the kind of goal set being pursued and the kind of reasoning reflected in their design. Male and female Ss differed systematically in the message design logic they employed, and there were significant relationships between interpersonal construct differentiation and message design logic and goal structure. ((c) 1997 APA/PsycINFO, all rights reserved)},
author = {O'Keefe, Barbara J},
journal = {Communication Monographs},
number = {1},
pages = {80--103},
title = {{The logic of message design: Individual differences in reasoning about communication}},
volume = {55},
year = {1988}
}
@misc{TheMendeleySupportTeam2011,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/The Mendeley Support Team - 2011 - Getting Started with Mendeley(4).pdf:pdf},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@article{Becker-Asano2009,
abstract = {We introduce theWASABI ([W]ASABI [A]ffect [S]imulation for [A]gents with [B]elievable [I]nteractivity)Affect SimulationArchitecture, in which a virtual human’s cog- nitive reasoning capabilities are combined with simulated embodiment to achieve the sim- ulation of primary and secondary emotions. In modeling primary emotions we follow the idea of “Core Affect” in combination with a continuous progression of bodily feeling in three-dimensional emotion space (PADspace), that is subsequently categorized into discrete emotions. In humans, primary emotions are understood as onto-genetically earlier emotions, which directly influence facial expressions. Secondary emotions, in contrast, afford the abil- ity to reason about current events in the light of experiences and expectations.},
author = {Becker-Asano, Christian and Wachsmuth, Ipke},
doi = {10.1007/s10458-009-9094-9},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Becker-Asano, Wachsmuth - 2009 - Affective computing with primary and secondary emotions in a virtual human(3).pdf:pdf},
issn = {1387-2532},
journal = {Autonomous Agents and Multi-Agent Systems},
keywords = {affect simulation,affective computing,affective gaming,architecture,aware emotions,bdi-based architecture,embodied agent,emotion dynamics,emotion expression,emotion modeling,pad emotion space,primary and secondary emotions,reality,virtual,virtual human},
month = may,
number = {1},
pages = {32--49},
title = {{Affective computing with primary and secondary emotions in a virtual human}},
volume = {20},
year = {2009}
}
@article{Cassell2000,
abstract = {Embodied conversational agents are computer-generated cartoon-like characters that demonstrate many of the same properties as humans in face-to-face conversation, including the ability to produce and respond to verbal and nonverbal communication. They constitute a type of (a) multimodal interface where the modalities are those natural to human conversation: speech, facial displays, hand gestures, and body stance; (b) software agent, insofar as they represent the computer in an interaction with a human or represent their human users in a computational environment (as avatars, for example); and (c) dialogue system where both verbal and nonverbal devices advance and regulate the dialogue between the user and the computer. With an embodied conversational agent, the visual dimension of interacting with an animated character on a screen plays an intrinsic role. Not just pretty pictures, the graphics display visual features of conversation in the same way that the face and hands do in face-to-face conversation among humans.This book describes research in all aspects of the design, implementation, and evaluation of embodied conversational agents as well as details of specific working systems. Many of the chapters are written by multidisciplinary teams of psychologists, linguists, computer scientists, artists, and researchers in interface design. The authors include Elisabeth Andre, Norm Badler, Gene Ball, Justine Cassell, Elizabeth Churchill, James Lester, Dominic Massaro, Cliff Nass, Sharon Oviatt, Isabella Poggi, Jeff Rickel, and Greg Sanders.},
author = {Cassell, Justine and Sullivan, Joseph and Prevost, Scott and Churchill, Elizabeth F.},
chapter = {Evaluation},
doi = {10.1027/1864-9335.40.1.26},
editor = {Cassell, Justine and Sullivan, Joseph and Prevost, Scott and Churchill, Elizabeth},
isbn = {0262032783},
issn = {18649335},
journal = {Social Psychology},
number = {1},
pages = {26--36},
publisher = {MIT Press},
title = {{Embodied Conversational Agents}},
url = {http://psycontent.metapress.com/openurl.asp?genre=article\&id=doi:10.1027/1864-9335.40.1.26},
volume = {40},
year = {2000}
}
@phdthesis{Becker-Asano2008,
author = {Becker-Asano, Christian},
file = {::},
keywords = {Emotion,Empathy,Secondary Emotions,primary Emotions},
publisher = {IOS Press},
school = {University of Bielefeld},
title = {{WASABI: Affect simulation for agents with believable interactivity}},
type = {IOS Press (DISKI 319)},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=8ABvlwHBCQIC\&amp;oi=fnd\&amp;pg=PA1\&amp;dq=WASABI+:+Affect+Simulation+for+Agents+with+Believable+Interactivity\&amp;ots=m6MhCZ6IzD\&amp;sig=IcDYrCYofbGlJ8E1szs\_wltd18k},
volume = {319},
year = {2008}
}
@inproceedings{Kashyap2012,
abstract = {Earlier works on personalized Web search focused on the click- through graphs, while recent works leverage social annotations, which are often unavailable. On the other hand, many users are members of the social networks and subscribe to social groups. Intuitively, users in the same group may have similar relevance judgments for queries related to these groups. SonetRank utilizes this observation to personalize the Web search results based on the aggregate relevance feedback of the users in similar groups. SonetRank builds and maintains a rich graph-based model, termed Social Aware Search Graph, consisting of groups, users, queries and results click-through information. SonetRank’s personalization scheme learns in a principled way to leverage the following three signals, of decreasing strength: the personal document preferences of the user, of the users of her social groups relevant to the query, and of the other users in the network. SonetRank also uses a novel approach to measure the amount of personalization with respect to a user and a query, based on the query-specific richness of the user’s social profile. We evaluate SonetRank with users on Amazon Mechanical Turk and show a significant improvement in ranking compared to state-of-the-art techniques.},
address = {Maui, HI, USA},
author = {Kashyap, Abhijith and Amini, Reza and Hristidis, Vagelis},
booktitle = {ACM 21st Conference on Information and Knowledge Management CIKM 2012},
file = {::},
isbn = {9781450311564},
keywords = {Results Re-ranking.,Search Personalization,Social Search},
publisher = {ACM},
title = {{SonetRank : Leveraging Social Networks to Personalize Search}},
year = {2012}
}
@article{STEVENP.SCHINKE,
author = {STEVEN, P. SCHINKE and TRACI, M. SCHWINN},
title = {{Reducing the Risks of Alcohol Use among Urban Youth: Three-Year Effects of a Computer-Based Intervention with and without Parent Involvement*}},
url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2795165/}
}
@phdthesis{Li2007,
author = {Li, Xi},
booktitle = {Interface},
file = {::},
school = {Marquette University},
title = {{SPEech Feature Toolbox (SPEFT) Design and Emotional Speech Feature Extraction}},
url = {http://speechlab.eece.mu.edu/johnson/papers/li\_thesis.pdf},
year = {2007}
}
@inproceedings{Dias2005,
abstract = {Interactive virtual environments (IVEs) are now seen as an engaging new way by which children learn experimental sciences and other disciplines. These environments are populated by synthetic characters that guide and stimulate the children activities. In order to build such environments, one needs to address the problem of how achieve believable and empathic characters that act autonomously. Inspired by the work of traditional character animators, this paper proposes an architectural model to build autonomous characters where the agent’s reasoning and behaviour is influenced by its emotional state and personality. We performed a small case evaluation in order to determine if the characters evoked empathic reactions in the users with positive results.},
address = {Covilh\~{a}, Portugal},
author = {Dias, J. and Paiva, Ana},
booktitle = {EPIA 2005, 12th Portuguese Conference on Artificial Intelligence},
doi = {10.1007/11595014\_13},
editor = {Bento, Carlos and Cardoso, Am\'{\i}lcar and Dias, Ga\"{e}l},
file = {::},
pages = {127--140},
publisher = {Springer Berlin / Heidelberg},
title = {{Feeling and reasoning: A computational model for emotional characters}},
url = {http://www.springerlink.com/index/YQ18H62602413554.pdf},
year = {2005}
}
@article{Russell1980,
abstract = {Factor-analytic evidence has led most psychologists to describe affect as a set of dimensions, such as displeasure, distress, depression, excitement, and so on, with each dimension varying independently of the others. However, there is other evidence that rather than being independent, these affective dimensions are interrelated in a highly systematic fashion. The evidence suggests that these interrelationships can be represented by a spatial model in which affective concepts fall in a circle in the following order: pleasure (0), excitement (45), arousal (90), distress (135), displeasure (180), depression (225), sleepiness (270), and relaxation (315). This model was offered both as a way psychologists can represent the structure of affective experience, as assessed through self-report, and as a representation of the cognitive structure that laymen utilize in conceptualizing affect. Supportive evidence was obtained by scaling 28 emotion-denoting adjectives in 4 different ways: R. T. Ross's (1938) technique for a circular ordering of variables, a multidimensional scaling procedure based on perceived similarity among the terms, a unidimensional scaling on hypothesized pleasure–displeasure and degree-of-arousal dimensions, and a principal-components analysis of 343 Ss' self-reports of their current affective states. (70 ref) (PsycINFO Database Record (c) 2010 APA, all rights reserved)},
author = {Russell, James A},
doi = {10.1037/h0077714},
file = {::},
journal = {Journal of Personality and Social Psychology},
number = {6},
pages = {1161--1178},
title = {{A circumplex model of affect}},
url = {http://psycnet.apa.org/psycinfo/1981-25062-001},
volume = {39},
year = {1980}
}
@inproceedings{Lee2006,
address = {Marina del Rey},
author = {Lee, Jina and Marsella, Stacy C and Rey, Marina Del},
booktitle = {Proceedings of the 6th international conference on Intelligent Virtual Agents (IVA'06)},
editor = {Gratch, Jonathan},
file = {::},
pages = {243--255},
publisher = {Springer Berlin / Heidelberg},
title = {{Nonverbal Behavior Generator for Embodied Conversational Agents}},
year = {2006}
}
@article{Hine2009,
author = {Hine, Michael J. and Murphy, Steven a. and Weber, Michael and Kersten, Gregory},
doi = {10.1007/s10726-008-9151-9},
file = {::},
issn = {0926-2644},
journal = {Group Decision and Negotiation},
keywords = {computer mediated communication,electronic negotiation,emotion,logistic regression},
month = jan,
number = {3},
pages = {193--211},
title = {{The Role of Emotion and Language in Dyadic E-negotiations}},
url = {http://www.springerlink.com/index/10.1007/s10726-008-9151-9},
volume = {18},
year = {2009}
}
@article{Lakin2003,
abstract = {The “chameleon effect” refers to the tendency to adopt the postures, gestures, and mannerisms of interaction partners (Chartrand \& Bargh, 1999). This type of mimicry occurs outside of conscious awareness, and without any intent to mimic or imitate. Empirical evidence suggests a bi-directional relationship between nonconscious mimicry on the one hand, and liking, rapport, and affiliation on the other. That is, nonconscious mimicry creates affiliation, and affiliation can be ex- pressed through nonconscious mimicry. We argue that mimicry played an impor- tant role in human evolution. Initially, mimicry may have had survival value by helping humans communicate. We propose that the purpose of mimicry has now evolved to serve a social function. Nonconscious behavioral mimicry increases af- filiation, which serves to foster relationships with others. We review current re- search in light of this proposed framework and suggest future areas of research.},
annote = {nonconscious mimicry creates affiliation, and affiliation can be expressed through nonconscious mimicry.
Initially, mimicry may have had survival value by helping humans communicate. The purpose of mimicry has now evolved to serve a social function. Nonconscious behavioral mimicry increases affiliation, which serves to foster relationships with others.
Empathic individuals mimic people more that people low in empathy.},
author = {Lakin, J. L. and Jefferis, VE and Cheng, CM},
file = {::},
journal = {Journal of nonverbal Behavior},
keywords = {affiliation,chameleon effect,human evolution,mimicry},
number = {3},
pages = {145--162},
title = {{The chameleon effect as social glue: Evidence for the evolutionary significance of nonconscious mimicry}},
volume = {27},
year = {2003}
}
@article{Pelachaud1996,
abstract = {This article reports results from a program that produces high-quality animation of facial expressions and head movements as automatically as possible in conjunction with meaning-based speech synthesis, including spoken intonation. The goal of the research is as much to test and define our theories of the formal semantics for such gestures, as to produce convincing animation. Towards this end, we have produced a high-level programming language for three-dimensional (3-D) animation of facial expressions. We have been concerned primarily with expressions conveying information correlated with the intonation of the voice: This includes the differences of timing, pitch, and emphasis that are related to such semantic distinctions of discourse as "focus," "topic," and "comment," "theme" and "rheme," or "given" and "new" information. We are also interested in the relation of affect or emotion to facial expression. Until now, systems have not embodied such rule-governed translation from spoken utterance meaning to facial expressions. Our system embodies rules that describe and coordinate these relations: ntonation/information, intonation/affect, and facial expressions/affect. A meaning representation includes discourse information: What is contrastive/background information in the given context, and what is the "topic" or "theme" of the discourse? The system maps the meaning representation into how accents and their placement are chosen, how they are conveyed over facial expression, and how speech and facial expressions are oordinated. This determines a sequence of functional groups: lip shapes, conversational signals, punctuators, regulators, and manipulators. Our algorithms then impose synchrony, create coarticulation effects, and determine affectual signals, eye and head movements. The lowest level representation is the Facial Action Coding System (FACS), which makes the generation system portable to other facial models.},
author = {Pelachaud, Catherine and Badler, Norman I and Steedman, Mark},
doi = {10.1207/s15516709cog2001\_1},
issn = {03640213},
journal = {Cognitive Science},
number = {1},
pages = {1--46},
publisher = {Elsevier},
title = {{Generating Facial Expressions for Speech}},
url = {http://www.sciencedirect.com/science/article/pii/S0364021399800019},
volume = {20},
year = {1996}
}
@techreport{Miller1981,
abstract = {Thirty-one self-referred problem drinkers were randomly assigned to one of two modalities for behavioral self-control training with a goal of moderation: (1) minimal therapist contact, in which clients worked only with a self-help manual; and (2) therapist directed training, in which clients received self-help materials plus 10 individual treatment sessions. Both groups showed significant reductions in alcohol consumption and peak blood alcohol concentration. Contrary to expectations, there were no significant differences on outcome measures between groups. Results are interpreted within a self-control framework.},
author = {Miller, William R. and Gribskov, C J and Mortell, R L},
booktitle = {The International journal of the addictions},
number = {7},
pages = {1247--1254},
pmid = {7327785},
publisher = {Informa UK Ltd UK},
title = {{Effectiveness of a self-control manual for problem drinkers with and without therapist contact.}},
url = {http://informahealthcare.com/doi/abs/10.3109/10826088109039178},
volume = {16},
year = {1981}
}
@inproceedings{Cassell1994,
abstract = {We describe an implemented system which automatically generates and animates conversations between multiple human-like agents with appropriate and synchronized speech, intonation, facial expressions, and hand gestures. Conversation is created by a dialogue planner that produces the text as well as the intonation of the utterances. The the text, and the intonation in turn drive facial expressions, lip motions, eye gaze, head motion, and arm gestures generators. Coordinated arm, wrist, and hand motions are invoked to create semantically meaningful gestures. Throughout we will use examples from an actual synthesized, fully animated conversation.},
author = {Cassell, Justine and Pelachaud, Catherine and Badler, Norman and Steedman, Mark and Achorn, Brett and Becket, Tripp and Douville, Brett and Prevost, Scott and Stone, Matthew},
booktitle = {Proceedings of the 21st annual conference on Computer graphics and interactive techniques},
doi = {10.1145/192161.192272},
isbn = {0897916670},
issn = {00978930},
number = {Annual Conference Series},
organization = {ACM New York, NY, USA},
pages = {413--420},
publisher = {ACM},
series = {SIGGRAPH '94},
title = {{Animated conversation: rule-based generation of facial expression, gesture \& spoken intonation for multiple conversational agents}},
url = {http://doi.acm.org/10.1145/192161.192272},
volume = {28},
year = {1994}
}
@article{Niewiadomski2008,
author = {Niewiadomski, Radoslaw and Ochs, Magalie},
file = {::},
journal = {Intelligent Virtual Agents},
keywords = {eca,empathy,facial expressions},
pages = {37--44},
title = {{Expressions of empathy in ECAs}},
url = {http://www.springerlink.com/index/618982507263X720.pdf},
year = {2008}
}
@inproceedings{Mateas2003,
abstract = {In this paper we discuss our research and development towards creating an architecture, and a story design using this architecture, that integrates a broad and shallow approach to natural language processing, a novel character authoring language and a novel drama manager, in order to build an interactive drama about human relationships.},
address = {San Jose, CA, UA},
author = {Mateas, Michael and Stern, Andrew},
booktitle = {Game Developers Conference Game Design track},
file = {::},
publisher = {Citeseer},
title = {{Fa\c{c}ade: An experiment in building a fully-realized interactive drama}},
url = {http://www.mendeley.com/research/faade-an-experiment-in-building-a-fullyrealized-interactive-drama/},
volume = {2},
year = {2003}
}
@article{D&39;Mello2006,
author = {Mello, Sidney D' and Graesser, Art},
file = {::},
journal = {Intelligent Virtual Agents},
pages = {54--67},
title = {{Affect detection from human-computer dialogue with an intelligent tutoring system}},
url = {http://www.springerlink.com/index/b574kpu6nl719408.pdf},
year = {2006}
}
@inproceedings{Nguyen2009,
abstract = {Experiencing emotional distress is the number one reason why people who are undergoing behaviour modification (e.g. quitting smoking, dieting) suffer from relapses. Providing emotional support is an effective way to help them overcome the unpleasant effects of negative affect and adhere to their regimen. Building computers with such ability has grabbed the attention of the HCI community in recent years. This paper presents the results of a 2 (modality: animated vs. no visual) by 3 (intervention: non-empathy vs. empathy vs. empathy and expressivity) between-subjects study that investigates the impact of two important factors and their interaction in the design of such systems: (1) different ways of expressing empathy, and (2) the modality of delivering such content.},
address = {Claremont, California, USA},
annote = {They investigate: 
1-      Different ways of expressing empathy 
2-      Modality of delivering such content. 
        
They define empathy as the ability to detect what others feel and to experience that emotion ourselves (seems like mimicry).
        
Empirical evidence indicates that expressing accurate empathy can lead to positive psychological, physical and health outcomes.
        
Their results show: 
1. The positive attitude of the users toward active support (active empathy). 
2.  The positive outcome of an empathic system regardless of its representation. 
3.  A system represented by a human-like representation is expected to be empathic.
        
they believe, adding a mechanism to allow the users to freely express themselves does not improve the effectiveness or liking of an empathic system.
      },
author = {Nguyen, H. and Masthoff, Judith},
booktitle = {Proceedings of the 4th International Conference on Persuasive Technology},
file = {::},
isbn = {9781605583761},
keywords = {affective computing,design,experimentation,human factors},
pages = {7},
publisher = {ACM},
title = {{Designing empathic computers: the effect of multimodal empathic feedback using animated agent}},
url = {http://portal.acm.org/citation.cfm?id=1541958},
year = {2009}
}
@article{Breazeal2005,
author = {Breazeal, Cynthia and Buchsbaum, Daphna and Gray, Jesse and Gatenby, David and Blumberg, Bruce},
file = {::},
journal = {Artificial Life},
number = {1-2},
pages = {31--62},
publisher = {MIT Press},
title = {{Learning from and about others: Towards using imitation to bootstrap the social understanding of others by robots}},
volume = {11},
year = {2005}
}
@article{Robbins1994,
abstract = {To date, cognitive and affective influences on performance evaluations have been addressed separately, although it is likely that affect may influence ratings indirectly through its impact on the cognitive processing involved in the evaluation. 83 management students participated in a study of the influence of affect on the cognitive processing of performance information. Results suggest that an affect-consistency bias influences ratings even though the cognitive processes that require some judgment indicated a bias toward both affect-consistent and affect-inconsistent performance. Additional findings suggest that the practical utility of affect as something distinct from past performance perceptions may be limited in field settings. Job-related affect, past performance perceptions, and social affect had similar influences on the cognitive process and ratings in performance evaluations. (PsycINFO Database Record (c) 2003 APA, all rights reserved)},
author = {Robbins, Tina L and DeNisi, Angelo S},
doi = {10.1037//0021-9010.79.3.341},
issn = {00219010},
journal = {Journal of Applied Psychology},
number = {3},
pages = {341--353},
publisher = {Elsevier},
title = {{A closer look at interpersonal affect as a distinct influence on cognitive processing in performance evaluations}},
url = {http://www.apa.org},
volume = {79},
year = {1994}
}
@article{Szymanski2012,
abstract = {Psycholinguistic theories of semantic memory form the basis of understanding of natural language concepts. These theories are used here as an inspiration for implementing a computational model of semantic memory in the form of semantic network. Combining this network with a vector-based object-relation-feature value representation of concepts that includes also weights for confidence and sup- port, allows for recognition of concepts by referring to their features, enabling a semantic search algorithm. This algorithm has been used for word games, in particular the 20-question game in which the program tries to guess a concept that a human player thinks about. The game facilitates lexical knowledge validation and acquisition through the interaction with humans via supervised dialog templates. The elementary linguistic competencies of the proposed model have been evaluated assessing how well it can represent the meaning of lin- guistic concepts. To study properties of information retrieval based on this type of semantic representation in contexts derived from on-going dialogs experiments in limited domains have been performed. Several similarity measures have been used to compare the com- pleteness of knowledge retrieved automatically and corrected through active dialogs to a “golden standard”. Comparison of semantic search with human performance has been made in a series of 20-question games. On average results achieved by human players were better than those obtained by semantic search, but not by a wide margin.},
author = {Szymański, Julian and Duch, Włodzisław},
doi = {10.1016/j.cogsys.2011.02.002},
file = {::},
issn = {13890417},
journal = {Cognitive Systems Research},
keywords = {corresponding author at,department of informatics,leading to low precision,nicolaus,that is returning},
month = apr,
number = {1},
pages = {84--100},
title = {{Information retrieval with semantic memory model}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1389041711000179},
volume = {14},
year = {2012}
}
@article{Peter2003,
author = {Sonnby-borgstr\"{o}m, Marianne and Jonsson, Peter and Svensson, Owe},
file = {::},
journal = {Journal of Nonverbal},
keywords = {emg,emotional contagion,empathy,facial expressions,facial mim-,icry,mirror neurons},
number = {1},
pages = {3--23},
title = {{Emotional empathy as related to mimicry reactions at different levels of information processing}},
url = {http://www.springerlink.com/index/P81X69QTH751V836.pdf},
volume = {27},
year = {2003}
}
@inproceedings{Boukricha2009,
abstract = {a system for simulating emotional facial expressions for a virtual human has been evolved. This system consists of two parts: (1) a control ar- chitecture for simulating emotional facial expressions with respect to Pleasure, Arousal, and Dominance (PAD) val- ues, (2) an expressive output component for animating the virtual human’s facial muscle actions called Action Units (AUs), modeled following the Facial Action Coding Sys- tem (FACS). A large face repertoire of about 6000 faces arranged in PAD-space with respect to two dominance val- ues (dominant vs. submissive) is obtained as a result of the empirical study. Using the face repertoire an approach to- wards realizing facial mimicry for a virtual human based on backward mapping AUs displaying an emotional facial expression on PAD-values is outlined.},
address = {Amsterdam},
annote = {- For automatic recognition, the mapping of AUs to PAD may be only useful once you can identify the active AUs and their intensity on the face (which you won't be able with image processing teckniques).
- For the expression, if you have an avatar which has control on the AUs, you don’t need to map the AUs to PAD. But, if you have an avatar which expresses based on PAD, then this mapping is useful. 
- Mapping of AUs to PAD is helpful when you want to fuse multiple modalities where other modalities are in PAD values. },
author = {Boukricha, Hana and Wachsmuth, Ipke and Hofstatter, A. and Grammer, Karl},
booktitle = {Interaction and Workshops of 3rd International Conference on Affective Computing and Intelligent ACII2009},
doi = {10.1109/ACII.2009.5349579},
file = {::},
isbn = {9781424447992},
pages = {1--7},
publisher = {IEEE},
title = {{Pleasure-arousal-dominance driven facial expression simulation}},
url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=5349579},
year = {2009}
}
@inproceedings{Bartneck2008,
abstract = {This study emphasizes the need for standardized measurement tools for human robot interaction (HRI). If we are to make progress in this field then we must be able to compare the results from different studies. A literature review has been performed on the measurements of five key concepts in HRI: anthropomorphism, animacy, likeability, perceived intelligence, and perceived safety. The results have been distilled into five consistent questionnaires using semantic differential scales. We report reliability and validity indicators based on several empirical studies that used these questionnaires. It is our hope that these questionnaires can be used by robot developers to monitor their progress. Psychologists are invited to further develop the questionnaires by adding new concepts, and to conduct further validations where it appears necessary.},
address = {Amsterdam},
author = {Bartneck, Christoph and Kulic, Dana and Croft, Elizabeth},
booktitle = {Proceedings of the Metrics for Human-Robot Interaction Workshop in affiliation with the 3rd ACM/IEEE International Conference on Human-Robot Interaction (HRI 2008), Technical Report 471},
file = {::},
keywords = {Human factors,measurement,perception,robot},
pages = {37--44},
publisher = {University of Hertfordshire},
title = {{Measuring the anthropomorphism, animacy, likeability, perceived intelligence and perceived safety of robots}},
url = {http://ece.uwaterloo.ca/~dkulic/pubs/bartneckKulicCroft.pdf},
volume = {471},
year = {2008}
}
@article{Heimgartner2011,
author = {Heimg\"{a}rtner, R\"{u}diger and Tiede, L.W. and Windl, Helmut},
file = {::},
journal = {Design, User Experience, and Usability. Theory, Methods, Tools and Practice},
keywords = {1 problems in hci,communication,cultural differences,culture,design caused by cultural,designing the functionality and,differences,empathy,intercultural communication,intercultural hci design,much cultural background has,to be considered when,understanding},
pages = {557--566},
publisher = {Springer},
title = {{Empathy as Key Factor for Successful Intercultural HCI Design}},
url = {http://www.springerlink.com/index/FG03081276H7K042.pdf},
year = {2011}
}
@article{Paiva2005,
author = {Paiva, Ana and Dias, Jo\~{a}o and Sobral, Daniel and Aylett, Ruth and Woods, Sarah and Hall, Lynne and Zoll, Carsten},
doi = {10.1080/08839510590910165},
file = {::},
issn = {0883-9514},
journal = {Applied Artificial Intelligence},
month = mar,
number = {3-4},
pages = {235--266},
title = {{Learning By Feeling: Evoking Empathy With Synthetic Characters}},
url = {http://www.tandfonline.com/doi/abs/10.1080/08839510590910165},
volume = {19},
year = {2005}
}
@article{Feller2003,
abstract = {In this investigation of the construct of empathy, the authors report that the literature reflects strong evidence that empathy is an essential component of the therapeutic alliance across theories and that empathy is necessary in the counseling process. The concept of empathy continues to be a central component of new forms of counseling and therapy.},
author = {Feller, C P and Cottone, R R},
journal = {Journal of Humanistic Counseling Education and Development},
number = {1},
pages = {53--62},
publisher = {American Counseling Association},
title = {{The Importance of Empathy in the Therapeutic Alliance.}},
volume = {42},
year = {2003}
}
@book{Ortony1988,
abstract = {What causes us to experience emotions? What makes emotions vary in intensity? How are different emotions related to one another and to the language used to talk about them? What are the information processing mechanisms and structures that underlie the elicitation and intensification of emotions? Despite an abundance of psychological research on emotions, many fundamental questions like these have yet to be answered. The Cognitive Structure of Emotions addresses such questions by presenting a systematic and detailed account of the cognitive antecedents of emotions. The authors propose three aspects of the world to which people can react emotionally. People can react to events of concern to them, to the actions of those they consider responsible for such events, and to objects. It is argued that these three classes of reactions lead to three classes of emotions, each based on evaluations in terms of different kinds of knowledge representations. The authors characterize a wide range of emotions, offering concrete proposals about the factors that influence the intensity of each. In doing so, they forge a clear separation between emotions themselves and the language of emotion, and offer the first systematic, comprehensive, and computationally tractable account of the cognitions that underlie distinct types of human emotions.},
address = {Cambridge, UK},
author = {Ortony, A and Clore, G L and Collins, A},
booktitle = {Contemporary Sociology},
doi = {10.1016/0004-3702(92)90091-B},
isbn = {0521353645},
number = {6},
pages = {957},
publisher = {Cambridge University Press},
title = {{The Cognitive Structure of Emotions}},
volume = {18},
year = {1988}
}
@article{McQuiggan2008,
abstract = {Humans continuously assess one another’s situational context, modify their own affective state, and then respond based on these outcomes through empathetic expression. Virtual agents should be capable of similarly empathizing with users in interactive environments. A key challenge posed by empathetic reasoning in virtual agents is determining whether to respond with parallel or reactive empathy. Parallel empathy refers to mere replication of another’s affective state, whereas reactive empathy exhibits greater cognitive awareness and may lead to incongruent emotional responses (i.e., emotions different from the recipient’s and perhaps intended to alter negative affect). This paper proposes a unified inductive framework for modeling parallel and reactive empathy. Empathy models are used to drive runtime situation-appropriate empathetic behaviors by selecting suitable parallel or reactive empathetic expressions.},
annote = {- No automatic affect detection
- agent demographics are not taken into account.},
author = {McQuiggan, SW and Robison, Jennifer and Phillips, Robert},
file = {::},
journal = {on Autonomous agents},
number = {Aamas},
pages = {167--174},
title = {{Modeling parallel and reactive empathy in virtual agents: An inductive approach}},
url = {http://portal.acm.org/citation.cfm?id=1402411},
year = {2008}
}
@article{Gupta2012,
author = {Gupta, Prabodh and Jhala, Darshana and Jhala, Nirag},
doi = {10.1309/AJCPLAE62CRYYXNW},
file = {::},
issn = {1943-7722},
journal = {American journal of clinical pathology},
month = jan,
number = {1},
pages = {160},
pmid = {22180490},
title = {{Book review.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22180490},
volume = {137},
year = {2002}
}
@article{Riek2009,
author = {Riek, Laurel D. and Paul, Philip C. and Robinson, Peter},
doi = {10.1007/s12193-009-0028-2},
file = {::},
issn = {1783-7677},
journal = {Journal on Multimodal User Interfaces},
keywords = {19,affective computing,emotionally conveying,empathy,expressions,facial,forms of expressive empathy,human-robot interaction,is known as,of the most basic,one,social robotics,understand what others are},
month = nov,
number = {1-2},
pages = {99--108},
title = {{When my robot smiles at me: Enabling human-robot rapport via real-time head gesture mimicry}},
url = {http://www.springerlink.com/index/10.1007/s12193-009-0028-2},
volume = {3},
year = {2009}
}
@article{Stockwell1994,
abstract = {The concept of the Alcohol Dependence Syndrome has been influential in the field of alcohol studies in the 1980s. The Severity of Alcohol Dependence Questionnaire (SADQ) is one of a generation of alcohol problem scales developed to measure degree of dependence rather than presence or absence of 'alcoholism'. This paper describes the development of a form of the SADQ for community samples of drinkers (SADQ-C) and its relationship to a brief scale designed to measure impaired control over drinking. In a sample of 52 problem drinkers, SADQ and SADQ-C correlated almost perfectly (r = 0.98). In a larger sample of 197 attenders at a controlled drinking clinic, Principal Components Analysis revealed one major factor accounting for 71.7\% of the total variance. High internal reliability was indicated with a Cronbach's Alpha of 0.98. Application of this instrument in a random survey of Western Australian households is then described. It was necessary to remove items relating to 'reinstatement of dependence' for this sample. A single major factor was identified by principal components analysis, accounting for 69.1\% of the total variance. In both the clinic and the community samples SADQ-C scores correlated highly with Impairment of Control scores. The findings are interpreted as supporting the view that there is a single dimension of alcohol dependence upon which all persons who drink alcohol with any regularity may be located.},
author = {Stockwell, T and Sitharthan, T and McGrath, D and Lang, E},
institution = {National Centre for Research into the Prevention of Drug Abuse, Curtin University of Technology, Perth, Western Australia.},
journal = {Addiction Abingdon England},
keywords = {adolescent,adult,aged,alcohol drinking,alcohol drinking adverse effects,alcohol drinking epidemiology,alcohol drinking psychology,alcoholism,alcoholism classification,alcoholism diagnosis,alcoholism epidemiology,alcoholism psychology,cross sectional studies,female,humans,incidence,internal external control,male,middle aged,psychometrics,reproducibility results,substance withdrawal syndrome,substance withdrawal syndrome classification,substance withdrawal syndrome diagnosis,substance withdrawal syndrome epidemiology,substance withdrawal syndrome psychology,western australia,western australia epidemiology},
number = {2},
pages = {167--174},
pmid = {8173482},
title = {{The measurement of alcohol dependence and impaired control in community samples.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8173482},
volume = {89},
year = {1994}
}
@article{Mao2009,
abstract = {Neste trabalho \'{e} proposto um ambiente de aprendizado online inteligente em conjunto com um tutor afetivo. O tutor chama-se "Alice" e \'{e} capaz de reconhecer o estado afetivo dos estudantes por meio de express\~{o}es faciais, fala e texto, bem como se adaptar a ele. Segundo seus autores, o sistema \'{e} capaz de aumentar a produtividade dos estudantes por meio do uso de express\~{o}es faciais e de fala sint\'{e}tica emocional.},
author = {Mao, Xia and Li, Zheng},
doi = {10.1145/1520340.1520572},
isbn = {9781605582474},
journal = {Science},
keywords = {acm classification keywords,affective computing,intelligent e learning system,multimodal interaction,perceptive interfaces,virtual agent},
pages = {3787--3792},
publisher = {ACM Press},
series = {CHI EA '09},
title = {{Implementing emotion-based user-aware e-learning}},
url = {http://portal.acm.org/citation.cfm?doid=1520340.1520572},
year = {2009}
}
@inproceedings{Kang2008,
author = {Kang, Sin-hwa and Gratch, Jonathan and Wang, Ning and Watt, J.H.},
booktitle = {Proceedings of the 7th international joint conference on Autonomous agents and multiagent systems-Volume 1},
file = {::},
keywords = {agents,contingency of nonverbal feedback,evaluation,rapport,social anxiety,virtual humans},
number = {Aamas},
pages = {120--127},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
title = {{Does the contingency of agents' nonverbal feedback affect users' social anxiety?}},
url = {http://dl.acm.org/citation.cfm?id=1402405},
year = {2008}
}
@article{Hogan1969,
author = {Hogan, R},
file = {::},
issn = {0022-006X},
journal = {Journal of consulting and clinical psychology},
keywords = {Emotions,Humans,MMPI,Morals,Personality Assessment,Personality Inventory,Social Behavior,Social Perception,Social Values,Socialization},
month = jun,
number = {3},
pages = {307--16},
pmid = {4389335},
title = {{Development of an empathy scale.}},
volume = {33},
year = {1969}
}
@phdthesis{Tatar1998,
author = {Tatar, D.},
school = {Stanford University},
title = {{Social and Personal Effects of Preoccupied Listeners}},
type = {Thesis},
year = {1998}
}
@incollection{Preston2007,
author = {Preston, SD},
booktitle = {Empathy in mental illness},
chapter = {23},
editor = {Farrow, T. and Woodruff, P.},
file = {::},
isbn = {0521847346},
pages = {428--446},
publisher = {Cambridge University Press},
title = {{A perception-action model for empathy}},
url = {http://www-personal.umich.edu/~prestos/Downloads/Preston2007\_MI.pdf},
year = {2007}
}
@article{Gruen1986,
author = {Gruen, Rand J. and Mendelsohn, Gerald},
doi = {10.1037/0022-3514.51.3.609},
file = {::},
issn = {1939-1315},
journal = {Journal of Personality and Social Psychology},
number = {3},
pages = {609--614},
title = {{Emotional responses to affective displays in others: The distinction between empathy and sympathy.}},
volume = {51},
year = {1986}
}
@article{Litvack-Miller1997,
abstract = {This study was an investigation of the structure and development of dispositional empathy during middle childhood and its relationship to altruism. A sample of 478 students from 2nd, 4th, and 6th grades completed an altruism questionnaire and a social desirability scale, both created for this study, and the Interpersonal Reactivity Index (Davis, 1980), adapted for this study. Teachers also rated the students on prosocial behaviors, such as sharing. In addition, as an experimental part of the study, the children could make monetary donations and volunteer time to raise funds. Results of a confirmatory factor analysis on the Interpersonal Reactivity Index supported Davis's (1980) findings that empathy comprises four components: perspective taking, fantasy, empathic concern, and personal distress. Factor intercorrelations, however, were not the same as those reported by Davis. MANOVAs were used to examine gender and age effects on empathy. Girls were more empathic in general than boys, and older children showed more empathic concern than younger children. Only empathic concern and perspective taking were significant predictors of prosocial behavior.},
author = {Litvack-Miller, W and McDougall, D and Romney, D M},
doi = {10.1037/0022-3514.45.6.1299},
file = {::},
issn = {8756-7547},
journal = {Genetic, social, and general psychology monographs},
keywords = {Adolescent,Altruism,Child,Empathy,Female,Humans,Interpersonal Relations,Male,Questionnaires,Social Behavior,Social Desirability},
month = aug,
number = {3},
pages = {303--24},
pmid = {9259121},
title = {{The structure of empathy during middle childhood and its relationship to prosocial behavior.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21981037},
volume = {123},
year = {1997}
}
@book{Davis1994,
author = {Davis, Mark H.},
isbn = {0697168948},
publisher = {Westview Press},
title = {{Empathy: A social psychological approach}},
year = {1994}
}
@article{Mehrabian1967a,
abstract = {DEALT WITH INCONSISTENT COMMUNICATION OF ATTITUDE IN 2 COMPONENTS OF A MESSAGE. POSITIVE, NEUTRAL, OR NEGATIVE ATTITUDES COMMUNICATED IN SINGLE-WORD CONTENTS WERE EACH COMBINED WITH 3 DEGREES OF ATTITUDE COMMUNICATED IN TONE OF VOICE. IT WAS FOUND, CONSISTENT WITH THE PROPOSED HYPOTHESIS, THAT THE VARIABILITY OF INFERENCES ABOUT COMMUNICATOR ATTITUDE ON THE BASIS OF INFORMATION AVAILABLE IN CONTENT AND TONE COMBINED IS MAINLY CONTRIBUTED BY VARIATIONS IN TONE ALONE. FOR EXAMPLE, WHEN THE ATTITUDE COMMUNICATED IN CONTENT CONTRADICTED THE ATTITUDE COMMUNICATED BY A NEGATIVE TONE, THE TOTAL MESSAGE WAS JUDGED AS COMMUNICATING A NEGATIVE ATTITUDE. THE LIMITATIONS OF THE FINDINGS, AS WELL AS THEIR IMPLICATIONS FOR THE DOUBLE-BLIND THEORY OF SCHIZOPHRENIA, ARE DISCUSSED. (PsycINFO Database Record (c) 2006 APA, all rights reserved)},
author = {Mehrabian, Albert and Wiener, M},
journal = {Journal of Personality and Social Psychology},
keywords = {attitude,communication,cues,humans,schizophrenic psychology,voice},
number = {1},
pages = {109--114},
pmid = {6032751},
title = {{Decoding of inconsistent communications.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/6032751},
volume = {6},
year = {1967}
}
@article{Gama2011,
author = {Gama, Sandra and Barata, Gabriel and Gon\c{c}alves, D. and Prada, R. and Paiva, Ana},
file = {::},
journal = {Affective Computing and Intelligent Interaction},
keywords = {affective computing,conversational agent,empathic agent},
pages = {507--516},
publisher = {Springer},
title = {{SARA: social affective relational agent: a study on the role of empathy in artificial social agents}},
url = {http://www.springerlink.com/index/G0433KX744258W62.pdf},
year = {2011}
}
@article{Vernon2010,
abstract = {This review summarizes the literature on computer-based drinking assessment and intervention programs evaluated using members of the general public. The primary aims were to summarize the demand, usage, and effectiveness of these services. A systematic search of the literature identified seven on-line drinking assessments and eight computerized interventions that were evaluated using members of the general public. Internet assessment users tend to be in their early thirties, are more often male, tend to be at risk for or are experiencing alcohol-related problems, more fully explore assessment sites and are more likely to enroll in interventions linked to these sites when their drinking problem is more severe. Although drop-out from computer-based interventions is often very high and treatment models vary widely program completers appear to show improvements.},
author = {Vernon, ML},
doi = {10.1016/j.jsat.2009.11.001.A},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Manuscript - 2010 - NIH Public Access.pdf:pdf},
journal = {Journal of substance abuse treatment},
keywords = {alcohol,alcohol intervention,drinking assessment,internet,treatment},
number = {3},
pages = {203--211},
title = {{A review of computer-based alcohol problem services designed for the general public}},
url = {http://www.sciencedirect.com/science/article/pii/S0740547209001846},
volume = {38},
year = {2010}
}
@phdthesis{Tatar1998,
author = {Tatar, D.},
school = {Stanford University},
title = {{Social and Personal Effects of Preoccupied Listeners}},
type = {Thesis},
year = {1998}
}
@book{Damasio1994,
abstract = {""Although I cannot tell for certain what sparked my interest in the neural underpinnings of reason, I do know when I became convinced that the traditional views on the nature of rationality could not be correct." Thus begins a book that takes the reader on a journey of discovery, from the story of Phineas Gage, the famous nineteenth-century case of behavioral change that followed brain damage, to the contemporary recreation of Gage's brain; and from the doubts of a young neurologist to a testable hypothesis concerning the emotions and their fundamental role in rational human behavior." "Drawing on his experiences with neurological patients affected by brain damage (his laboratory is recognized worldwide as the foremost center for the study of such patients), Antonio Damasio shows how the absence of emotion and feeling can break down rationality. In the course of explaining how emotions and feelings contribute to reason and to adaptive social behavior, Damasio also offers a novel perspective on what emotions and feelings actually are: a direct sensing of our own body states, a link between the body and its survival-oriented regulations, on the one hand, and consciousness, on the other." "Descartes' Error leads us to conclude that human organisms are endowed from the very beginning with a spirited passion for making choices, which the social mind can use to build rational behavior."-BOOK JACKET.},
author = {Damasio, Antonio R},
booktitle = {New York},
editor = {Damasio, A R},
isbn = {0399138943},
number = {6988},
pages = {312},
pmid = {327},
publisher = {Putnam},
title = {{Descartes' Error: Emotion, Reason, and the Human Brain}},
url = {http://books.google.com/books?id=\_6gLAQAAIAAJ\&pgis=1},
volume = {33},
year = {1994}
}
@article{Clayman2001,
abstract = {This article provides an overview of the dynamics of answering and resisting or evading questions in broadcast news interviews. After a preliminary examination of the practices through which answers are recognizably constructed, the analysis turns to the practices through which interviewees manage responses that resist the agenda of an interviewer's question. When resisting overtly, interviewees engage in various forms of damage control. When resisting covertly, interviewees take steps to render the resistance less conspicuous. Both sets of practices facilitate resistant responses by reducing the negative consequences that might otherwise follow. Such practices demonstrate that, although interviewees have developed practices for resisting questions, the norm of answering remains a salient feature of the contemporary broadcast news interview.},
author = {Clayman, Steven E},
journal = {Language in Society},
number = {03},
pages = {403--442},
title = {{Answers and evasions}},
volume = {30},
year = {2001}
}
@incollection{Stueber2008,
author = {Stueber, Karsten},
booktitle = {The Stanford Encyclopedia of Philosophy},
edition = {Fall 2008},
editor = {Zalta, Edward N.},
title = {{Empathy}},
url = {http://plato.stanford.edu/archives/fall2008/entries/empathy/},
year = {2008}
}
@article{Varni2009,
author = {Varni, Giovanna and Camurri, Antonio and Coletta, Paolo and Volpe, Gualtiero},
doi = {10.1109/CSE.2009.230},
file = {::},
isbn = {978-1-4244-5334-4},
journal = {2009 International Conference on Computational Science and Engineering},
keywords = {Social signals, music, synchronisation},
pages = {843--848},
publisher = {Ieee},
title = {{Toward a Real-Time Automated Measure of Empathy and Dominance}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5283210},
year = {2009}
}
@article{Ochs2010,
author = {Ochs, Magalie and Sadek, David and Pelachaud, Catherine},
doi = {10.1007/s10458-010-9156-z},
file = {::},
issn = {1387-2532},
journal = {Autonomous Agents and Multi-Agent Systems},
keywords = {affective computing,dialog,emotions,empathy,rational dialog agent},
month = nov,
title = {{A formal model of emotions for an empathic rational dialog agent}},
url = {http://www.springerlink.com/index/10.1007/s10458-010-9156-z},
year = {2010}
}
@article{Zeng2009,
abstract = {Automated analysis of human affective behavior has attracted increasing attention from researchers in psychology, computer science, linguistics, neuroscience, and related disciplines. However, the existing methods typically handle only deliberately displayed and exaggerated expressions of prototypical emotions despite the fact that deliberate behaviour differs in visual appearance, audio profile, and timing from spontaneously occurring behaviour. To address this problem, efforts to develop algorithms that can process naturally occurring human affective behaviour have recently emerged. Moreover, an increasing number of efforts are reported toward multimodal fusion for human affect analysis including audiovisual fusion, linguistic and paralinguistic fusion, and multi-cue visual fusion based on facial expressions, head movements, and body gestures. This paper introduces and surveys these recent advances. We first discuss human emotion perception from a psychological perspective. Next we examine available approaches to solving the problem of machine understanding of human affective behavior, and discuss important issues like the collection and availability of training and test data. We finally outline some of the scientific and engineering challenges to advancing human affect sensing technology.},
author = {Zeng, Zhihong and Pantic, Maja and Roisman, Glenn I and Huang, Thomas S},
doi = {10.1109/TPAMI.2008.52},
file = {::},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Affect,Affect: physiology,Algorithms,Artificial Intelligence,Automated,Automated: methods,Emotions,Emotions: physiology,Facial Expression,Monitoring,Pattern Recognition,Physiologic,Physiologic: methods,Sound Spectrography,Sound Spectrography: methods},
month = jan,
number = {1},
pages = {39--58},
pmid = {19029545},
title = {{A survey of affect recognition methods: audio, visual, and spontaneous expressions.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19029545},
volume = {31},
year = {2009}
}
@article{Bryant1982,
abstract = {56 1st, 115 4th, and 87 7th graders were administered a newly devised index of empathy partly based on A. Mehrabian and N. Epstein's (see record 1973-23075-001) measure. Item means, item-total correlations, testretest reliabilities, correlations of empathy with aggressiveness and acceptance of individual differences, and correlations with other existing measures of empathy as well as to social desirability response set and reading achievement formed the basis of internal, discriminant, convergent, and general construct validation. The measure demonstrated satisfactory reliability and preliminary construct validity. The study of developmental aspects of empathic arousal toward peers of different sexes is indicated. (38 ref) (PsycINFO Database Record (c) 2010 APA, all rights reserved)},
author = {Bryant, Brenda K},
doi = {10.2307/1128984},
issn = {00093920},
journal = {Child Development},
number = {2},
pages = {413--425},
publisher = {Blackwell Publishing on behalf of the Society for Research in Child Development},
title = {{An Index of Empathy for Children and Adolescents}},
volume = {53},
year = {1982}
}
@inproceedings{Boukricha2009,
abstract = {a system for simulating emotional facial expressions for a virtual human has been evolved. This system consists of two parts: (1) a control ar- chitecture for simulating emotional facial expressions with respect to Pleasure, Arousal, and Dominance (PAD) val- ues, (2) an expressive output component for animating the virtual human’s facial muscle actions called Action Units (AUs), modeled following the Facial Action Coding Sys- tem (FACS). A large face repertoire of about 6000 faces arranged in PAD-space with respect to two dominance val- ues (dominant vs. submissive) is obtained as a result of the empirical study. Using the face repertoire an approach to- wards realizing facial mimicry for a virtual human based on backward mapping AUs displaying an emotional facial expression on PAD-values is outlined.},
annote = {- For automatic recognition, the mapping of AUs to PAD may be only useful once you can identify the active AUs and their intensity on the face (which you won't be able with image processing teckniques).
- For the expression, if you have an avatar which has control on the AUs, you don’t need to map the AUs to PAD. But, if you have an avatar which expresses based on PAD, then this mapping is useful. 
- Mapping of AUs to PAD is helpful when you want to fuse multiple modalities where other modalities are in PAD values. },
author = {Boukricha, Hana and Wachsmuth, Ipke and Hofstatter, A. and Grammer, Karl},
booktitle = {Affective Computing and Intelligent Interaction and Workshops, 2009. ACII 2009. 3rd International Conference on},
file = {::},
isbn = {9781424447992},
pages = {1--7},
publisher = {IEEE},
title = {{Pleasure-arousal-dominance driven facial expression simulation}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5349579},
year = {2009}
}
@article{Lakin2003b,
author = {Lakin, J. L. and Chartrand, T. L.},
doi = {10.1111/1467-9280.14481},
file = {::},
issn = {0956-7976},
journal = {Psychological Science},
month = jul,
number = {4},
pages = {334--339},
title = {{Using Nonconscious Behavioral Mimicry to Create Affiliation and Rapport}},
url = {http://pss.sagepub.com/lookup/doi/10.1111/1467-9280.14481},
volume = {14},
year = {2003}
}
@article{Bavelas1986,
author = {Bavelas, Janet Beavin and Black, Alex and Lemery, Charles R. and {Jennifer Muller}},
file = {::},
journal = {Journal of Personality and Social Psychology},
number = {2},
pages = {322--329},
title = {{"I show how you feel" - Motor mimicry as a communicative act}},
volume = {50},
year = {1986}
}
@article{Sabourin,
author = {Sabourin, Jennifer and Mott, Bradford and Lester, James},
file = {::},
journal = {lorentzcenter.nl},
keywords = {empathetic virtual agents,pedagogical agents,virtual learning},
title = {{Computational Models of Affect and Empathy for Pedagogical Virtual Agents}},
url = {http://www.lorentzcenter.nl/lc/web/2011/464/presentations/Sabourin.pdf}
}
@article{Sarrafzadeh2006,
author = {Sarrafzadeh, Abdolhossein and Alexander, Samuel and Dadgostar, Farhad and Fan, Chao and Bigdeli, Abbas},
doi = {10.1109/INNOVATIONS.2006.301981},
file = {::},
isbn = {1-4244-0673-0},
journal = {2006 Innovations in Information Technology},
keywords = {affective,affective computing,affective tutoring systems,agents,emotion detection,human computer,interaction,lifelike,new type of its,proposed by the authors},
month = nov,
pages = {1--5},
publisher = {Ieee},
title = {{See Me, Teach Me: Facial Expression and Gesture Recognition for Intelligent Tutoring Systems}},
year = {2006}
}
@article{Dias2005,
author = {Dias, J. and Paiva, Ana},
file = {::},
journal = {Progress in artificial intelligence},
pages = {127--140},
publisher = {Springer},
title = {{Feeling and reasoning: A computational model for emotional characters}},
url = {http://www.springerlink.com/index/YQ18H62602413554.pdf},
year = {2005}
}
@article{Warner1987,
author = {Warner, Rebecca M. and Malloy, Daniel and Schneider, Kathy and Knoth, Russell and Wilder, Bruce},
doi = {10.1007/BF00990958},
file = {::},
issn = {0191-5886},
journal = {Journal of Nonverbal Behavior},
number = {2},
pages = {57--74},
title = {{Rhythmic organization of social interaction and observer ratings of positive affect and involvement}},
url = {http://www.springerlink.com/index/10.1007/BF00990958},
volume = {11},
year = {1987}
}
@article{Tickle-Degnen1990,
abstract = {The purpose of this article is to offer a conceptualization of rapport that has utility for identifiing the nonverbal correlates associated with rapport. We describe the nature of rapport in terms of a dynamic structure of three interrelating components: mutual attentiveness, positivity, and coor- dination. We propose that the relative weighting of these components in the experience of rapport changes over the course of a developing relationship between individuals. In early interactions, positivity and attentiveness are more heavily weighted than coordination, whereas in later interactions, coordination and attentiveness are the more heavily weighted components. Because of the gestalt nature of the experience of rapport, it is not easy to identifi nonverbal behavioral correlates of the components. We discuss two approaches to nonverbal measurement, molecular and molar, along with recommendations for their appropriate application in the study of rapport at different stages of an interpersonal relationship. We present a meta-analytic study that demon- strates the effect of nonverbal behavior, measured at the molecular level, on the positivity component of rapport, and we conclude with an outline of hypotheses relevant to the investigation of the nonverbal correlates of rapport.},
author = {Tickle-Degnen, L. and Rosenthal, Robert},
file = {::},
journal = {Psychological Inquiry},
number = {4},
pages = {285--293},
publisher = {Taylor \& Francis},
title = {{The nature of rapport and its nonverbal correlates}},
url = {http://www.tandfonline.com/doi/abs/10.1207/s15327965pli0104\_1},
volume = {1},
year = {1990}
}
@article{Brave2005,
author = {Brave, Scott and Nass, Clifford and Hutchinson, Kevin},
doi = {10.1016/j.ijhcs.2004.11.002},
file = {::},
issn = {10715819},
journal = {International Journal of Human-Computer Studies},
keywords = {affective computing,characters,embodied agents,emotion,empathy,social interfaces},
month = feb,
number = {2},
pages = {161--178},
title = {{Computers that care: investigating the effects of orientation of emotion exhibited by an embodied computer agent}},
volume = {62},
year = {2005}
}
@article{Hancock2007,
abstract = {Our ability to express and accurately assess emotional states is central to human life. The present study examines how people express and detect emotions during text-based communication, an environment that eliminates the nonverbal cues typically associated with emotion. The results from 40 dyadic interactions suggest that users relied on four strategies to express happiness versus sadness, including disagreement, negative affect terms, punctuation, and verbosity. Contrary to conventional wisdom, communication partners readily distinguished between positive and negative valence emotional communicators in this text-based context. The results are discussed with respect to the Social Information Processing model of strategic relational adaptation in mediated communication.},
author = {Hancock, Jeffrey T and Landrigan, Christopher and Silver, Courtney},
doi = {10.1145/1240624.1240764},
isbn = {9781595935939},
journal = {Proceedings of the SIGCHI conference on Human factors in computing systems CHI 07},
pages = {929},
publisher = {ACM Press},
series = {Proceedings of the SIGCHI conference on Human factors in computing systems},
title = {{Expressing emotion in text-based communication}},
url = {http://portal.acm.org/citation.cfm?doid=1240624.1240764},
year = {2007}
}
@inproceedings{Cramer2010,
abstract = {Empathy has great potential in human-robot interaction. However, the challenging nature of assessing the user's emotional state points to the importance of also understanding the effects of empathic behaviours incongruent with users' affective experience. A 3x2 between-subject video-based survey experiment (N=133) was conducted with empathic robot behaviour (empathically accurate, neutral, inaccurate) and valence of the situation (positive, negative) as dimensions. Trust decreased when empathic responses were incongruent with the affective state of the user. However, in the negative valence condition, reported perceived empathic abilities were greater when the robot responded as if the situation were positive.},
author = {Cramer, Henriette and Goddijn, Jorrit and Wielinga, Bob and Evers, Vanessa},
booktitle = {HRI '10 Proceedings of the 5th ACM/IEEE international conference on Human-robot interaction},
doi = {10.1145/1734454.1734513},
file = {::},
isbn = {9781424448937},
pages = {141--142},
publisher = {ACM},
title = {{Effects of (in) accurate empathy and situational valence on attitudes towards robots}},
url = {http://dl.acm.org/citation.cfm?id=1734513},
year = {2010}
}
@inproceedings{Hamza2004,
abstract = {This paper introduces the IBM Expressive Speech Synthesis system. We describe recent work in improving the quality of our baseline text-to-speech system as well as extending our capabilities to generate expressive synthetic speech. We present results showing improved base quality, especially for sentences drawn from a limited domain. We also demonstrate our ability to convey good news and bad news, produce contrastive emphasis, and ask a question appropriately. In order to facilitate access to the expressive capabilities, we use some of our proposed extensions to the Speech Synthesis Markup Language (SSML).},
address = {Jeju, Korea},
author = {Hamza, Wael and Bakis, Raimo and Eide, EM and Picheny, MA and Pitrelli, JF},
booktitle = {Proc. of the 8th International Conference on Spoken Language Processing},
file = {::},
title = {{The IBM expressive speech synthesis system}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.129.1962\&rep=rep1\&type=pdf},
year = {2004}
}
@article{Gerdes2009,
abstract = {This article presents a social work model of empathy that reflects the latest interdisciplinary research findings on empathy. The model reflects the social work commitment to social justice. The three model components are: 1) the affective response to another’s emotions and actions; 2) the cognitive processing of one’s affective response and the other person’s perspective; and 3) the conscious decision-making to take empathic action. Mirrored affective responses are involuntary, while cognitive processing and conscious decision-making are voluntary. The affective component requires healthy, neural pathways to function appropriately and accurately. The cognitive aspects of perspective-taking, self-awareness, and emotion regulation can be practiced and cultivated, particularly through the use of mindfulness techniques. Empathic action requires that we move beyond affective responses and cognitive processing toward utilizing social work values and knowledge to inform our actions. By introducing the proposed model of empathy, we hope it will serve as a catalyst for discussion and future research and development of the model.},
author = {Gerdes, Karen E. and Segal, Elizabeth A.},
file = {::},
journal = {Advances in Social Work},
keywords = {empathy,social cognitive neuroscience,social empathy},
number = {2},
pages = {114--127},
title = {{A social work model of empathy}},
url = {https://advancesinsocialwork.iupui.edu/index.php/advancesinsocialwork/article/viewArticle/235 http://journals.iupui.edu/index.php/advancesinsocialwork/article/view/235/215},
volume = {10},
year = {2009}
}
@article{D'Mello2009,
abstract = {We explored the reliability of detecting learners' affect by monitoring their gross body language (body position and arousal) during interactions with an intelligent tutoring system called AutoTutor. Training and validation data on affective states were collected in a learning session with AutoTutor, after which the learners' affective states (i.e., emotions) were rated by the learner, a peer, and two trained judges. An automated body pressure measurement system was used to capture the pressure exerted by the learner on the seat and back of a chair during the tutoring session. We extracted two sets of features from the pressure maps. The first set focused on the average pressure exerted, along with the magnitude and direction of changes in the pressure during emotional experiences. The second set of features monitored the spatial and temporal properties of naturally occurring pockets of pressure. We constructed five data sets that temporally integrated the affective judgments with the two sets of pressure features. The first four datasets corresponded to judgments of the learner, a peer, and two trained judges, whereas the final data set integrated judgments of the two trained judges. Machine-learning experiments yielded affect detection accuracies of 73\%, 72\%, 70\%, 83\%, and 74\%, respectively (chance=50\%) in detecting boredom, confusion, delight, flow, and frustration, from neutral. Accuracies involving discriminations between two, three, four, and five affective states (excluding neutral) were 71\%, 55\%, 46\%, and 40\% with chance rates being 50\%, 33\%, 25\%, and 20\%, respectively.},
author = {D'Mello, Sidney and Graesser, Arthur C},
doi = {10.1080/08839510802631745},
issn = {08839514},
journal = {Applied Artificial Intelligence},
number = {2},
pages = {123--150},
publisher = {Taylor \& Francis, Inc.},
title = {{Automatic Detection of Learner's Affect From Gross Body Language}},
url = {http://www.tandfonline.com/doi/abs/10.1080/08839510802631745},
volume = {23},
year = {2009}
}
@article{Boukricha2011b,
author = {Boukricha, Hana and Nguyen, H.},
file = {::},
journal = {Intelligent Virtual Agents},
pages = {350--362},
title = {{Sharing Emotions and Space – Empathy as a Basis for}},
url = {http://www.springerlink.com/index/Q22784632U008337.pdf},
year = {2011}
}
@inproceedings{Jiang2007,
author = {Jiang, Hong and Vidal, J.M. and Huhns, M.N.},
booktitle = {Proceedings of the 6th international joint conference on Autonomous agents and multiagent systems},
file = {::},
keywords = {agent architecture,belief-desire-intention,emotional agent},
pages = {11},
publisher = {ACM},
title = {{EBDI: an architecture for emotional agents}},
url = {http://dl.acm.org/citation.cfm?id=1329139},
year = {2007}
}
@article{Suchman1997,
abstract = {To formulate an empirically derived model of empathic communication in medical interviews by describing the specific behaviors and patterns of interaction associated with verbal expressions of emotion.},
author = {Suchman, a L and Markakis, K and Beckman, H B and Frankel, R},
file = {::},
issn = {0098-7484},
journal = {JAMA : the journal of the American Medical Association},
keywords = {Communication,Empathy,Humans,Interviews as Topic,Models,Physician-Patient Relations,Psychological},
month = feb,
number = {8},
pages = {678--82},
pmid = {9039890},
title = {{A model of empathic communication in the medical interview.}},
volume = {277},
year = {1997}
}
@inproceedings{Stoyanchev2011,
author = {Stoyanchev, Svetlana and Piwek, Paul and Prendinger, Helmut},
booktitle = {Intelligent Virtual Agents},
file = {::},
pages = {377--383},
publisher = {Springer},
title = {{Comparing modes of information presentation: text versus ECA and single versus two ECAs}},
url = {http://www.springerlink.com/index/H72521305G072173.pdf},
year = {2011}
}
@article{Vannini2010,
author = {Vannini, Natalie and Enz, Sibylle and Sapouna, Maria and Wolke, Dieter and Watson, Scott and Woods, Sarah and Dautenhahn, Kerstin and Hall, Lynne and Paiva, Ana and Andr\'{e}, Elizabeth and Aylett, Ruth and Schneider, Wolfgang},
doi = {10.1007/s10212-010-0035-4},
file = {::},
issn = {0256-2928},
journal = {European Journal of Psychology of Education},
month = jun,
number = {1},
pages = {21--44},
title = {{“FearNot!”: a computer-based anti-bullying-programme designed to foster peer intervention}},
url = {http://www.springerlink.com/index/10.1007/s10212-010-0035-4},
volume = {26},
year = {2010}
}
@inproceedings{Becker2005,
abstract = {This paper first describes two independently conducted research strands on affective human-computer interaction: one on an emotion simulation system for an expressive 3D humanoid agent called Max, which was designed at the University of Bielefeld; the other one on a real-time system for empathic (agent) feedback that is based on human emotional states derived from physiological information, and developed at the University of Tokyo and the National Institute of Informatics. Then, the integration of both systems is suggested for the purpose of realizing a highly believable agent with empathic qualities.},
address = {Takamatsu, Kagawa, Japan},
author = {Becker-Asano, Christian and Prendinger, Helmut and Ishizuka, M.},
booktitle = {Proceedings of the 2005 International Conference on Active Media Technology, 2005. (AMT 2005)},
doi = {10.1109/AMT.2005.1505417},
file = {::},
isbn = {0780390350},
keywords = {embodied conversational agents,empa-},
pages = {541 -- 545},
title = {{Empathy for Max}},
url = {http://www.techfak.uni-bielefeld.de/~cbecker/becker-helmut-amt05.pdf},
year = {2005}
}
@incollection{Creed2008,
abstract = {Why do computers need emotional intelligence? Science fiction often portrays emotional computers as dangerous and frightening, and as a serious threat to human life. One of the most famous examples is HAL, the supercomputer onboard the spaceship Discovery, in the movie 2001: A Space Odyssey. HAL could express, recognize and respond to human emotion, and generally had strong emotional skills — the consequences of which were catastrophic. However, since the movie’s release almost 40 years ago, the traditional view of emotions as contributing to irrational and unpredictable behavior has changed. Recent research has suggested that emotions play an essential role in important areas such as learning, memory, motivation, attention, creativity, and decision making. These findings have prompted a large number of research groups around the world to start examining the role of emotions and emotional intelligence in human-computer interaction (HCI). For almost half a century, computer scientists have been attempting to build machines that can interact intelligently with us, and despite initial optimism, they are still struggling to do so. For much of this time, the role of emotion in developing intelligent computers was largely overlooked, and it is only recently that interest in this area has risen dramatically. This increased interest can largely be attributed to the work of [6] and [85] who were amongst the first to bring emotion to the attention of computer scientists. The former highlighted emotion as a fundamental component required in building believable agents, while the latter further raised the awareness of emotion and its potential importance in HCI. Since these publications, the literature on emotions and computing has grown considerably with progress being made on a number of different fronts.},
author = {Creed, Chris and Beale, Russell},
booktitle = {Computational Intelligence: A Compendium},
doi = {10.1007/978-3-540-78293-3},
editor = {Fulcher, John and Jain, L. C.},
file = {::},
isbn = {978-3-540-78292-6},
pages = {185--230},
publisher = {Springer Berlin / Heidelberg},
title = {{Emotional Intelligence: Giving Computers Effective Emotional Skills to Aid Interaction}},
url = {http://www.springerlink.com/index/U2231064587Q8V07.pdf},
volume = {230},
year = {2008}
}
@article{Saunier2010,
author = {Saunier, Julien and Jones, Hazael and Lourdeaux, Domitile},
doi = {10.1109/WI-IAT.2010.255},
file = {::},
isbn = {978-1-4244-8482-9},
journal = {2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology},
keywords = {emotions,empathy,multi-agent architecture,personality,placebo},
month = aug,
pages = {277--282},
publisher = {Ieee},
title = {{Empathy and Placebo for Autonomous Agents}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5616059},
year = {2010}
}
@article{Mendelson1999,
author = {Mendelson, M.J. and Aboud, F.E.},
file = {::},
journal = {Canadian Journal of Behavioural Science/Revue canadienne des sciences du comportement},
number = {2},
pages = {130},
publisher = {Canadian Psychological Association},
title = {{Measuring friendship quality in late adolescents and young adults: McGill Friendship Questionnaires.}},
url = {http://psycnet.apa.org/journals/cbs/31/2/130/},
volume = {31},
year = {1999}
}
@incollection{Preston2007,
author = {Preston, SD},
booktitle = {Empathy in mental illness},
chapter = {23},
editor = {Farrow, T. and Woodruff, P.},
file = {::},
isbn = {0521847346},
pages = {428--446},
publisher = {Cambridge University Press},
title = {{A perception-action model for empathy}},
url = {http://www-personal.umich.edu/~prestos/Downloads/Preston2007\_MI.pdf},
year = {2007}
}
@article{Novielli2010,
abstract = {We describe how the interaction mode with an embodied conversational agent (ECA) affects the users’ perception of the agent and their behavior during interaction, and propose a method to recognize the social attitude of users towards the agent from their verbal behavior. A corpus of human–ECA dialogues was collected with a Wizard-of-Oz study in which the input mode of the user moves was varied (written vs. speech-based). After labeling the corpus, we evaluated the relationship between input mode and social attitude of users towards the agent. The results show that, by increasing naturalness of interaction, spoken input produces a warmer attitude of users and a richer language: this effect is more evident for users with a background in humanities. Recognition of signs of social attitude is needed for adapting the ECA’s verbal and nonverbal behavior.},
author = {Novielli, Nicole and de Rosis, Fiorella and Mazzotta, Irene},
doi = {10.1016/j.pragma.2009.12.016},
file = {::},
issn = {03782166},
journal = {Journal of Pragmatics},
keywords = {evaluation of artificial agents,natural language user interfaces,user-centered design},
month = sep,
number = {9},
pages = {2385--2397},
publisher = {Elsevier B.V.},
title = {{User attitude towards an embodied conversational agent: Effects of the interaction mode}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0378216609003324},
volume = {42},
year = {2010}
}
@article{Chavhan2010,
author = {Chavhan, Yashpalsing and Dhore, M. L. and Yesaware, Pallavi},
doi = {10.5120/431-636},
file = {::},
issn = {09758887},
journal = {International Journal of Computer Applications},
keywords = {emotion recognition,mfcc and,speech emotion,svm},
month = feb,
number = {20},
pages = {8--11},
title = {{Speech Emotion Recognition using Support Vector Machine}},
url = {http://www.ijcaonline.org/journal/number20/pxc387636.pdf},
volume = {1},
year = {2010}
}
@inproceedings{Sourina2011,
address = {New York, New York, USA},
author = {Sourina, O. and Liu, Y. and Nguyen, Minh Khoa},
booktitle = {SIGGRAPH Asia 2011 Posters on - SA '11},
doi = {10.1145/2073304.2073315},
file = {::},
isbn = {9781450311373},
pages = {1},
publisher = {ACM Press},
title = {{Emotion-enabled EEG-based interaction}},
url = {http://dl.acm.org/citation.cfm?doid=2073304.2073315},
year = {2011}
}
@article{Becker2008,
author = {Becker-Asano, Christian and Prendinger, H and Ishizuka, M.},
file = {::},
isbn = {0780390350},
journal = {Data Processing},
keywords = {embodied conversational agents,empa-},
title = {{Empathy for Max}},
url = {http://www.techfak.uni-bielefeld.de/~cbecker/becker-helmut-amt05.pdf},
year = {2008}
}
@article{Pierre-Yves2003,
author = {Pierre-Yves, O},
doi = {10.1016/S1071-5819(02)00141-6},
file = {::},
issn = {10715819},
journal = {International Journal of Human-Computer Studies},
keywords = {emotion production,emotion recognition,emotions,robots,speech},
month = jul,
number = {1-2},
pages = {157--183},
title = {{The production and recognition of emotions in speech: features and algorithms}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1071581902001416},
volume = {59},
year = {2003}
}
@article{Sebe2005b,
author = {Sebe, Nicu and Cohen, Ira and Gevers, Theo},
file = {::},
journal = {Proc. SPIE},
keywords = {emotion recognition,human-computer interaction,multimodal approach},
title = {{Multimodal approaches for emotion recognition: a survey}},
url = {http://disi.unitn.it/~sebe/PUBS/PDF/2005/sebeSPIE2005a.pdf},
year = {2005}
}
@inproceedings{Lisetti2012a,
abstract = {We discuss the design and implementation of the prototype of an avatar-based health system aimed at providing people access to an effective behavior change intervention which can help them to find and cultivate motivation to change unhealthy lifestyles. An empathic Embodied Conversational Agent (ECA) delivers the intervention. The health dialog is directed by a computational model of Motivational Interviewing, a novel effective face-to-face patient-centered counseling style which respects an individual’s pace toward behavior change. Although conducted on a small sample size, results of a preliminary user study to asses users’ acceptance of the avatar counselor indicate that the system prototype is well accepted by 75\% of users.},
address = {Miami, FL, US},
author = {Lisetti, Christine L and Yasavur, Ugan and Leon, Claudia De and Amini, Reza and Rishe, Napthali},
booktitle = {Preceeding of FLAIRS'2012 Association for the Advancement of Artificial Intelligence (www.aaai.org)},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lisetti et al. - 2012 - Building an On-demand Avatar-based Health Intervention for Behavior Change(5).pdf:pdf},
number = {Mi},
title = {{Building an On-demand Avatar-based Health Intervention for Behavior Change}},
year = {2012}
}
@article{Kendon2002,
abstract = {A context-of-use study is reported of the `head shake'. A large number of examples are described and compared, drawn from video recordings of naturally occasioned interactions in the circumstances of everyday life, made in Campania, Italy, central England and the Eastern United States. Eight different kinds of uses for the head shake are illustrated. It is concluded that the head shake is not to be understood simply as the kinesic equivalent of a unit of verbal expression. It appears as an expression in its own right which, furthermore, the speaker uses as a component in the construction of an utterance which, it seems, is so often a multimodal construction in which the different modalities of expression available are deployed by the speaker in the course of building a unit of expression according to the rhetorical needs of the interactive moment.},
author = {Kendon, Adam},
doi = {10.1075/gest.2.2.03ken},
journal = {Gesture},
keywords = {conversation,gesture,kinesics,multi-modalcommunication,negation},
number = {2},
pages = {147--182},
title = {{Some uses of the head shake}},
volume = {2},
year = {2002}
}
@techreport{Miller1981,
abstract = {Thirty-one self-referred problem drinkers were randomly assigned to one of two modalities for behavioral self-control training with a goal of moderation: (1) minimal therapist contact, in which clients worked only with a self-help manual; and (2) therapist directed training, in which clients received self-help materials plus 10 individual treatment sessions. Both groups showed significant reductions in alcohol consumption and peak blood alcohol concentration. Contrary to expectations, there were no significant differences on outcome measures between groups. Results are interpreted within a self-control framework.},
author = {Miller, William R. and Gribskov, C J and Mortell, R L},
booktitle = {The International journal of the addictions},
number = {7},
pages = {1247--1254},
pmid = {7327785},
publisher = {Informa UK Ltd UK},
title = {{Effectiveness of a self-control manual for problem drinkers with and without therapist contact.}},
url = {http://informahealthcare.com/doi/abs/10.3109/10826088109039178},
volume = {16},
year = {1981}
}
@article{Fuchs1987,
abstract = {The impact of examiner/examinee familiarity and rapport on psychological test performance is reviewed. Drawing upon research involving hundreds of young handicapped and nonhandicapped children, it was found that certain handicapped children obtain higher scores when tested by familiar examiners. Implications for practice, theory, and personnel preparation are discussed.},
author = {Fuchs, Douglas},
journal = {Topics in Early Childhood Special Education},
number = {3},
pages = {90--104},
title = {{Examiner Familiarity Effects on Test Performance: Implications for Training and Practice}},
volume = {7},
year = {1987}
}
@article{Moridis2012,
abstract = {Empathetic behavior has been suggested to be one effective way for Embodied Conversational Agents (ECAs) to provide feedback to learners’ emotions. An issue that has been raised is the effective integration of parallel and reactive empathy. The aim of this study is to examine the impact of ECAs’ emotional facial and tone of voice expressions combined with empathetic verbal behavior when displayed as feedback to students’ fear, sad, and happy emotions in the context of a self-assessment test. Three identical female agents were used for this experiment: 1) an ECA performing parallel empathy combined with neutral emotional expressions, 2) an ECA performing parallel empathy displaying emotional expressions that were relevant to the emotional state of the student, and 3) an ECA performing parallel empathy by displaying relevant emotional expressions followed by emotional expressions of reactive empathy with the goal of altering the student’s emotional state. Results indicate that an agent performing parallel empathy displaying emotional expressions relevant to the emotional state of the student may cause this emotion to persist. Moreover, the agent performing parallel and then reactive empathy appeared to be effective in altering an emotional state of fear to a neutral one.},
author = {Moridis, Christos N and Economides, Anastasios A and Member, Senior},
file = {::},
journal = {IEEE TRANSACTIONS ON AFFECTIVE COMPUTING},
keywords = {Computers and education,empathy,intelligent agents,user interfaces},
number = {3},
pages = {260--272},
title = {{Affective Learning : Empathetic Agents with Emotional Facial and Tone of Voice Expressions}},
volume = {3},
year = {2012}
}
@article{Gratch2007a,
author = {Gratch, Jonathan and Wang, Ning and Gerten, Jillian and Fast, Edward},
file = {::},
journal = {Intelligent Virtual Agents},
keywords = {evaluation,rapport,virtual agents},
title = {{Creating rapport with virtual agents}},
url = {http://www.springerlink.com/index/X568357400058UM7.pdf},
year = {2007}
}
@inproceedings{Huang2010,
abstract = {Virtual humans are embodied software agents that should not only be realistic looking but also have natural and realistic behaviors. Traditional virtual human systems learn these interaction behaviors by observing how individuals respond in face-to-face situations (i.e., direct interaction). In contrast, this paper introduces a novel methodological approach called parasocial consensus sampling (PCS) which allows multiple individuals to vicariously experience the same situation to gain insight on the typical (i.e., consensus view) of human responses in social interaction. This approach can help tease apart what is idiosyncratic from what is essential and help reveal the strength of cues that elicit social responses. Our PCS approach has several advantages over traditional methods: (1) it integrates data from multiple independent listeners interacting with the same speaker, (2) it associates probability of how likely feedback will be given over time, (3) it can be used as a prior to analyze and understand the face-to-face interaction data, (4) it facilitates much quicker and cheaper data collection. In this paper, we apply our PCS approach to learn a predictive model of listener backchannel feedback. Our experiments demonstrate that a virtual human driven by our PCS approach creates significantly more rapport and is perceived as more believable than the virtual human driven by face-to-face interaction data.},
address = {Toronto, Canada},
author = {Huang, Lixing and Morency, Louis-Philippe and Gratch, Jonathan},
booktitle = {9th International Conference on Autonomous Agents and Multiagent Systems (AAMAS'2010)},
doi = {10.1145/1838206.1838371},
editor = {Hoek, Van Der and Kaminka and Lesperance and Luck and Sen},
file = {::},
keywords = {Backchannel Feedback,Parasocial,Rapport,Virtual Humans},
number = {Aamas},
pages = {10--14},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org)},
title = {{Parasocial consensus sampling: combining multiple perspectives to learn virtual human behavior}},
url = {http://dl.acm.org/citation.cfm?id=1838371},
year = {2010}
}
@inproceedings{Kumano2011,
author = {Kumano, Shiro and Otsuka, Kazuhiro and Mikami, Dan and Yamato, Junji},
booktitle = {Automatic Face \& Gesture Recognition and Workshops (FG 2011), 2011 IEEE International Conference on},
file = {::},
pages = {43--50},
publisher = {IEEE},
title = {{Analyzing empathetic interactions based on the probabilistic modeling of the co-occurrence patterns of facial expressions in group meetings}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5771440},
year = {2011}
}
@inproceedings{Nor2010,
author = {Nor, R.M. and Muhlberger, Ralf},
booktitle = {User Science and Engineering (i-USEr), 2010 International Conference on},
file = {::},
isbn = {9781424490493},
keywords = {-component,community,empathy,emphatic communication,user experience},
pages = {7--10},
publisher = {IEEE},
title = {{Designing to support empathy: Understanding user experience by using a model of interaction in meeting human needs}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5716713},
year = {2010}
}
@book{Osgood1990,
author = {Osgood, C.E.},
publisher = {Praeger Publishers},
title = {{Language Meaning, and Culture: The Selected Papers of C.E. Osgood}},
year = {1990}
}
@article{Cooper2003,
abstract = {BACKGROUND: African-American patients who visit physicians of the same race rate their medical visits as more satisfying and participatory than do those who see physicians of other races. Little research has investigated the communication process in race-concordant and race-discordant medical visits. OBJECTIVES: To compare patient-physician communication in race-concordant and race-discordant visits and examine whether communication behaviors explain differences in patient ratings of satisfaction and participatory decision making. DESIGN: Cohort study with follow-up using previsit and postvisit surveys and audiotape analysis. SETTING: 16 urban primary care practices. PATIENTS: 252 adults (142 African-American patients and 110 white patients) receiving care from 31 physicians (of whom 18 were African-American and 13 were white). MEASUREMENTS: Audiotape measures of patient-centeredness, patient ratings of physicians' participatory decision-making styles, and overall satisfaction. RESULTS: Race-concordant visits were longer (2.15 minutes 95\% CI, 0.60 to 3.71) and had higher ratings of patient positive affect (0.55 point, 95\% CI, 0.04 to 1.05) compared with race-discordant visits. Patients in race-concordant visits were more satisfied and rated their physicians as more participatory (8.42 points 95\% CI, 3.23 to 13.60). Audiotape measures of patient-centered communication behaviors did not explain differences in participatory decision making or satisfaction between race-concordant and race-discordant visits. CONCLUSIONS: Race-concordant visits are longer and characterized by more patient positive affect. Previous studies link similar communication findings to continuity of care. The association between race concordance and higher patient ratings of care is independent of patient-centered communication, suggesting that other factors, such as patient and physician attitudes, may mediate the relationship. Until more evidence is available regarding the mechanisms of this relationship and the effectiveness of intercultural communication skills programs, increasing ethnic diversity among physicians may be the most direct strategy to improve health care experiences for members of ethnic minority groups.},
author = {Cooper, Lisa A and Roter, Debra L and Johnson, Rachel L and Ford, Daniel E and Steinwachs, Donald M and Powe, Neil R},
institution = {Johns Hopkins University School of Medicine and the Welch Center for Prevention, Epidemiology, and Clinical Research, Johns Hopkins University, Baltimore, Maryland 21205-2223, USA. lisa.cooper@jhmi.edu},
journal = {Annals of Internal Medicine},
keywords = {empirical approach,professional patient relationship},
number = {11},
pages = {907--915},
pmid = {14644893},
title = {{Patient-centered communication, ratings of care, and concordance of patient and physician race.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/14644893},
volume = {139},
year = {2003}
}
@article{Decety2004,
abstract = {Empathy accounts for the naturally occurring subjective experience of similarity between the feelings expressed by self and others without loosing sight of whose feelings belong to whom. Empathy involves not only the affective experience of the other person's actual or inferred emotional state but also some minimal recognition and understanding of another's emotional state. In light of multiple levels of analysis ranging from developmental psychology, social psychology, cognitive neuroscience, and clinical neuropsychology, this article proposes a model of empathy that involves parallel and distributed processing in a number of dissociable computational mechanisms. Shared neural representations, self-awareness, mental flexibility, and emotion regulation constitute the basic macrocomponents of empathy, which are underpinned by specific neural systems. This functional model may be used to make specific predictions about the various empathy deficits that can be encountered in different forms of social and neurological disorders.},
author = {Decety, Jean and Jackson, Philip L},
doi = {10.1177/1534582304267187},
file = {::},
isbn = {1534582304267},
issn = {1534-5823},
journal = {Behavioral and cognitive neuroscience reviews},
keywords = {affective sharing,emotion regulation,executive inhibition,intersubjectivity,perspective taking,self-awareness,shared representations},
month = jun,
number = {2},
pages = {71--100},
pmid = {15537986},
title = {{The functional architecture of human empathy}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15537986},
volume = {3},
year = {2004}
}
@inproceedings{Vargas2010,
abstract = {Multimodal conversational dialogue sys- tems consisting of numerous software components create challenges for the un- derlying software architecture and devel- opment practices. Typically, such sys- tems are built on separate, often pre- existing components developed by dif- ferent organizations and integrated in a highly iterative way. The traditional dia- logue system pipeline is not flexible enough to address the needs of highly in- teractive systems, which include parallel processing of multimodal input and out- put. We present an architectural solution for a multimodal conversational social dialogue system.},
address = {The University of Tokyo},
author = {Vargas, C Emilio and Field, Debora},
booktitle = {Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
file = {::},
pages = {47--50},
publisher = {Association for Computational Linguistics},
title = {{‘ How was your day ?’ An architecture for multimodal ECA systems}},
year = {2010}
}
@article{Sebe2005b,
author = {Sebe, Nicu and Cohen, Ira and Gevers, Theo},
file = {::},
journal = {Proc. SPIE},
keywords = {emotion recognition,human-computer interaction,multimodal approach},
title = {{Multimodal approaches for emotion recognition: a survey}},
url = {http://disi.unitn.it/~sebe/PUBS/PDF/2005/sebeSPIE2005a.pdf},
year = {2005}
}
@article{Shamay-Tsoory2011,
abstract = {Human empathy relies on the ability to share emotions as well as the ability to understand the other's thoughts, desires, and feelings. Recent evidence points to 2 separate systems for empathy: an emotional system that supports our ability to empathize emotionally and a cognitive system that involves cognitive understanding of the other's perspective. A neural network that includes the inferior frontal gyrus and the inferior parietal lobule is necessary for emotion recognition and emotional contagion. Although the emotional and cognitive systems appear to work independently, every empathic response may still evoke both components to some extent, depending on the social context.},
annote = {Difference between cognitive empathy and emotional empathy is explained in this paper. Also they talk about the active brain parts in each empathy type.},
author = {Shamay-Tsoory, Simone G},
doi = {10.1177/1073858410379268},
file = {::},
issn = {1089-4098},
journal = {The Neuroscientist : a review journal bringing neurobiology, neurology and psychiatry},
keywords = {Brain,Brain: physiology,Empathy,Empathy: physiology,Humans,Neural Pathways,Neural Pathways: physiology},
month = feb,
number = {1},
pages = {18--24},
pmid = {21071616},
title = {{The neural bases for empathy.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21071616},
volume = {17},
year = {2011}
}
@inproceedings{Gilroy2011,
address = {New York, New York, USA},
author = {Gilroy, Stephen W. and Cavazza, Marc O. and Vervondel, Valentin},
booktitle = {Proceedings of the 16th international conference on Intelligent user interfaces - IUI '11},
doi = {10.1145/1943403.1943413},
file = {::},
isbn = {9781450304191},
pages = {53--62},
publisher = {ACM Press},
title = {{Evaluating multimodal affective fusion using physiological signals}},
url = {http://portal.acm.org/citation.cfm?doid=1943403.1943413},
year = {2011}
}
@article{Schneier2011,
author = {Schneier, B.},
file = {::},
journal = {Security \& Privacy, IEEE},
number = {5},
pages = {88--88},
publisher = {IEEE},
title = {{Empathy and Security}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6029366},
volume = {9},
year = {2011}
}
@inproceedings{Cramer2010,
abstract = {Empathy has great potential in human-robot interaction. However, the challenging nature of assessing the user's emotional state points to the importance of also understanding the effects of empathic behaviours incongruent with users' affective experience. A 3x2 between-subject video-based survey experiment (N=133) was conducted with empathic robot behaviour (empathically accurate, neutral, inaccurate) and valence of the situation (positive, negative) as dimensions. Trust decreased when empathic responses were incongruent with the affective state of the user. However, in the negative valence condition, reported perceived empathic abilities were greater when the robot responded as if the situation were positive.},
author = {Cramer, Henriette and Goddijn, Jorrit and Wielinga, Bob and Evers, Vanessa},
booktitle = {HRI '10 Proceedings of the 5th ACM/IEEE international conference on Human-robot interaction},
doi = {10.1145/1734454.1734513},
file = {::},
isbn = {9781424448937},
pages = {141--142},
publisher = {ACM},
title = {{Effects of (in) accurate empathy and situational valence on attitudes towards robots}},
url = {http://dl.acm.org/citation.cfm?id=1734513},
year = {2010}
}
@article{Ambady1992,
abstract = {A meta-analysis was conducted on the accuracy of predictions of various objective outcomes in the areas of social and clinical psychology from short observations of expressive behavior (under 5 min). The overall effect size (ry for the accuracy of predictions for 38 different resu1ts was .39. Studies using longer periods of behavioral observation did not yield greater predictive accuracy; predictions based on observations under 112 min in length did not differ significantly from predictions based on 4- and 5-min observations. The type ofbehavioral channel (such as the face, speech, the body, tone ofvoic on which the ratings were based was not related to the accuracy of predictions. Accuracy did not vary significantly between behaviors rnanipulated in a laboratory and more naturally occurring behavior. L t effect sizes did not differ significantly for predictions in the areas of clinical psychology social psychology, and the accuracy of detecting deception.},
author = {Ambady, N and Rosenthal, Robert},
doi = {10.1037/0033-2909.111.2.256},
file = {::},
issn = {00332909},
journal = {Psychological Bulletin},
number = {2},
pages = {256--274},
publisher = {American Psychological Association},
title = {{Thin slices of expressive behavior as predictors of interpersonal consequences: A meta-analysis.}},
volume = {111},
year = {1992}
}
@inproceedings{Boukricha2009a,
abstract = {a system for simulating emotional facial expressions for a virtual human has been evolved. This system consists of two parts: (1) a control ar- chitecture for simulating emotional facial expressions with respect to Pleasure, Arousal, and Dominance (PAD) val- ues, (2) an expressive output component for animating the virtual human’s facial muscle actions called Action Units (AUs), modeled following the Facial Action Coding Sys- tem (FACS). A large face repertoire of about 6000 faces arranged in PAD-space with respect to two dominance val- ues (dominant vs. submissive) is obtained as a result of the empirical study. Using the face repertoire an approach to- wards realizing facial mimicry for a virtual human based on backward mapping AUs displaying an emotional facial expression on PAD-values is outlined.},
annote = {- For automatic recognition, the mapping of AUs to PAD may be only useful once you can identify the active AUs and their intensity on the face (which you won't be able with image processing teckniques).
- For the expression, if you have an avatar which has control on the AUs, you don’t need to map the AUs to PAD. But, if you have an avatar which expresses based on PAD, then this mapping is useful. 
- Mapping of AUs to PAD is helpful when you want to fuse multiple modalities where other modalities are in PAD values. },
author = {Boukricha, Hana and Wachsmuth, Ipke and Hofstatter, A. and Grammer, Karl},
booktitle = {Affective Computing and Intelligent Interaction and Workshops, 2009. ACII 2009. 3rd International Conference on},
file = {::},
isbn = {9781424447992},
pages = {1--7},
publisher = {IEEE},
title = {{Pleasure-arousal-dominance driven facial expression simulation}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5349579},
year = {2009}
}
@inproceedings{Campbell2005,
abstract = {Building relationships is a central concern for professionals (e.g., physicians, engineers, sales representatives, managers, etc.) because relationships promote a client's trust and loyalty. Rapport is a concept used to describe relationship quality and has two facets: enjoyable interactions and personal connection. Prior research has described the communication strategies of leaders for building better relationships with their subordinates and sales representatives with their customers by borrowing concepts from rapport management in sociolinguistics. The goal of this paper is to extend that work by demonstrating how rapport management applies to interaction between physicians and patients. The rapport management model helps us explain how professionals succeed or fail to build relationships with clients based on their verbal communication behavior.},
address = {Limerick, Ireland},
author = {Campbell, K.S.},
booktitle = {Proceedings in International Professional Communication Conference IPCC2005},
doi = {10.1109/IPCC.2005.1494206},
file = {::},
isbn = {0-7803-9027-X},
keywords = {communication,face-to-face interaction,health,medical interviews,sociolinguistics,verbal communication},
pages = {422--432},
publisher = {IEEE},
title = {{The rapport management model: how physicians build relationships with patients}},
url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=1494206},
year = {2005}
}
@article{Hartholt2008,
author = {Hartholt, Arno and Russ, Thomas and Traum, David},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hartholt, Russ, Traum - 2008 - A common ground for virtual humans Using an ontology in a natural language oriented virtual human architecture.pdf:pdf},
journal = {Language},
title = {{A common ground for virtual humans: Using an ontology in a natural language oriented virtual human architecture}},
url = {http://pages.cs.brandeis.edu/~marc/misc/proceedings/lrec-2008/pdf/811\_paper.pdf},
year = {2008}
}
@article{DeRosis2003,
abstract = {This paper describes the results of a research project aimed at implementing a 'realistic' 3D Embodied Agent that can be animated in real-time and is 'believable and expressive': that is, able to coherently communicate complex information through the combination and the tight synchronisation of verbal and nonverbal signals. We describe, in particular, how we 'animate' this Agent (that we called Greta) so as to enable her to manifest the affective states that are dynamically activated and de-activated in her mind during the dialog with the user. The system is made up of three tightly interrelated components: A representation of the Agent Mind: this includes long and short-term affective components (personality and emotions) and simulates how emotions are triggered and decay over time according to the Agent's personality and to the context, and how several emotions may overlap. Dynamic belief networks with weighting of goals is the formalism we employ to this purpose. A mark-up language to denote the communicative meanings that may be associated with dialog moves performed by the Agent. A translation of the Agent's tagged move into a face expression, that combines appropriately the available channels (gaze direction, eyebrow shape, head direction and movement etc). The final output is a 3-D facial model that respects the MPEG-4 standard and uses MPEG-4 Facial Animation Parameters to produce facial expressions. Throughout the paper, we illustrate the results obtained, with an example of dialog in the domain of 'Advice about eating disorders'. The paper concludes with an analysis of advantages of our cognitive model of emotion triggering and of the problems found in testing it. Although we did not yet complete a formal evaluation of our system, we briefly describe how we plan to assess the agent's believability in terms of consistency of its communicative behaviour. (C) 2003 Elsevier Science Ltd. All rights reserved.},
author = {{De Rosis}, F and Pelachaud, Catherine and Poggi, I and Carofiglio, V and {De Carolis}, B},
doi = {10.1016/S1071-5819(03)00020-X},
issn = {10715819},
journal = {International Journal of Human-Computer Studies},
number = {1-2},
pages = {81--118},
title = {{From Greta's mind to her face: modelling the dynamics of affective states in a conversational embodied agent}},
volume = {59},
year = {2003}
}
@article{Dias2005,
author = {Dias, J. and Paiva, Ana},
file = {::},
journal = {Progress in artificial intelligence},
pages = {127--140},
publisher = {Springer},
title = {{Feeling and reasoning: A computational model for emotional characters}},
url = {http://www.springerlink.com/index/YQ18H62602413554.pdf},
year = {2005}
}
@article{Devoldre2010,
abstract = {Social support researchers and clinicians have repeatedly expressed the need to identify the antecedents of social support provision within close relationships. The aim of the present study is to investigate the extent to which individual differences in cognitive empathy (perspective taking) and affective empathy (empathic concern and personal distress) are predictive of social support provision in couples. Study 1 involved 83 female participants in a relatively young relationship; Study 2 involved 128 married couples. The authors used self-report measures in both studies to assess individual differences in empathy and participants' support provision behaviors. The main findings suggest a significant contribution of the different components of empathy with rather different pictures for each of these components. The authors discuss the present findings in light of existing theory and research on social support in relationships.},
author = {Devoldre, Inge and Davis, Mark H and Verhofstadt, Lesley L and Buysse, Ann},
doi = {10.1080/00223981003648294},
file = {::},
issn = {0022-3980},
journal = {The Journal of psychology},
keywords = {80 and over,Adolescent,Adult,Affect,Aged,Empathy,Family Characteristics,Female,Humans,Individuality,Male,Middle Aged,Personal Construct Theory,Personality Inventory,Personality Inventory: statistics \& numerical data,Psychometrics,Social Support,Young Adult},
number = {3},
pages = {259--284},
pmid = {20461931},
title = {{Empathy and social support provision in couples: social support and the need to study the underlying processes.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21506454},
volume = {144},
year = {2010}
}
@article{Foster2008,
abstract = {Humans are known to use a wide range of non-verbal behaviour while speaking. Generating naturalistic embodied speech for an artificial agent is therefore an application where techniques that draw directly on recorded human motions can be helpful. We present a system that uses corpus-based selection strategies to specify the head and eyebrow motion of an animated talking head. We first describe how a domain-specific corpus of facial displays was recorded and annotated, and outline the regularities that were found in the data. We then present two different methods of selecting motions for the talking head based on the corpus data: one that chooses the majority option in all cases, and one that makes a weighted choice among all of the options. We compare these methods to each other in two ways: through cross-validation against the corpus, and by asking human judges to rate the output. The results of the two evaluation studies differ: the cross-validation study favoured the majority strategy, while the human judges preferred schedules gene- rated using weighted choice. The judges in the second study also showed a preference for the original corpus data over the output of either of the generation strategies.},
author = {Foster, Mary Ellen and Oberlander, Jon},
doi = {10.1007/s10579-007-9055-3},
file = {::},
issn = {1574-020X},
journal = {Language Resources and Evaluation},
keywords = {Data-driven generation,Embodied conversational agents,Evaluation of generated output,Multimodal corpora},
month = feb,
number = {3-4},
pages = {305--323},
title = {{Corpus-based generation of head and eyebrow motion for an embodied conversational agent}},
url = {http://www.springerlink.com/index/10.1007/s10579-007-9055-3},
volume = {41},
year = {2008}
}
@article{Bickmore2005,
author = {Bickmore, TW},
journal = {ACM Transactions on Computer-Human},
pages = {617--638},
title = {{Establishing and maintaining long-term human-computer relationships}},
url = {http://dl.acm.org/citation.cfm?id=1067860.1067867},
year = {2005}
}
@inproceedings{Higashinaka2008,
author = {Higashinaka, R. and Dohsaka, K. and Isozaki, H.},
booktitle = {Spoken Language Technology Workshop, 2008. SLT 2008. IEEE},
file = {::},
isbn = {9781424434725},
pages = {109--112},
publisher = {IEEE},
title = {{Effects of self-disclosure and empathy in human-computer dialogue}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4777852},
year = {2008}
}
@article{Roberts1996,
author = {Roberts, William and Strayer, Janet},
doi = {10.2307/1131826},
file = {::},
issn = {00093920},
journal = {Child Development},
month = apr,
number = {2},
pages = {449},
title = {{Empathy, Emotional Expressiveness, and Prosocial Behavior}},
url = {http://www.jstor.org/stable/1131826?origin=crossref},
volume = {67},
year = {1996}
}
@article{Segal2011,
author = {Segal, Elizabeth},
doi = {10.1080/01488376.2011.564040},
file = {::},
issn = {0148-8376},
journal = {Journal of Social Service Research},
keywords = {a dedication to justice,a nation that proclaims,and social well-being and,civic involvement,empathy,scapegoating,social empathy,social responsibility,the united states is},
month = may,
number = {3},
pages = {266--277},
title = {{Social Empathy: A Model Built on Empathy, Contextual Understanding, and Social Responsibility That Promotes Social Justice}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/01488376.2011.564040\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {37},
year = {2011}
}
@inproceedings{Strapparava2004,
abstract = {In this paper we present a linguistic resource for the lexical representation of affective knowledge. This resource (named WORDNETAFFECT) was developed starting from WORDNET, through a selection and tagging of a subset of synsets representing the affective meanings.},
author = {Strapparava, Carlo and Valitutti, Alessandro},
booktitle = {Proceedings of LREC},
number = {March},
organization = {ELRA},
pages = {1083--1086},
publisher = {Citeseer},
title = {{WordNet-Affect: an affective extension of WordNet}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.122.4281\&amp;rep=rep1\&amp;type=pdf},
volume = {4},
year = {2004}
}
@misc{TheMendeleySupportTeam2011,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/The Mendeley Support Team - 2011 - Getting Started with Mendeley(4).pdf:pdf},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@inproceedings{Liu2010a,
abstract = {Emotions accompany everyone in the daily life, playing a key role in non-verbal communication, and they are essential to the understanding of human behavior. Emotion recognition could be done from the text, speech, facial expression or gesture. In this paper, we concentrate on recognition of “inner” emotions from electroencephalogram (EEG) signals as humans could control their facial expressions or vocal intonation. The need and importance of the automatic emotion recognition from EEG signals has grown with increasing role of brain computer interface applications and development of new forms of human-centric and human-driven interaction with digital media. We propose fractal dimension based algorithm of quantification of basic emotions and describe its implementation as a feedback in 3D virtual environments. The user emotions are recognized and visualized in real time on his/her avatar adding one more so-called “emotion dimension” to human computer interfaces.},
address = {Singapore},
author = {Liu, Yisi and Sourina, Olga and Nguyen, Minh Khoa},
booktitle = {International Conference on Cyberworlds (CW)},
doi = {10.1109/CW.2010.37},
file = {::},
isbn = {978-1-4244-8301-3},
keywords = {- emotion recognition,bci,eeg,emotion visualization,fractal dimension,hci},
month = oct,
pages = {262--269},
publisher = {IEEE Computer Society},
title = {{Real-Time EEG-Based Human Emotion Recognition and Visualization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5656346},
year = {2010}
}
@inproceedings{Polajnar2011,
author = {Polajnar, Jernej and Dalvandi, B. and Polajnar, D.},
booktitle = {Cognitive Informatics \& Cognitive Computing (ICCI'CC'11), 2011 10th IEEE International Conference on},
file = {::},
isbn = {9781457716973},
pages = {96--102},
publisher = {IEEE},
title = {{Does empathy between artificial agents improve agent teamwork?}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6016126},
year = {2011}
}
@article{Cassell1999,
abstract = {In this article we describe results froman experiment of user interaction with autonomous , human - like ( humanoid ) conversational agents . We hypothesize that for embodied conversational agents , nonverbal behaviors related to the process of conversation , what we call envelope feedback, is much more important than other feedback , such as emotional expression . We test this hypothesis by having subjects interact with three autonomous agents , all capable of full - duplex multimodal interaction: able to generate and recognize speech , intonation , facial displays , and gesture . Each agent , however , gave a different kind of feedback: ( 1 ) content - related only , ( 2 ) content + envelope feedback , and ( 3 ) content + emotional . Content-related feedback includes answering questions and executing commands; envelope feedback includes behaviors such as gaze , manual beat gesture , and head movements; emotional feedback includes smiles and looks of puzzlement . Subjects' evaluations of the systemwere collected with a questionnaire , and videotapes of their speech patterns and behaviors were scored according to how often the users repeated themselves , how often they hesitated , and how often they got frustrated . The results confirmour hypothesis that envelope feedback is more important in interaction than emotional feedback and that envelope feedback plays a crucial role in supporting the process of dialog . A secondary result fromthis study shows that users give our multimodal conversational humanoids very high ratings of lifelikeness and fluidity of interaction when the agents are capable of giving such feedback .},
author = {Cassell, Justine and Thorisson, K.R.},
doi = {10.1080/088395199117360},
file = {::},
journal = {Applied Artificial Intelligence},
number = {4-5},
pages = {519--538},
publisher = {Taylor \& Francis},
title = {{The power of a nod and a glance: Envelope vs. emotional feedback in animated conversational agents}},
url = {http://www.tandfonline.com/doi/abs/10.1080/088395199117360},
volume = {13},
year = {1999}
}
@article{Devoldre2010,
abstract = {Social support researchers and clinicians have repeatedly expressed the need to identify the antecedents of social support provision within close relationships. The aim of the present study is to investigate the extent to which individual differences in cognitive empathy (perspective taking) and affective empathy (empathic concern and personal distress) are predictive of social support provision in couples. Study 1 involved 83 female participants in a relatively young relationship; Study 2 involved 128 married couples. The authors used self-report measures in both studies to assess individual differences in empathy and participants' support provision behaviors. The main findings suggest a significant contribution of the different components of empathy with rather different pictures for each of these components. The authors discuss the present findings in light of existing theory and research on social support in relationships.},
author = {Devoldre, Inge and Davis, Mark H and Verhofstadt, Lesley L and Buysse, Ann},
doi = {10.1080/00223981003648294},
file = {::},
issn = {0022-3980},
journal = {The Journal of psychology},
keywords = {80 and over,Adolescent,Adult,Affect,Aged,Empathy,Family Characteristics,Female,Humans,Individuality,Male,Middle Aged,Personal Construct Theory,Personality Inventory,Personality Inventory: statistics \& numerical data,Psychometrics,Social Support,Young Adult},
number = {3},
pages = {259--284},
pmid = {20461931},
title = {{Empathy and social support provision in couples: social support and the need to study the underlying processes.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21506454},
volume = {144},
year = {2010}
}
@inproceedings{Liu2010a,
abstract = {Emotions accompany everyone in the daily life, playing a key role in non-verbal communication, and they are essential to the understanding of human behavior. Emotion recognition could be done from the text, speech, facial expression or gesture. In this paper, we concentrate on recognition of “inner” emotions from electroencephalogram (EEG) signals as humans could control their facial expressions or vocal intonation. The need and importance of the automatic emotion recognition from EEG signals has grown with increasing role of brain computer interface applications and development of new forms of human-centric and human-driven interaction with digital media. We propose fractal dimension based algorithm of quantification of basic emotions and describe its implementation as a feedback in 3D virtual environments. The user emotions are recognized and visualized in real time on his/her avatar adding one more so-called “emotion dimension” to human computer interfaces.},
address = {Singapore},
author = {Liu, Yisi and Sourina, Olga and Nguyen, Minh Khoa},
booktitle = {International Conference on Cyberworlds (CW)},
doi = {10.1109/CW.2010.37},
file = {::},
isbn = {978-1-4244-8301-3},
keywords = {- emotion recognition,bci,eeg,emotion visualization,fractal dimension,hci},
month = oct,
pages = {262--269},
publisher = {IEEE Computer Society},
title = {{Real-Time EEG-Based Human Emotion Recognition and Visualization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5656346},
year = {2010}
}
@article{Peter2003,
author = {Sonnby-borgstr\"{o}m, Marianne and Jonsson, Peter and Svensson, Owe},
file = {::},
journal = {Journal of Nonverbal},
keywords = {emg,emotional contagion,empathy,facial expressions,facial mim-,icry,mirror neurons},
number = {1},
pages = {3--23},
title = {{Emotional empathy as related to mimicry reactions at different levels of information processing}},
url = {http://www.springerlink.com/index/P81X69QTH751V836.pdf},
volume = {27},
year = {2003}
}
@article{Becker-Asano2009,
abstract = {We introduce theWASABI ([W]ASABI [A]ffect [S]imulation for [A]gents with [B]elievable [I]nteractivity)Affect SimulationArchitecture, in which a virtual human’s cog- nitive reasoning capabilities are combined with simulated embodiment to achieve the sim- ulation of primary and secondary emotions. In modeling primary emotions we follow the idea of “Core Affect” in combination with a continuous progression of bodily feeling in three-dimensional emotion space (PADspace), that is subsequently categorized into discrete emotions. In humans, primary emotions are understood as onto-genetically earlier emotions, which directly influence facial expressions. Secondary emotions, in contrast, afford the abil- ity to reason about current events in the light of experiences and expectations.},
author = {Becker-Asano, Christian and Wachsmuth, Ipke},
doi = {10.1007/s10458-009-9094-9},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Becker-Asano, Wachsmuth - 2009 - Affective computing with primary and secondary emotions in a virtual human(3).pdf:pdf},
issn = {1387-2532},
journal = {Autonomous Agents and Multi-Agent Systems},
keywords = {affect simulation,affective computing,affective gaming,architecture,aware emotions,bdi-based architecture,embodied agent,emotion dynamics,emotion expression,emotion modeling,pad emotion space,primary and secondary emotions,reality,virtual,virtual human},
month = may,
number = {1},
pages = {32--49},
title = {{Affective computing with primary and secondary emotions in a virtual human}},
url = {http://www.becker-asano.de/AffectiveComputingWithPrimaryAndSecondaryEmotionsInAVirtualHuman.pdf},
volume = {20},
year = {2009}
}
@article{Lakin2003,
abstract = {The “chameleon effect” refers to the tendency to adopt the postures, gestures, and mannerisms of interaction partners (Chartrand \& Bargh, 1999). This type of mimicry occurs outside of conscious awareness, and without any intent to mimic or imitate. Empirical evidence suggests a bi-directional relationship between nonconscious mimicry on the one hand, and liking, rapport, and affiliation on the other. That is, nonconscious mimicry creates affiliation, and affiliation can be expressed through nonconscious mimicry. We argue that mimicry played an important role in human evolution. Initially, mimicry may have had survival value by helping humans communicate. We propose that the purpose of mimicry has now evolved to serve a social function. Nonconscious behavioral mimicry increases affiliation, which serves to foster relationships with others.},
annote = {nonconscious mimicry creates affiliation, and affiliation can be expressed through nonconscious mimicry.
Initially, mimicry may have had survival value by helping humans communicate. The purpose of mimicry has now evolved to serve a social function. Nonconscious behavioral mimicry increases affiliation, which serves to foster relationships with others.
Empathic individuals mimic people more that people low in empathy.},
author = {Lakin, J. L. and Jefferis, VE and Cheng, CM},
file = {::},
journal = {Journal of nonverbal},
keywords = {1994,1999,2000,2001a,affiliation,and sometimes from,animals,aronson,caporael,chameleon effect,dusk to dawn,ehrlich,from dawn to dusk,human beings are social,human evolution,mimicry,our lives are filled,we talk to signif-,with social interactions,wright},
number = {3},
pages = {145--162},
title = {{The chameleon effect as social glue: Evidence for the evolutionary significance of nonconscious mimicry}},
volume = {27},
year = {2003}
}
@article{Hingson2005,
author = {Hingson, Ralph and Heeren, Timothy and Winter, Michael and Wechsler, Henry},
journal = {Journal of Studies on Alcohol and Drugs},
pages = {12--20},
title = {{MAGNITUDE OF ALCOHOL-RELATED MORTALITY AND MORBIDITY AMONG U.S. COLLEGE STUDENTS AGES 18–24: Changes from 1999 to 2005}},
url = {http://www.jsad.com/},
volume = {16},
year = {2009}
}
@article{Ververidis2006,
author = {Ververidis, Dimitrios},
file = {::},
journal = {Speech communication},
keywords = {acoustic features,emotional speech classification,emotional speech data collections,emotions,interfaces,stress},
number = {April},
title = {{Emotional speech recognition: Resources, features, and methods}},
url = {http://www.sciencedirect.com/science/article/pii/S0167639306000422},
year = {2006}
}
@article{Chartrand1999,
abstract = {The chameleon effect refers to nonconscious mimicry of the postures, mannerisms, facial expressions, and other behaviors of one's interaction partners, such that one's behavior passively and unintentionally changes to match that of others in one's current social environment. The authors suggest that the mechanism involved is the perception-behavior link, the recently documented finding (e.g., J. A. Bargh, M. Chen, \& L. Burrows, 1996) that the mere perception of another's behavior automatically increases the likelihood of engaging in that behavior oneself. Experiment 1 showed that the motor behavior of participants unintentionally matched that of strangers with whom they worked on a task. Experiment 2 had confederates mimic the posture and movements of participants and showed that mimicry facilitates the smoothness of interactions and increases liking between interaction partners. Experiment 3 showed that dispositionally empathic individuals exhibit the chameleon effect to a greater extent than do other people.},
author = {Chartrand, T. L. and Bargh, J A},
file = {::},
issn = {0022-3514},
journal = {Journal of personality and social psychology},
keywords = {Analysis of Variance,Empathy,Facial Expression,Female,Group Processes,Humans,Imitative Behavior,Interpersonal Relations,Male,Models,Multivariate Analysis,New York City,Posture,Psychological,Social Behavior,Social Perception},
month = jun,
number = {6},
pages = {893--910},
pmid = {10402679},
title = {{The chameleon effect: the perception-behavior link and social interaction.}},
volume = {76},
year = {1999}
}
@book{Hojat2007,
author = {Hojat, Mohammadreza},
booktitle = {Patient Care},
file = {::},
isbn = {9780387336077},
publisher = {New York, NY: Springer},
title = {{Empathy in patient care: antecedents, development, measurement, and outcomes}},
year = {2007}
}
@book{Dimeff1999,
abstract = {(from the cover) This manual presents a pragmatic and clinically proven approach to the prevention and treatment of undergraduate alcohol abuse. The Brief Alcohol Screening and Intervention for College Students (BASICS) model is a nonconfrontational, harm reduction approach that helps students reduce their alcohol consumption and decrease the behavioral and health risks associated with heavy drinking. Including reproducible handouts and assessment forms, the book takes readers step-by-step through conducting BASICS assessment and feedback sessions. Special topics covered include the use of Diagnostic and Statistical Manual of Mental Disorders-IV (DSM-IV) criteria to evaluate alcohol abuse, ways to counter defensiveness about drinking and how to help students who continue to drink in a hazardous fashion. (PsycINFO Database Record (c) 2010 APA, all rights reserved) (cover)},
author = {Dimeff, Linda A and Baer, John S and Kivlahan, Daniel R and Marlatt, G Alan},
booktitle = {The Journal of Psychiatry Law},
isbn = {1572303921},
pages = {1929--1945},
publisher = {Guilford Press},
title = {{Brief alcohol screening and intervention for college students (BASICS): A harm reduction approach}},
url = {http://search.ebscohost.com/login.aspx?direct=true\&db=psyh\&AN=1999-02125-000\&lang=fr\&site=ehost-live},
volume = {30},
year = {1999}
}
@inproceedings{Polajnar2011,
author = {Polajnar, Jernej and Dalvandi, B. and Polajnar, D.},
booktitle = {Cognitive Informatics \& Cognitive Computing (ICCI• CC), 2011 10th IEEE International Conference on},
file = {::},
isbn = {9781457716973},
pages = {96--102},
publisher = {IEEE},
title = {{Does empathy between artificial agents improve agent teamwork?}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6016126},
year = {2011}
}
@article{Bailenson2005,
abstract = {Previous research demonstrated social influence resulting from mimicry (the chameleon effect); a confederate who mimicked participants was more highly regarded than a confederate who did not, despite the fact that participants did not explicitly notice the mimicry. In the current study, participants interacted with an embodied artificial intelligence agent in immersive virtual reality. The agent either mimicked a participant's head movements at a 4-s delay or utilized prerecorded movements of another participant as it verbally presented an argument. Mimicking agents were more persuasive and received more positive trait ratings than nonmimickers, despite participants' inability to explicitly detect the mimicry. These data are uniquely powerful because they demonstrate the ability to use automatic, indiscriminate mimicking (i.e., a computer algorithm blindly applied to all movements) to gain social influence. Furthermore, this is the first study to demonstrate social influence effects with a nonhuman, nonverbal mimicker.},
author = {Bailenson, Jeremy N and Yee, Nick},
file = {::},
journal = {Psychological Science},
number = {10},
pages = {814--819},
title = {{Digital Chameleons: Automatic Assimilation of Nonverbal Gestures in Immersive Virtual Environments}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16181445},
volume = {16},
year = {2005}
}
@article{D&39;Mello2006,
author = {Mello, Sidney D' and Graesser, Art},
file = {::},
journal = {Intelligent Virtual Agents},
pages = {54--67},
title = {{Affect detection from human-computer dialogue with an intelligent tutoring system}},
url = {http://www.springerlink.com/index/b574kpu6nl719408.pdf},
year = {2006}
}
@article{Carey,
abstract = {In this study, the authors evaluated the efficacy of a brief motivational intervention (BMI) and a computerized program for reducing drinking and related problems among college students sanctioned for alcohol violations. Referred students (N = 198, 46\% women), stratified by gender, were randomly assigned to a BMI or to the Alcohol 101 Plus computer program. Data obtained at baseline, 1, 6, and 12 months were used to evaluate intervention efficacy. Planned analyses revealed 3 primary findings. First, women who received the BMI reduced drinking more than did women who received the computer intervention; in contrast, men's drinking reductions did not differ by condition. Second, readiness to change and hazardous drinking status predicted drinking reductions at 1 month postintervention, regardless of intervention. Third, by 1 year, drinking returned to presanction (baseline) levels, with no differences in recidivism between groups. Exploratory analyses revealed an overall mean reduction in drinking immediately after the sanction event and before taking part in an intervention. Furthermore, after the self-initiated reductions prompted by the sanction were accounted for, participation in the BMI but not the computer intervention was found to produce additional reduction in drinking and related consequences. },
author = {Carey, Kate B. and Henson, James M. and Carey, Michael P. and Maisto, Stephen A.},
title = {{Computer versus in-person intervention for students violating campus alcohol policy.}},
url = {http://psycnet.apa.org/journals/ccp/77/1/74}
}
@article{Hunsdahl1967,
author = {Hunsdahl, JB},
doi = {10.1016/0022-1910(58)90015-5},
issn = {00221910},
journal = {Journal of the History of the Behavioral},
number = {4},
pages = {298--312},
title = {{Concerning Einf\"{u}hlung (empathy): A concept analysis of its origin and early development}},
volume = {2},
year = {1967}
}
@inproceedings{Hegel2006,
author = {Hegel, Frank and Spexard, Torsten and Wrede, Britta and Horstmann, G. and Vogt, T.},
booktitle = {Humanoid Robots, 2006 6th IEEE-RAS International Conference on},
file = {::},
isbn = {142440200X},
pages = {56--61},
publisher = {IEEE},
title = {{Playing a different imitation game: Interaction with an Empathic Android Robot}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4115580},
year = {2006}
}
@article{Hess1960,
abstract = {Increases in the size of the pupil of the eye have been found to accompany the viewing of emotionally toned or interesting visual stimuli. A technique for recording such changes has been developed, and preliminary results with cats and human beings are reported with attention being given to differences between the sexes in response to particular types of material.},
author = {Hess, E H and Polt, J M},
journal = {Science},
keywords = {pupil,sex characteristics,sympathetic nervous system},
number = {3423},
pages = {349--350},
pmid = {14401489},
title = {{Pupil size as related to interest value of visual stimuli.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/14401489},
volume = {132},
year = {1960}
}
@inproceedings{Amini2012,
abstract = {In this article, we present HapFACS 1.0, a new software/API for generating static and dynamic three-dimensional facial expressions based on the Facial Action Coding System (FACS). HapFACS pro- vides total control over the FACS Action Units (AUs) activated at all levels of intensity. HapFACS allows generating faces with an individual AU or composition of AUs activated unilaterally or bilat- erally with different intensities. The reliable and emotionally valid facial expressions can be generated on inﬁnite number of faces in different ethnicities, genders, and ages using HapFACS to be used in numerous scientiﬁc areas including psychology, emotion, FACS learning, clinical, and neuroscience research.},
address = {Vienna, AUSTRIA},
author = {Amini, Reza and Yasavur, U and Lisetti, Christine L},
booktitle = {Proceedings of the ACM 3rd International Symposium on Facial Analysis and Animation (FAA'12)},
file = {::},
publisher = {ACM Press},
title = {{HapFACS 1.0: Software/API for Generating FACS-Based Facial Expressions}},
url = {http://ascl.cis.fiu.edu/uploads/1/3/4/2/13423859/amini-faa-2012.pdf},
year = {2012}
}
@article{Ochs2010,
author = {Ochs, Magalie and Sadek, David and Pelachaud, Catherine},
doi = {10.1007/s10458-010-9156-z},
file = {::},
issn = {1387-2532},
journal = {Autonomous Agents and Multi-Agent Systems},
keywords = {affective computing,dialog,emotions,empathy,rational dialog agent},
month = nov,
title = {{A formal model of emotions for an empathic rational dialog agent}},
url = {http://www.springerlink.com/index/10.1007/s10458-010-9156-z},
year = {2010}
}
@article{Page2002,
abstract = {In the Ultimatum Game, two players are asked to split a prize. The first player, the proposer, makes an offer of how to split the prize. The second player, the responder, either accepts the offer, in which case the prize is split as agreed, or rejects it, in which case neither player receives anything. The rational strategy suggested by classical game theory is for the proposer to offer the smallest possible positive share and for the responder to accept. Humans do not play this way, however, and instead tend to offer 50\% of the prize and to reject offers below 20\%. Here we study the Ultimatum Game in an evolutionary context and show that empathy can lead to the evolution of fairness. Empathy means that individuals make offers which they themselves would be prepared to accept.},
author = {Page, Karen M and Nowak, Martin a},
doi = {10.1006/bulm.2002.0321},
file = {::},
issn = {0092-8240},
journal = {Bulletin of mathematical biology},
keywords = {Biological Evolution,Choice Behavior,Empathy,Games, Experimental,Humans,Models, Psychological,Social Behavior},
month = nov,
number = {6},
pages = {1101--16},
pmid = {12508533},
title = {{Empathy leads to fairness.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12508533},
volume = {64},
year = {2002}
}
@article{Robison2010,
abstract = {affective interventions can both positively and negatively influence learning experiences. In this paper we investigate the role of student personality, including goal orienta- tion and empathetic tendencies, in estimating confidence in the benefits of an affective intervention strategy. The results indicate that student personality profiles can serve as a powerful tool for informing affective feedback models.},
annote = {We can use the same way of menu base self-report affective state recognition (in addition to automatic) and text-base empathic feedback. Then after each feedback we can evaluate the feedback with another user self-report.},
author = {Robison, Jennifer and Mcquiggan, Scott and Lester, James and Carolina, North},
file = {::},
keywords = {affect,affective computing,pedagogical agents},
pages = {285--295},
title = {{Developing Empirically Based Student Personality Profiles for Affective Feedback Models}},
year = {2010}
}
@inproceedings{Courgeon2008,
address = {Estoril, Portugal},
annote = {The user reports his/her affective state in real-time with changing the position of a 3D point in PAD space using a joystick. The system captures the position of that point and maps it to a blend of 8 selected emotions. },
author = {Courgeon, Matthieu and Martin, Jean-claude and Jacquemin, Christian},
booktitle = {Proc. of 7th Int. Conf. on Autonomous Agents and Multiagent Systems (AAMAS 2008)},
file = {::},
number = {Aamas},
pages = {1237--1240},
title = {{User ’ s Gestural Exploration of Different Virtual Agents ’ Expressive Profiles ( Short Paper )}},
year = {2008}
}
@inproceedings{Johnson2007,
abstract = {Any new tool validated. introduced for education needs to be We developed a virtual human experience called the Virtual Objective Structured Clinical Examination (VOSCE). In the VOSCE, a medical student examines a life-size virtual human who is presenting symptoms of an illness. The student is then graded on interview skills. As part of a medical school class requirement, thirty three second year medical students participated in a user study designed to determine the validity of the VOSCE for testing interview skills. In the study, participant performance in the VOSCE is compared to participant performance in the OSCE, an interview with a trained actor. There was a significant correlation (r(33)=.49, p<.005) between overall score in the VOSCE and overall score in the OSCE. This means that the interaction skills used with a virtual human translate to the interaction skills used with a real human. Comparing the experience of virtual human interaction to real human interaction is the critical validation step towards using virtual humans for interpersonal skills education.},
address = {San Jose, California, USA},
author = {Johnsen, Kyle and Raij, Andrew and Stevens, Amy and Lind, D Scott and Lok, Benjamin and Ph, D},
booktitle = {CHI 2007 Proceedings of Learning \& Education},
file = {::},
isbn = {9781595935939},
keywords = {medicine,multimodal interfaces.,validation,virtual characters,virtual humans,virtual reality},
pages = {1049--1058},
publisher = {ACM},
title = {{The Validity of a Virtual Human Experience for Interpersonal Skills Education}},
year = {2007}
}
@article{Fellner2012,
abstract = {Individuals may differ in their ability to learn the significance of emotional cues within a specific context. If so, trait emotional intelligence (EI) may be associated with faster cue learning. This study (N = 180) tested whether trait EI predicts faster learning of a critical cue for discriminating ‘‘terrorists’’ from ‘‘non-terrorists’’, using virtual-reality heads as stimuli. The critical cue was either facial emotion (positive or negative), or a neutral feature (hat size). Cognitive ability and subjective state were also assessed. Par- ticipants were faster to learn with an emotive cue. Surprisingly, high trait EI was correlated with poorer performance, especially early in learning. Subjective distress was also associated with impaired learning to emotive cues. },
author = {Fellner, Angela N. and Matthews, Gerald and Shockley, Kevin D. and Warm, Joel S. and Zeidner, Moshe and Karlov, Lisa and Roberts, Richard D.},
doi = {10.1016/j.jrp.2012.01.004},
file = {::},
issn = {00926566},
journal = {Journal of Research in Personality},
keywords = {trait emotional intelligence},
month = jun,
number = {3},
pages = {239--247},
publisher = {Elsevier Inc.},
title = {{Using emotional cues in a discrimination learning task: Effects of trait emotional intelligence and affective state}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0092656612000050},
volume = {46},
year = {2012}
}
@article{Riek2008,
abstract = {Expressing empathy is a key component of human social communication. One common way people convey empathy is via facial expression mirroring. It may be helpful for machines intended to interact with people to also convey empathy in this manner. We have thus created Virgil, an expression-mimicking robot. We hypothesize that if people feel like a machine is empathizing with them they will be more likely to rate the interaction positively. We conducted a pilot study to test our hypothesis, and through quantitative and qualitative analysis of our results found some support for it.},
author = {Riek, Laurel D. and Robinson, Peter},
file = {::},
journal = {ACM Workshop on Affective Interaction in Natural Environments AFFINE at the International ACM Conference on Multimodal Interfaces ICMI 08},
pages = {1--5},
publisher = {ACM},
title = {{Real-time empathy: Facial mimicry on a robot}},
year = {2008}
}
@article{Clark1998,
abstract = {Speakers often repeat the first word of major constituents, as in, "I uh I wouldn't be surprised at that." Repeats like this divide into four stages: an initial commitment to the constituent (with "I"); the suspension of speech; a hiatus in speaking (filled with "uh"); and a restart of the constituent ("I wouldn't."). An analysis of all repeated articles and pronouns in two large corpora of spontaneous speech shows that the four stages reflect different principles. Speakers are more likely to make a premature commitment, immediately suspending their speech, as both the local constituent and the constituent containing it become more complex. They plan some of these suspensions from the start as preliminary commitments to what they are about to say. And they are more likely to restart a constituent the more their stopping has disrupted its delivery. We argue that the principles governing these stages are general and not specific to repeats.},
author = {Clark, H H and Wasow, T},
doi = {10.1006/cogp.1998.0693},
file = {::},
issn = {0010-0285},
journal = {Cognitive psychology},
keywords = {Humans,Language,Verbal Behavior},
month = dec,
number = {3},
pages = {201--42},
pmid = {9892548},
title = {{Repeating words in spontaneous speech.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9892548},
volume = {37},
year = {1998}
}
@article{Lee2009,
author = {Lee, Jina and Prendinger, Helmut},
file = {::},
isbn = {9781424447992},
journal = {Affective Computing},
title = {{Learning models of speaker head nods with affective information}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5349543},
year = {2009}
}
@article{Prendinger2005,
abstract = {In this paper, we report on our efforts in developing affective character-based interfaces, i.e., interfaces that recognize and measure affective information of the user and address user affect by employing embodied characters. In particular, we describe the Empathic Companion, an ani- mated interface agent that accompanies the user in the setting of a virtual job interview. This inter- face application takes physiological data (skin conductance and electromyography) of a user in realtime, interprets them as emotions, and addresses the user’s affective states in the form of empathic feedback. The Empathic Companion is conceived as an educational agent that supports job seekers preparing for a job interview. We also present results from an exploratory study that aims to evaluate the impact of the Empathic Companion by measuring users’ skin conductance and heart rate. While an overall positive effect of the Empathic Companion could not be shown, the outcome of the experiment suggests that empathic feedback has a positive effect on the interviewee’s stress level while hearing the interviewer question.},
annote = {They take physiological data (skin conductance and electromyography) of a user in real-time, interpret them as emotions, and address the user’s affective states by empathic feedback. A decision making agent relates these signals and the user’s answer to arousal and valence to infer the user’s emotional state by applying the model of Lang (1995) (Lang claims that all emotions can be characterized in terms of valence (pleasant or unpleasant) and arousal (calm or aroused)). Then it selects empathetic actions that maximize some utility function. They use text-based empathetic actions in addition to a small full body character.We can use the decision-theoretic agent aspect in our empathy model.
The empathy is mainly expressed in a text-base fashion in their job. The embodied agent that they have is so small and no facial expressions are used. There are some gestural expressions.
As shown in this paper and many other ones, text-base empathy expression can be effective. So we can use that too.
      },
author = {Prendinger, Helmut and Ishizuka, M.},
doi = {10.1080/08839510590910174},
file = {::;::},
journal = {Applied Artificial Intelligence},
keywords = {electromyography,physiological signals,skin conductance},
number = {3-4},
pages = {267--286},
publisher = {Citeseer},
title = {{The Empathic Companion - A Character-based Interface that Addresses Users’ Affective States}},
volume = {19},
year = {2005}
}
@article{Hess2001,
author = {Hess, Ursula and Blairy, Sylvie},
file = {::},
journal = {International Journal of Psychophysiology},
keywords = {emotion recognition,emotional contagion,facial mimicry},
pages = {129--141},
title = {{Facial mimicry and emotional contagion to dynamic emotional facial expressions and their influence on decoding accuracy}},
volume = {40},
year = {2001}
}
@article{Kessous2009,
author = {Kessous, Loic and Castellano, Ginevra and Caridakis, George},
doi = {10.1007/s12193-009-0025-5},
file = {::},
issn = {1783-7677},
journal = {Journal on Multimodal User Interfaces},
keywords = {affective body language,affective speech,emotion recognition,facial expression,multimodal},
month = dec,
number = {1-2},
pages = {33--48},
title = {{Multimodal emotion recognition in speech-based interaction using facial expression, body gesture and acoustic analysis}},
url = {http://www.springerlink.com/index/10.1007/s12193-009-0025-5},
volume = {3},
year = {2009}
}
@book{Hoffman2000,
author = {Hoffman, Martin L},
booktitle = {Development},
isbn = {052158034X},
pages = {2},
publisher = {Cambridge University Press},
title = {{Empathy and Moral Development}},
year = {2000}
}
@article{Lakin2003,
abstract = {The “chameleon effect” refers to the tendency to adopt the postures, gestures, and mannerisms of interaction partners (Chartrand \& Bargh, 1999). This type of mimicry occurs outside of conscious awareness, and without any intent to mimic or imitate. Empirical evidence suggests a bi-directional relationship between nonconscious mimicry on the one hand, and liking, rapport, and affiliation on the other. That is, nonconscious mimicry creates affiliation, and affiliation can be expressed through nonconscious mimicry. We argue that mimicry played an important role in human evolution. Initially, mimicry may have had survival value by helping humans communicate. We propose that the purpose of mimicry has now evolved to serve a social function. Nonconscious behavioral mimicry increases affiliation, which serves to foster relationships with others.},
annote = {nonconscious mimicry creates affiliation, and affiliation can be expressed through nonconscious mimicry.
Initially, mimicry may have had survival value by helping humans communicate. The purpose of mimicry has now evolved to serve a social function. Nonconscious behavioral mimicry increases affiliation, which serves to foster relationships with others.
Empathic individuals mimic people more that people low in empathy.},
author = {Lakin, J. L. and Jefferis, VE and Cheng, CM},
file = {::},
journal = {Journal of nonverbal},
keywords = {1994,1999,2000,2001a,affiliation,and sometimes from,animals,aronson,caporael,chameleon effect,dusk to dawn,ehrlich,from dawn to dusk,human beings are social,human evolution,mimicry,our lives are filled,we talk to signif-,with social interactions,wright},
number = {3},
pages = {145--162},
title = {{The chameleon effect as social glue: Evidence for the evolutionary significance of nonconscious mimicry}},
volume = {27},
year = {2003}
}
@article{Wicker2003,
abstract = {What neural mechanism underlies the capacity to understand the emotions of others? Does this mechanism involve brain areas normally involved in experiencing the same emotion? We performed an fMRI study in which participants inhaled odorants producing a strong feeling of disgust. The same participants observed video clips showing the emotional facial expression of disgust. Observing such faces and feeling disgust activated the same sites in the anterior insula and to a lesser extent in the anterior cingulate cortex. Thus, as observing hand actions activates the observer's motor representation of that action, observing an emotion activates the neural representation of that emotion. This finding provides a unifying mechanism for understanding the behaviors of others.},
author = {Wicker, Bruno and Keysers, Christian and Plailly, Jane and Royet, Jean Pierre and Gallese, Vittorio and Rizzolatti, Giacomo},
doi = {10.1016/S0896-6273(03)00679-2},
institution = {Institut de Neurosciences Physiologiques et Cognitives, CNRS, Chemin Joseph Aiguier, 13402 cedex 20, Marseille, France.},
issn = {08966273},
journal = {Neuron},
keywords = {adult,brain mapping,cerebral cortex,cerebral cortex anatomy \& histology,cerebral cortex physiology,chemical,computer assisted,emotions,emotions physiology,facial expression,humans,image processing,magnetic resonance imaging,magnetic resonance imaging methods,male,ocular,ocular physiology,odors,photic stimulation,random allocation,stimulation,vision},
number = {3},
pages = {655--64},
pmid = {14642287},
publisher = {Elsevier},
title = {{Both of us disgusted in My insula: the common neural basis of seeing and feeling disgust.}},
volume = {40},
year = {2003}
}
@article{Varni2009,
author = {Varni, Giovanna and Camurri, Antonio and Coletta, Paolo and Volpe, Gualtiero},
doi = {10.1109/CSE.2009.230},
file = {::},
isbn = {978-1-4244-5334-4},
journal = {2009 International Conference on Computational Science and Engineering},
keywords = {Social signals, music, synchronisation},
pages = {843--848},
publisher = {Ieee},
title = {{Toward a Real-Time Automated Measure of Empathy and Dominance}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5283210},
year = {2009}
}
@inproceedings{Steunebrink2009,
author = {Steunebrink, B.R. and Dastani, Mehdi and Meyer, J.J.C.},
booktitle = {Proceedings of the 4th Workshop on Emotion and Computing},
file = {::},
title = {{The OCC model revisited}},
url = {http://www.idsia.ch/~steunebrink/Publications/KI09\_OCC\_revisited.pdf},
year = {2009}
}
@article{Boukricha2011,
abstract = {Allowing virtual humans to align to others’ perceived emotions is believed to enhance their cooperative and communicative social skills. In our work, emotional alignment is realized by endowing a virtual human with the ability to empathize. Recent research shows that humans empathize with each other to different degrees depending on several factors including, among others, their mood, their personality, and their social relationships. Although providing virtual humans with features like affect, personality, and the ability to build social relationships, little attention has been devoted to the role of such features as factors modulating their empathic behavior. Supported by psychological models of empathy, we propose an approach to model empathy for the virtual human EMMA—an Empathic MultiModal Agent—consisting of three processing steps: First, the Empathy Mechanism by which an empathic emotion is produced. Second, the Empathy Modulation by which the empathic emotion is modulated. Third, the Expression of Empathy by which EMMA’s multiple modalities are triggered through the modulated empathic emotion. The proposed model of empathy is illustrated in a conversational agent scenario involving the virtual humans MAX and EMMA.},
author = {Boukricha, Hana and Wachsmuth, Ipke},
doi = {10.1007/s13218-011-0109-8},
file = {::},
issn = {0933-1875},
journal = {KI - K\"{u}nstliche Intelligenz},
keywords = {agent-agent interaction,empathic virtual humans,human-agent,internal simulation},
month = may,
number = {3},
pages = {195--204},
title = {{Empathy-Based Emotional Alignment for a Virtual Human: A Three-Step Approach}},
url = {http://www.springerlink.com/content/9322738p4101p94w/},
volume = {25},
year = {2011}
}
@article{Bryant2008,
author = {Bryant, Gregory a. and Barrett, H. Clark},
doi = {10.1163/156770908X289242},
file = {::},
issn = {15677095},
journal = {Journal of Cognition and Culture},
keywords = {and can include bodily,com-,cross-cultural comparisons,deployed physical displays with,emotional expressions are strategically,evolutionary psychology,facial movements and,gestures,municative function,speech,universals,vocal emotion},
month = apr,
number = {1},
pages = {135--148},
title = {{Vocal Emotion Recognition Across Disparate Cultures}},
url = {http://openurl.ingenta.com/content/xref?genre=article\&issn=1567-7095\&volume=8\&issue=1\&spage=135},
volume = {8},
year = {2008}
}
@article{Lakin2003,
abstract = {The “chameleon effect” refers to the tendency to adopt the postures, gestures, and mannerisms of interaction partners (Chartrand \& Bargh, 1999). This type of mimicry occurs outside of conscious awareness, and without any intent to mimic or imitate. Empirical evidence suggests a bi-directional relationship between nonconscious mimicry on the one hand, and liking, rapport, and affiliation on the other. That is, nonconscious mimicry creates affiliation, and affiliation can be expressed through nonconscious mimicry. We argue that mimicry played an important role in human evolution. Initially, mimicry may have had survival value by helping humans communicate. We propose that the purpose of mimicry has now evolved to serve a social function. Nonconscious behavioral mimicry increases affiliation, which serves to foster relationships with others.},
annote = {nonconscious mimicry creates affiliation, and affiliation can be expressed through nonconscious mimicry.
Initially, mimicry may have had survival value by helping humans communicate. The purpose of mimicry has now evolved to serve a social function. Nonconscious behavioral mimicry increases affiliation, which serves to foster relationships with others.
Empathic individuals mimic people more that people low in empathy.},
author = {Lakin, JL and Jefferis, VE and Cheng, CM},
file = {::},
journal = {Journal of nonverbal},
keywords = {1994,1999,2000,2001a,affiliation,and sometimes from,animals,aronson,caporael,chameleon effect,dusk to dawn,ehrlich,from dawn to dusk,human beings are social,human evolution,mimicry,our lives are filled,we talk to signif-,with social interactions,wright},
number = {3},
pages = {145--162},
title = {{The chameleon effect as social glue: Evidence for the evolutionary significance of nonconscious mimicry}},
url = {http://www.springerlink.com/index/R16K6T278246H656.pdf},
volume = {27},
year = {2003}
}
@book{Arnold1960,
address = {New York},
author = {Arnold, M. B},
publisher = {Columbia University Press},
title = {{Emotion and personality}},
year = {1960}
}
@book{Watson1930,
address = {Chicago},
author = {Watson, J. B.},
publisher = {University of Chicago Press},
title = {{Behaviorism}},
year = {1930}
}
@book{Andreassi2009,
author = {Andreassi, John L.},
edition = {5},
publisher = {Taylor \& Francis},
title = {{Psychophysiology: Human Behavior and Physiological Response}},
year = {2009}
}
@article{Krumhuber2012,
abstract = {In this article, we present FACSGen 2.0, new animation software for creating static and dynamic three-dimensional facial expressions on the basis of the Facial Action Coding System (FACS). FACSGen permits total control over the action units (AUs), which can be animated at all levels of intensity and applied alone or in combination to an infinite number of faces. In two studies, we tested the validity of the software for the AU appearance defined in the FACS manual and the conveyed emotionality of FACSGen expressions. In Experiment 1, four FACS-certified coders evaluated the complete set of 35 single AUs and 54 AU combinations for AU presence or absence, appearance quality, intensity, and asymmetry. In Experiment 2, lay participants performed a recognition task on emotional expressions created with FACSGen software and rated the similarity of expressions displayed by human and FACSGen faces. Results showed good to excellent classification levels for all AUs by the four FACS coders, suggesting that the AUs are valid exemplars of FACS specifications. Lay participants' recognition rates for nine emotions were high, and comparisons of human and FACSGen expressions were very similar. The findings demonstrate the effectiveness of the software in producing reliable and emotionally valid expressions, and suggest its application in numerous scientific areas, including perception, emotion, and clinical and neuroscience research. (PsycINFO Database Record (c) 2012 APA, all rights reserved).},
author = {Krumhuber, Eva G and Tamarit, Lucas and Roesch, Etienne B and Scherer, Klaus R.},
doi = {10.1037/a0026632},
file = {::},
issn = {1931-1516},
journal = {Emotion},
keywords = {and recognition of emotions,animation,emotion,expressions,expressive stimuli has contributed,facial action coding system,facial expression,facsgen,knowledge of the perception,last years,much to our,over the,several databases of emotion-specific,the use of facial},
month = jan,
number = {2},
pages = {351--363},
pmid = {22251045},
title = {{FACSGen 2.0 animation software: Generating three-dimensional FACS-valid facial expressions for emotion research.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22251045},
volume = {12},
year = {2012}
}
@article{Davidson1986,
author = {Davidson, R and Raistrick, D},
journal = {British journal of addiction},
keywords = {adolescent,adult,age factors,aged,alcoholism,humans,middle aged,questionnaires,self disclosure},
number = {2},
pages = {217--222},
pmid = {3458489},
title = {{The validity of the Short Alcohol Dependence Data (SADD) Questionnaire: a short self-report questionnaire for the assessment of alcohol dependence.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/3458489},
volume = {81},
year = {1986}
}
@article{Ortony1990,
abstract = {A widespread assumption in theories of emotion is that there exists a small set of basic emotions. From a biological perspective, this idea is manifested in the belief that there might be neurophysiological and anatomical substrates corresponding to the basic emotions. From a psychological perspective, basic emotions are often held to be the primitive building blocks of other, nonbasic emotions. The content of such claims is examined, and the results suggest that there is no coherent nontrivial notion of basic emotions as the elementary psychological primitives in terms of which other emotions can be explained. Thus, the view that there exist basic emotions out of which all other emotions are built, and in terms of which they can be explained, is questioned, raising the possibility that this position is an article of faith rather than an empirically or theoretically defensible basis for the conduct of emotion research. This suggests that perhaps the notion of basic emotions will not lead to significant progress in the field. An alternative approach to explaining the phenomena that appear to motivate the postulation of basic emotions is presented.},
author = {Ortony, A and Turner, T J},
institution = {Institute for the Learning Sciences, Northwestern University, Evanston, Illinois 60201.},
journal = {Psychological Review},
number = {3},
pages = {315--331},
pmid = {1669960},
publisher = {Citeseer},
title = {{What's basic about basic emotions?}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0033-295X.97.3.315},
volume = {97},
year = {1990}
}
@inproceedings{Bickmore2009,
abstract = {Ninety million Americans have inadequate health literacy, resulting in a reduced ability to read and follow directions in the healthcare environment. We describe an animated, empathic virtual nurse interface for design rationale, and two Boston University School of Medicine Boston Medical Center brian.jack@bmc.org educating and counseling hospital patients with inadequate health literacy in their hospital beds at the time of discharge. The development methodology, iterations of user testing are described. Results indicate that hospital patients with low health literacy found the system easy to use, reported high levels of satisfaction, and most said they preferred receiving the discharge information from the agent over their doctor or nurse. Patients also expressed appreciation for the time and attention provided by the virtual nurse, and felt that it provided an additional authoritative source for their medical information.},
address = {New York},
author = {Bickmore, Timothy W. and Pfeifer, Laura M and Jack, Brian W},
booktitle = {Proceedings of the 27th interna- tional conference on Human factors in computing systems},
file = {::},
isbn = {9781605582467},
keywords = {Access,Conversational Agent,Embodied,Health Literacy,Hospital Discharge,Patient Education,Patient Safety,Relational Agent,Universal},
pages = {1265--1274},
publisher = {ACM},
title = {{Taking the Time to Care : Empowering Low Health Literacy Hospital Patients with Virtual Nurse Agents}},
year = {2009}
}
@book{Russell2010,
author = {Russell, S.J. and Norvig, P.},
booktitle = {Artificial Intelligence},
edition = {3},
editor = {Russell, Stuart and Norvig, Peter},
file = {::},
isbn = {9780136042594},
publisher = {Prentice hall},
title = {{Artificial intelligence: a modern approach}},
url = {http://www.just.edu.jo/CoursesAndLabs/ARTIFICAL  INTELLIGENCE\_CS362/Syllabus\_362.doc},
year = {2010}
}
@article{Gratch2004,
author = {Gratch, Jonathan and Marsella, Stacy C},
file = {::;::},
journal = {Cognitive Systems Research},
number = {4},
pages = {269--306},
publisher = {Elsevier},
title = {{A domain-independent framework for modeling emotion}},
volume = {5},
year = {2004}
}
@article{Scherer2003,
author = {Scherer, Klaus R.},
doi = {10.1016/S0167-6393(02)00084-5},
file = {::},
issn = {01676393},
journal = {Speech communication},
month = apr,
number = {1-2},
pages = {227--256},
title = {{Vocal communication of emotion: A review of research paradigms}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167639302000845 http://www.sciencedirect.com/science/article/pii/S0167639302000845},
volume = {40},
year = {2003}
}
@phdthesis{Sze2005,
author = {Sze, Ian},
booktitle = {Ambient Intelligence in Everyday Life},
file = {::},
school = {UNIVERSITY OF NEW SOUTH WALES},
title = {{Empathic computing}},
year = {2005}
}
@inproceedings{Courgeon2008,
address = {Estoril, Portugal},
annote = {The user reports his/her affective state in real-time with changing the position of a 3D point in PAD space using a joystick. The system captures the position of that point and maps it to a blend of 8 selected emotions. },
author = {Courgeon, Matthieu and Martin, Jean-claude and Jacquemin, Christian},
booktitle = {Proc. of 7th Int. Conf. on Autonomous Agents and Multiagent Systems (AAMAS 2008)},
file = {::},
number = {Aamas},
pages = {1237--1240},
title = {{User ’ s Gestural Exploration of Different Virtual Agents ’ Expressive Profiles ( Short Paper )}},
year = {2008}
}
@inproceedings{Bosse2010,
abstract = {In order to enhance user involvement in financial services, this paper proposes to combine the idea of adaptive personalisation with intelligent virtual agents. To this end, a computational model for human decision making in financial context is incorporated within an intelligent virtual agent. To test whether the agent enhances user involvement, a web application has been developed, in which users have to make a number of investment decisions. This application has been evaluated in an experiment for a number of participants interacting with the system and afterwards providing their judgement by means of a questionnaire. The preliminary results indicate that the virtual agent can show appropriate emotional expressions related to states like happiness, greed and fear, and has high potential to enhance user involvement.},
author = {Bosse, Tibor and Siddiqui, Ghazanfar F and Treur, Jan},
booktitle = {IVA'10 Proceedings of the 10th international conference on Intelligent virtual agents},
file = {::},
keywords = {adaptive personalisation.,finance,greed and risk,user involvement},
pages = {378--384},
publisher = {Springer-Verlag Berlin, Heidelberg},
title = {{An Intelligent Virtual Agent to Increase Involvement in Financial Services}},
year = {2010}
}
@inproceedings{Wang2009,
abstract = {How to build virtual agents that establish rapport with human? According to Tickle-Degnen and Rosenthal, the three essential components of rapport are mutual attentiveness, positivity and coordination. In our previous work, we designed an embodied virtual agent to establish rapport with a human speaker by providing rapid and contingent nonverbal feedback. How do we know that a human speaker is feeling a sense of rapport? In this paper, we focus on the positivity component of rapport by investigating the relationship of human speakers' facial expressions on the establishment of rapport. We used an automatic facial expression coding tool called CERT to analyze the human dyad interactions and human-virtual human interactions. Results show that recognizing positive facial displays alone may be insufficient and that recognized negative facial displays was more diagnostic in assessing the level of rapport between participants.},
address = {Amsterdam},
annote = {Out of three components of rapport by Tickle-Degnene and Rosenthal (mutual attentiveness, positivity, and coordination), they investigated the relationship between human speakers' facial expression and rapport. Results show that recognizing positive facial expressions alone is insufficient but negative facial displays are more effective in assessing the level of rapport between participants.},
author = {Wang, Ning and Gratch, Jonathan},
booktitle = {3rd International Conference on Affective Computing and Intelligent Interaction and Workshops, 2009. ACII 2009},
doi = {10.1109/ACII.2009.5349514},
file = {::},
isbn = {978-1-4244-4800-5},
month = sep,
pages = {1--6},
publisher = {IEEE},
title = {{Rapport and facial expression}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5349514},
year = {2009}
}
@article{Breitfuss2009,
abstract = {This paper presents a system capable of automatically adding ges- tures to an embodied virtual character processing information from a simple text input. Gestures are generated based on the analysis of linguistic and contex- tual information of the input text. The system is embedded in the virtual world called second life and consists of an in world object and an off world server component that handles the analysis. Either a user controlled avatar or a non user controlled character can be used to display the gestures, that are timed with speech output from an Text-to-Speech system, and so show non verbal behavior without pushing the user to manually select it.},
author = {Breitfuss, Werner and Prendinger, Helmut and Ishizuka, Mitsuru},
file = {::},
journal = {Online Communities and Social Computing},
keywords = {animated agent systems,embodied virtual characters,multimodal,multimodal presentations,output generation,virtual worlds},
pages = {153--161},
title = {{Automatic generation of non-verbal behavior for agents in virtual worlds: A system for supporting multimodal conversations of bots and avatars}},
url = {http://www.springerlink.com/index/V8112R75N1830666.pdf},
volume = {LNCS 5621},
year = {2009}
}
@misc{TheMendeleySupportTeam2011,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/The Mendeley Support Team - 2011 - Getting Started with Mendeley(4).pdf:pdf},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@article{Campbell1994,
abstract = {OBJECTIVES. To achieve the Healthy People 2000 objectives, public health professionals must develop effective dietary interventions that address psychosocial and behavioral components of change. This study tested the effect of individually computer-tailored messages designed to decrease fat intake and increase fruit and vegetable intake. METHODS. Adult patients from four North Carolina family practices were surveyed at baseline and then randomly assigned to one of two interventions or to a control group. The first intervention consisted of individually computer-tailored nutrition messages; the second consisted of nontailored nutrition information based on the 1990 Dietary Guidelines for Americans. Patients were resurveyed 4 months postintervention. RESULTS. The tailored intervention produced significant decreases in total fat and saturated fat scores compared with those of the control group (P < .05). Total fat was decreased in the tailored group by 23\%, in the nontailored group by 9\%, and in the control group by 3\%. Fruit and vegetable consumption did not increase in any study group. Seventy-three percent of the tailored intervention group recalled receiving a message, compared with 33\% of the nontailored intervention group. CONCLUSIONS. Tailored nutrition messages are effective in promoting dietary fat reduction for disease prevention.},
author = {Campbell, M K and DeVellis, B M and Strecher, V J and Ammerman, A S and DeVellis, R F and Sandler, R S},
institution = {Department of Health Behavior, Department of Nutrition, School of Public Health, University of North Carolina, Chapel Hill 27599-7400.},
journal = {American Journal of Public Health},
number = {5},
pages = {783--787},
title = {{Improving dietary behavior: the effectiveness of tailored messages in primary care settings.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1615043\&tool=pmcentrez\&rendertype=abstract},
volume = {84},
year = {1994}
}
@article{Gunes2008,
author = {Gunes, Hatice and Piccardi, Massimo},
file = {::},
journal = {Emotion},
title = {{From the lab to the real world: Affect recognition using multiple cues and modalities}},
year = {2008}
}
@article{Liu2008,
author = {Liu, Zhen},
file = {::},
journal = {InTech Education and Publishing},
title = {{Computational Emotion Model for Virtual Characters}},
url = {http://www.intechopen.com/source/pdfs/5186/InTech-Computational\_emotion\_model\_for\_virtual\_characters.pdf},
year = {2008}
}
@article{Bailenson2005,
abstract = {Previous research demonstrated social influence resulting from mimicry (the chameleon effect); a confederate who mimicked participants was more highly regarded than a confederate who did not, despite the fact that participants did not explicitly notice the mimicry. In the current study, participants interacted with an embodied artificial intelligence agent in immersive virtual reality. The agent either mimicked a participant's head movements at a 4-s delay or utilized prerecorded movements of another participant as it verbally presented an argument. Mimicking agents were more persuasive and received more positive trait ratings than nonmimickers, despite participants' inability to explicitly detect the mimicry. These data are uniquely powerful because they demonstrate the ability to use automatic, indiscriminate mimicking (i.e., a computer algorithm blindly applied to all movements) to gain social influence. Furthermore, this is the first study to demonstrate social influence effects with a nonhuman, nonverbal mimicker.},
author = {Bailenson, Jeremy N and Yee, Nick},
file = {::},
journal = {Psychological Science},
number = {10},
pages = {814--819},
title = {{Digital Chameleons: Automatic Assimilation of Nonverbal Gestures in Immersive Virtual Environments}},
volume = {16},
year = {2005}
}
@article{Cliffordson2002,
abstract = {The purpose of the present study was to examine the structure of empathy using a hierarchical approach, and to compare the dimensions of empathy with measures of social functioning, in order to contribute to the understanding of the nature of empathy. The dimensionality of the Interpersonal Reactivity Index, which comprises four subscales (empathic concern, perspective taking, fantasy and personal distress) was examined using confirmatory factor analysis. Relations with the Social Skills Inventory were also investigated. A sample of 127 applicants for places on nursing and social work undergraduate programs participated in the study. The study findings indicate that empathy is hierarchically organized, with one general dimension at the apex. The general factor is identical to empathic concern and this dimension overlaps to a great extent with perspective taking and fantasy. The findings also indicate that the general dimension constitutes an integrated entirety, with its main emphasis on emotional reactivity by also involving cognitive processes.},
author = {Cliffordson, Christina},
file = {::},
issn = {0036-5564},
journal = {Scandinavian journal of psychology},
keywords = {Empathy,Factor Analysis,Humans,Social Behavior,Statistical},
month = feb,
number = {1},
pages = {49--59},
pmid = {11885760},
title = {{The hierarchical structure of empathy: dimensional organization and relations to social functioning.}},
volume = {43},
year = {2002}
}
@inproceedings{Kumano2011,
author = {Kumano, Shiro and Otsuka, Kazuhiro and Mikami, Dan and Yamato, Junji},
booktitle = {Automatic Face \& Gesture Recognition and Workshops (FG 2011), 2011 IEEE International Conference on},
file = {::},
pages = {43--50},
publisher = {IEEE},
title = {{Analyzing empathetic interactions based on the probabilistic modeling of the co-occurrence patterns of facial expressions in group meetings}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5771440},
year = {2011}
}
@article{Drolet2000,
abstract = {We propose that face-to-face contact fosters the development of rapport and thereby helps negotiators coordinate on mutually beneficial settlements in mixed-motive conflicts. Specifically, we investigate whether, in a cooperative climate, negotiators visual access to each others nonverbal behavior fosters a dyadic state of rapport that facilitates mutual cooperation. Experiment 1 manipulated whether negotiators stood face-to-face or side-by- side (unable to see each other) in a simulated strike negotiation. Face-to-face dyads were more likely to coordinate on a settlement early in the strike, resulting in higher joint gains. An alternative interpretation in terms of an anticipatory effect of face-to-face contact was not supported. Experiment 2 manipulated whether previously unacquainted negotiators conversed face-to-face or by telephone before separating to play a conflict game with the structure of a Prisoners Dilemma game. Face-to-face dyads were more likely to coordinate on high joint gain outcomes. The facilitatory effect of face-to-face contact was statistically mediated by ameasure of dyadic rapport. Results did not support alternative interpretations based on individual-level positive affect or expectations about opponents. We conclude with a discussion of the role of affective and dyad-level processes in social psychological models of conflict resolution.},
author = {Drolet, Aimee L and Morris, Michael W},
doi = {10.1006/jesp.1999.1395},
issn = {00221031},
journal = {Journal of Experimental Social Psychology},
number = {1},
pages = {26--50},
publisher = {ACADEMIC PRESS INC},
title = {{Rapport in Conflict Resolution: Accounting for How Face-to-Face Contact Fosters Mutual Cooperation in Mixed-Motive Conflicts}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0022103199913951},
volume = {36},
year = {2000}
}
@article{Gratch2007a,
author = {Gratch, Jonathan and Wang, Ning and Gerten, Jillian and Fast, Edward},
file = {::},
journal = {Intelligent Virtual Agents},
keywords = {evaluation,rapport,virtual agents},
title = {{Creating rapport with virtual agents}},
url = {http://www.springerlink.com/index/X568357400058UM7.pdf},
year = {2007}
}
@article{Bavelas1986,
abstract = {Elementary motor mimicry (e.g., wincing when another is injured) has been previously considered in social psychology as the overt manifestation of some intrapersonal process such as vicarious emotion. A 2-part experiment with 50 university students tested the hypothesis that motor mimicry is instead an interpersonal event, a nonverbal communication intended to be seen by the other. Part 1 examined the effect of a receiver on the observer's motor mimicry. The victim of an apparently painful injury was either increasingly or decreasingly available for eye contact with the observer. Microanalysis showed that the pattern and timing of the observer's motor mimicry were significantly affected by the visual availability of the victim. In Part 2, naive decoders viewed and rated the reactions of these observers. Their ratings confirmed that motor mimicry was consistently decoded as "knowing" and "caring" and that these interpretations were significantly related to the experimental condition under which the reactions were elicited. Results cannot be explained by any alternative intrapersonal theory, so a parallel process model is proposed in which the eliciting stimulus may set off both internal reactions and communicative responses, and it is the communicative situation that determines the visable behavior. (37 ref) (PsycINFO Database Record (c) 2010 APA, all rights reserved)},
author = {Bavelas, Janet Beavin and Black, Alex and Lemery, Charles R. and {Jennifer Muller}},
doi = {10.1037/0022-3514.50.2.322},
file = {::},
journal = {Journal of Personality and Social Psychology},
number = {2},
pages = {322--329},
title = {{"I show how you feel" - Motor mimicry as a communicative act}},
url = {http://psycnet.apa.org/journals/psp/50/2/322/},
volume = {50},
year = {1986}
}
@inproceedings{Schulman2011,
abstract = {We present a conversational agent designed as a virtual counselor for health behavior change. The incorporates techniques drawn from agent Motivational Interviewing to enhance client motivation and confidence to change; these techniques are modeled and implemented based on a domain-specific taxonomy of dialogue acts. We discuss the design and preliminary evaluation of the agent.},
author = {Schulman, Daniel and Bickmore, Timothy and Sidner, Candace L},
booktitle = {AAAI Spring Symposium Series},
file = {::},
pages = {61--64},
title = {{An Intelligent Conversational Agent for Promoting Long-Term Health Behavior Change using Motivational Interviewing}},
year = {2011}
}
@article{Cassell1999,
author = {Cassell, Justine and Thorisson, K.R.},
file = {::},
journal = {Applied Artificial Intelligence},
number = {4-5},
pages = {519--538},
publisher = {Taylor \& Francis},
title = {{The power of a nod and a glance: Envelope vs. emotional feedback in animated conversational agents}},
url = {http://www.tandfonline.com/doi/abs/10.1080/088395199117360},
volume = {13},
year = {1999}
}
@article{Cassell2000,
abstract = {Embodied conversational agents are computer-generated cartoon-like characters that demonstrate many of the same properties as humans in face-to-face conversation, including the ability to produce and respond to verbal and nonverbal communication. They constitute a type of (a) multimodal interface where the modalities are those natural to human conversation: speech, facial displays, hand gestures, and body stance; (b) software agent, insofar as they represent the computer in an interaction with a human or represent their human users in a computational environment (as avatars, for example); and (c) dialogue system where both verbal and nonverbal devices advance and regulate the dialogue between the user and the computer. With an embodied conversational agent, the visual dimension of interacting with an animated character on a screen plays an intrinsic role. Not just pretty pictures, the graphics display visual features of conversation in the same way that the face and hands do in face-to-face conversation among humans.This book describes research in all aspects of the design, implementation, and evaluation of embodied conversational agents as well as details of specific working systems. Many of the chapters are written by multidisciplinary teams of psychologists, linguists, computer scientists, artists, and researchers in interface design. The authors include Elisabeth Andre, Norm Badler, Gene Ball, Justine Cassell, Elizabeth Churchill, James Lester, Dominic Massaro, Cliff Nass, Sharon Oviatt, Isabella Poggi, Jeff Rickel, and Greg Sanders.},
author = {Cassell, Justine and Sullivan, Joseph and Prevost, Scott and Churchill, Elizabeth F.},
chapter = {Evaluation},
doi = {10.1027/1864-9335.40.1.26},
editor = {Cassell, Justine and Sullivan, Joseph and Prevost, Scott and Churchill, Elizabeth},
isbn = {0262032783},
issn = {18649335},
journal = {Social Psychology},
number = {1},
pages = {26--36},
publisher = {MIT Press},
title = {{Embodied Conversational Agents}},
url = {http://psycontent.metapress.com/openurl.asp?genre=article\&id=doi:10.1027/1864-9335.40.1.26},
volume = {40},
year = {2000}
}
@article{Cliffordson2002,
abstract = {The purpose of the present study was to examine the structure of empathy using a hierarchical approach, and to compare the dimensions of empathy with measures of social functioning, in order to contribute to the understanding of the nature of empathy. The dimensionality of the Interpersonal Reactivity Index, which comprises four subscales (empathic concern, perspective taking, fantasy and personal distress) was examined using confirmatory factor analysis. Relations with the Social Skills Inventory were also investigated. A sample of 127 applicants for places on nursing and social work undergraduate programs participated in the study. The study findings indicate that empathy is hierarchically organized, with one general dimension at the apex. The general factor is identical to empathic concern and this dimension overlaps to a great extent with perspective taking and fantasy. The findings also indicate that the general dimension constitutes an integrated entirety, with its main emphasis on emotional reactivity by also involving cognitive processes.},
author = {Cliffordson, Christina},
file = {::},
issn = {0036-5564},
journal = {Scandinavian journal of psychology},
keywords = {Empathy,Factor Analysis,Humans,Social Behavior,Statistical},
month = feb,
number = {1},
pages = {49--59},
pmid = {11885760},
title = {{The hierarchical structure of empathy: dimensional organization and relations to social functioning.}},
volume = {43},
year = {2002}
}
@article{Catucci2006,
author = {Catucci, Graziano and Abbattista, Fabio and Gadaleta, R. and Guaccero, Domenico and Semeraro, Giovanni},
file = {::},
journal = {Applied Soft Computing Technologies: The Challenge of Complexity},
keywords = {autonomous agents,emotional agents,synthetic characters},
pages = {265--277},
publisher = {Springer},
title = {{Empathy: A computational framework for emotion generation}},
url = {http://www.springerlink.com/index/LJ26L065L0072722.pdf},
year = {2006}
}
@book{Hojat2007,
author = {Hojat, M.},
booktitle = {Patient Care},
file = {::},
isbn = {9780387336077},
publisher = {Springer Verlag},
title = {{Empathy in patient care: antecedents, development, measurement, and outcomes}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=OZT1sypBp5EC\&amp;oi=fnd\&amp;pg=PR7\&amp;dq=Empathy+In+Patient+Care:+Antecedents,+Development,+Measurements,+and+Outcomes\&amp;ots=8aQbxTclHN\&amp;sig=HFiEPtCVpFvXI6HU3rprIwvHGXc},
year = {2007}
}
@article{Banziger2009,
abstract = {Emotion recognition ability has been identified as a central component of emotional competence. We describe the development of an instrument that objectively measures this ability on the basis of actor portrayals of dynamic expressions of 10 emotions (2 variants each for 5 emotion families), operationalized as recognition accuracy in 4 presentation modes combining the visual and auditory sense modalities (audio/video, audio only, video only, still picture). Data from a large validation study, including construct validation using related tests (Profile of Nonverbal Sensitivity; Rosenthal, Hall, DiMatteo, Rogers, \& Archer, 1979; Japanese and Caucasian Facial Expressions of Emotion; Biehl et al., 1997; Diagnostic Analysis of Nonverbal Accuracy; Nowicki \& Duke, 1994; Emotion Recognition Index; Scherer \& Scherer, 2008), are reported. The results show the utility of a test designed to measure both coarse and fine-grained emotion differentiation and modality-specific skills. Factor analysis of the data suggests 2 separate abilities, visual and auditory recognition, which seem to be largely independent of personality dispositions.},
author = {B\"{a}nziger, Tanja and Grandjean, Didier and Scherer, Klaus R.},
doi = {10.1037/a0017088},
file = {::},
issn = {1931-1516},
journal = {Emotion (Washington, D.C.)},
keywords = {Adolescent,Adult,Discrimination (Psychology),Emotional Intelligence,Emotions,Facial Expression,Female,Humans,Male,Nonverbal Communication,Pattern Recognition,Personality Inventory,Personality Inventory: statistics \& numerical data,Psychometrics,Psychometrics: statistics \& numerical data,Recognition (Psychology),Reproducibility of Results,Social Adjustment,Visual,Voice Quality,Young Adult},
month = oct,
number = {5},
pages = {691--704},
pmid = {19803591},
title = {{Emotion recognition from expressions in face, voice, and body: the Multimodal Emotion Recognition Test (MERT).}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19803591},
volume = {9},
year = {2009}
}
@inproceedings{Campbell2005,
abstract = {Building relationships is a central concern for professionals (e.g., physicians, engineers, sales representatives, managers, etc.) because relationships promote a client's trust and loyalty. Rapport is a concept used to describe relationship quality and has two facets: enjoyable interactions and personal connection. Prior research has described the communication strategies of leaders for building better relationships with their subordinates and sales representatives with their customers by borrowing concepts from rapport management in sociolinguistics. The goal of this paper is to extend that work by demonstrating how rapport management applies to interaction between physicians and patients. The rapport management model helps us explain how professionals succeed or fail to build relationships with clients based on their verbal communication behavior.},
address = {Limerick, Ireland},
author = {Campbell, K.S.},
booktitle = {Proceedings in International Professional Communication Conference IPCC2005},
doi = {10.1109/IPCC.2005.1494206},
file = {::},
isbn = {0-7803-9027-X},
keywords = {communication,face-to-face interaction,health,medical interviews,sociolinguistics,verbal communication},
pages = {422--432},
publisher = {IEEE},
title = {{The rapport management model: how physicians build relationships with patients}},
url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=1494206},
year = {2005}
}
@article{Russell2003a,
abstract = {At the heart of emotion, mood, and any other emotionally charged event are states experienced as simply feeling good or bad, energized or enervated. These states-called core affect-influence reflexes, perception, cognition, and behavior and are influenced by many causes internal and external, but people have no direct access to these causal connections. Core affect can therefore be experienced as free-floating (mood) or can be attributed to some cause (and thereby begin an emotional episode). These basic processes spawn a broad framework that includes perception of the core-affect-altering properties of stimuli, motives, empathy, emotional meta-experience, and affect versus emotion regulation; it accounts for prototypical emotional episodes, such as fear and anger, as core affect attributed to something plus various nonemotional processes.},
author = {Russell, James A},
institution = {Department of Psychology, Boston College, Chestnut Hill, Massachusetts 02467, USA. james.russell@bc.edu},
journal = {Psychological Review},
number = {1},
pages = {145--172},
pmid = {12529060},
publisher = {[Washington, etc.] American Psychological Association [etc.]},
title = {{Core affect and the psychological construction of emotion.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0033-295X.110.1.145},
volume = {110},
year = {2003}
}
@article{Paiva2000,
author = {Paiva, Ana},
file = {::},
journal = {Affective interactions},
pages = {1--8},
title = {{Affective interactions: toward a new generation of computer interfaces?}},
url = {http://www.springerlink.com/index/826w110p65762167.pdf},
year = {2000}
}
@article{Paiva2005,
author = {Paiva, Ana and Dias, Jo\~{a}o and Sobral, Daniel and Aylett, Ruth and Woods, Sarah and Hall, Lynne and Zoll, Carsten},
doi = {10.1080/08839510590910165},
file = {::},
issn = {0883-9514},
journal = {Applied Artificial Intelligence},
month = mar,
number = {3-4},
pages = {235--266},
title = {{Learning By Feeling: Evoking Empathy With Synthetic Characters}},
url = {http://www.tandfonline.com/doi/abs/10.1080/08839510590910165},
volume = {19},
year = {2005}
}
@inproceedings{Kang2008,
author = {Kang, Sin-hwa and Gratch, Jonathan and Wang, Ning and Watt, J.H.},
booktitle = {Proceedings of the 7th international joint conference on Autonomous agents and multiagent systems-Volume 1},
file = {::},
keywords = {agents,contingency of nonverbal feedback,evaluation,rapport,social anxiety,virtual humans},
number = {Aamas},
pages = {120--127},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
title = {{Does the contingency of agents' nonverbal feedback affect users' social anxiety?}},
url = {http://dl.acm.org/citation.cfm?id=1402405},
year = {2008}
}
@book{Arnold1960,
address = {New York},
author = {Arnold, M. B},
publisher = {Columbia University Press},
title = {{Emotion and personality}},
year = {1960}
}
@article{Breemen2005,
author = {van Breemen, A and Yan, X},
file = {::},
journal = {Proceedings of the fourth},
pages = {143--144},
title = {{iCat: an animated user-interface robot with personality}},
url = {http://dl.acm.org/citation.cfm?id=1082823},
year = {2005}
}
@article{Sebe2005b,
author = {Sebe, Nicu and Cohen, Ira and Gevers, Theo},
file = {::},
journal = {Proc. SPIE},
keywords = {emotion recognition,human-computer interaction,multimodal approach},
title = {{Multimodal approaches for emotion recognition: a survey}},
url = {http://disi.unitn.it/~sebe/PUBS/PDF/2005/sebeSPIE2005a.pdf},
year = {2005}
}
@article{Straalen2009,
author = {Straalen, Bart Van and Heylen, Dirk and Theune, Mari\"{e}t},
file = {::},
journal = {Agents for Games and},
keywords = {bad news con-,embodied conversational agents,empathy,social agents,tutoring,versations},
pages = {95--106},
title = {{Enhancing Embodied Conversational Agents with Social and Emotional Capabilities}},
url = {http://www.springerlink.com/index/3612181747K5L570.pdf},
year = {2009}
}
@article{Kaysen2009,
abstract = {Objective: Motivational interviewing (MI) therapies are effective in reducing high-risk drinking in college populations. Although research supports efficacy of MI prevention strategies in reducing alcohol use, there are little data examining readiness to change (RTC), the underlying theoretical model of MI interventions. The purpose of the present study was to explore RTC variability and drinking behavior and whether MI increases RTC in an intervention group compared with controls. Method: Two-hundred eighty-five first-year female college students participated in the study. Present analyses focused on those students who consumed alcohol in the month before the study (n = 182). RTC was measured using the Readiness to Change Ruler. Results: Analyses were conducted using hierarchical linear modeling. There was significant variability in RTC: 71.86\% of variance in RTC was between- person differences, and 28.14\% was within-person differences. Higher RTC was associated with lower intentions to drink and future drinking behavior. However, in weeks in which students drank more, they experienced a decrease in RTC. Based on the significant cross-level interaction, the intervention group had significantly higher RTC than controls. Conclusions: These results provided partial support for our hypotheses. The overall theoretical construct of RTC varies both across and within individuals. These results also offer support for the utility of MI-based prevention strategies in increasing RTC within individuals. However, we did not consistently find that these changes related to drinking changes. Findings provide support for both the construct of RTC and utility of MI interventions in changing these beliefs in female college students.},
author = {Kaysen, Debra L and Lee, Christine M and Labrie, Joseph W and Tollison, Sean J},
institution = {Department of Psychiatry and Behavioral Sciences, University of Washington, Seattle, WA 98105, USA. dkaysen@u.washington.edu},
journal = {Journal of studies on alcohol and drugs Supplement},
number = {Supplement no. 16},
pages = {106--114},
publisher = {Rutgers University},
title = {{Readiness to Change Drinking Behavior in Female College Students}},
url = {http://ovidsp.ovid.com/ovidweb.cgi?T=JS\&CSC=Y\&NEWS=N\&PAGE=fulltext\&D=emed9\&AN=19538918},
year = {2009}
}
@inproceedings{Nguyen2009c,
author = {Nguyen, H. and Masthoff, Judith},
booktitle = {Proceedings of the 4th International Conference on Persuasive Technology},
file = {::},
isbn = {9781605583761},
keywords = {affective computing,design,experimentation,human factors},
pages = {7},
publisher = {ACM},
title = {{Designing empathic computers: the effect of multimodal empathic feedback using animated agent}},
url = {http://dl.acm.org/citation.cfm?id=1541958},
year = {2009}
}
@article{Gratch2006,
author = {Gratch, Jonathan and Okhmatovskaia, Anna and Lamothe, Francois},
file = {::},
journal = {Intelligent Virtual},
title = {{Virtual rapport}},
url = {http://www.springerlink.com/index/k720537752657m81.pdf},
year = {2006}
}
@misc{Ma2005,
abstract = {This short paper contains a preliminary description of a novel type of chat system that aims at realizing natural and social communication between distant communication partners. The system is based on an emotion estimation module that assesses the affective content of textual messages. Avatars associated with chat partners act out the assessed emotions of messages through multiple modalities, including synthetic speech and affect-related gestures.},
author = {Ma, C and Osherenko, A and Prendinger, Helmut and Ishizuka, M},
booktitle = {Proceedings of the 2005 International Conference on Active Media Technology 2005 AMT 2005},
doi = {10.1109/AMT.2005.1505418},
isbn = {0780390350},
number = {i},
pages = {546--548},
publisher = {Ieee},
title = {{A chat system based on emotion estimation from text and embodied conversational messengers}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1505418},
year = {2005}
}
@inproceedings{Courgeon2008,
abstract = {Designing affective user interfaces involving expressive characters raises several questions. The system should be able to display facial expressions of complex emotions as dynamic and realtime reactions to user’s inputs. From a cognitive point of view, designers need to know how the user will perceive the dynamics of these facial expressions as a function of his/her input. We aim at evaluating if users can perceive different expressive profiles of a virtual character by manually controlling its expressions and observing its reaction to his/her input. This paper describes our platform that enables a virtual character to display blended facial expressions of emotions as realtime continuous reactions to users’ gesture input. We explain the techniques underlying the computation of intermediate facial expressions of emotion, and their control in the 3D space PAD (Pleasure, Arousal, Dominance) using gesture input. Preliminary results of a perceptive study show the potential of such an approach for assessing the dynamics of the perception of emotional expressions during gesture interaction with virtual characters endowed with different expressive profiles.},
address = {Estoril, Portugal},
annote = {The user reports his/her affective state in real-time with changing the position of a 3D point in PAD space using a joystick. The system captures the position of that point and maps it to a blend of 8 selected emotions. },
author = {Courgeon, Matthieu and Martin, Jean-claude and Jacquemin, Christian},
booktitle = {AAMAS '08 Proceedings of the 7th international joint conference on Autonomous agents and multiagent systems - Volume 3},
doi = {10.1.1.149.8130},
editor = {Padgham and Parkes and M\"{u}ller and Parsons},
file = {::},
keywords = {Expressive agent,facial expressions,realtime interaction},
number = {Aamas},
pages = {1237--1240},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
title = {{User’s Gestural Exploration of Different Virtual Agents ’ Expressive Profiles (Short Paper)}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.149.8130},
year = {2008}
}
@article{Greenson1960,
author = {Greenson, Ralph R},
journal = {International Journal of PsychoAnalysis},
pages = {418--424},
title = {{Empathy and its vicissitudes}},
volume = {41},
year = {1960}
}
@article{Denef2009,
author = {Denef, Sebastian},
file = {::},
journal = {Human-Computer Interaction–INTERACT 2009},
pages = {864--867},
publisher = {Springer},
title = {{Human-Computer Interaction Techniques in Firefighting}},
url = {http://www.springerlink.com/index/n0688783567n3251.pdf},
year = {2009}
}
@inproceedings{Wang2010,
abstract = {Communication is more effective and persuasive when par- ticipants establish rapport. Tickle-Degnen and Rosenthal [57] argue rapport arises when participants exhibit mutual attentiveness, positivity and coordination. In this paper, we investigate how these factors relate to perceptions of rap- port when users interact via avatars in virtual worlds. In this study, participants told a story to what they believed was the avatar of another participant. In fact, the avatar was a computer program that systematically manipulated levels of attentiveness, positivity and coordination. In contrast to Tickel-Degnen and Rosenthal’s findings, its impact in a wide range of interpersonal domains includ- ing social engagement [52], classroom learning [22], suc- cess in negotiations [20], improving worker compliance [18], psychotherapeutic effectiveness [59], and improved quality of child care [11]. Recent research in virtual envi- ronments has demonstrated the possibility of translating these findings into computer-mediated (CMC) and human- computer interactions (HCI) where embodied communi- cated behaviors can not only be reproduced but altered in novel ways to perhaps amplify their interpersonal conse- quences [26] [5]. high-levels of mutual attentiveness alone can dramatically lower percep- tions of rapport in avatar communication. Indeed, an agent that attempted to maximize mutual attention performed as poorly as an agent that was designed to convey boredom. Adding positivity and coordination to mutual attentiveness, on the other hand, greatly improved rapport. This work un- veils the dependencies between components of rapport and informs the design of agents and avatars in computer medi- ated communication.},
address = {Atlanta, GA, USA},
author = {Wang, Ning and Gratch, Jonathan},
booktitle = {28th ACM Conference on Human Factors in Computing Systems (CHI'10)},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - p1241-wang.pdf(6).pdf:pdf},
keywords = {Virtual human,back-channel,gaze,head nod,pos- ture mirroring.,rapport},
pages = {1241--1249},
publisher = {ACM},
title = {{Don't just stare at me!}},
year = {2010}
}
@inproceedings{Lisetti2008a,
author = {Lisetti, Christine L and Wagner, Eric},
booktitle = {Proceedings of the AAAI Spring Symposium on Emotion, Personality and Social Behavior},
file = {::},
keywords = {Technical Report SS-08-04},
title = {{Mental Health Promotion with Animated Characters : Exploring Issues and Potential}},
year = {2008}
}
@inproceedings{Lisetti2012a,
abstract = {We discuss the design and implementation of the prototype of an avatar-based health system aimed at providing people access to an effective behavior change intervention which can help them to find and cultivate motivation to change unhealthy lifestyles. An empathic Embodied Conversational Agent (ECA) delivers the intervention. The health dialog is directed by a computational model of Motivational Interviewing, a novel effective face-to-face patient-centered counseling style which respects an individual’s pace toward behavior change. Although conducted on a small sample size, results of a preliminary user study to asses users’ acceptance of the avatar counselor indicate that the system prototype is well accepted by 75\% of users.},
address = {Miami, FL, US},
author = {Lisetti, Christine L and Yasavur, Ugan and Leon, Claudia De and Amini, Reza and Rishe, Napthali},
booktitle = {Preceeding of FLAIRS'2012 Association for the Advancement of Artificial Intelligence (www.aaai.org)},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lisetti et al. - 2012 - Building an On-demand Avatar-based Health Intervention for Behavior Change(5).pdf:pdf},
number = {Mi},
title = {{Building an On-demand Avatar-based Health Intervention for Behavior Change}},
year = {2012}
}
@inproceedings{Bickmore2007,
abstract = {Interactions in which computer agents comfort users through expressed empathy have been shown to be important in alleviating user frustration and increasing user liking of the agent, and may have important healthcare applications. Given the current state of technology, designers of these systems are forced to choose between (a) allowing users to freely express their feelings, but having the agents provide imperfect empathic responses, or (b) greatly restricting how users can express themselves, but having the agents provide very accurate empathic feedback. This study investigates which of these options leads to better outcomes, in terms of comforting users and increasing user-agent social bonds. Results, on almost all measures, indicate that empathic accuracy is more important than user expressivity.},
address = {San Jose, California, USA},
author = {Bickmore, Timothy W. and Schulman, Daniel},
booktitle = {Preceeding of ACM CHI 2007 Conference on Human Factors in Computing Systems},
doi = {10.1145/1240866.1240996},
file = {::},
isbn = {9781595936424},
keywords = {affective computing,caring,comforting,embodied conversational agent,relational agent,social interface},
pages = {2291--2296},
publisher = {ACM},
title = {{Practical approaches to comforting users with relational agents}},
url = {http://dl.acm.org/citation.cfm?id=1240996},
year = {2007}
}
@inproceedings{Hartmann2005,
abstract = {To increase the believability and life-likeness of Embodied Conversational Agents (ECAs), we introduce a behavior syn- thesis technique for the generation of expressive gesturing. A small set of dimensions of expressivity is used to char- acterize individual variability of movement. We empirically evaluate our implementation in two separate user studies. The results suggest that our approach works well for a sub- set of expressive behavior. However, animation fidelity is not high enough to realize subtle changes. Interaction effects between different parameters need to be studied further.},
address = {Utrecht, Netherlands},
author = {Hartmann, B and Mancini, M and Buisine, S. and Pelachaud, Catherine},
booktitle = {4th International Joint Conference on Autonomous Agents and Multi Agent Systems (AAMAS'05)},
doi = {10.1145/1082473.1082640},
file = {::},
isbn = {1595930949},
keywords = {embodied conversational agents},
pages = {1095--1096},
publisher = {ACM},
title = {{Design and evaluation of expressive gesture synthesis for embodied conversational agents}},
url = {http://dl.acm.org/citation.cfm?id=1082640},
year = {2005}
}
@article{Gratch2007a,
author = {Gratch, Jonathan and Wang, Ning and Gerten, Jillian and Fast, Edward},
file = {::},
journal = {Intelligent Virtual Agents},
keywords = {evaluation,rapport,virtual agents},
title = {{Creating rapport with virtual agents}},
url = {http://www.springerlink.com/index/X568357400058UM7.pdf},
year = {2007}
}
@article{Dimeff2000,
author = {Dimeff, Linda A. and McNeely, Marguerite},
doi = {10.1016/S1077-7229(00)80010-3},
issn = {10777229},
journal = {Cognitive and Behavioral Practice},
month = dec,
number = {1},
pages = {82--100},
title = {{Computer-enhanced primary care practitioner advice for high-risk college drinkers in a student primary health-care setting}},
url = {http://dx.doi.org/10.1016/S1077-7229(00)80010-3},
volume = {7},
year = {2000}
}
@article{Drapeau2009,
abstract = {Persons with dementia of the Alzheimer type (DAT) are impaired in recognizing emotions from face and voice. Yet clinical practitioners use these mediums to communicate with DAT patients. Music is also used in clinical practice, but little is known about emotional processing from music in DAT. This study aims to assess emotional recognition in mild DAT. Seven patients with DAT and 16 healthy elderly adults were given three tasks of emotional recognition for face, prosody, and music. DAT participants were only impaired in the emotional recognition from the face. These preliminary results suggest that dynamic auditory emotions are preserved in DAT.},
author = {Drapeau, Joanie and Gosselin, Nathalie and Gagnon, Lise and Peretz, Isabelle and Lorrain, Dominique},
doi = {10.1111/j.1749-6632.2009.04768.x},
file = {::},
issn = {1749-6632},
journal = {Annals of the New York Academy of Sciences},
keywords = {Aged,Alzheimer Disease,Alzheimer Disease: physiopathology,Alzheimer Disease: psychology,Emotions,Face,Female,Humans,Male,Music,Recognition (Psychology),Recognition (Psychology): physiology,Voice},
month = jul,
pages = {342--5},
pmid = {19673804},
title = {{Emotional recognition from face, voice, and music in dementia of the Alzheimer type.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19673804},
volume = {1169},
year = {2009}
}
@inproceedings{Amini2012,
abstract = {In this article, we present HapFACS 1.0, a new software/API for generating static and dynamic three-dimensional facial expressions based on the Facial Action Coding System (FACS). HapFACS pro- vides total control over the FACS Action Units (AUs) activated at all levels of intensity. HapFACS allows generating faces with an individual AU or composition of AUs activated unilaterally or bilat- erally with different intensities. The reliable and emotionally valid facial expressions can be generated on inﬁnite number of faces in different ethnicities, genders, and ages using HapFACS to be used in numerous scientiﬁc areas including psychology, emotion, FACS learning, clinical, and neuroscience research.},
address = {Vienna, AUSTRIA},
author = {Amini, Reza and Yasavur, U and Lisetti, Christine L},
booktitle = {Proceedings of the ACM 3rd International Symposium on Facial Analysis and Animation (FAA'12)},
file = {::},
publisher = {ACM Press},
title = {{HapFACS 1.0: Software/API for Generating FACS-Based Facial Expressions}},
url = {http://ascl.cis.fiu.edu/uploads/1/3/4/2/13423859/amini-faa-2012.pdf},
year = {2012}
}
@book{Goldstein1985,
author = {Goldstein, Arnold P. and Michaels, Gerald Y.},
edition = {1},
isbn = {089859538X},
pages = {304},
publisher = {Hillsdale, N.J. : L. Erlbaum Associates},
title = {{Empathy: development, training, and consequences}},
year = {1985}
}
@article{Fehr1984,
author = {Fehr, B. and Russell, S.J.},
journal = {Journal of experimental psychology. General},
pages = {464 -- 486},
title = {{Concept of emotion viewed from a prototype perspective}},
volume = {113},
year = {1984}
}
@article{Heimgartner2011,
author = {Heimg\"{a}rtner, R\"{u}diger and Tiede, L.W. and Windl, Helmut},
file = {::},
journal = {Design, User Experience, and Usability. Theory, Methods, Tools and Practice},
keywords = {1 problems in hci,communication,cultural differences,culture,design caused by cultural,designing the functionality and,differences,empathy,intercultural communication,intercultural hci design,much cultural background has,to be considered when,understanding},
pages = {557--566},
publisher = {Springer},
title = {{Empathy as Key Factor for Successful Intercultural HCI Design}},
url = {http://www.springerlink.com/index/FG03081276H7K042.pdf},
year = {2011}
}
@inproceedings{Schipor2011,
author = {Schipor, O.A. and Pentiuc, S.G. and Schipor, M.D.},
booktitle = {Speech Technology and Human-Computer Dialogue (SpeD), 2011 6th Conference on},
file = {::},
isbn = {9781457704413},
keywords = {-computer assisted,multimodal interfaces,recognition},
pages = {1--6},
publisher = {IEEE},
title = {{Towards a multimodal emotion recognition framework to be integrated in a Computer Based Speech Therapy System}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5940727},
year = {2011}
}
@inproceedings{Courgeon2008,
abstract = {Designing affective user interfaces involving expressive characters raises several questions. The system should be able to display facial expressions of complex emotions as dynamic and realtime reactions to user’s inputs. From a cognitive point of view, designers need to know how the user will perceive the dynamics of these facial expressions as a function of his/her input. We aim at evaluating if users can perceive different expressive profiles of a virtual character by manually controlling its expressions and observing its reaction to his/her input. This paper describes our platform that enables a virtual character to display blended facial expressions of emotions as realtime continuous reactions to users’ gesture input. We explain the techniques underlying the computation of intermediate facial expressions of emotion, and their control in the 3D space PAD (Pleasure, Arousal, Dominance) using gesture input. Preliminary results of a perceptive study show the potential of such an approach for assessing the dynamics of the perception of emotional expressions during gesture interaction with virtual characters endowed with different expressive profiles.},
address = {Estoril, Portugal},
annote = {The user reports his/her affective state in real-time with changing the position of a 3D point in PAD space using a joystick. The system captures the position of that point and maps it to a blend of 8 selected emotions. },
author = {Courgeon, Matthieu and Martin, Jean-claude and Jacquemin, Christian},
booktitle = {AAMAS '08 Proceedings of the 7th international joint conference on Autonomous agents and multiagent systems - Volume 3},
doi = {10.1.1.149.8130},
editor = {Padgham and Parkes and M\"{u}ller and Parsons},
file = {::},
keywords = {Expressive agent,facial expressions,realtime interaction},
number = {Aamas},
pages = {1237--1240},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
title = {{User’s Gestural Exploration of Different Virtual Agents ’ Expressive Profiles (Short Paper)}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.149.8130},
year = {2008}
}
@book{Fussell2002a,
author = {Fussell, S.R.},
file = {::},
isbn = {0805836896},
publisher = {Lawrence Erlbaum},
title = {{The verbal communication of emotions: Interdisciplinary perspectives}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=p3M13y2yfwMC\&amp;oi=fnd\&amp;pg=PP1\&amp;dq=The+Verbal+Communication+of+Emotions\&amp;ots=btc4zGRJN4\&amp;sig=16kr5bEkJhKg\_zO6ond9vkI4uLY},
year = {2002}
}
@inproceedings{Boukricha2009,
abstract = {a system for simulating emotional facial expressions for a virtual human has been evolved. This system consists of two parts: (1) a control ar- chitecture for simulating emotional facial expressions with respect to Pleasure, Arousal, and Dominance (PAD) val- ues, (2) an expressive output component for animating the virtual human’s facial muscle actions called Action Units (AUs), modeled following the Facial Action Coding Sys- tem (FACS). A large face repertoire of about 6000 faces arranged in PAD-space with respect to two dominance val- ues (dominant vs. submissive) is obtained as a result of the empirical study. Using the face repertoire an approach to- wards realizing facial mimicry for a virtual human based on backward mapping AUs displaying an emotional facial expression on PAD-values is outlined.},
annote = {- For automatic recognition, the mapping of AUs to PAD may be only useful once you can identify the active AUs and their intensity on the face (which you won't be able with image processing teckniques).
- For the expression, if you have an avatar which has control on the AUs, you don’t need to map the AUs to PAD. But, if you have an avatar which expresses based on PAD, then this mapping is useful. 
- Mapping of AUs to PAD is helpful when you want to fuse multiple modalities where other modalities are in PAD values. },
author = {Boukricha, Hana and Wachsmuth, Ipke and Hofstatter, A. and Grammer, Karl},
booktitle = {Affective Computing and Intelligent Interaction and Workshops, 2009. ACII 2009. 3rd International Conference on},
file = {::},
isbn = {9781424447992},
pages = {1--7},
publisher = {IEEE},
title = {{Pleasure-arousal-dominance driven facial expression simulation}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5349579},
year = {2009}
}
@article{Brave2005,
author = {Brave, Scott and Nass, Clifford and Hutchinson, Kevin},
doi = {10.1016/j.ijhcs.2004.11.002},
file = {::},
issn = {10715819},
journal = {International Journal of Human-Computer Studies},
keywords = {affective computing,characters,embodied agents,emotion,empathy,social interfaces},
month = feb,
number = {2},
pages = {161--178},
title = {{Computers that care: investigating the effects of orientation of emotion exhibited by an embodied computer agent}},
volume = {62},
year = {2005}
}
@article{Rogers1957,
author = {Rogers, C R},
editor = {Kirschenbaum, H},
isbn = {9780395483572},
issn = {00958891},
journal = {Journal of Consulting Psychology},
number = {2},
pages = {95--103},
pmid = {13416422},
publisher = {Houghton Mifflin},
title = {{The necessary and sufficient conditions of therapeutic personality change}},
volume = {21},
year = {1957}
}
@article{Poh2010,
author = {Poh, MZ and McDuff, DJ},
file = {::},
journal = {Optics Express},
number = {10},
pages = {10762--10774},
title = {{Non-contact, automated cardiac pulse measurements using video imaging and blind source separation}},
volume = {18},
year = {2010}
}
@article{Luo2012,
abstract = {Web-based personal health records (PHRs) are being widely deployed. To improve PHR's capability and usability, we proposed the concept of intelligent PHR (iPHR). In this paper, we use automatic home medical product recommendation as a concrete application to demonstrate the benefits of introducing intelligence into PHRs. In this new application domain, we develop several techniques to address the emerging challenges. Our approach uses treatment knowledge and nursing knowledge, and extends the language modeling method to (1) construct a topic-selection input interface for recommending home medical products, (2) produce a global ranking of Web pages retrieved by multiple queries, and (3) provide diverse search results. We demonstrate the effectiveness of our techniques using USMLE medical exam cases.},
author = {Luo, Gang and Thomas, Selena B and Tang, Chunqiang},
doi = {10.1007/s10916-010-9483-2},
file = {:X$\backslash$:/Papers/Recommender Systems/device.pdf:pdf},
issn = {0148-5598},
journal = {Journal of medical systems},
keywords = {health record,home medical product,language model,nursing knowledge,personal,search engine},
month = apr,
number = {2},
pages = {383--98},
pmid = {20703712},
title = {{Automatic home medical product recommendation.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20703712},
volume = {36},
year = {2012}
}
@article{Russell1980,
abstract = {Factor-analytic evidence has led most psychologists to describe affect as a set of dimensions, such as displeasure, distress, depression, excitement, and so on, with each dimension varying independently of the others. However, there is other evidence that rather than being independent, these affective dimensions are interrelated in a highly systematic fashion. The evidence suggests that these interrelationships can be represented by a spatial model in which affective concepts fall in a circle in the following order: pleasure (0), excitement (45), arousal (90), distress (135), displeasure (180), depression (225), sleepiness (270), and relaxation (315). This model was offered both as a way psychologists can represent the structure of affective experience, as assessed through self-report, and as a representation of the cognitive structure that laymen utilize in conceptualizing affect. Supportive evidence was obtained by scaling 28 emotion-denoting adjectives in 4 different ways: R. T. Ross's (1938) technique for a circular ordering of variables, a multidimensional scaling procedure based on perceived similarity among the terms, a unidimensional scaling on hypothesized pleasure–displeasure and degree-of-arousal dimensions, and a principal-components analysis of 343 Ss' self-reports of their current affective states. (70 ref) (PsycINFO Database Record (c) 2010 APA, all rights reserved)},
author = {Russell, James A},
doi = {10.1037/h0077714},
file = {::},
journal = {Journal of Personality and Social Psychology},
number = {6},
pages = {1161--1178},
title = {{A circumplex model of affect}},
url = {http://psycnet.apa.org/psycinfo/1981-25062-001},
volume = {39},
year = {1980}
}
@phdthesis{Lisetti2011,
author = {Lisetti, Christine L},
school = {Florida International University},
title = {{What Kind of Emotions Are There? Structure of Emotion}},
type = {Lecture},
year = {2011}
}
@article{Watson1985,
abstract = {Reanalyses of 7 studies of self-reported mood by researchers such as M. A. Lebo and J. R. Nesselroade (see record 1979-30118-001) and J. A. Russell and D. Ridgeway (see record 1984-03807-001) indicate that Positive Affect and Negative Affect consistently emerge as the 1st 2 varimax rotated dimensions in orthogonal factor analyses or as the 1st 2 2nd-order factors derived from oblique solutions. The 2 factors emerged with varying sets of descriptors and were even replicated in several data sets characterized by possible methodological problems (e.g., acquiescence response bias, inappropriate response formats) noted by earlier authors. The results thus attest to the stability and robustness of Positive and Negative Affect in self-report. Because this same 2-dimensional configuration has also been consistently identified in most other major lines of mood research, it is now firmly established as the basic structure of English-language affect at the general factor level.},
author = {Watson, D and Tellegen, A},
journal = {Psychological Bulletin},
number = {2},
pages = {219--235},
pmid = {3901060},
publisher = {bepress},
title = {{Toward a consensual structure of mood.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/3901060},
volume = {98},
year = {1985}
}
@phdthesis{Tatar1998,
author = {Tatar, D.},
school = {Stanford University},
title = {{Social and Personal Effects of Preoccupied Listeners}},
type = {Thesis},
year = {1998}
}
@inproceedings{Wang2010,
address = {Atlanta, GA, USA},
author = {Wang, Ning and Gratch, Jonathan},
booktitle = {CHI},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - p1241-wang.pdf(6).pdf:pdf},
pages = {1241--1249},
title = {{Don't just stare at me.pdf}},
year = {2010}
}
@article{Eisenberg1983,
abstract = {Reviews the literature on sex differences in empathy (defined as vicarious affective responding to the emotional state of another) and related capacities (affective role taking and decoding of nonverbal cues). The literature is discussed according to method used to assess empathy and affective role taking. Where appropriate, meta-analyses were also computed. In general, sex differences in empathy were found to be a function of the methods used to assess empathy. There was a large sex difference favoring women when the measure of empathy was self-report scales; moderate differences (favoring females) were found for reflexive crying and self-report measures in laboratory situations; and no sex differences were evident when the measure of empathy was either physiological or unobtrusive observations of nonverbal reactions to another's emotional state. Moreover, few sex differences were found for children's affective role taking and decoding abilities. (156 ref) (PsycINFO Database Record (c) 2006 APA, all rights reserved), (C) 1983 by the American Psychological Association},
author = {Eisenberg, Nancy and Lennon, Randy},
issn = {19391455},
journal = {Psychological Bulletin},
number = {1},
pages = {100--131},
title = {{Sex Differences in Empathy and Related Capacities}},
volume = {94},
year = {1983}
}
@inproceedings{Lisetti2008a,
author = {Lisetti, Christine L and Wagner, Eric},
booktitle = {Proceedings of the AAAI Spring Symposium on Emotion, Personality and Social Behavior},
file = {::},
keywords = {Technical Report SS-08-04},
title = {{Mental Health Promotion with Animated Characters : Exploring Issues and Potential}},
year = {2008}
}
@article{Jacob2011,
author = {Jacob, Pierre},
doi = {10.1007/s13164-011-0065-0},
file = {::},
issn = {1878-5158},
journal = {Review of Philosophy and Psychology},
month = aug,
number = {August},
pages = {519--540},
title = {{The Direct-Perception Model of Empathy: a Critique}},
url = {http://www.springerlink.com/index/10.1007/s13164-011-0065-0},
year = {2011}
}
@inproceedings{Wang2010,
address = {Atlanta, GA, USA},
author = {Wang, Ning and Gratch, Jonathan},
booktitle = {CHI},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - p1241-wang.pdf(6).pdf:pdf},
pages = {1241--1249},
title = {{Don't just stare at me.pdf}},
year = {2010}
}
@article{Hatfield2009,
author = {Hatfield, Elaine and Rapson, Richard L. and Le, Yen-Chi L.},
file = {::},
journal = {The social neuroscience of empathy},
pages = {1--20},
title = {{Emotional Contagion and Empathy}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=KLvJKTN\_nDoC\&amp;oi=fnd\&amp;pg=PA19\&amp;dq=Emotional+Contagion+and+Empathy\&amp;ots=gC929Xij3X\&amp;sig=IFpRxpx1igOlZl86Jr837oVgfhY},
year = {2009}
}
@article{Matthews1993,
abstract = {Healers must try to understand what the illness means to the patient and create a therapeutic sense of connection in the patient-clinician relationship. A favorable climate for "connexional" experiences can be created through the use of various interviewing techniques. Attending to rapport, silencing internal talk, accessing unconscious processes, and communicating understanding can help clinicians enhance their sensitivity to the subtle clues on which issues of meaning and connection often depend. Several risks are associated with the establishment of closer patient-clinician relationships, including dependence and power issues, sexual attraction, and deeper exposure of the clinician to the patient's pain. Prepared with an awareness of these risks and techniques to address them, clinicians are encouraged to deepen their level of dialogue with patients, to compare their experiences with those of other clinicians, and to thereby develop a more systematic understanding of therapeutic relationships.},
author = {Matthews, D A and Suchman, A L and Branch, W T},
institution = {National Center for Chronic Fatigue, Arlington, Virginia.},
journal = {Annals of Internal Medicine},
keywords = {professional patient relationship},
number = {12},
pages = {973--977},
pmid = {8489112},
title = {{Making "connexions": enhancing the therapeutic potential of patient-clinician relationships.}},
volume = {118},
year = {1993}
}
@article{Caridakis2008,
abstract = {As input they consider the image sequence of the recorded human behavior. Computer vision and image processing techniques are incorporated in order to detect cues needed for expressivity features extraction. Using multimodalities, the virtual agent mimics the human expressions. The multimodality of the approach lies in the fact that both facial and gestural aspects of the user’s behavior are analyzed and processed. The mimicry consists of perception, interpretation, planning and animation of the expressions shown by the human, resulting not in an exact duplicate rather than an expressive model of the user’s original behavior.},
annote = {They use both facial and gestural aspects of the user’s behavior to mimic the user’s expressions. The introductory information and references about the psychological background of the mimicry in the paper are useful. But because most of the work is image processing, other sections would not be useful for our job.
Their system does not work in real time because they use a recorded video or sequence of images (limitation).},
author = {Caridakis, George and Raouzaiou, Amaryllis and Bevacqua, Elisabetta and Mancini, Maurizio and Karpouzis, Kostas and Malatesta, Lori and Pelachaud, Catherine},
doi = {10.1007/s10579-007-9057-1},
file = {::},
issn = {1574-020X},
journal = {International Language Resources and Evaluation Journal: Special issue on Multimodal Corpora For Modelling Human Multimodal Behavior},
keywords = {facial,gesture,mimicry,multimodal,virtual agent},
month = jan,
number = {3-4},
pages = {367--388},
title = {{Virtual agent multimodal mimicry of humans}},
volume = {41},
year = {2008}
}
@inproceedings{Broek2005,
abstract = {A new view on empathic agents is introduced, named: Empathic Agent Technology (EAT). It incorporates a speech analysis, which provides an indication for the amount of tension present in people. It is founded on an indirect physiological measure for the amount of experienced stress, defined as the variability of the fundamental frequency of the human voice. A thorough review of literature is provided on which the EAT is founded. In addition, the complete processing line of this measure is introduced. Hence, the first generally applicable, completely automated technique is introduced that enables the development of truly empathic agents.},
address = {Utrecht – The Netherlands},
author = {van den Broek, E. L.},
booktitle = {Proceedings of the AAMAS-05 Agent-Based Systems for Human Learning workshop (ABSHL 2005)},
editor = {Johnson, L. and Richards, D. and Sklar, E. and Wilensky, U.},
keywords = {affect,agents,emotion,empathy,fundamental frequency,pitch,speech,stress},
pages = {59--67},
publisher = {Brooklyn College},
title = {{Empathic agent technology}},
url = {http://eprints.eemcs.utwente.nl/21142/},
year = {2005}
}
@article{Pereira2011,
author = {Pereira, A. and Leite, Iolanda and Mascarenhas, Samuel and Martinho, Carlos and Paiva, Ana},
file = {::},
journal = {Human-Robot Personal Relationships},
keywords = {companionship,empathy,human-robot interaction},
pages = {130--138},
publisher = {Springer},
title = {{Using empathy to improve human-robot relationships}},
url = {http://www.springerlink.com/index/R468X62581620V62.pdf},
volume = {59},
year = {2011}
}
@article{Behrend2011,
abstract = {In this study, trainees worked with computerized trainer agents that were either similar to them or different regarding appearance or feedback-giving style. Similarity was assessed objectively, based on appearance and feedback style matching, and subjectively, based on participants’ self-reported perceptions of similarity. Appearance similarity had few effects. Objective feedback similarity led to higher scores on a declarative knowledge test and higher liking for the trainer. Subjective feedback similarity was related to reactions, engagement, and liking for the trainer. Overall, results indicated that subjective similarity is more important in predicting training outcomes than objective similarity, and that surfacelevel similarity is less important than deep-level similarity. These results shed new light on the dynamics between e-learners and trainer agents, and inform the design of agent-based training.},
author = {Behrend, Tara S. and Thompson, Lori Foster},
doi = {10.1016/j.chb.2010.12.016},
file = {::},
issn = {07475632},
journal = {Computers in Human Behavior},
keywords = {Intelligent agents Similarity-attraction E-learnin},
month = may,
number = {3},
pages = {1201--1206},
publisher = {Elsevier Ltd},
title = {{Similarity effects in online training: Effects with computerized trainer agents}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0747563211000033},
volume = {27},
year = {2011}
}
@article{Gratch2007,
annote = {They explore the rapport, a feeling of connectedness that arises from rapid and contingent positive feedback between partners and is often associated with socio-emotional processes. Rapport can lead to communicative efficiency, better learning outcomes, improved acceptance of medical advice and successful negotiations.
They experimentally proved that a simple virtual character with positive listening feedback can induce stronger rapport-like effects than face-to-face communication between human partners.},
author = {Gratch, Jonathan and Wang, Ning and Okhmatovskaia, Anna},
file = {::},
journal = {conference on Human-},
title = {{Can virtual humans be more engaging than real ones?}},
url = {http://dl.acm.org/citation.cfm?id=1769622},
year = {2007}
}
@article{Chung,
author = {Chung, Donghun and DeBuys, B. and Nam, C.},
file = {::},
journal = {Human-Computer Interaction. Interaction Design and Usability},
keywords = {attitude,avatar,empathy,para-social interaction,presence,wii},
pages = {711--720},
publisher = {Springer},
title = {{Influence of avatar creation on attitude, empathy, presence, and para-social interaction}},
url = {http://www.springerlink.com/index/9518116J51670433.pdf},
year = {2007}
}
@article{Steunebrink2011,
abstract = {[1] B. R. Steunebrink, M. Dastani, and J.-J. C. Meyer, “A formal model of emotion triggers: an approach for BDI agents,” Synthese, vol. 185, no. S1, pp. 83–129, Sep. 2011.},
author = {Steunebrink, Bas R. and Dastani, Mehdi and Meyer, John-Jules Ch.},
doi = {10.1007/s11229-011-0004-8},
file = {::},
isbn = {1122901100},
issn = {0039-7857},
journal = {Synthese},
keywords = {cognitive modeling,intelligent agents,logic of emotions},
month = sep,
number = {S1},
pages = {83--129},
title = {{A formal model of emotion triggers: an approach for BDI agents}},
url = {http://www.springerlink.com/index/10.1007/s11229-011-0004-8},
volume = {185},
year = {2011}
}
@inproceedings{Steunebrink2009,
author = {Steunebrink, B.R. and Dastani, Mehdi and Meyer, J.J.C.},
booktitle = {Proceedings of the 4th Workshop on Emotion and Computing},
file = {::},
title = {{The OCC model revisited}},
url = {http://www.idsia.ch/~steunebrink/Publications/KI09\_OCC\_revisited.pdf},
year = {2009}
}
@article{DiClemente2001,
abstract = {OBJECTIVE: To offer a taxonomy of types of feedback and describe potential mechanisms of action particularly in the area of addictive behaviors. METHOD: Reviewed the literature to examine support for types-Generic, Targeted, and Personalized-and for mechanisms of feedback. RESULTS: Although it is not clear how it works, feedback is thought to offer important information, to create a sense of caring and helping relationship, to reach more directly decisional considerations, to increase engagement in the materials, to increase motivation, or to provide social comparison and norms. CONCLUSIONS: Avenues for future research in search of the most effective manner of using feedback to promote health behavior change are discussed.},
author = {DiClemente, C C and Marinilli, A S and Singh, M and Bellino, L E},
institution = {Psychology Department, University of Maryland, Baltimore County, Baltimore 21250, USA. diclemen@umbc.edu},
journal = {American Journal of Health Behavior},
keywords = {addictive,addictive prevention \& control,addictive psychology,behavior,classification,feedback,health behavior,health education,health education classification,humans,mass screening,models,psychological,risk taking},
number = {3},
pages = {217--227},
pmid = {11322620},
publisher = {PNG Publications},
title = {{The role of feedback in the process of health behavior change.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11322620},
volume = {25},
year = {2001}
}
@article{Cassell1999,
author = {Cassell, Justine and Thorisson, K.R.},
file = {::},
journal = {Applied Artificial Intelligence},
number = {4-5},
pages = {519--538},
publisher = {Taylor \& Francis},
title = {{The power of a nod and a glance: Envelope vs. emotional feedback in animated conversational agents}},
url = {http://www.tandfonline.com/doi/abs/10.1080/088395199117360},
volume = {13},
year = {1999}
}
@article{Ochs2010,
author = {Ochs, Magalie and Sadek, David and Pelachaud, Catherine},
doi = {10.1007/s10458-010-9156-z},
file = {::},
issn = {1387-2532},
journal = {Autonomous Agents and Multi-Agent Systems},
keywords = {affective computing,dialog,emotions,empathy,rational dialog agent},
month = nov,
title = {{A formal model of emotions for an empathic rational dialog agent}},
url = {http://www.springerlink.com/index/10.1007/s10458-010-9156-z},
year = {2010}
}
@article{Hingson2005,
author = {Hingson, Ralph and Heeren, Timothy and Winter, Michael and Wechsler, Henry},
journal = {Journal of Studies on Alcohol and Drugs},
pages = {12--20},
title = {{MAGNITUDE OF ALCOHOL-RELATED MORTALITY AND MORBIDITY AMONG U.S. COLLEGE STUDENTS AGES 18–24: Changes from 1999 to 2005}},
url = {http://www.jsad.com/},
volume = {16},
year = {2009}
}
@article{Neiberg2006,
author = {Neiberg, Daniel and Elenius, Kjell and Karlsson, Inger},
file = {::},
journal = {Working Papers of Lund University, Centre for Languages \& Literature, Dept. of Linguistics \& Phonetics},
pages = {101--104},
title = {{Emotion recognition in spontaneous speech}},
url = {http://nile.lub.lu.se/ojs/index.php/LWPL/article/viewFile/2306/1881},
volume = {52},
year = {2006}
}
@article{Rabiner1989,
author = {Rabiner, Lawrence R.},
file = {::},
journal = {Proceedings of the IEEE},
number = {2},
pages = {257--286},
title = {{A tutorial on hidden Markov models and selected applications in speech recognition}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=18626},
volume = {77},
year = {1989}
}
@article{Elliot2001,
author = {Elliot, Andrew J. and McGregor, holly A.},
file = {::},
journal = {Journal of Personality and Social Psychology},
number = {3},
pages = {501--519},
title = {{A 2 x 2 achievement goal framework.pdf}},
volume = {80},
year = {2001}
}
@article{Robison2010,
abstract = {affective interventions can both positively and negatively influence learning experiences. In this paper we investigate the role of student personality, including goal orienta- tion and empathetic tendencies, in estimating confidence in the benefits of an affective intervention strategy. The results indicate that student personality profiles can serve as a powerful tool for informing affective feedback models.},
annote = {We can use the same way of menu base self-report affective state recognition (in addition to automatic) and text-base empathic feedback. Then after each feedback we can evaluate the feedback with another user self-report.},
author = {Robison, Jennifer and Mcquiggan, Scott and Lester, James and Carolina, North},
file = {::},
keywords = {affect,affective computing,pedagogical agents},
pages = {285--295},
title = {{Developing Empirically Based Student Personality Profiles for Affective Feedback Models}},
year = {2010}
}
@article{Riek2008,
abstract = {Expressing empathy is a key component of human social communication. One common way people convey empathy is via facial expression mirroring. It may be helpful for machines intended to interact with people to also convey empathy in this manner. We have thus created Virgil, an expression-mimicking robot. We hypothesize that if people feel like a machine is empathizing with them they will be more likely to rate the interaction positively. We conducted a pilot study to test our hypothesis, and through quantitative and qualitative analysis of our results found some support for it.},
author = {Riek, Laurel D. and Robinson, Peter},
file = {::},
journal = {ACM Workshop on Affective Interaction in Natural Environments AFFINE at the International ACM Conference on Multimodal Interfaces ICMI 08},
pages = {1--5},
publisher = {ACM},
title = {{Real-time empathy: Facial mimicry on a robot}},
year = {2008}
}
@incollection{Tomkins1984,
address = {Hillsdale, NJ},
author = {Tomkins, S S},
booktitle = {Approaches to emotion},
editor = {Scherer, Klaus R and Ekman, Paul},
isbn = {0898594065},
pages = {163--195},
publisher = {Erlbaum},
title = {{Affect theory}},
volume = {163},
year = {1984}
}
@inproceedings{Lisetti2012,
address = {Miami, FLorida},
author = {Lisetti, Christine L},
booktitle = {IHI2012 International Health Informatics Sysmposium},
file = {::},
title = {{10 Advantages of using Avatars in Patient-Centered Computer-based Interventions for Behavior Change}},
year = {2012}
}
@article{Gruen1986,
author = {Gruen, Rand J. and Mendelsohn, Gerald},
doi = {10.1037/0022-3514.51.3.609},
file = {::},
issn = {1939-1315},
journal = {Journal of Personality and Social Psychology},
number = {3},
pages = {609--614},
title = {{Emotional responses to affective displays in others: The distinction between empathy and sympathy.}},
volume = {51},
year = {1986}
}
@article{Riek2009,
author = {Riek, Laurel D. and Paul, Philip C. and Robinson, Peter},
doi = {10.1007/s12193-009-0028-2},
file = {::},
issn = {1783-7677},
journal = {Journal on Multimodal User Interfaces},
keywords = {19,affective computing,emotionally conveying,empathy,expressions,facial,forms of expressive empathy,human-robot interaction,is known as,of the most basic,one,social robotics,understand what others are},
month = nov,
number = {1-2},
pages = {99--108},
title = {{When my robot smiles at me: Enabling human-robot rapport via real-time head gesture mimicry}},
url = {http://www.springerlink.com/index/10.1007/s12193-009-0028-2},
volume = {3},
year = {2009}
}
@book{Babor2001,
abstract = {This manual introduces the AUDIT, the Alcohol Use Disorders Identification Test, and describes how to use it to identify persons with hazardous and harmful patterns of alcohol consumption. The AUDIT was developed by the World Health Organization (WHO) as a simple method of screening for excessive drinking and to assist in brief assessment. It can help in identifying excessive drinking as the cause of the presenting illness. It also provides a framework for intervention to help hazardous and harmful drinkers reduce or cease alcohol consumption and thereby avoid the harmful consequences of their drinking. The first edition of this manual was published in 1989 (Document No. WHO/MNH/DAT/89.4) and was subsequently updated in 1992 (WHO/PSA/92.4). Since that time it has enjoyed widespread use by both health workers and alcohol researchers. With the growing use of alcohol screening and the international popularity of the AUDIT, there was a need to revise the manual to take into account advances in research and clinical experience. This manual is written primarily for health care practitioners, but other professionals who encounter persons with alcohol-related problems may also find it useful. It is designed to be used in conjunction with a companion document that provides complementary information about early intervention procedures, entitled “Brief Intervention for Hazardous and Harmful Drinking: A Manual for Use in Primary Care”. Together these manuals describe a comprehensive approach to screening and brief intervention for alcohol-related problems in primary health care.},
author = {Babor, Thomas F. and Higgins-Biddle, John C. and Saunders, John B. and Monteiro, Maristela G.},
edition = {2},
pages = {39},
publisher = {World Health Organization, Department of Mental Health and Substance Dependence},
title = {{AUDIT: The Alcohol Use Disorders Identification Test. Guidelines for use in primary health care}},
year = {2001}
}
@article{Vanbaaren2004,
author = {Van baaren, Rick B. and Holland, Rob W. and Kawakami, Kerry and Knippenberg, Ad Van},
doi = {10.1111/j.0963-7214.2004.01501012.x},
file = {::},
issn = {0956-7976},
journal = {Psychological Science},
month = jan,
number = {1},
pages = {71--74},
title = {{Mimicry and Prosocial Behavior}},
url = {http://pss.sagepub.com/lookup/doi/10.1111/j.0963-7214.2004.01501012.x},
volume = {15},
year = {2004}
}
@book{Dennett1987,
author = {Dennett, D C},
booktitle = {Technology},
publisher = {MIT Press},
title = {{The Intentional Stance}},
year = {1987}
}
@article{Wu2008,
author = {Wu, Siew-Rong},
doi = {10.1109/DIGITEL.2008.27},
file = {::},
isbn = {978-0-7695-3409-1},
journal = {2008 Second IEEE International Conference on Digital Game and Intelligent Toy Enhanced Learning},
pages = {213--214},
publisher = {Ieee},
title = {{Humor and Empathy: Developing Students' Empathy through Teaching Robots to Tell English Jokes}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4700764},
year = {2008}
}
@article{Zhang2009,
abstract = {This paper presents a new anthropometrics-based method for generating realistic, controllable face models. Our method establishes an intuitive and efficient interface to facilitate procedures for interactive 3D face modeling and editing. It takes 3D face scans as examples in order to exploit the variations presented in the real faces of individuals. The system automatically learns a model prior from the data-sets of example meshes of facial features using principal component analysis (PCA) and uses it to regulate the naturalness of synthesized faces. For each facial feature, we compute a set of anthropometric measurements to parameterize the example meshes into a measurement space. Using PCA coefficients as a compact shape representation, we formulate the face modeling problem in a scattered data interpolation framework which takes the user-specified anthropometric parameters as input. Solving the interpolation problem in a reduced subspace allows us to generate a natural face shape that satisfies the user-specified constraints. At runtime, the new face shape can be generated at an interactive rate.We demonstrate the utility of our method by presenting several applications, including analysis of facial features of subjects in different race groups, facial feature transfer, and adapting face models to a particular population group.},
author = {Zhang, Yu and Prakash, Edmond C.},
doi = {10.1155/2009/573924},
file = {::},
issn = {1687-7047},
journal = {International Journal of Computer Games Technology},
pages = {1--15},
title = {{Face to Face: Anthropometry-Based Interactive Face Shape Modeling Using Model Priors}},
url = {http://www.hindawi.com/journals/ijcgt/2009/573924/},
volume = {2009},
year = {2009}
}
@inproceedings{Becker2005,
abstract = {This paper first describes two independently conducted research strands on affective human-computer interaction: one on an emotion simulation system for an expressive 3D humanoid agent called Max, which was designed at the University of Bielefeld; the other one on a real-time system for empathic (agent) feedback that is based on human emotional states derived from physiological information, and developed at the University of Tokyo and the National Institute of Informatics. Then, the integration of both systems is suggested for the purpose of realizing a highly believable agent with empathic qualities.},
address = {Takamatsu, Kagawa, Japan},
author = {Becker-Asano, Christian and Prendinger, Helmut and Ishizuka, M.},
booktitle = {Proceedings of the 2005 International Conference on Active Media Technology, 2005. (AMT 2005)},
doi = {10.1109/AMT.2005.1505417},
file = {::},
isbn = {0780390350},
keywords = {embodied conversational agents,empa-},
pages = {541 -- 545},
title = {{Empathy for Max}},
url = {http://www.techfak.uni-bielefeld.de/~cbecker/becker-helmut-amt05.pdf},
year = {2005}
}
@article{DiMatteo1980,
abstract = {The relationship between physicians' nonverbal communication skills (their ability to communicate and to understand facial expression, body movement and voice tone cues to emotion) and their patients' satisfaction with medical care was examined in 2 studies. The research involved 71 residents in internal medicine and 462 of their ambulatory and hospitalized patients. Standardized, reliable and valid measures of nonverbal communication skills were administered to the physicians. Their scores on these tests were correlated with ratings they received from a sample of their patients on measures of satisfaction with the technical aspects and the socioemotional aspects (or art) of the medical care they received. While the nonverbal communication skills of the physicians bore little relationship to patients' ratings of the technical quality of care, measures of these skills did predict patient satisfaction with the art of medical care received. Across both samples, physicians who were more sensitive to body movement and posture cues to emotion (the channel suggested by nonverbal researchers as the one in which true affect can be perceived) received higher ratings from their patients on the art of care than did less sensitive physicians. In addition, physicians who were successful at expressing emotion through their nonverbal communications tended to receive higher ratings from patients on the art of care than did physicians who were less effective communicators. The implications of successfully identifying characteristics of physicians with whom patients are satisfied are discussed.},
author = {DiMatteo, M R and Taranta, a and Friedman, H S and Prince, L M},
file = {::},
issn = {0025-7079},
journal = {Medical care},
keywords = {Adult,Consumer Satisfaction,Evaluation Studies as Topic,Female,Humans,Male,Nonverbal Communication,Physician-Patient Relations},
month = apr,
number = {4},
pages = {376--87},
pmid = {7401698},
title = {{Predicting patient satisfaction from physicians' nonverbal communication skills.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/7401698},
volume = {18},
year = {1980}
}
@article{Vannini2010,
abstract = {Bullying is widespread in European schools, despite multiple intervention strategies having been proposed over the years. The present study investigates the effects of a novel virtual learning strategy (“FearNot!”) to tackle bullying in both UK and German samples. The approach is intended primarily for victims to increase their coping skills and further to heighten empathy and defence of victims by non-involved bystanders. This paper focuses on the defender role. Applying quantitative as well as qualitative methodology, the present study found that “FearNot!” helped non-involved children to become defenders in the German sub-sample while it had no such effect in the UK sub-sample. German “New Defenders” (children who are initially uninvolved but are nominated as defenders by their peers after the intervention period) were found to be significantly more popular at baseline, and to show more cognitive empathy (Theory of Mind) for the virtual victims as compared to permanently non-involved pupils. Moreover, gender interacts with becoming a defender in its effects on affective empathy, with emotional contagion being particularly associated with New Defender status among girls. The findings are discussed in relation to previous research on anti-bullying intervention strategies and cultural differences in bullying prevalence rates and intervention outcomes.},
author = {Vannini, Natalie and Enz, Sibylle and Sapouna, Maria and Wolke, Dieter and Watson, Scott and Woods, Sarah and Dautenhahn, Kerstin and Hall, Lynne and Paiva, Ana and Andr\'{e}, Elizabeth and Aylett, Ruth and Schneider, Wolfgang},
doi = {10.1007/s10212-010-0035-4},
file = {::},
issn = {0256-2928},
journal = {European Journal of Psychology of Education},
month = jun,
number = {1},
pages = {21--44},
title = {{“FearNot!”: a computer-based anti-bullying-programme designed to foster peer intervention}},
url = {http://www.springerlink.com/index/10.1007/s10212-010-0035-4 http://dx.doi.org/10.1007/s10212-010-0035-4},
volume = {26},
year = {2010}
}
@article{Kissler2008,
abstract = {We investigated the effect of emotional target content on the generation of pro- and anti-saccades. Subjects had to generate saccades towards (pro-saccade) or away from (anti-saccade) peripherally presented pleasant, unpleasant or neutral pictures. Two different SOAs were used, either with simultaneous fixation offset and target onset (no gap) or with fixation offset preceding target onset by 200 ms (gap). In the pro-saccade task participants were faster to respond to emotional pictures in the left visual field. In the right visual field facilitation occurred only for pleasant pictures and saccadic reaction times towards unpleasant pictures were slowed. In the anti-saccade task more anti-saccade errors towards emotional pictures (pleasant and unpleasant) were made in the gap condition. On the whole, endogenous saccade generation appears facilitated by emotional target content, probably via increased input from extra-striate and parietal brain areas to the superior colliculus. Moderating factors such as the SOA or the visual field of presentation are discussed.},
author = {Kissler, Johanna and Keil, Andreas},
doi = {10.1007/s00221-008-1358-0},
file = {::},
issn = {1432-1106},
journal = {Experimental brain research. Experimentelle Hirnforschung. Exp\'{e}rimentation c\'{e}r\'{e}brale},
keywords = {Adult,Affect,Affect: physiology,Arousal,Arousal: physiology,Attention,Attention: physiology,Emotions,Emotions: physiology,Female,Fixation, Ocular,Fixation, Ocular: physiology,Functional Laterality,Functional Laterality: physiology,Humans,Male,Neuropsychological Tests,Orientation,Orientation: physiology,Parietal Lobe,Parietal Lobe: anatomy \& histology,Parietal Lobe: physiology,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Photic Stimulation,Reaction Time,Reaction Time: physiology,Saccades,Saccades: physiology,Signal Processing, Computer-Assisted,Superior Colliculi,Superior Colliculi: anatomy \& histology,Superior Colliculi: physiology,Visual Cortex,Visual Cortex: anatomy \& histology,Visual Cortex: physiology,Visual Fields,Visual Fields: physiology,Visual Pathways,Visual Pathways: anatomy \& histology,Visual Pathways: physiology},
month = jun,
number = {2},
pages = {215--22},
pmid = {18368396},
title = {{Look-don't look! How emotional pictures affect pro- and anti-saccades.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18368396},
volume = {188},
year = {2008}
}
@incollection{Cooper2000,
abstract = {This paper considers how research into empathy in teaching and learning can inform the research into intelligent systems and intelligent agents embedded in educational applications. It also relates this research to some analysis of classroom practice completed as part of the EU funded NIMIS project. The project is developing three applications, one of which aims to support writing development with young children aged 5-6 years based on a cartoon format. The NIMIS classroom as a whole is designed to enhance and augment existing classroom practices and to foster collaboration by non-intrusive hardware and intuitive hardware and software interfaces. To this end it seeks to enhance both human and electronic communication in the classroom. Empathy is central to ensuring the quality of human communication and personal development. This paper suggests that intelligent systems that can consider more carefully the processes and feelings involved in human interactions in teaching and learning, may promote higher quality support for students in classrooms.},
author = {Cooper, Bridget and Brna, Paul and Martins, Alex},
booktitle = {Affective Interactions Towards a New Generation of Computer Interfaces},
doi = {10.1007/10720296\_3},
editor = {Paiva, Ana},
file = {::},
isbn = {978-3-540-41520-6},
pages = {21--34},
publisher = {Springer Berlin / Heidelberg},
title = {{Effective affective in intelligent systems–building on evidence of empathy in teaching and learning}},
url = {http://www.springerlink.com/index/j8v0l230t3503367.pdf},
volume = {1814/2000},
year = {2000}
}
@article{Kurlander1996,
abstract = {Comics have a rich visual vocabulary, and people find them appealing. They are also an effective form of communication. We have built a system, called Comic Chat, that represents on-line communications in the form of comics. Comic Chat automates numerous aspects of comics generation, including balloon construction and layout, the placement and orientation of comic characters, the default selection of character gestures and expressions, the incorporation of semantic panel elements, and the choice of zoom factor for the virtual camera. This paper describes the mechanisms that Comic Chat uses to perform this automation, as well as novel aspects of the program's user interface. Comic Chat is a working program, allowing groups of people to communicate over the Internet. It has several advantages over other graphical chat programs, including the availability of a graphical history, and a dynamic graphical presentation.},
author = {Kurlander, David and Skelly, Tim and Salesin, David},
doi = {10.1145/237170.237260},
editor = {Rushmeier, Holly},
isbn = {0897917464},
issn = {00978930},
journal = {Proceedings of the 23rd annual conference on Computer graphics and interactive techniques SIGGRAPH 96},
keywords = {automated presentation,chat programs,comics,graphical histories,illustra,internet,non photorealistic rendering,tion,user interfaces,virtual worlds,world wide web},
number = {Annual Conference Series},
pages = {225--236},
publisher = {ACM Press},
series = {\{C\}omputer \{G\}raphics \{P\}roceedings, \{A\}nnual \{C\}onference \{S\}eries},
title = {{Comic Chat}},
url = {http://portal.acm.org/citation.cfm?doid=237170.237260},
volume = {96},
year = {1996}
}
@article{Picard2001,
author = {Picard, Rosalind W and Vyzas, E. and Healey, J.},
doi = {10.1109/34.954607},
file = {::},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {10},
pages = {1175--1191},
title = {{Toward machine emotional intelligence: analysis of affective physiological state}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=954607},
volume = {23},
year = {2001}
}
@phdthesis{Lisetti2011,
author = {Lisetti, Christine L},
school = {Florida International University},
title = {{What Kind of Emotions Are There? Structure of Emotion}},
type = {Lecture},
year = {2011}
}
@book{Mowrer1960,
address = {New York},
author = {Mowrer, Orval Hobart},
pages = {555},
publisher = {Wiley},
title = {{Learning theory and behavior}},
year = {1960}
}
@techreport{Gratch2010,
author = {Gratch, Jonathan and Kang, Sin-hwa and Wang, Ning},
booktitle = {Imagine},
file = {::},
institution = {University of Southern California},
number = {Chap X},
pages = {1--22},
title = {{Using social agents explore theories of rapport and emotional resonance}},
year = {2010}
}
@article{McNear,
author = {McNear},
journal = {ACM Computing Surveys},
title = {{Spoken Dialogue Technology: Enabling the Conversational User Interface}}
}
@inproceedings{Lopez2007,
abstract = {In this paper we present validation tests that we have carried out on gestures that we have designed for an embodied conver- sational agent (ECAs), to assess their soundness with a view to applying said gestures in a forthcoming experiment to explore the possibilities ECAs can offer to overcome typical robustness problems in spoken language dialogue systems (SLDSs). The paper is divided into two parts: First we carry our a literature review to acquire a sense of the extent to which ECAs can help overcome user frustration during human-machine interaction. Then we associate tentative, yet specific, ECA gestural behaviour with each of the main dialogue stages, with special emphasis on problem situations. In the second part we describe the tests we have carried out to validate our ECA’s gestural repertoire. The results obtained show that users generally understand and naturally accept the ges- tures, to a reasonable degree. This encour- ages us to proceed with the next stage of research: evaluating the gestural strategy in real dialogue situations with the aim of learning about how to favour a more effi- cient and pleasant dialogue flow for the us- ers.},
address = {Prague, Czech Republic},
author = {L\'{o}pez, Beatriz and Hern\'{a}ndez, \'{A}lvaro and D\'{\i}az, David and Fern\'{a}ndez, Rub\'{e}n and Hern\'{a}ndez, Luis and Torre, Doroteo},
booktitle = {Proceedings of the Workshop on Embodied Language Processing},
doi = {10.3115/1610065.1610074},
file = {::},
pages = {67--74},
publisher = {Association for Computational Linguistics},
title = {{Design and validation of ECA gestures to improve dialogue system robustness}},
url = {http://portal.acm.org/citation.cfm?doid=1610065.1610074},
year = {2007}
}
@article{Drapeau2009,
abstract = {Persons with dementia of the Alzheimer type (DAT) are impaired in recognizing emotions from face and voice. Yet clinical practitioners use these mediums to communicate with DAT patients. Music is also used in clinical practice, but little is known about emotional processing from music in DAT. This study aims to assess emotional recognition in mild DAT. Seven patients with DAT and 16 healthy elderly adults were given three tasks of emotional recognition for face, prosody, and music. DAT participants were only impaired in the emotional recognition from the face. These preliminary results suggest that dynamic auditory emotions are preserved in DAT.},
author = {Drapeau, Joanie and Gosselin, Nathalie and Gagnon, Lise and Peretz, Isabelle and Lorrain, Dominique},
doi = {10.1111/j.1749-6632.2009.04768.x},
file = {::},
issn = {1749-6632},
journal = {Annals of the New York Academy of Sciences},
keywords = {Aged,Alzheimer Disease,Alzheimer Disease: physiopathology,Alzheimer Disease: psychology,Emotions,Face,Female,Humans,Male,Music,Recognition (Psychology),Recognition (Psychology): physiology,Voice},
month = jul,
pages = {342--5},
pmid = {19673804},
title = {{Emotional recognition from face, voice, and music in dementia of the Alzheimer type.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19673804},
volume = {1169},
year = {2009}
}
@incollection{Rogers1959,
address = {New York},
author = {Rogers, C R},
booktitle = {Psychology: the Study of a Science},
chapter = {3},
editor = {Koch, S},
pages = {184--256},
publisher = {McGraw-Hill},
title = {{A theory of therapy, personality and interpersonal relationships as developed in the client-centered framework}},
volume = {3},
year = {1959}
}
@misc{Putten2009,
author = {P\"{u}tten, Astrid M Von Der and Kr\"{a}mer, Nicole C and Gratch, Jonathan},
booktitle = {Design},
file = {::},
keywords = {--- virtual agents,avatars,behavioral realism,experimental study},
pages = {1--7},
title = {{Who´s there? Can a Virtual Agent Really Elicit Social Presence?}}
}
@article{Oatley1987,
abstract = {A theory is proposed that emotions are cognitively based states which co-ordinate quasi-autonomous processes in the nervous system. Emotions provide a biological solution to certain problems of transition between plans, in systems with multiple goals. Their function is to accomplish and maintain these transitions, and to communicate them to ourselves and others. Transitions occur at significant junctures of plans when the evaluation of success in a plan changes. Complex emotions are derived from a small number of basic emotions and arise at junctures of social plans.},
author = {Oatley, Keith and Johnson-laird, P N},
doi = {10.1080/02699938708408362},
isbn = {0269993114640600},
issn = {02699931},
journal = {Cognition \& Emotion},
number = {1},
pages = {29--50},
publisher = {Psychology Press},
title = {{Towards a Cognitive Theory of Emotions}},
url = {http://www.tandfonline.com/doi/abs/10.1080/02699938708408362?journalCode=pcem20},
volume = {1},
year = {1987}
}
@article{Nischt2006,
abstract = {MPML3D is our first candidate of the next generation of authoring languages aimed at supporting digital content creators in providing highly appealing and highly interactive content with little effort. The language is based on our previously developed family of Multimodal Presentation Markup Languages (MPML) that broadly followed the \^{a}? sequential\^{a}? and \^{a}? parallel\^{a}? tagging structure scheme for generating presynchronized presentations featuring life-like characters and interactions with the user. The new markup language MPML3D deviates from this design framework and proposes a reactive model instead, which is apt to handle interaction-rich scenarios with highly realistic 3D characters. Interaction in previous versions of MPML could be handled only at the cost of considerable scripting effort due to branching. By contrast, MPML3D advocates a reactive model that allows perceptions of other characters or the user interfere with the presentation flow at any time, and thus facilitates natural and unrestricted interaction. MPML3D is designed as a powerful and flexible language that is easy-to-use by non-experts, but it is also extensible as it allows content creators to add functionality such as a narrative model by using popular scripting languages.},
author = {Nischt, Michael and Prendinger, Helmut and Andr\'{e}, Elisabeth and Ishizuka, Mitsuru},
isbn = {9101007118},
journal = {Lecture Notes in Computer Science},
number = {1},
pages = {218--229},
publisher = {Springer},
title = {{MPML3D: a reactive framework for the Multimodal Presentation Markup Language}},
url = {http://www.springerlink.com/index/j7217706p7658021.pdf},
volume = {62},
year = {2006}
}
@book{Apa1994,
abstract = {DSM-IV},
author = {APA},
booktitle = {W},
institution = {American Psychiatric Association},
isbn = {0890420629},
number = {VI},
pages = {xxvii, 886 p.},
pmid = {1595545},
publisher = {American Psychiatric Association},
title = {{Diagnostic and statistical manual of mental disorders: DSM-IV}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:DSM-IV:+diagnostic+and+statistical+manual+of+mental+disorders\#0},
volume = {4th},
year = {1994}
}
@article{DeVignemont2006,
abstract = {Recent imaging results suggest that individuals automatically share the emotions of others when exposed to their emotions. We question the assumption of the automaticity and propose a contextual approach, suggesting several modulatory factors that might influence empathic brain responses. Contextual appraisal could occur early in emotional cue evaluation, which then might or might not lead to an empathic brain response, or not until after an empathic brain response is automatically elicited. We propose two major roles for empathy; its epistemological role is to provide information about the future actions of other people, and important environmental properties. Its social role is to serve as the origin of the motivation for cooperative and prosocial behavior, as well as help for effective social communication.},
author = {de Vignemont, Frederique and Singer, Tania},
doi = {10.1016/j.tics.2006.08.008},
file = {::},
issn = {1364-6613},
journal = {Trends in cognitive sciences},
keywords = {Automatism,Automatism: psychology,Brain,Brain Mapping,Brain: physiology,Cerebral,Cerebral Cortex,Cerebral Cortex: physiology,Cerebral: physiology,Communication,Cooperative Behavior,Cues,Dominance,Emotions,Emotions: physiology,Empathy,Female,Gyrus Cinguli,Gyrus Cinguli: physiology,Humans,Interpersonal Relations,Magnetic Resonance Imaging,Male,Motivation,Nerve Net,Nerve Net: physiology,Neurons,Neurons: physiology,Social Behavior,Social Environment},
month = oct,
number = {10},
pages = {435--41},
pmid = {16949331},
title = {{The empathic brain: how, when and why?}},
volume = {10},
year = {2006}
}
@inproceedings{Denef2009,
abstract = {This thesis investigates the design of human computer interaction techniques for ubiquitous computing solutions in firefighting.},
address = {Uppsala, Sweden},
author = {Denef, Sebastian},
booktitle = {INTERACT '09 Proceedings of the 12th IFIP TC 13 International Conference on Human-Computer Interaction: Part II},
doi = {10.1007/978-3-642-03658-3\_97},
editor = {Gross, Tom and Gulliksen, Jan and Kotz\'{e}, Paula and Oestreicher, Lars and Palanque, Philippe and Prates, Raquel Oliveira and Winckler, Marco},
file = {::},
pages = {864--867},
publisher = {Springer Berlin / Heidelberg},
title = {{Human-Computer Interaction Techniques in Firefighting}},
url = {http://www.springerlink.com/index/n0688783567n3251.pdf http://dl.acm.org/citation.cfm?id=1616339},
year = {2009}
}
@article{Calvo2010,
author = {Calvo, R.A. and D'Mello, S.},
file = {::},
journal = {Affective Computing, IEEE Transactions on},
number = {1},
pages = {18--37},
publisher = {IEEE},
title = {{Affect detection: An interdisciplinary review of models, methods, and their applications}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5520655},
volume = {1},
year = {2010}
}
@article{Eisenberg1983,
abstract = {Reviews the literature on sex differences in empathy (defined as vicarious affective responding to the emotional state of another) and related capacities (affective role taking and decoding of nonverbal cues). The literature is discussed according to method used to assess empathy and affective role taking. Where appropriate, meta-analyses were also computed. In general, sex differences in empathy were found to be a function of the methods used to assess empathy. There was a large sex difference favoring women when the measure of empathy was self-report scales; moderate differences (favoring females) were found for reflexive crying and self-report measures in laboratory situations; and no sex differences were evident when the measure of empathy was either physiological or unobtrusive observations of nonverbal reactions to another's emotional state. Moreover, few sex differences were found for children's affective role taking and decoding abilities. (156 ref) (PsycINFO Database Record (c) 2006 APA, all rights reserved), (C) 1983 by the American Psychological Association},
author = {Eisenberg, Nancy and Lennon, Randy},
issn = {19391455},
journal = {Psychological Bulletin},
number = {1},
pages = {100--131},
title = {{Sex Differences in Empathy and Related Capacities}},
volume = {94},
year = {1983}
}
@article{Kiesler2008,
author = {Kiesler, Sara and Powers, Aaron and Fussell, Susan R. and Torrey, Cristen},
doi = {10.1521/soco.2008.26.2.169},
file = {::},
issn = {0278-016X},
journal = {Social Cognition},
month = apr,
number = {2},
pages = {169--181},
title = {{Anthropomorphic Interactions with a Robot and Robot–like Agent}},
url = {http://guilfordjournals.com/doi/abs/10.1521/soco.2008.26.2.169},
volume = {26},
year = {2008}
}
@article{Woods1970,
abstract = {The use of augmented transition network grammars for the analysis of natural language sentences is described. Struc- ture-building actions associated with the arcs of the gram- mar network allow for the reordering, restructuring, and copy- ing of constituents necessary to produce deep-structure repre- sentations of the type normally obtained from a transforma- tional analysis, and conditions on the arcs allow for a powerful selectivity which can rule out meaningless analyses and take advantage of semantic information to guide the parsing. The advantages of this model for natural language analysis are discussed in detail and illustrated by examples. An imple- mentation of an experimental parsing system for transition network grammars is briefly described.},
author = {Woods, W A},
doi = {10.1145/355598.362773},
editor = {Grosz, Barbara and Jones, Karen and Webber, Bonnie},
file = {::},
issn = {00010782},
journal = {Communications of the ACM},
number = {10},
pages = {591--606},
publisher = {ASSOC COMPUTING MACHINERY},
title = {{Transition Network Grammars for Natural Language Analysis}},
url = {http://portal.acm.org/citation.cfm?doid=355598.362773},
volume = {13},
year = {1970}
}
@article{Fabri2007,
author = {Fabri, Marc and Elzouki, SYA},
file = {::},
journal = {of the 12th international conference on},
keywords = {autism,avatar,education,emotion,empathy,facial expression,instant,messaging,therapeutic intervention,virtual reality},
pages = {275--285},
title = {{Emotionally expressive avatars for chatting, learning and therapeutic intervention}},
url = {http://dl.acm.org/citation.cfm?id=1769621},
year = {2007}
}
@article{Boukricha2007,
abstract = {Addressing user’s emotions in human-computer interaction significantly enhances the believability and lifelikeness of virtual humans. Emotion recognition and interpretation is realized in our approach by integrating empathy as a designated process within the agent’s cognitive architecture. In this paper we describe this empathy process which comprises of two interconnected components: a belief-desire-intention (BDI) based cognitive component and an affective component based on the emotion simulation system of the virtual human Max.},
author = {Boukricha, Hana and Becker-Asano, Christian},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Boukricha, Becker-Asano - 2007 - Simulating empathy for the virtual human max(3).pdf:pdf},
journal = {on Emotion and Computing in conj},
title = {{Simulating empathy for the virtual human max}},
year = {2007}
}
@misc{TheMendeleySupportTeam2011,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/The Mendeley Support Team - 2011 - Getting Started with Mendeley(4).pdf:pdf},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@inproceedings{Kumano2011,
author = {Kumano, Shiro and Otsuka, Kazuhiro and Mikami, Dan and Yamato, Junji},
booktitle = {Automatic Face \& Gesture Recognition and Workshops (FG 2011), 2011 IEEE International Conference on},
file = {::},
pages = {43--50},
publisher = {IEEE},
title = {{Analyzing empathetic interactions based on the probabilistic modeling of the co-occurrence patterns of facial expressions in group meetings}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5771440},
year = {2011}
}
@article{Shamay-Tsoory2011,
abstract = {Human empathy relies on the ability to share emotions as well as the ability to understand the other's thoughts, desires, and feelings. Recent evidence points to 2 separate systems for empathy: an emotional system that supports our ability to empathize emotionally and a cognitive system that involves cognitive understanding of the other's perspective. A neural network that includes the inferior frontal gyrus and the inferior parietal lobule is necessary for emotion recognition and emotional contagion. Although the emotional and cognitive systems appear to work independently, every empathic response may still evoke both components to some extent, depending on the social context.},
annote = {Difference between cognitive empathy and emotional empathy is explained in this paper. Also they talk about the active brain parts in each empathy type.},
author = {Shamay-Tsoory, Simone G},
doi = {10.1177/1073858410379268},
file = {::},
issn = {1089-4098},
journal = {The Neuroscientist : a review journal bringing neurobiology, neurology and psychiatry},
keywords = {Brain,Brain: physiology,Empathy,Empathy: physiology,Humans,Neural Pathways,Neural Pathways: physiology},
month = feb,
number = {1},
pages = {18--24},
pmid = {21071616},
title = {{The neural bases for empathy.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21071616},
volume = {17},
year = {2011}
}
@book{Stueber2006,
author = {Stueber, Karsten},
edition = {1},
isbn = {026219550X},
publisher = {MIT Press},
title = {{Rediscovering Empathy: Agency, Folk Psychology, and the Human Sciences}},
year = {2006}
}
@inproceedings{Hubal2003,
abstract = {This paper describes lessons learned in developing the linguistic, cognitive, emotional, and gestural models underlying virtual human behavior in a training application designed to train civilian police officers how to recognize gestures and verbal cues indicating different forms of mental illness and how to verbally interact with the mentally ill. Schizophrenia, paranoia, and depression were all modeled for the application. For linguistics, the application has quite complex language grammars that captured a range of syntactic structures and semantic categories. For cognition, there is a great deal of augmentation to a plan-based transition network needed to model the virtual human’s knowledge. For emotions and gestures, virtual human behavior is based on expert-validated mapping tables specific to each mental illness. The paper presents five areas demanding continued research to improve virtual human behavior for use in training applications.},
address = {Miami, FL, US},
author = {Hubal, Robert C and Frank, Geoffrey A and Guinn, Curry I},
booktitle = {Proceedings of the 2003 International Conference on Intelligent User Interfaces (IUI'03)},
file = {::},
isbn = {1581135866},
keywords = {agents,behavior modeling,interaction skills training,managing encounters with the,mentally ill,responsive virtual humans},
pages = {85--92},
publisher = {ACM},
title = {{Lessons Learned in Modeling Schizophrenic and Depressed Responsive Virtual Humans for Training}},
year = {2003}
}
@book{Davis1994,
author = {Davis, Mark H.},
isbn = {0697168948},
publisher = {Westview Press},
title = {{Empathy: A social psychological approach}},
year = {1994}
}
@article{Chuang2004,
author = {Chuang, ZJ},
file = {::},
journal = {International Journal of Computational},
number = {2},
pages = {45--62},
title = {{Multi-modal emotion recognition from speech and text}},
url = {http://www.mendeley.com/research/multimodal-emotion-recognition-from-speech-and-text/},
volume = {9},
year = {2004}
}
@article{Sharma1998,
author = {Sharma, R. and Pavlovic, V.I. and Huang, Thomas S.},
file = {::},
journal = {Proceedings of the IEEE},
keywords = {computer interface,human,multimodality,sensor},
number = {5},
pages = {853--869},
publisher = {IEEE},
title = {{Toward multimodal human-computer interface}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=664275},
volume = {86},
year = {1998}
}
@inproceedings{Gonsior2011,
author = {Gonsior, Barbara and Sosnowski, Stefan and Mayer, Christoph and Blume, Jiirgen and Radig, B. and Wollherr, D. and Kuhnlenz, K.},
booktitle = {RO-MAN, 2011 IEEE},
file = {::},
isbn = {9781457715730},
pages = {350--356},
publisher = {IEEE},
title = {{Improving aspects of empathy and subjective performance for HRI through mirroring facial expressions}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6005294},
year = {2011}
}
@inproceedings{Stone2004,
abstract = {We describe a method for using a database of recorded speech and captured motion to create an animated conversational character. People's utterances are composed of short, clearly-delimited phrases; in each phrase, gesture and speech go together meaningfully and synchronize at a common point of maximum emphasis. We develop tools for collecting and managing performance data that exploit this structure. The tools help create scripts for performers, help annotate and segment performance data, and structure specific messages for characters to use within application contexts. Our animations then reproduce this structure. They recombine motion samples with new speech samples to recreate coherent phrases, and blend segments of speech and motion together phrase-by-phrase into extended utterances. By framing problems for utterance generation and synthesis so that they can draw closely on a talented performance, our techniques support the rapid construction of animated characters with rich and appropriate expression.},
author = {Stone, Matthew and DeCarlo, Doug and Oh, Insuk and Rodriguez, Christian and Stere, Adrian and Lees, Alyssa and Bregler, Chris},
booktitle = {SIGGRAPH 04 ACM SIGGRAPH 2004 Papers},
doi = {10.1145/1186562.1015753},
file = {::},
issn = {07300301},
number = {3},
pages = {506--513},
publisher = {ACM Press},
title = {{Speaking with hands: creating animated conversational characters from recordings of human performance}},
url = {http://portal.acm.org/citation.cfm?doid=1015706.1015753},
volume = {23},
year = {2004}
}
@article{Elliot2001,
author = {Elliot, Andrew J. and McGregor, holly A.},
file = {::},
journal = {Journal of Personality and Social Psychology},
number = {3},
pages = {501--519},
title = {{A 2 x 2 achievement goal framework.pdf}},
volume = {80},
year = {2001}
}
@article{Sabourin,
author = {Sabourin, Jennifer and Mott, Bradford and Lester, James},
file = {::},
journal = {lorentzcenter.nl},
keywords = {empathetic virtual agents,pedagogical agents,virtual learning},
title = {{Computational Models of Affect and Empathy for Pedagogical Virtual Agents}},
url = {http://www.lorentzcenter.nl/lc/web/2011/464/presentations/Sabourin.pdf}
}
@article{Beck1981,
author = {Beck, K H and Lund, A K},
journal = {Journal of Applied Social Psychology},
number = {5},
pages = {401--415},
title = {{The Effects of Health Threat Seriousness and Personal Efficacy upon Intentions and Behavior}},
volume = {11},
year = {1981}
}
@article{Hester2005,
abstract = {Sixty-one problem drinkers were randomly assigned to either immediate treatment or a 4-week wait-list control group. Treatment consisted of a computer-based brief motivational intervention, the Drinker's Check-up (DCU). Outcomes strongly support the experimental hypotheses and long-term effectiveness of the treatment. Overall, participants reduced the quantity and frequency of drinking by 50\%, and had similar reductions in alcohol-related problems that were sustained through 12-month follow-up. The DCU seems to be effective in enhancing problem drinkers' motivation for change.},
author = {Hester, Reid K and Squires, Daniel D and Delaney, Harold D},
journal = {Journal of Substance Abuse Treatment},
keywords = {adult,alcohol drinking,alcoholism,blood,computer assisted,epidemiology,ethanol,female,follow up studies,humans,male,middle aged,motivation,outcome assessment (health care),patient compliance,patient dropouts,personality assessment,psychometrics,px [psychology],rh [rehabilitation],sn [statistics \&,sn [statistics \& numer,sn [statistics \& numerical,sn [statistics \& numerical data,sn [statistics \& numerical data],software,therapy,united states,waiting lists},
number = {2},
pages = {159--169},
pmid = {15780546},
publisher = {Research Division, Behavior Therapy Associates, LLP, Albuquerque, NM 87112, USA. reidhester@behaviortherapy.com},
title = {{The Drinker's Check-up: 12-month outcomes of a controlled clinical trial of a stand-alone software program for problem drinkers}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15780546},
volume = {28},
year = {2005}
}
@article{Bailenson2005,
abstract = {Previous research demonstrated social influence resulting from mimicry (the chameleon effect); a confederate who mimicked participants was more highly regarded than a confederate who did not, despite the fact that participants did not explicitly notice the mimicry. In the current study, participants interacted with an embodied artificial intelligence agent in immersive virtual reality. The agent either mimicked a participant's head movements at a 4-s delay or utilized prerecorded movements of another participant as it verbally presented an argument. Mimicking agents were more persuasive and received more positive trait ratings than nonmimickers, despite participants' inability to explicitly detect the mimicry. These data are uniquely powerful because they demonstrate the ability to use automatic, indiscriminate mimicking (i.e., a computer algorithm blindly applied to all movements) to gain social influence. Furthermore, this is the first study to demonstrate social influence effects with a nonhuman, nonverbal mimicker.},
author = {Bailenson, Jeremy N and Yee, Nick},
file = {::},
journal = {Psychological Science},
number = {10},
pages = {814--819},
title = {{Digital Chameleons: Automatic Assimilation of Nonverbal Gestures in Immersive Virtual Environments}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16181445},
volume = {16},
year = {2005}
}
@article{Larimer2007,
abstract = {The current study was designed to evaluate the efficacy of a mailed feedback and tips intervention as a universal prevention strategy for college drinking. Participants (N = 1,488) were randomly assigned to feedback or assessment-only control conditions. Results indicated that the mailed feedback intervention had a preventive effect on drinking rates overall, with participants in the feedback condition consuming less alcohol at follow-up in comparison with controls. In addition, abstainers in the feedback condition were twice as likely to remain abstinent from alcohol at follow-up in comparison with control participants (odds ratio = 2.02), and feedback participants were significantly more likely to refrain from heavy episodic drinking (odds ratio = 1.43). Neither gender nor severity of baseline drinking moderated the efficacy of the intervention in these analyses, but more conservative analyses utilizing last-observation carryforward suggested women and abstainers benefited more from this prevention approach. Protective behaviors mediated intervention efficacy, with participants who received the intervention being more likely to use strategies such as setting limits and alternating alcohol with nonalcoholic beverages. Implications of these findings for universal prevention of college drinking are discussed.},
author = {Larimer, Mary E and Lee, Christine M and Kilmer, Jason R and Fabiano, Patricia M and Stark, Christopher B and Geisner, Irene M and Mallett, Kimberly A and Lostutter, Ty W and Cronce, Jessica M and Feeney, Maggie and Neighbors, Clayton},
institution = {Department of Psychiatry and Behavioral Sciences, University of Washington, Seattle, WA 98105, USA. larimer@u.washington.edu},
journal = {Journal of Consulting and Clinical Psychology},
keywords = {adult,alcohol drinking,alcohol drinking epidemiology,alcohol drinking prevention \& control,communication,feedback,female,humans,male,motivation,postal service,students,students statistics \& numerical data,universities},
number = {2},
pages = {285--293},
pmid = {17469886},
publisher = {American Psychological Association. Journals Department, 750 First Street NE, Washington, DC 20002-4242. Tel: 800-374-2721; Tel: 202-336-5510; Fax: 202-336-5502; e-mail: order@apa.org; Web site: http://www.apa.org/publications},
title = {{Personalized mailed feedback for college drinking prevention: a randomized clinical trial.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17469886},
volume = {75},
year = {2007}
}
@inproceedings{Huang2010,
abstract = {Virtual humans are embodied software agents that should not only be realistic looking but also have natural and realistic behaviors. Traditional virtual human systems learn these interaction behaviors by observing how individuals respond in face-to-face situations (i.e., direct interaction). In contrast, this paper introduces a novel methodological approach called parasocial consensus sampling (PCS) which allows multiple individuals to vicariously experience the same situation to gain insight on the typical (i.e., consensus view) of human responses in social interaction. This approach can help tease apart what is idiosyncratic from what is essential and help reveal the strength of cues that elicit social responses. Our PCS approach has several advantages over traditional methods: (1) it integrates data from multiple independent listeners interacting with the same speaker, (2) it associates probability of how likely feedback will be given over time, (3) it can be used as a prior to analyze and understand the face-to-face interaction data, (4) it facilitates much quicker and cheaper data collection. In this paper, we apply our PCS approach to learn a predictive model of listener backchannel feedback. Our experiments demonstrate that a virtual human driven by our PCS approach creates significantly more rapport and is perceived as more believable than the virtual human driven by face-to-face interaction data.},
address = {Toronto, Canada},
author = {Huang, Lixing and Morency, Louis-Philippe and Gratch, Jonathan},
booktitle = {9th International Conference on Autonomous Agents and Multiagent Systems (AAMAS'2010)},
doi = {10.1145/1838206.1838371},
editor = {Hoek, Van Der and Kaminka and Lesperance and Luck and Sen},
file = {::},
keywords = {Backchannel Feedback,Parasocial,Rapport,Virtual Humans},
number = {Aamas},
pages = {10--14},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org)},
title = {{Parasocial consensus sampling: combining multiple perspectives to learn virtual human behavior}},
url = {http://dl.acm.org/citation.cfm?id=1838371},
year = {2010}
}
@inproceedings{Boukricha2009,
abstract = {a system for simulating emotional facial expressions for a virtual human has been evolved. This system consists of two parts: (1) a control ar- chitecture for simulating emotional facial expressions with respect to Pleasure, Arousal, and Dominance (PAD) val- ues, (2) an expressive output component for animating the virtual human’s facial muscle actions called Action Units (AUs), modeled following the Facial Action Coding Sys- tem (FACS). A large face repertoire of about 6000 faces arranged in PAD-space with respect to two dominance val- ues (dominant vs. submissive) is obtained as a result of the empirical study. Using the face repertoire an approach to- wards realizing facial mimicry for a virtual human based on backward mapping AUs displaying an emotional facial expression on PAD-values is outlined.},
annote = {- For automatic recognition, the mapping of AUs to PAD may be only useful once you can identify the active AUs and their intensity on the face (which you won't be able with image processing teckniques).
- For the expression, if you have an avatar which has control on the AUs, you don’t need to map the AUs to PAD. But, if you have an avatar which expresses based on PAD, then this mapping is useful. 
- Mapping of AUs to PAD is helpful when you want to fuse multiple modalities where other modalities are in PAD values. },
author = {Boukricha, Hana and Wachsmuth, Ipke and Hofstatter, A. and Grammer, Karl},
booktitle = {Affective Computing and Intelligent Interaction and Workshops, 2009. ACII 2009. 3rd International Conference on},
file = {::},
isbn = {9781424447992},
pages = {1--7},
publisher = {IEEE},
title = {{Pleasure-arousal-dominance driven facial expression simulation}},
year = {2009}
}
@article{Matthews1993,
abstract = {Healers must try to understand what the illness means to the patient and create a therapeutic sense of connection in the patient-clinician relationship. A favorable climate for "connexional" experiences can be created through the use of various interviewing techniques. Attending to rapport, silencing internal talk, accessing unconscious processes, and communicating understanding can help clinicians enhance their sensitivity to the subtle clues on which issues of meaning and connection often depend. Several risks are associated with the establishment of closer patient-clinician relationships, including dependence and power issues, sexual attraction, and deeper exposure of the clinician to the patient's pain. Prepared with an awareness of these risks and techniques to address them, clinicians are encouraged to deepen their level of dialogue with patients, to compare their experiences with those of other clinicians, and to thereby develop a more systematic understanding of therapeutic relationships.},
author = {Matthews, D A and Suchman, A L and Branch, W T},
institution = {National Center for Chronic Fatigue, Arlington, Virginia.},
journal = {Annals of Internal Medicine},
keywords = {professional patient relationship},
number = {12},
pages = {973--977},
pmid = {8489112},
title = {{Making "connexions": enhancing the therapeutic potential of patient-clinician relationships.}},
volume = {118},
year = {1993}
}
@article{Emmons2001,
abstract = {Motivational interviewing (MI) has been well studied in specialist settings. There has been considerable interest in applying MI to community health care settings. Such settings represent a significant departure from the more traditional, specialist settings in which MI has been developed and tested. The purpose of this paper is to provide a brief overview of MI and to identify and discuss the key issues that are likely to arise when adapting this approach to health care and public health settings. This paper provides an overview of important issues to consider in adapting an effective counseling strategy to new settings, and is intended to begin a dialogue about the use of MI in community health care settings.},
author = {Emmons, K M and Rollnick, S},
file = {::},
issn = {0749-3797},
journal = {American journal of preventive medicine},
keywords = {Adult,Attitude of Health Personnel,Community Health Services,Community Health Services: standards,Community Health Services: trends,Female,Health Care Surveys,Humans,Interviews as Topic,Interviews as Topic: methods,Male,Motivation,Outcome Assessment (Health Care),Preventive Medicine,Preventive Medicine: standards,Preventive Medicine: trends,United States},
month = jan,
number = {1},
pages = {68--74},
pmid = {11137778},
title = {{Motivational interviewing in health care settings. Opportunities and limitations.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11137778},
volume = {20},
year = {2001}
}
@article{Wu2008,
author = {Wu, Siew-Rong},
doi = {10.1109/DIGITEL.2008.27},
file = {::},
isbn = {978-0-7695-3409-1},
journal = {2008 Second IEEE International Conference on Digital Game and Intelligent Toy Enhanced Learning},
pages = {213--214},
publisher = {Ieee},
title = {{Humor and Empathy: Developing Students' Empathy through Teaching Robots to Tell English Jokes}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4700764},
year = {2008}
}
@incollection{Ekman1982,
address = {New York},
author = {Ekman, Paul and Friesen, W V and Ellsworth, P},
booktitle = {Emotion in the human face},
editor = {Ekman, Paul},
pages = {39--55},
publisher = {Cambridge University Press},
title = {{What emotion categories or dimensions can observers judge from facial behavior?}},
year = {1982}
}
@inproceedings{Kang2008,
author = {Kang, Sin-hwa and Gratch, Jonathan and Wang, Ning and Watt, J.H.},
booktitle = {Proceedings of the 7th international joint conference on Autonomous agents and multiagent systems-Volume 1},
file = {::},
keywords = {agents,contingency of nonverbal feedback,evaluation,rapport,social anxiety,virtual humans},
number = {Aamas},
pages = {120--127},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
title = {{Does the contingency of agents' nonverbal feedback affect users' social anxiety?}},
url = {http://dl.acm.org/citation.cfm?id=1402405},
year = {2008}
}
@article{Robison2010b,
abstract = {affective interventions can both positively and negatively influence learning experiences. In this paper we investigate the role of student personality, including goal orienta- tion and empathetic tendencies, in estimating confidence in the benefits of an affective intervention strategy. The results indicate that student personality profiles can serve as a powerful tool for informing affective feedback models.},
annote = {We can use the same way of menu base self-report affective state recognition (in addition to automatic) and text-base empathic feedback. Then after each feedback we can evaluate the feedback with another user self-report.},
author = {Robison, Jennifer and Mcquiggan, Scott and Lester, James and Carolina, North},
file = {::},
keywords = {affect,affective computing,pedagogical agents},
pages = {285--295},
title = {{Profiles for Affective Feedback Models}},
year = {2010}
}
@inproceedings{Wright2008,
author = {Wright, Peter and McCarthy, J.},
booktitle = {Proceeding of the twenty-sixth annual SIGCHI conference on Human factors in computing systems},
file = {::},
isbn = {9781605580111},
pages = {637--646},
publisher = {ACM},
title = {{Empathy and experience in HCI}},
url = {http://dl.acm.org/citation.cfm?id=1357156},
year = {2008}
}
@article{Rameson2009,
author = {Rameson, Lian T. and Lieberman, Matthew D.},
doi = {10.1111/j.1751-9004.2008.00154.x},
file = {::},
issn = {17519004},
journal = {Social and Personality Psychology Compass},
month = jan,
number = {1},
pages = {94--110},
title = {{Empathy: A Social Cognitive Neuroscience Approach}},
url = {http://doi.wiley.com/10.1111/j.1751-9004.2008.00154.x},
volume = {3},
year = {2009}
}
@article{Mehrabian1967a,
abstract = {DEALT WITH INCONSISTENT COMMUNICATION OF ATTITUDE IN 2 COMPONENTS OF A MESSAGE. POSITIVE, NEUTRAL, OR NEGATIVE ATTITUDES COMMUNICATED IN SINGLE-WORD CONTENTS WERE EACH COMBINED WITH 3 DEGREES OF ATTITUDE COMMUNICATED IN TONE OF VOICE. IT WAS FOUND, CONSISTENT WITH THE PROPOSED HYPOTHESIS, THAT THE VARIABILITY OF INFERENCES ABOUT COMMUNICATOR ATTITUDE ON THE BASIS OF INFORMATION AVAILABLE IN CONTENT AND TONE COMBINED IS MAINLY CONTRIBUTED BY VARIATIONS IN TONE ALONE. FOR EXAMPLE, WHEN THE ATTITUDE COMMUNICATED IN CONTENT CONTRADICTED THE ATTITUDE COMMUNICATED BY A NEGATIVE TONE, THE TOTAL MESSAGE WAS JUDGED AS COMMUNICATING A NEGATIVE ATTITUDE. THE LIMITATIONS OF THE FINDINGS, AS WELL AS THEIR IMPLICATIONS FOR THE DOUBLE-BLIND THEORY OF SCHIZOPHRENIA, ARE DISCUSSED. (PsycINFO Database Record (c) 2006 APA, all rights reserved)},
author = {Mehrabian, Albert and Wiener, M},
journal = {Journal of Personality and Social Psychology},
keywords = {attitude,communication,cues,humans,schizophrenic psychology,voice},
number = {1},
pages = {109--114},
pmid = {6032751},
title = {{Decoding of inconsistent communications.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/6032751},
volume = {6},
year = {1967}
}
@article{Spurgeon2010,
abstract = {There has been a recent acceleration in the development and testing of programs for computer-assisted cognitive-behavioral therapy (CCBT). Programs are now available for treatment of depression, anxiety disorders, and other psychiatric conditions. Technology for delivery of CCBT includes multimedia programs, virtual reality, and handheld devices. Research on CCBT generally has supported the efficacy of computer-assisted therapy and has shown patient acceptance of computer tools for psychotherapy. Completion rates and treatment efficacy typically have been higher when clinicians prescribe and support the use of psychotherapeutic computer programs than when programs are delivered in a self-help format without clinician involvement. CCBT seems to have the potential to improve access to evidence-based therapies while reducing the demand for clinician time.},
author = {Spurgeon, Joyce a and Wright, Jesse H},
doi = {10.1007/s11920-010-0152-4},
file = {::},
isbn = {1192001001},
issn = {1535-1645},
journal = {Current psychiatry reports},
keywords = {Anxiety Disorders,Anxiety Disorders: therapy,Cognitive Therapy,Depressive Disorder,Depressive Disorder: therapy,Humans,Therapy, Computer-Assisted,Treatment Outcome},
month = dec,
number = {6},
pages = {547--52},
pmid = {20872100},
title = {{Computer-assisted cognitive-behavioral therapy.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20872100},
volume = {12},
year = {2010}
}
@article{Miller1984,
author = {Miller, William R. and Marlatt, G. Alan},
file = {::},
journal = {Psychological Assessment Resources, Odessa, FL},
title = {{Brief Drinker Profile}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Brief+Drinker+Profile\#0},
year = {1984}
}
@article{Decety2004,
abstract = {Empathy accounts for the naturally occurring subjective experience of similarity between the feelings expressed by self and others without loosing sight of whose feelings belong to whom. Empathy involves not only the affective experience of the other person's actual or inferred emotional state but also some minimal recognition and understanding of another's emotional state. In light of multiple levels of analysis ranging from developmental psychology, social psychology, cognitive neuroscience, and clinical neuropsychology, this article proposes a model of empathy that involves parallel and distributed processing in a number of dissociable computational mechanisms. Shared neural representations, self-awareness, mental flexibility, and emotion regulation constitute the basic macrocomponents of empathy, which are underpinned by specific neural systems. This functional model may be used to make specific predictions about the various empathy deficits that can be encountered in different forms of social and neurological disorders.},
author = {Decety, Jean and Jackson, Philip L},
doi = {10.1177/1534582304267187},
file = {::},
isbn = {1534582304267},
issn = {1534-5823},
journal = {Behavioral and cognitive neuroscience reviews},
keywords = {affective sharing,emotion regulation,executive inhibition,intersubjectivity,perspective taking,self-awareness,shared representations},
month = jun,
number = {2},
pages = {71--100},
pmid = {15537986},
title = {{The functional architecture of human empathy}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15537986},
volume = {3},
year = {2004}
}
@article{Gunes2008,
author = {Gunes, Hatice and Piccardi, Massimo},
file = {::},
journal = {Emotion},
title = {{From the lab to the real world: Affect recognition using multiple cues and modalities}},
year = {2008}
}
@inproceedings{Magerko2011,
abstract = {This article presents our work on building a virtual coach agent, called Dr. Vicky, and training environment (called the Virtual BNI Trainer, or VBT) for learning how to correctly talk with medical patients who have substance abuse issues. This work focuses on how to effectively design menu-based dialogue interactions for conversing with a virtual patient within the context of learning how to properly engage in such conversations according to the brief negotiated interview techniques we desire to train. Dr. Vicky also employs a model of student knowledge to influence the mediation strategies used in personalizing the training experience and guidance offered. The VBT is a prototype training application that will be used by medical students and practitioners within the Yale medical community in the future.},
author = {Magerko, Brian and Dean, James and Idnani, Avinash and Pantalon, Michael and Onofrio, Gail D},
booktitle = {AAAI Spring Symposium},
file = {::},
keywords = {AAAI Technical Report SS-11-01},
pages = {25--32},
title = {{Dr . Vicky : A Virtual Coach for Learning Brief Negotiated Interview Techniques for Treating Emergency Room Patients}},
year = {2011}
}
@book{Apa1994,
abstract = {DSM-IV},
author = {APA},
booktitle = {W},
institution = {American Psychiatric Association},
isbn = {0890420629},
number = {VI},
pages = {xxvii, 886 p.},
pmid = {1595545},
publisher = {American Psychiatric Association},
title = {{Diagnostic and statistical manual of mental disorders: DSM-IV}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:DSM-IV:+diagnostic+and+statistical+manual+of+mental+disorders\#0},
volume = {4th},
year = {1994}
}
@book{Fogg2003,
abstract = {Can computers change what you think and do? Can they motivate you to stop smoking, persuade you to buy insurance, or convince you to join the Army? "Yes, they can," says Dr. B.J. Fogg, director of the Persuasive Technology Lab at Stanford University. Fogg has coined the phrase "Captology"(an acronym for computers as persuasive technologies) to capture the domain of research, design, and applications of persuasive computers.In this thought-provoking book, based on nine years of research in captology, Dr. Fogg reveals how Web sites, software applications, and mobile devices can be used to change people's attitudes and behavior. Technology designers, marketers, researchers, consumersanyone who wants to leverage or simply understand the persuasive power of interactive technologywill appreciate the compelling insights and illuminating examples found inside. Persuasive technology can be controversialand it should be. Who will wield this power of digital influence? And to what end? Now is the time to survey the issues and explore the principles of persuasive technology, and B.J. Fogg has written this book to be your guide. Filled with key term definitions in persuasive computingProvides frameworks for understanding this domainDescribes real examples of persuasive technologies},
author = {Fogg, B J},
booktitle = {Persuasive Technology Using Computers to Change What We Think and Do},
doi = {10.4017/gt.2006.05.01.009.00},
editor = {Kort, Yvonne and IJsselsteijn, Wijnand and Midden, Cees and Eggen, Berry and Fogg, B J},
file = {::},
isbn = {1558606432},
issn = {15691101},
number = {1},
pages = {283},
publisher = {Morgan Kaufmann},
series = {The Morgan Kaufmann series in interactive technologies},
title = {{Persuasive Technology: Using Computers to Change What We Think and Do}},
url = {http://books.google.com/books?id=r9JIkNjjTfEC\&pgis=1},
volume = {5},
year = {2003}
}
@article{Roberts1996,
author = {Roberts, William and Strayer, Janet},
doi = {10.2307/1131826},
file = {::},
issn = {00093920},
journal = {Child Development},
month = apr,
number = {2},
pages = {449},
title = {{Empathy, Emotional Expressiveness, and Prosocial Behavior}},
url = {http://www.jstor.org/stable/1131826?origin=crossref},
volume = {67},
year = {1996}
}
@inproceedings{Kipp2006,
abstract = {Providing virtual characters with natural gestures is a com- plex task. Even if the range of gestures is limited, deciding when to play whichgesture maybe considered bothanengineeringor anartistic task. We want to strike a balance by presenting a system where gesture selec- tion and timing can be human authored in a script, leaving full artistic freedom to the author. However, to make authoring faster we offer a rule system that generates gestures on the basis of human authored rules. To push automation further, we show how machine learning can be uti- lized to suggest further rules on the basis of previously annotated scripts. Our system thus offers different degrees of automation for the author, allowing for creativity and automation to join forces.},
address = {Marina Del Rey, CA, USA},
author = {Kipp, Michael},
booktitle = {6th International Conference on Intelligent Virtual Agents (IVA'06)},
doi = {10.1007/11821830\_19},
editor = {Gratch, Jonathan},
file = {::},
pages = {230--242},
publisher = {Springer Berlin Heidelberg},
title = {{Creativity Meets Automation : Combining Nonverbal Action Authoring with Rules and Machine Learning}},
year = {2006}
}
@inproceedings{Hegel2006,
author = {Hegel, Frank and Spexard, Torsten and Wrede, Britta and Horstmann, G. and Vogt, T.},
booktitle = {Humanoid Robots, 2006 6th IEEE-RAS International Conference on},
file = {::},
isbn = {142440200X},
pages = {56--61},
publisher = {IEEE},
title = {{Playing a different imitation game: Interaction with an Empathic Android Robot}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4115580},
year = {2006}
}
@article{Hatfield2009,
author = {Hatfield, Elaine and Rapson, Richard L. and Le, Yen-Chi L.},
file = {::},
journal = {The social neuroscience of empathy},
pages = {1--20},
title = {{Emotional Contagion and Empathy}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=KLvJKTN\_nDoC\&amp;oi=fnd\&amp;pg=PA19\&amp;dq=Emotional+Contagion+and+Empathy\&amp;ots=gC929Xij3X\&amp;sig=IFpRxpx1igOlZl86Jr837oVgfhY},
year = {2009}
}
@article{Mairesse2010,
author = {Mairesse, Fran\c{c}ois and Walker, Marilyn a.},
doi = {10.1007/s11257-010-9076-2},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mairesse, Walker - 2010 - Towards personality-based user adaptation psychologically informed stylistic language generation.pdf:pdf},
issn = {0924-1868},
journal = {User Modeling and User-Adapted Interaction},
keywords = {big five traits,dialogue,individual differences,linguistic style,natural language generation,personality,recommendation},
month = jul,
number = {3},
pages = {227--278},
title = {{Towards personality-based user adaptation: psychologically informed stylistic language generation}},
url = {http://www.springerlink.com/index/10.1007/s11257-010-9076-2},
volume = {20},
year = {2010}
}
@article{Schulman2011a,
abstract = {We present a conversational agent designed as a virtual counselor for health behavior change. The agent incorporates techniques drawn from Motivational Interviewing to enhance client motivation and confidence to change; these techniques are modeled and implemented based on a domain-specific taxonomy of dialogue acts. We discuss the design and preliminary evaluation of the agent.},
author = {Schulman, Daniel and Bickmore, Timothy and Sidner, Candace L},
journal = {I Can},
pages = {61--64},
title = {{An Intelligent Conversational Agent for Promoting Long-term Health Behavior Change using Motivational Interviewing}},
url = {http://www.aaai.org/ocs/index.php/SSS/SSS11/paper/download/2401/2854},
year = {2011}
}
@article{Fellner2012,
abstract = {Individuals may differ in their ability to learn the significance of emotional cues within a specific context. If so, trait emotional intelligence (EI) may be associated with faster cue learning. This study (N = 180) tested whether trait EI predicts faster learning of a critical cue for discriminating ‘‘terrorists’’ from ‘‘non-terrorists’’, using virtual-reality heads as stimuli. The critical cue was either facial emotion (positive or negative), or a neutral feature (hat size). Cognitive ability and subjective state were also assessed. Par- ticipants were faster to learn with an emotive cue. Surprisingly, high trait EI was correlated with poorer performance, especially early in learning. Subjective distress was also associated with impaired learning to emotive cues. },
author = {Fellner, Angela N. and Matthews, Gerald and Shockley, Kevin D. and Warm, Joel S. and Zeidner, Moshe and Karlov, Lisa and Roberts, Richard D.},
doi = {10.1016/j.jrp.2012.01.004},
file = {::},
issn = {00926566},
journal = {Journal of Research in Personality},
keywords = {trait emotional intelligence},
month = jun,
number = {3},
pages = {239--247},
publisher = {Elsevier Inc.},
title = {{Using emotional cues in a discrimination learning task: Effects of trait emotional intelligence and affective state}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0092656612000050},
volume = {46},
year = {2012}
}
@article{Creed2008,
author = {Creed, Chris and Beale, Russell},
file = {::},
journal = {Computational Intelligence: A Compendium},
pages = {185--230},
publisher = {Springer},
title = {{Emotional Intelligence: Giving Computers Effective Emotional Skills to Aid Interaction}},
url = {http://www.springerlink.com/index/U2231064587Q8V07.pdf},
volume = {230},
year = {2008}
}
@article{Hanna2007,
abstract = {This article describes how an object-oriented approach can be applied to the architectural design of a spoken language dialog system with the aim of facilitating the modification, extension, and reuse of discourse-related expertise. The architecture of the developed system is described and a functionally similar VoiceXML system is used to provide a comparative baseline across a range of modification and reuse scenarios. It is shown that the use of an object-oriented dialog manager can provide a capable means of reusing existing discourse expertise in a manner that limits the degree of structural decay associated with system change.},
author = {Hanna, Philip and O'neill, Ian and Wootton, Craig and Mctear, Michael},
doi = {10.1145/1255171.1255173},
file = {::},
issn = {15504875},
journal = {ACM Transactions on Speech and Language Processing},
keywords = {Design,Human Factors,Human-computer interaction,dialog management,speech and language processing,spoken dialog systems},
mendeley-tags = {Design,Human Factors},
month = jul,
number = {3},
pages = {Article 7 (July 2007), 39 pages},
title = {{Promoting extension and reuse in a spoken dialog manager}},
url = {http://portal.acm.org/citation.cfm?doid=1255171.1255173},
volume = {4},
year = {2007}
}
@article{Cooper2003,
abstract = {BACKGROUND: African-American patients who visit physicians of the same race rate their medical visits as more satisfying and participatory than do those who see physicians of other races. Little research has investigated the communication process in race-concordant and race-discordant medical visits. OBJECTIVES: To compare patient-physician communication in race-concordant and race-discordant visits and examine whether communication behaviors explain differences in patient ratings of satisfaction and participatory decision making. DESIGN: Cohort study with follow-up using previsit and postvisit surveys and audiotape analysis. SETTING: 16 urban primary care practices. PATIENTS: 252 adults (142 African-American patients and 110 white patients) receiving care from 31 physicians (of whom 18 were African-American and 13 were white). MEASUREMENTS: Audiotape measures of patient-centeredness, patient ratings of physicians' participatory decision-making styles, and overall satisfaction. RESULTS: Race-concordant visits were longer (2.15 minutes 95\% CI, 0.60 to 3.71) and had higher ratings of patient positive affect (0.55 point, 95\% CI, 0.04 to 1.05) compared with race-discordant visits. Patients in race-concordant visits were more satisfied and rated their physicians as more participatory (8.42 points 95\% CI, 3.23 to 13.60). Audiotape measures of patient-centered communication behaviors did not explain differences in participatory decision making or satisfaction between race-concordant and race-discordant visits. CONCLUSIONS: Race-concordant visits are longer and characterized by more patient positive affect. Previous studies link similar communication findings to continuity of care. The association between race concordance and higher patient ratings of care is independent of patient-centered communication, suggesting that other factors, such as patient and physician attitudes, may mediate the relationship. Until more evidence is available regarding the mechanisms of this relationship and the effectiveness of intercultural communication skills programs, increasing ethnic diversity among physicians may be the most direct strategy to improve health care experiences for members of ethnic minority groups.},
author = {Cooper, Lisa A and Roter, Debra L and Johnson, Rachel L and Ford, Daniel E and Steinwachs, Donald M and Powe, Neil R},
institution = {Johns Hopkins University School of Medicine and the Welch Center for Prevention, Epidemiology, and Clinical Research, Johns Hopkins University, Baltimore, Maryland 21205-2223, USA. lisa.cooper@jhmi.edu},
journal = {Annals of Internal Medicine},
keywords = {empirical approach,professional patient relationship},
number = {11},
pages = {907--915},
pmid = {14644893},
title = {{Patient-centered communication, ratings of care, and concordance of patient and physician race.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/14644893},
volume = {139},
year = {2003}
}
@inproceedings{Wang2010,
abstract = {Communication is more effective and persuasive when par- ticipants establish rapport. Tickle-Degnen and Rosenthal [57] argue rapport arises when participants exhibit mutual attentiveness, positivity and coordination. In this paper, we investigate how these factors relate to perceptions of rap- port when users interact via avatars in virtual worlds. In this study, participants told a story to what they believed was the avatar of another participant. In fact, the avatar was a computer program that systematically manipulated levels of attentiveness, positivity and coordination. In contrast to Tickel-Degnen and Rosenthal’s findings, its impact in a wide range of interpersonal domains includ- ing social engagement [52], classroom learning [22], suc- cess in negotiations [20], improving worker compliance [18], psychotherapeutic effectiveness [59], and improved quality of child care [11]. Recent research in virtual envi- ronments has demonstrated the possibility of translating these findings into computer-mediated (CMC) and human- computer interactions (HCI) where embodied communi- cated behaviors can not only be reproduced but altered in novel ways to perhaps amplify their interpersonal conse- quences [26] [5]. high-levels of mutual attentiveness alone can dramatically lower percep- tions of rapport in avatar communication. Indeed, an agent that attempted to maximize mutual attention performed as poorly as an agent that was designed to convey boredom. Adding positivity and coordination to mutual attentiveness, on the other hand, greatly improved rapport. This work un- veils the dependencies between components of rapport and informs the design of agents and avatars in computer medi- ated communication.},
address = {Atlanta, GA, USA},
author = {Wang, Ning and Gratch, Jonathan},
booktitle = {28th ACM Conference on Human Factors in Computing Systems (CHI'10)},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - p1241-wang.pdf(6).pdf:pdf},
keywords = {Virtual human,back-channel,gaze,head nod,pos- ture mirroring.,rapport},
pages = {1241--1249},
publisher = {ACM},
title = {{Don't just stare at me!}},
year = {2010}
}
@inproceedings{Bartneck2008,
author = {Bartneck, Christoph and Kulic, Dana and Croft, Elizabeth},
booktitle = {Metrics for HRI Workshop, Technical Report},
file = {::},
pages = {37--44},
title = {{Measuring the anthropomorphism, animacy, likeability, perceived intelligence and perceived safety of robots}},
url = {http://ece.uwaterloo.ca/~dkulic/pubs/bartneckKulicCroft.pdf},
volume = {471},
year = {2008}
}
@book{Hoffman2000,
author = {Hoffman, Martin L},
booktitle = {Development},
isbn = {052158034X},
pages = {2},
publisher = {Cambridge University Press},
title = {{Empathy and Moral Development: Implications for Caring and Justice}},
year = {2000}
}
@article{Drolet2000,
abstract = {We propose that face-to-face contact fosters the development of rapport and thereby helps negotiators coordinate on mutually beneficial settlements in mixed-motive conflicts. Specifically, we investigate whether, in a cooperative climate, negotiators visual access to each others nonverbal behavior fosters a dyadic state of rapport that facilitates mutual cooperation. Experiment 1 manipulated whether negotiators stood face-to-face or side-by- side (unable to see each other) in a simulated strike negotiation. Face-to-face dyads were more likely to coordinate on a settlement early in the strike, resulting in higher joint gains. An alternative interpretation in terms of an anticipatory effect of face-to-face contact was not supported. Experiment 2 manipulated whether previously unacquainted negotiators conversed face-to-face or by telephone before separating to play a conflict game with the structure of a Prisoners Dilemma game. Face-to-face dyads were more likely to coordinate on high joint gain outcomes. The facilitatory effect of face-to-face contact was statistically mediated by ameasure of dyadic rapport. Results did not support alternative interpretations based on individual-level positive affect or expectations about opponents. We conclude with a discussion of the role of affective and dyad-level processes in social psychological models of conflict resolution.},
author = {Drolet, Aimee L and Morris, Michael W},
doi = {10.1006/jesp.1999.1395},
issn = {00221031},
journal = {Journal of Experimental Social Psychology},
number = {1},
pages = {26--50},
publisher = {ACADEMIC PRESS INC},
title = {{Rapport in Conflict Resolution: Accounting for How Face-to-Face Contact Fosters Mutual Cooperation in Mixed-Motive Conflicts}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0022103199913951},
volume = {36},
year = {2000}
}
@inproceedings{Nor2010,
author = {Nor, R.M. and Muhlberger, Ralf},
booktitle = {User Science and Engineering (i-USEr), 2010 International Conference on},
file = {::},
isbn = {9781424490493},
keywords = {-component,community,empathy,emphatic communication,user experience},
pages = {7--10},
publisher = {IEEE},
title = {{Designing to support empathy: Understanding user experience by using a model of interaction in meeting human needs}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5716713},
year = {2010}
}
@article{Cowell2005a,
abstract = {For years, people have sought more natural means of communicating with their computers. Many have suggested that interaction with a computer should be as easy as interacting with other people, taking advantage of the multimodal nature of human communication. While users should, in theory, gravitate to such anthropomorphic embodiments, quite the contrary has been experienced; users generally have been dissatisfied and abandoned their use. This suggests a disconnect between factors that make human-human communication engaging and those used by designers to support human-agent interaction. This paper discusses a set of empirical studies that attempted to replicate human-human non-verbal behavior. The focus revolved around behaviors that portray a credible fa\c{c}ade, thereby helping embodied conversational agents (ECAs) to form a successful cooperative dyad with users. Based on a review of the non-verbal literature, a framework was created that identified trustworthy and credible non-verbal behaviors across five areas and formed design guidelines for character interaction. The design suggestions for those areas emanating from the facial region were experimentally supported but there was no concordant increase in perceived trust when bodily regions (posture, gesture) were added. In addition, in examining the importance of demographic elements in embodiment, it was found that users prefer to interact with characters that match their ethnicity and are young looking. There was no significant preference for gender. The implications of these results, as well as other interesting consequences are discussed.},
author = {Cowell, Andrew J. and Stanney, Kay M.},
doi = {10.1016/j.ijhcs.2004.11.008},
file = {::},
issn = {10715819},
journal = {International Journal of Human-Computer Studies},
month = feb,
number = {2},
pages = {281--306},
title = {{Manipulation of non-verbal interaction style and demographic embodiment to increase anthropomorphic computer character credibility}},
url = {http://ocw.tudelft.nl/fileadmin/ocw/opener/Manipulation\_of\_non-verbal\_interaction\_style\_and\_demographic\_embodiment\_to\_increase\_anthropomorphic\_computer\_character\_credibility.pdf},
volume = {62},
year = {2005}
}
@book{Doherty1998,
author = {Doherty, William Joseph and Campbell, Thomas},
pages = {159},
publisher = {Stage Pubications},
title = {{Families and Health}},
year = {1998}
}
@misc{TheMendeleySupportTeam2011,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/The Mendeley Support Team - 2011 - Getting Started with Mendeley(4).pdf:pdf},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@article{Mairesse2010a,
author = {Mairesse, Fran\c{c}ois and Walker, Marilyn a.},
doi = {10.1007/s11257-010-9076-2},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mairesse, Walker - 2010 - Towards personality-based user adaptation psychologically informed stylistic language generation.pdf:pdf},
issn = {0924-1868},
journal = {User Modeling and User-Adapted Interaction},
keywords = {big five traits,dialogue,individual differences,linguistic style,natural language generation,personality,recommendation},
month = jul,
number = {3},
pages = {227--278},
title = {{Towards personality-based user adaptation: psychologically informed stylistic language generation}},
url = {http://www.springerlink.com/index/10.1007/s11257-010-9076-2},
volume = {20},
year = {2010}
}
@article{Boukricha2011a,
author = {Boukricha, Hana and Wachsmuth, Ipke},
doi = {10.1007/s13218-011-0109-8},
file = {::},
issn = {0933-1875},
journal = {KI - K\"{u}nstliche Intelligenz},
keywords = {agent-agent interaction,empathic virtual humans,human-agent,internal simulation},
month = may,
number = {3},
pages = {195--204},
title = {{Empathy-Based Emotional Alignment for a Virtual Human: A Three-Step Approach}},
url = {http://www.springerlink.com/index/10.1007/s13218-011-0109-8},
volume = {25},
year = {2011}
}
@article{Zeng2009a,
abstract = {Automated analysis of human affective behavior has attracted increasing attention from researchers in psychology, computer science, linguistics, neuroscience, and related disciplines. However, the existing methods typically handle only deliberately displayed and exaggerated expressions of prototypical emotions despite the fact that deliberate behaviour differs in visual appearance, audio profile, and timing from spontaneously occurring behaviour. To address this problem, efforts to develop algorithms that can process naturally occurring human affective behaviour have recently emerged. Moreover, an increasing number of efforts are reported toward multimodal fusion for human affect analysis including audiovisual fusion, linguistic and paralinguistic fusion, and multi-cue visual fusion based on facial expressions, head movements, and body gestures. This paper introduces and surveys these recent advances. We first discuss human emotion perception from a psychological perspective. Next we examine available approaches to solving the problem of machine understanding of human affective behavior, and discuss important issues like the collection and availability of training and test data. We finally outline some of the scientific and engineering challenges to advancing human affect sensing technology.},
author = {Zeng, Zhihong and Pantic, Maja and Roisman, Glenn I and Huang, Thomas S.},
doi = {10.1109/TPAMI.2008.52},
file = {::},
isbn = {9781595938176},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Affect,Affect: physiology,Algorithms,Artificial Intelligence,Automated,Automated: methods,Emotions,Emotions: physiology,Facial Expression,Monitoring,Pattern Recognition,Physiologic,Physiologic: methods,Sound Spectrography,Sound Spectrography: methods},
month = jan,
number = {1},
pages = {39--58},
pmid = {19029545},
title = {{A survey of affect recognition methods: audio, visual, and spontaneous expressions.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19029545},
volume = {31},
year = {2009}
}
@inproceedings{Gratch2007,
abstract = {Emotional bonds don’t arise from a simple exchange of facial displays, but often emerge through the dynamic give and take of face-to-face interactions. This article explores the phenome- non of rapport, a feeling of connectedness that seems to arise from rapid and contingent positive feedback between partners and is often associated with socio-emotional processes. Rapport has been argued to lead to communicative efficiency, better learning outcomes, improved acceptance of medical advice and successful negotiations. We provide experimental evidence that a simple vir- tual character that provides positive listening feedback can induce stronger rapport-like effects than face-to-face communication between human partners. Specifically, this interaction can be more en- gaging to storytellers than speaking to a human audience, as measured by the length and content of their stories.},
address = {Chamonix, France},
annote = {They explore the rapport, a feeling of connectedness that arises from rapid and contingent positive feedback between partners and is often associated with socio-emotional processes. Rapport can lead to communicative efficiency, better learning outcomes, improved acceptance of medical advice and successful negotiations.
They experimentally proved that a simple virtual character with positive listening feedback can induce stronger rapport-like effects than face-to-face communication between human partners.},
author = {Gratch, Jonathan and Wang, Ning and Okhmatovskaia, Anna},
booktitle = {Proceedings of the 12th international conference on Human-computer interaction: intelligent multimodal interaction environments, HCI'07},
file = {::},
publisher = {Springer-Verlag Berlin, Heidelber},
title = {{Can virtual humans be more engaging than real ones?}},
url = {http://dl.acm.org/citation.cfm?id=1769622},
year = {2007}
}
@article{Breemen2005,
author = {van Breemen, A and Yan, X},
file = {::},
journal = {Proceedings of the fourth},
pages = {143--144},
title = {{iCat: an animated user-interface robot with personality}},
url = {http://dl.acm.org/citation.cfm?id=1082823},
year = {2005}
}
@article{BickmoreReview2005,
author = {Bickmore, Timothy and Toni Giorgino},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bickmore, Pavia - Unknown - Methodological Review Health Dialog Systems for Patients and Consumers.pdf:pdf},
journal = {Journal of Biomedical Informatics},
number = {617},
pages = {1--61},
title = {{Methodological Review : Health Dialog Systems for Patients and Consumers}}
}
@article{Becker-Asano2009,
abstract = {We introduce theWASABI ([W]ASABI [A]ffect [S]imulation for [A]gents with [B]elievable [I]nteractivity)Affect SimulationArchitecture, in which a virtual human’s cog- nitive reasoning capabilities are combined with simulated embodiment to achieve the sim- ulation of primary and secondary emotions. In modeling primary emotions we follow the idea of “Core Affect” in combination with a continuous progression of bodily feeling in three-dimensional emotion space (PADspace), that is subsequently categorized into discrete emotions. In humans, primary emotions are understood as onto-genetically earlier emotions, which directly influence facial expressions. Secondary emotions, in contrast, afford the abil- ity to reason about current events in the light of experiences and expectations.},
author = {Becker-Asano, Christian and Wachsmuth, Ipke},
doi = {10.1007/s10458-009-9094-9},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Becker-Asano, Wachsmuth - 2009 - Affective computing with primary and secondary emotions in a virtual human(3).pdf:pdf},
issn = {1387-2532},
journal = {Autonomous Agents and Multi-Agent Systems},
keywords = {affect simulation,affective computing,affective gaming,architecture,aware emotions,bdi-based architecture,embodied agent,emotion dynamics,emotion expression,emotion modeling,pad emotion space,primary and secondary emotions,reality,virtual,virtual human},
month = may,
number = {1},
pages = {32--49},
title = {{Affective computing with primary and secondary emotions in a virtual human}},
url = {http://www.springerlink.com/index/10.1007/s10458-009-9094-9},
volume = {20},
year = {2009}
}
@article{Hine2009,
author = {Hine, Michael J. and Murphy, Steven a. and Weber, Michael and Kersten, Gregory},
doi = {10.1007/s10726-008-9151-9},
file = {::},
issn = {0926-2644},
journal = {Group Decision and Negotiation},
keywords = {computer mediated communication,electronic negotiation,emotion,logistic regression},
month = jan,
number = {3},
pages = {193--211},
title = {{The Role of Emotion and Language in Dyadic E-negotiations}},
url = {http://www.springerlink.com/index/10.1007/s10726-008-9151-9},
volume = {18},
year = {2009}
}
@article{Pereira2011,
author = {Pereira, A. and Leite, Iolanda and Mascarenhas, Samuel and Martinho, Carlos and Paiva, Ana},
file = {::},
journal = {Human-Robot Personal Relationships},
keywords = {companionship,empathy,human-robot interaction},
pages = {130--138},
publisher = {Springer},
title = {{Using empathy to improve human-robot relationships}},
url = {http://www.springerlink.com/index/R468X62581620V62.pdf},
volume = {59},
year = {2011}
}
@article{Sabourin,
author = {Sabourin, Jennifer and Mott, Bradford and Lester, James},
file = {::},
journal = {lorentzcenter.nl},
keywords = {empathetic virtual agents,pedagogical agents,virtual learning},
title = {{Computational Models of Affect and Empathy for Pedagogical Virtual Agents}},
url = {http://www.lorentzcenter.nl/lc/web/2011/464/presentations/Sabourin.pdf}
}
@article{Suchman1997,
abstract = {To formulate an empirically derived model of empathic communication in medical interviews by describing the specific behaviors and patterns of interaction associated with verbal expressions of emotion.},
author = {Suchman, a L and Markakis, K and Beckman, H B and Frankel, R},
file = {::},
issn = {0098-7484},
journal = {JAMA : the journal of the American Medical Association},
keywords = {Communication,Empathy,Humans,Interviews as Topic,Models,Physician-Patient Relations,Psychological},
month = feb,
number = {8},
pages = {678--82},
pmid = {9039890},
title = {{A model of empathic communication in the medical interview.}},
volume = {277},
year = {1997}
}
@inproceedings{Pasquariello2001,
author = {Pasquariello, Stefano and Pelachaud, Catherine},
booktitle = {Proceedings 6th Online World Conference on Soft Computing in Industrial Appications Session on Soft Computing for Intelligent 3D Agents},
title = {{Greta: A Simple Facial Animation Engine}},
year = {2001}
}
@article{Bartlett2006,
author = {Bartlett, Marian Stewart and Littlewort, Gwen C and Frank, Mark G and Lainscsek, Claudia and Fasel, Ian R and Movellan, Javier R},
doi = {10.4304/jmm.1.6.22-35},
file = {::},
institution = {UCSD},
issn = {17962048},
journal = {Journal of Multimedia},
number = {6},
pages = {22--35},
publisher = {Citeseer},
title = {{Automatic Recognition of Facial Actions in Spontaneous Expressions}},
volume = {1},
year = {2006}
}
@book{C.E.Osgood1975,
author = {{C.E. Osgood} and May, W.H. and Miron, M.S.},
publisher = {University of Illinois Press},
title = {{Cross-Cultural Universals of Affective Meaning}},
year = {1975}
}
@article{Berry1997,
author = {Berry, D S and Pennebaker, J W and Mueller, J S and Hiller, W S},
doi = {10.1177/0146167297235008},
issn = {01461672},
journal = {Personality and Social Psychology Bulletin},
number = {5},
pages = {526--537},
title = {{Linguistic Bases of Social Perception}},
url = {http://psp.sagepub.com/cgi/doi/10.1177/0146167297235008},
volume = {23},
year = {1997}
}
@article{Davis1983,
author = {Davis, Mark H.},
doi = {10.1037/0022-3514.44.1.113},
file = {::},
issn = {0022-3514},
journal = {Journal of Personality and Social Psychology},
number = {1},
pages = {113--126},
title = {{Measuring individual differences in empathy: Evidence for a multidimensional approach.}},
volume = {44},
year = {1983}
}
@article{Caridakis2008,
abstract = {As input they consider the image sequence of the recorded human behavior. Computer vision and image processing techniques are incorporated in order to detect cues needed for expressivity features extraction. Using multimodalities, the virtual agent mimics the human expressions. The multimodality of the approach lies in the fact that both facial and gestural aspects of the user’s behavior are analyzed and processed. The mimicry consists of perception, interpretation, planning and animation of the expressions shown by the human, resulting not in an exact duplicate rather than an expressive model of the user’s original behavior.},
annote = {They use both facial and gestural aspects of the user’s behavior to mimic the user’s expressions. The introductory information and references about the psychological background of the mimicry in the paper are useful. But because most of the work is image processing, other sections would not be useful for our job.
Their system does not work in real time because they use a recorded video or sequence of images (limitation).},
author = {Caridakis, George and Raouzaiou, Amaryllis and Bevacqua, Elisabetta and Mancini, Maurizio and Karpouzis, Kostas and Malatesta, Lori and Pelachaud, Catherine},
doi = {10.1007/s10579-007-9057-1},
file = {::},
issn = {1574-020X},
journal = {Language Resources and Evaluation},
keywords = {facial,gesture,mimicry,multimodal,virtual agent},
month = jan,
number = {3-4},
pages = {367--388},
title = {{Virtual agent multimodal mimicry of humans}},
volume = {41},
year = {2008}
}
@inproceedings{Heerink2009,
author = {Heerink, Marcel and Krose, B. and Evers, Vanessa and Wielinga, Bob},
booktitle = {Robot and Human Interactive Communication, 2009. RO-MAN 2009. The 18th IEEE International Symposium on},
file = {::},
pages = {528--533},
publisher = {IEEE},
title = {{Measuring acceptance of an assistive social robot: a suggested toolkit}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5326320},
year = {2009}
}
@article{Catucci2006,
author = {Catucci, Graziano and Abbattista, Fabio and Gadaleta, R. and Guaccero, Domenico and Semeraro, Giovanni},
file = {::},
journal = {Applied Soft Computing Technologies: The Challenge of Complexity},
keywords = {autonomous agents,emotional agents,synthetic characters},
pages = {265--277},
publisher = {Springer},
title = {{Empathy: A computational framework for emotion generation}},
url = {http://www.springerlink.com/index/LJ26L065L0072722.pdf},
year = {2006}
}
@article{Orozco2010,
author = {Orozco, H. and Thalmann, Daniel and Ramos, F.},
file = {::},
journal = {Proceedings of 11th Computer Graphics International, CGI},
title = {{Making empathetic virtual humans in human–computer interaction scenarios}},
url = {http://cgi2010.miralab.unige.ch/short/SP09/SP09.pdf},
volume = {10},
year = {2010}
}
@inproceedings{Legaspi2008,
author = {Legaspi, Roberto and Kurihara, Satoshi and Fukui, K.I. and Moriyama, Koichi and Numao, Masayuki},
booktitle = {Human system interactions, 2008 conference on},
file = {::},
isbn = {1424415438},
keywords = {empathic computing,interfaces,machine learning,user modeling and user-adaptive},
pages = {209--214},
publisher = {IEEE},
title = {{An empathy learning problem for HSI: To be empathic, self-improving and ambient}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4581435},
year = {2008}
}
@article{Yacoub2003,
author = {Yacoub, Sherif and Simske, Steve and Lin, Xiaofan and Burns, John},
file = {::},
journal = {8th European Conference on Speech Communication and Technology},
number = {September},
pages = {1--4},
title = {{Recognition of emotions in interactive voice response systems}},
url = {http://www.isca-speech.org/archive/eurospeech\_2003/e03\_0729.html},
year = {2003}
}
@article{Hand2008,
author = {Hand, Stacey and Varan, Duane},
file = {::},
journal = {Changing Television Environments},
pages = {11--19},
publisher = {Springer},
title = {{Interactive Narratives: Exploring the Links between Empathy, Interactivity and Structure}},
url = {http://www.springerlink.com/index/15385726247gu863.pdf},
year = {2008}
}
@article{Sebe2005a,
author = {Sebe, Nicu and Cohen, Ira and Huang, Thomas S.},
file = {::},
journal = {Handbook of Pattern Recognition and Computer Vision},
pages = {981--256},
publisher = {Citeseer},
title = {{Multimodal emotion recognition}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.110.1129\&amp;rep=rep1\&amp;type=pdf},
year = {2005}
}
@book{Greene2003,
abstract = {Providing a thorough review and synthesis of work on communication skills and skill enhancement, this "Handbook" serves as a comprehensive and contemporary survey of theory and research on social interaction skills. Editors John O. Greene and Brant R. Burleson have brought together preeminent researchers and writers to contribute to this volume, establishing a foundation on which future study and research will build. The handbook chapters are organized into five major units: general theoretical and methodological issues (models of skill acquisition, methods of skill assessment); fundamental interaction skills (both transfunctional and transcontextual); function-focused skills (informing, persuading, supporting); skills used in management of diverse personal relationships (friendships, romances, marriages); and skills used in varied venues of public and professional life (managing leading, teaching). Distinctive features of this handbook include: broad, comprehensive treatment of work on social interaction skills and skill acquisition; up-to-date reviews of research in each area; and emphasis on empirically supported strategies for developing and enhancing specific skills. Researchers in communication studies, psychology, family studies, business management, and related areas will find this volume a comprehensive, authoritative source on communications skills and their enhancement, and it will be essential reading for scholars and students across the spectrum of disciplines studying social interaction.},
author = {Greene, John O and Burleson, Brant Raney},
booktitle = {Communication},
editor = {Greene, John O and Burleson, Brant R},
isbn = {0805834176},
pages = {1051},
publisher = {Lawrence Erlbaum Associates, Inc., Publishers},
title = {{Handbook of Communication and Social Interaction Skills}},
year = {2003}
}
@article{Zeng2009,
abstract = {Automated analysis of human affective behavior has attracted increasing attention from researchers in psychology, computer science, linguistics, neuroscience, and related disciplines. However, the existing methods typically handle only deliberately displayed and exaggerated expressions of prototypical emotions despite the fact that deliberate behaviour differs in visual appearance, audio profile, and timing from spontaneously occurring behaviour. To address this problem, efforts to develop algorithms that can process naturally occurring human affective behaviour have recently emerged. Moreover, an increasing number of efforts are reported toward multimodal fusion for human affect analysis including audiovisual fusion, linguistic and paralinguistic fusion, and multi-cue visual fusion based on facial expressions, head movements, and body gestures. This paper introduces and surveys these recent advances. We first discuss human emotion perception from a psychological perspective. Next we examine available approaches to solving the problem of machine understanding of human affective behavior, and discuss important issues like the collection and availability of training and test data. We finally outline some of the scientific and engineering challenges to advancing human affect sensing technology.},
author = {Zeng, Zhihong and Pantic, Maja and Roisman, Glenn I and Huang, Thomas S.},
doi = {10.1109/TPAMI.2008.52},
file = {::},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Affect,Affect: physiology,Algorithms,Artificial Intelligence,Automated,Automated: methods,Emotions,Emotions: physiology,Facial Expression,Monitoring,Pattern Recognition,Physiologic,Physiologic: methods,Sound Spectrography,Sound Spectrography: methods},
month = jan,
number = {1},
pages = {39--58},
pmid = {19029545},
title = {{A survey of affect recognition methods: audio, visual, and spontaneous expressions.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19029545},
volume = {31},
year = {2009}
}
@article{Stevenson2007,
abstract = {The Affective Norms for English Words (ANEW) are a commonly used set of 1034 words characterized on the affective dimensions of valence, arousal, and dominance. Traditionally, studies of affect have used stimuli characterized along either affective dimensions or discrete emotional categories, but much current research draws on both of these perspectives. As such, stimuli that have been thoroughly characterized according to both of these approaches are exceptionally useful. In an effort to provide researchers with such a characterization of stimuli, we have collected descriptive data on the ANEW to identify which discrete emotions are elicited by each word in the set. Our data, coupled with previous characterizations of the dimensional aspects of these words, will allow researchers to control for or manipulate stimulus properties in accordance with both dimensional and discrete emotional views, and provide an avenue for further integration of these two perspectives. Our data have been archived at},
author = {Stevenson, Ryan A and Mikels, Joseph A and James, Thomas W},
institution = {Department of Psychological and Brain Sciences, Indiana University, Bloomington, Indiana 47405, USA. stevenra@indiana.edu},
journal = {Behavior Research Methods},
number = {1},
pages = {1020--1024},
pmid = {18183921},
publisher = {Psychonomic Society},
title = {{Characterization of the affective norms for English words by discrete emotional categories.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18183921},
volume = {40},
year = {2007}
}
@inproceedings{Nor2010,
author = {Nor, R.M. and Muhlberger, Ralf},
booktitle = {User Science and Engineering (i-USEr), 2010 International Conference on},
file = {::},
isbn = {9781424490493},
keywords = {-component,community,empathy,emphatic communication,user experience},
pages = {7--10},
publisher = {IEEE},
title = {{Designing to support empathy: Understanding user experience by using a model of interaction in meeting human needs}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5716713},
year = {2010}
}
@article{Chen2004,
abstract = {The high prevalence of drinking in young adults is a serious public health concern. Alcohol use among young adults often is associated with a wide variety of risky behaviors and both immediate and long-term negative consequences. The 2001–2002 National Epidemiologic Survey on Alcohol and Related Conditions (NESARC) presents a unique opportunity to examine young adult drinking because it has an excellent response rate, oversamples young adults ages 18–24, and includes college-related group housing. According to the NESARC data, in 2001–2002 over three-quarters of young adults ages 21–24 were current drinkers, as were nearly two-thirds of those ages 18–20, despite the fact that the legal drinking age is 21. More than half of young adult men exceeded the recommended daily drinking limit, as did two-fifths of young adult women. Although the prevalence of exceeding the daily limit is higher for those ages 21–24 than for those ages 18–20, it also is substantial for those ages 18–20. Because drinking more than the recommended per-occasion maximum is likely to impair mental and physical performance, the increase over the past decade in the prevalence among young adults of drinking five or more drinks 12 or more times per year may help explain the increased risk of injury and other acute negative consequences commonly observed among college students ages 18–24.},
author = {Chen, C. M. and Dufour, M. C. and Yi, H.},
journal = {Alcohol Research and Health},
keywords = {AOD (alcohol and other drug) use pattern,AOD intake per occasion,AOD use frequency,National Epidemiologic Survey on Alcohol and Relat,aggregate AOD consumption,amount of AOD use,binge drinking,ethnic differences,gender differences,heavy drinking,individual AOD consumption,racial differences,underage drinking,undergraduate student,young adult},
pages = {269-- 280},
title = {{Alcohol consumption among young adults ages 18–24 in the United States: Results from the 2001–2002 NESARC Survey}},
url = {http://pubs.niaaa.nih.gov/publications/arh284/269?280.htm},
volume = {28},
year = {2004}
}
@incollection{Mora1999,
abstract = {Beliefs-Desires-Intentions models (or BDI models) of agents have been around for quit a long time. The purpose of these models is to characterize agents using anthropomorphic notions, such as mental states and actions. How- ever, despite the fact that many systems have been developed based on these mod- els, it is a general concern that there is a gap between those powerful BDI logics and practical systems. The purpose of this paper is to present a BDI model that, besides being a formal model of agents, is also suitable to be used to implement agents. Instead of defining a new BDI logic or choosing an existing one, and ex- tending it with an operational model, we define the notions of belief, desires and intentions using a logic formalism that is both well-defined and computational.},
author = {Mora, M and Lopes, J and Viccariz, R and Coelho, H},
booktitle = {Intelligent Agents V: Agents Theories, Architectures, and Languages},
chapter = {Section I},
doi = {10.1007/3-540-49057-4\_2},
editor = {Muller, J.P.},
file = {::},
keywords = {BDI models,agent architectures,logic program- ming.,mental states modeling},
pages = {11--27},
publisher = {Springer-Verlag Berlin Heidelberg},
title = {{BDI models and systems: Reducing the gap}},
url = {http://www.springerlink.com/index/m674631247x60251.pdf},
year = {1999}
}
@inproceedings{Boukricha2007,
abstract = {Addressing user’s emotions in human-computer interaction significantly enhances the believability and lifelikeness of virtual humans. Emotion recognition and interpretation is realized in our approach by integrating empathy as a designated process within the agent’s cognitive architecture. In this paper we describe this empathy process which comprises of two interconnected components: a belief-desire-intention (BDI) based cognitive component and an affective component based on the emotion simulation system of the virtual human Max.},
address = {Osnabr\"{u}ck, Germany},
author = {Boukricha, Hana and Becker-Asano, Christian},
booktitle = {Proceedings of the 2nd Workshop at KI2007 on Emotion and Computing – Current Research and Future Impact},
editor = {{Dirk Reichardt} and Levi, Paul},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Boukricha, Becker-Asano - 2007 - Simulating empathy for the virtual human max(3).pdf:pdf},
pages = {23--28},
title = {{Simulating empathy for the virtual human max}},
url = {http://wwwlehre.dhbw-stuttgart.de/~reichard/itemotion/2007/},
year = {2007}
}
@article{Behrend2012,
abstract = {It is increasingly common for people engaging in computer–mediated interactions to be accompanied by a digital avatar that represents them. Little is known, however, about how these avatars influence others’ impressions. We examine this question in the context of employment interviews. It is well known that attractive job candidates are afforded an advantage in traditional face-to-face job interviews. We investigate whether raters evaluating computer–mediated interviews will follow a similar pattern when a digital avatar represents the candidate. To investigate this question, we asked 374 raters to view an interview transcript that was accompanied by either a male or female avatar, applying for either a male or female gender-typed job. We found that candidates with more attractive avatars received more favorable interview ratings, regardless of job gender type. These findings support the notion that the ‘‘what is beautiful is good’’ stereotype influences interview ratings even in computer-mediated interviews; raters automatically apply the same heuristics to digital and non-digital faces.},
author = {Behrend, Tara and Toaddy, Steven and Thompson, Lori Foster and Sharek, David J.},
doi = {10.1016/j.chb.2012.06.017},
file = {::},
issn = {07475632},
journal = {Computers in Human Behavior},
keywords = {Computer–mediated interview Attractiveness bias Se,Virtual world},
month = jul,
publisher = {Elsevier Ltd},
title = {{The effects of avatar appearance on interviewer ratings in virtual employment interviews}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0747563212001677},
year = {2012}
}
@article{Bryant2008,
author = {Bryant, Gregory a. and Barrett, H. Clark},
doi = {10.1163/156770908X289242},
file = {::},
issn = {15677095},
journal = {Journal of Cognition and Culture},
keywords = {and can include bodily,com-,cross-cultural comparisons,deployed physical displays with,emotional expressions are strategically,evolutionary psychology,facial movements and,gestures,municative function,speech,universals,vocal emotion},
month = apr,
number = {1},
pages = {135--148},
title = {{Vocal Emotion Recognition Across Disparate Cultures}},
url = {http://openurl.ingenta.com/content/xref?genre=article\&issn=1567-7095\&volume=8\&issue=1\&spage=135},
volume = {8},
year = {2008}
}
@article{Prendinger2006,
annote = {they have tested 4 different empathic behaviours in a competitive card game.
1- Non-Emotional2- Self-Centered Emotional
3- Negative Empathic 
4- Positive Empathic 
They found out that:
 - absence of the agent's display of negative emotions is arousing for the user and highers his/her stress.
 - valence of users' emotional response is congruent with the valence of the emotion expressed by the agent.},
author = {Prendinger, H and Becker-Asano, Christian},
file = {::},
journal = {International Journal of Humanoid},
keywords = {affective behavior,empathy,evaluation,life-like characters,physiological user information},
number = {3},
pages = {371--391},
title = {{A STUDY IN USERS'S;PHYSIOLOGICAL RESPONSE TO AN EMPATHIC INTERFACE AGENT}},
volume = {3},
year = {2006}
}
@book{Picard1997,
address = {Cambridge, Massachusetts},
author = {Picard, Rosalind W},
isbn = {0-262-16170-2},
publisher = {The MIT Press},
title = {{Affective Computing}},
year = {1997}
}
@inproceedings{Nguyen2009c,
author = {Nguyen, H. and Masthoff, Judith},
booktitle = {Proceedings of the 4th International Conference on Persuasive Technology},
file = {::},
isbn = {9781605583761},
keywords = {affective computing,design,experimentation,human factors},
pages = {7},
publisher = {ACM},
title = {{Designing empathic computers: the effect of multimodal empathic feedback using animated agent}},
url = {http://dl.acm.org/citation.cfm?id=1541958},
year = {2009}
}
@inproceedings{Pulman2010,
abstract = {We describe a ‘How was your day?’ (HWYD) Companion whose purpose is to establish a comforting and supportive rela- tionship with a user via a conversation on a variety of work-related topics. The sys- tem has several fairly novel features aimed at increasing the naturalness of the interac- tion: a rapid ‘short loop’ response primed by the results of acoustic emotion anal- ysis, and an ‘interruption manager’, en- abling the user to interrupt lengthy or ap- parently inappropriate system responses, prompting a replanning of behaviour on the part of the system. The ‘long loop’ also takes into account the emotional state of the user, but using more conventional dialogue management and planning tech- niques. We describe the architecture and components of the implemented prototype HWYD system.},
address = {Uppsala, Sweden},
author = {Pulman, S G and Boye, J and Cavazza, M and Smith, Cameron},
booktitle = {Proceedings of the 2010 Workshop on Companionable Dialogue Systems, ACL 2010},
file = {::},
number = {July},
pages = {37--42},
publisher = {Association for Computational Linguistics},
title = {{‘ How was your day ?’}},
year = {2010}
}
@article{BickmoreReview2005,
author = {Bickmore, Timothy and Toni Giorgino},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bickmore, Pavia - Unknown - Methodological Review Health Dialog Systems for Patients and Consumers.pdf:pdf},
journal = {Journal of Biomedical Informatics},
number = {617},
pages = {1--61},
title = {{Methodological Review : Health Dialog Systems for Patients and Consumers}}
}
@book{Stueber2006,
author = {Stueber, Karsten},
edition = {1},
isbn = {026219550X},
publisher = {MIT Press},
title = {{Rediscovering Empathy: Agency, Folk Psychology, and the Human Sciences}},
year = {2006}
}
@article{Gratch2007a,
author = {Gratch, Jonathan and Wang, Ning and Gerten, Jillian and Fast, Edward},
file = {::},
journal = {Intelligent Virtual Agents},
keywords = {evaluation,rapport,virtual agents},
title = {{Creating rapport with virtual agents}},
url = {http://www.springerlink.com/index/X568357400058UM7.pdf},
year = {2007}
}
@article{Paiva2004,
author = {Paiva, Ana and Dias, J. and Sobral, Daniel and Aylett, Ruth},
file = {::},
isbn = {1581138644},
journal = {on Autonomous Agents},
title = {{Caring for agents and agents that care: Building empathic relations with synthetic agents}},
url = {http://dl.acm.org/citation.cfm?id=1018754},
year = {2004}
}
@inproceedings{Higashinaka2008,
author = {Higashinaka, R. and Dohsaka, K. and Isozaki, H.},
booktitle = {Spoken Language Technology Workshop, 2008. SLT 2008. IEEE},
file = {::},
isbn = {9781424434725},
pages = {109--112},
publisher = {IEEE},
title = {{Effects of self-disclosure and empathy in human-computer dialogue}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4777852},
year = {2008}
}
@article{Clark1998,
abstract = {Speakers often repeat the first word of major constituents, as in, "I uh I wouldn't be surprised at that." Repeats like this divide into four stages: an initial commitment to the constituent (with "I"); the suspension of speech; a hiatus in speaking (filled with "uh"); and a restart of the constituent ("I wouldn't."). An analysis of all repeated articles and pronouns in two large corpora of spontaneous speech shows that the four stages reflect different principles. Speakers are more likely to make a premature commitment, immediately suspending their speech, as both the local constituent and the constituent containing it become more complex. They plan some of these suspensions from the start as preliminary commitments to what they are about to say. And they are more likely to restart a constituent the more their stopping has disrupted its delivery. We argue that the principles governing these stages are general and not specific to repeats.},
author = {Clark, H H and Wasow, T},
doi = {10.1006/cogp.1998.0693},
file = {::},
issn = {0010-0285},
journal = {Cognitive psychology},
keywords = {Humans,Language,Verbal Behavior},
month = dec,
number = {3},
pages = {201--42},
pmid = {9892548},
title = {{Repeating words in spontaneous speech.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9892548},
volume = {37},
year = {1998}
}
@inproceedings{Dahlberg2008,
abstract = {Research experiences for undergraduates are considered an effective means for increasing student retention and encouraging undergraduate students to continue on to graduate school. However, managing a cohort of undergraduate researchers, with varying skill levels, can be daunting for faculty advisors. We have developed a program to engage students in research and outreach in visualization, virtual reality, networked robotics, and interactive games. Our program immerses students into the life of a lab, employing a situated learning approach that includes tiered mentoring and collaboration to enable students at all levels to contribute to research. Students work in research comprised of other undergraduates, graduate students and faculty, and participate in professional development and social gatherings within the larger cohort. Results from our first two years indicate this approach is manageable and effective for increasing students’ ability and desire to conduct research.},
address = {New York, New York, USA},
author = {Dahlberg, Teresa and Barnes, Tiffany and Rorrer, Audrey and Powell, Eve and Cairco, Lauren},
booktitle = {Proceedings of the 39th SIGCSE technical symposium on Computer science education - SIGCSE '08},
doi = {10.1145/1352135.1352293},
file = {::},
isbn = {9781595937995},
keywords = {education,undergraduate research},
pages = {466},
publisher = {ACM Press},
title = {{Improving retention and graduate recruitment through immersive research experiences for undergraduates}},
url = {http://portal.acm.org/citation.cfm?doid=1352135.1352293},
year = {2008}
}
@article{Maurer1983,
author = {Maurer, R.E. and Tindall, J.H.},
file = {::},
journal = {Journal of Counseling Psychology},
number = {2},
pages = {158},
publisher = {American Psychological Association},
title = {{Effect of postural congruence on client's perception of counselor empathy.}},
volume = {30},
year = {1983}
}
@inproceedings{Whitehill2008,
author = {Whitehill, Jacob and Bartlett, Marian and Movellan, Javier R},
booktitle = {Intelligent Tutoring Systems},
file = {::},
pages = {668--670},
publisher = {Springer},
title = {{Measuring the perceived difficulty of a lecture using automatic facial expression recognition}},
year = {2008}
}
@inproceedings{Wang2009,
abstract = {How to build virtual agents that establish rapport with human? According to Tickle-Degnen and Rosenthal, the three essential components of rapport are mutual attentiveness, positivity and coordination. In our previous work, we designed an embodied virtual agent to establish rapport with a human speaker by providing rapid and contingent nonverbal feedback. How do we know that a human speaker is feeling a sense of rapport? In this paper, we focus on the positivity component of rapport by investigating the relationship of human speakers' facial expressions on the establishment of rapport. We used an automatic facial expression coding tool called CERT to analyze the human dyad interactions and human-virtual human interactions. Results show that recognizing positive facial displays alone may be insufficient and that recognized negative facial displays was more diagnostic in assessing the level of rapport between participants.},
address = {Amsterdam},
annote = {Out of three components of rapport by Tickle-Degnene and Rosenthal (mutual attentiveness, positivity, and coordination), they investigated the relationship between human speakers' facial expression and rapport. Results show that recognizing positive facial expressions alone is insufficient but negative facial displays are more effective in assessing the level of rapport between participants.},
author = {Wang, Ning and Gratch, Jonathan},
booktitle = {3rd International Conference on Affective Computing and Intelligent Interaction and Workshops, 2009. ACII 2009},
doi = {10.1109/ACII.2009.5349514},
file = {::},
isbn = {978-1-4244-4800-5},
month = sep,
pages = {1--6},
publisher = {IEEE},
title = {{Rapport and facial expression}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5349514},
year = {2009}
}
@article{Friesen1983,
author = {Friesen, Wallace V and Ekman, Paul},
journal = {Unpublished manuscript, University of California at San Francisco},
publisher = {University of California},
title = {{EMFACS-7: Emotional Facial Action Coding System}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:EMFACS-7:+Emotional+Facial+Action+Coding+System\#0},
year = {1983}
}
@article{Cappella1990,
author = {Cappella, Joseph N.},
doi = {10.1207/s15327965pli0104\_5},
file = {::},
issn = {1047-840X},
journal = {Psychological Inquiry},
month = oct,
number = {4},
pages = {303--305},
title = {{On Defining Conversational Coordination and Rapport}},
url = {http://www.tandfonline.com/doi/abs/10.1207/s15327965pli0104\_5},
volume = {1},
year = {1990}
}
@book{Miller2002,
abstract = {This bestselling work has introduced hundreds of thousands of professionals and students to motivational interviewing (MI), a proven approach to helping people overcome ambivalence that gets in the way of change. William R. Miller and Stephen Rollnick explain current thinking on the process of behavior change, present the principles of MI, and provide detailed guidelines for putting it into practice. Case examples illustrate key points and demonstrate the benefits of MI in addictions treatment and other clinical contexts. The authors also discuss the process of learning MI. Chapters contributed by other leading experts address such special topics as MI and the stages-of-change model; applications in medical, public health, and criminal justice settings; and using the approach with groups, couples, and adolescents.},
address = {New York},
author = {Miller, William R. and Rollnick, Stephen},
booktitle = {Zeitschrift f\"{u}r Klinische Psychologie und Psychotherapie},
chapter = {428},
doi = {10.1026/1616-3443.34.1.66},
edition = {2nd},
isbn = {1572305630},
issn = {16163443},
number = {1},
pages = {428},
pmid = {12538308},
publisher = {Guilford Press},
title = {{Motivational Interviewing: Preparing People for Change}},
url = {http://books.google.com/books?id=r\_CuyHwdz7EC\&pgis=1},
volume = {2nd},
year = {2002}
}
@article{Chartrand1999,
abstract = {The chameleon effect refers to nonconscious mimicry of the postures, mannerisms, facial expressions, and other behaviors of one's interaction partners, such that one's behavior passively and unintentionally changes to match that of others in one's current social environment. The authors suggest that the mechanism involved is the perception-behavior link, the recently documented finding (e.g., J. A. Bargh, M. Chen, \& L. Burrows, 1996) that the mere perception of another's behavior automatically increases the likelihood of engaging in that behavior oneself. Experiment 1 showed that the motor behavior of participants unintentionally matched that of strangers with whom they worked on a task. Experiment 2 had confederates mimic the posture and movements of participants and showed that mimicry facilitates the smoothness of interactions and increases liking between interaction partners. Experiment 3 showed that dispositionally empathic individuals exhibit the chameleon effect to a greater extent than do other people.},
author = {Chartrand, T. L. and Bargh, J A},
file = {::},
issn = {0022-3514},
journal = {Journal of personality and social psychology},
keywords = {Analysis of Variance,Empathy,Facial Expression,Female,Group Processes,Humans,Imitative Behavior,Interpersonal Relations,Male,Models,Multivariate Analysis,New York City,Posture,Psychological,Social Behavior,Social Perception},
month = jun,
number = {6},
pages = {893--910},
pmid = {10402679},
title = {{The chameleon effect: the perception-behavior link and social interaction.}},
volume = {76},
year = {1999}
}
@article{Robison2010,
abstract = {affective interventions can both positively and negatively influence learning experiences. In this paper we investigate the role of student personality, including goal orienta- tion and empathetic tendencies, in estimating confidence in the benefits of an affective intervention strategy. The results indicate that student personality profiles can serve as a powerful tool for informing affective feedback models.},
annote = {We can use the same way of menu base self-report affective state recognition (in addition to automatic) and text-base empathic feedback. Then after each feedback we can evaluate the feedback with another user self-report.},
author = {Robison, Jennifer and McQuiggan, Scott W and Lester, James and Carolina, North},
keywords = {affect,affective computing,pedagogical agents},
pages = {285--295},
title = {{Developing Empirically Based Student Personality Profiles for Affective Feedback Models}},
year = {2010}
}
@article{Scherer2003,
author = {Scherer, Klaus R.},
doi = {10.1016/S0167-6393(02)00084-5},
file = {::},
issn = {01676393},
journal = {Speech communication},
month = apr,
number = {1-2},
pages = {227--256},
title = {{Vocal communication of emotion: A review of research paradigms}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167639302000845 http://www.sciencedirect.com/science/article/pii/S0167639302000845},
volume = {40},
year = {2003}
}
@article{Jacob2011,
author = {Jacob, Pierre},
doi = {10.1007/s13164-011-0065-0},
file = {::},
issn = {1878-5158},
journal = {Review of Philosophy and Psychology},
month = aug,
number = {August},
pages = {519--540},
title = {{The Direct-Perception Model of Empathy: a Critique}},
url = {http://www.springerlink.com/index/10.1007/s13164-011-0065-0},
year = {2011}
}
@article{Rebolledo-Mendez2009,
author = {Rebolledo-Mendez, Genaro and Freitas, Sara De and Gaona, Alma Rosa Garcia},
doi = {10.1109/VS-GAMES.2009.33},
file = {::},
isbn = {978-0-7695-3588-3},
journal = {2009 Conference in Games and Virtual Worlds for Serious Applications},
keywords = {- empathy,alma rosa garcia gaona,facultad de inform\'{a}tica,motivation,serious games,universidad veracruzana},
month = mar,
pages = {5--11},
publisher = {Ieee},
title = {{A Model of Motivation Based on Empathy for AI-Driven Avatars in Virtual Worlds}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5116547},
year = {2009}
}
@book{Apa1994,
abstract = {DSM-IV},
author = {APA},
booktitle = {W},
institution = {American Psychiatric Association},
isbn = {0890420629},
number = {VI},
pages = {xxvii, 886 p.},
pmid = {1595545},
publisher = {American Psychiatric Association},
title = {{Diagnostic and statistical manual of mental disorders: DSM-IV}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:DSM-IV:+diagnostic+and+statistical+manual+of+mental+disorders\#0},
volume = {4th},
year = {1994}
}
@inproceedings{Breitfuss2007,
address = {New York, New York, USA},
author = {Breitfuss, Werner and Prendinger, Helmut and Ishizuka, Mitsuru},
booktitle = {Proceedings of the ninth international conference on Multimodal interfaces - ICMI '07},
doi = {10.1145/1322192.1322247},
file = {::},
isbn = {9781595938176},
keywords = {interfaces,multi-modal presentation,multimodal input and output},
pages = {319--322},
publisher = {ACM Press},
title = {{Automated generation of non-verbal behavior for virtual embodied characters}},
url = {http://portal.acm.org/citation.cfm?doid=1322192.1322247},
year = {2007}
}
@misc{Tsui1985,
abstract = {The extent to which relatively unassimilated Asian clients can utilize traditional psychotherapy is likely to depend upon the ability of therapists to understand cultural differences and to adapt their clinical styles accordingly. Common errors made by non-Asian therapists attempting to engage Asians in psychotherapy are identified and appropriate therapeutic strategies are suggested.},
author = {Tsui, P and Schultz, G L},
booktitle = {The American journal of orthopsychiatry},
number = {4},
pages = {561--569},
pmid = {4073227},
title = {{Failure of rapport: why psychotherapeutic engagement fails in the treatment of Asian clients.}},
volume = {55},
year = {1985}
}
@article{Bewick2008,
abstract = {To review the published literature on the effectiveness of web-based interventions designed to decrease consumption of alcohol and/or prevent alcohol abuse.},
author = {Bewick, Bridgette M and Trusler, Karen and Barkham, Michael and Hill, Andrew J and Cahill, Jane and Mulhern, Brendan},
doi = {10.1016/j.ypmed.2008.01.005},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bewick et al. - 2008 - The effectiveness of web-based interventions designed to decrease alcohol consumption--a systematic review.pdf:pdf},
issn = {0091-7435},
journal = {Preventive medicine},
keywords = {Alcohol Drinking,Alcohol Drinking: prevention \& control,Alcoholism,Alcoholism: prevention \& control,Health Education,Humans,Internet,United States},
month = jul,
number = {1},
pages = {17--26},
pmid = {18302970},
title = {{The effectiveness of web-based interventions designed to decrease alcohol consumption--a systematic review.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18302970},
volume = {47},
year = {2008}
}
@incollection{Chartrand2005,
author = {Chartrand, T. L. and Maddux, W W and Lakin, J. L.},
booktitle = {The new unconscious},
file = {::},
pages = {334--361},
publisher = {Oxford University Press New York},
title = {{Beyond the perception-behavior link: The ubiquitous utility and motivational moderators of nonconscious mimicry}},
year = {2005}
}
@article{Segal2011,
author = {Segal, Elizabeth},
doi = {10.1080/01488376.2011.564040},
file = {::},
issn = {0148-8376},
journal = {Journal of Social Service Research},
keywords = {a dedication to justice,a nation that proclaims,and social well-being and,civic involvement,empathy,scapegoating,social empathy,social responsibility,the united states is},
month = may,
number = {3},
pages = {266--277},
title = {{Social Empathy: A Model Built on Empathy, Contextual Understanding, and Social Responsibility That Promotes Social Justice}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/01488376.2011.564040\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {37},
year = {2011}
}
@article{Gama2011,
author = {Gama, Sandra and Barata, Gabriel and Gon\c{c}alves, D. and Prada, R. and Paiva, Ana},
file = {::},
journal = {Affective Computing and Intelligent Interaction},
keywords = {affective computing,conversational agent,empathic agent},
pages = {507--516},
publisher = {Springer},
title = {{SARA: social affective relational agent: a study on the role of empathy in artificial social agents}},
url = {http://www.springerlink.com/index/G0433KX744258W62.pdf},
year = {2011}
}
@inproceedings{Boukricha2007,
abstract = {Addressing user’s emotions in human-computer interaction significantly enhances the believability and lifelikeness of virtual humans. Emotion recognition and interpretation is realized in our approach by integrating empathy as a designated process within the agent’s cognitive architecture. In this paper we describe this empathy process which comprises of two interconnected components: a belief-desire-intention (BDI) based cognitive component and an affective component based on the emotion simulation system of the virtual human Max.},
address = {Osnabr\"{u}ck, Germany},
author = {Boukricha, Hana and Becker-Asano, Christian},
booktitle = {Proceedings of the 2nd Workshop at KI2007 on Emotion and Computing – Current Research and Future Impact},
editor = {{Dirk Reichardt} and Levi, Paul},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Boukricha, Becker-Asano - 2007 - Simulating empathy for the virtual human max(3).pdf:pdf},
pages = {23--28},
title = {{Simulating empathy for the virtual human max}},
url = {http://wwwlehre.dhbw-stuttgart.de/~reichard/itemotion/2007/},
year = {2007}
}
@article{Rameson2009,
author = {Rameson, Lian T. and Lieberman, Matthew D.},
doi = {10.1111/j.1751-9004.2008.00154.x},
file = {::},
issn = {17519004},
journal = {Social and Personality Psychology Compass},
month = jan,
number = {1},
pages = {94--110},
title = {{Empathy: A Social Cognitive Neuroscience Approach}},
url = {http://doi.wiley.com/10.1111/j.1751-9004.2008.00154.x},
volume = {3},
year = {2009}
}
@inproceedings{Cramer2010,
author = {Cramer, Henriette and Goddijn, Jorrit and Wielinga, Bob and Evers, Vanessa},
booktitle = {Proceeding of the 5th ACM/IEEE international conference on Human-robot interaction},
file = {::},
isbn = {9781424448937},
pages = {141--142},
publisher = {ACM},
title = {{Effects of (in) accurate empathy and situational valence on attitudes towards robots}},
url = {http://dl.acm.org/citation.cfm?id=1734513},
year = {2010}
}
@book{Miller1995a,
author = {Miller, William R. and Tonigan, JS and Longabaugh, R},
booktitle = {Psychology},
editor = {Mattson, Margaret E},
pages = {98},
publisher = {National Institute on Alcohol Abuse and Alcoholism},
series = {Project MATCH Monograph Series},
title = {{The Drinker Inventory of Consequences (DrInC): An Instrument for Assessing Adverse Consequences of Alcohol Abuse}},
url = {http://scholar.google.com/scholar?q=The+Drinker+Inventory+of+Consequences+(DrInC).+An+Instrument+for+Assessing+Adverse+Consequences+of+Alcohol+Abuse\&hl=en\&btnG=Search\&as\_sdt=2001\&as\_sdtp=on\#1},
volume = {4},
year = {1995}
}
@article{Wolf2010,
abstract = {Computer Vision and Biometrics systems have demonstrated considerable improvement in recognizing and verifying faces in digital images. Still, recognizing faces appearing in unconstrained, natural conditions remains a challenging task. In this paper we present a face-image, pair-matching approach primarily developed and tested on the "Labeled Faces in the Wild" (LFW) benchmark that reflect the challenges of face recognition from unconstrained images. The approach we propose makes the following contributions. (a) We present a family of novel face-image descriptors designed to capture statistics of local patch similarities. (b) We demonstrate how semi-labeled background samples may be used to better evaluate image similarities. To this end we describe a number of novel, effective similarity measures. (c) We show how labeled background samples, when available, may further improve classification performance, by employing a unique pair-matching pipeline. We present state-of-the-art results on the LFW pair-matching benchmarks. In addition, we show our system to be well suited for multi-label face classification (recognition) problems. We perform recognition tests on LFW images as well images from the laboratory controlled multiPIE database.},
author = {Wolf, Lior and Hassner, Tal and Taigman, Yaniv},
doi = {10.1109/TPAMI.2010.230},
file = {::},
issn = {1939-3539},
journal = {IEEE transactions on pattern analysis and machine intelligence},
month = dec,
pages = {1--13},
pmid = {21173442},
title = {{Effective Unconstrained Face Recognition by Combining Multiple Descriptors and Learned Background Statistics.}},
volume = {33},
year = {2010}
}
@article{Lakin2003b,
author = {Lakin, J. L. and Chartrand, T. L.},
doi = {10.1111/1467-9280.14481},
file = {::},
issn = {0956-7976},
journal = {Psychological Science},
month = jul,
number = {4},
pages = {334--339},
title = {{Using Nonconscious Behavioral Mimicry to Create Affiliation and Rapport}},
url = {http://pss.sagepub.com/lookup/doi/10.1111/1467-9280.14481},
volume = {14},
year = {2003}
}

@inproceedings{Yasavur2013,
  title={Ontology-Based Named Entity Recognizer for Behavioral Health},
  author={Yasavur, Ugan and Amini, Reza and Lisetti, Christine and Rishe, Napthali},
  booktitle={The Twenty-Sixth International FLAIRS Conference},
  year={2013}
}

@inproceedings{Wang2010,
abstract = {Communication is more effective and persuasive when par- ticipants establish rapport. Tickle-Degnen and Rosenthal [57] argue rapport arises when participants exhibit mutual attentiveness, positivity and coordination. In this paper, we investigate how these factors relate to perceptions of rap- port when users interact via avatars in virtual worlds. In this study, participants told a story to what they believed was the avatar of another participant. In fact, the avatar was a computer program that systematically manipulated levels of attentiveness, positivity and coordination. In contrast to Tickel-Degnen and Rosenthal’s findings, its impact in a wide range of interpersonal domains includ- ing social engagement [52], classroom learning [22], suc- cess in negotiations [20], improving worker compliance [18], psychotherapeutic effectiveness [59], and improved quality of child care [11]. Recent research in virtual envi- ronments has demonstrated the possibility of translating these findings into computer-mediated (CMC) and human- computer interactions (HCI) where embodied communi- cated behaviors can not only be reproduced but altered in novel ways to perhaps amplify their interpersonal conse- quences [26] [5]. high-levels of mutual attentiveness alone can dramatically lower percep- tions of rapport in avatar communication. Indeed, an agent that attempted to maximize mutual attention performed as poorly as an agent that was designed to convey boredom. Adding positivity and coordination to mutual attentiveness, on the other hand, greatly improved rapport. This work un- veils the dependencies between components of rapport and informs the design of agents and avatars in computer medi- ated communication.},
address = {Atlanta, GA, USA},
author = {Wang, Ning and Gratch, Jonathan},
booktitle = {28th ACM Conference on Human Factors in Computing Systems (CHI'10)},
file = {::},
keywords = {Virtual human,back-channel,gaze,head nod,pos- ture mirroring.,rapport},
pages = {1241--1249},
publisher = {ACM},
title = {{Don't just stare at me!}},
year = {2010}
}

@inproceedings{Kang2008,
author = {Kang, Sin-hwa and Gratch, Jonathan and Wang, Ning and Watt, J.H.},
booktitle = {Proceedings of the 7th international joint conference on Autonomous agents and multiagent systems-Volume 1},
file = {:C$\backslash$:/Users/ramin001/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kang et al. - 2008 - Does the contingency of agents' nonverbal feedback affect users' social anxiety.pdf:pdf},
keywords = {agents,contingency of nonverbal feedback,evaluation,rapport,social anxiety,virtual humans},
number = {Aamas},
pages = {120--127},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
title = {{Does the contingency of agents' nonverbal feedback affect users' social anxiety?}},
url = {http://dl.acm.org/citation.cfm?id=1402405},
year = {2008}
}

@article{Cassell2001b,
abstract = {This paper addresses the issue of designing embodied conversational agents that exhibit appropriate posture shifts during dialogues with human users. Previous research has noted the importance of hand gestures, eye gaze and head nods in conversations between embodied agents and humans. We present an analysis of human monologues and dialogues that suggests that postural shifts can be predicted as a function of discourse state in monologues, and discourse and conversation state in dialogues. On the basis of these findings, we have implemented an embodied conversational agent that uses Collagen in such a way as to generate postural shifts.},
author = {Cassell, Justine and Nakano, Yukiko I and Bickmore, Timothy W and Sidner, Candace L and Rich, Charles},
doi = {10.3115/1073012.1073028},
institution = {Association for Computational Linguistics Morristown, NJ, USA},
journal = {Proceedings of the 39th Annual Meeting on Association for Computational Linguistics ACL 01},
pages = {114--123},
publisher = {Association for Computational Linguistics},
series = {ACL '01},
title = {{Non-verbal cues for discourse structure}},
url = {http://portal.acm.org/citation.cfm?doid=1073012.1073028},
year = {2001}
}
@article{Wang2009,
annote = {Out of three components of rapport by Tickle-Degnene and Rosenthal (mutual attentiveness, positivity, and coordination), they investigated the relationship between human speakers' facial expression and rapport. Results show that recognizing positive facial expressions alone is insufficient but negative facial displays are more effective in assessing the level of rapport between participants.},
author = {Wang, Ning},
doi = {10.1109/ACII.2009.5349514},
file = {::},
isbn = {978-1-4244-4800-5},
journal = {and Workshops, 2009. ACII 2009. 3rd},
month = sep,
pages = {1--6},
publisher = {Ieee},
title = {{Rapport and facial expression}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5349514 http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5349514},
year = {2009}
}
@article{Orozco2010,
author = {Orozco, H. and Thalmann, Daniel and Ramos, F.},
file = {::},
journal = {Proceedings of 11th Computer Graphics International, CGI},
title = {{Making empathetic virtual humans in human–computer interaction scenarios}},
url = {http://cgi2010.miralab.unige.ch/short/SP09/SP09.pdf},
volume = {10},
year = {2010}
}
@article{Poggi2000,
abstract = {Our goal is to create an intelligent 3D agent able to send complex, natural messages to users and, in the future, to converse with them. We look at the relationship between the agents communicative intentions and the way that these intentions are expressed into verbal and nonverbal messages. In this paper, we concentrate on the study and generation of coordinated linguistic and gaze communicative acts. In this view we analyse gaze signals according to their functional meaning rather than to their physical actions. We propose a formalism where a communicative act is represented by two elements: a meaning (that corresponds to a set of goals and beliefs that the agent has the purpose to transmit to the interlocutor) and a signal, that is the nonverbal expression of that meaning. We also outline a methodology to generate messages that coordinate verbal with nonverbal signals.},
author = {Poggi, Isabella and Pelachaud, Catherine and {De Rosis}, Fiorella},
issn = {09217126},
journal = {Ai Communications},
number = {3},
pages = {169--181},
publisher = {IOS Press},
title = {{Eye communication in a conversational 3D synthetic agent}},
url = {http://portal.acm.org/citation.cfm?id=1216435.1216439},
volume = {13},
year = {2000}
}
@misc{Ekman1980,
author = {Ekman, Paul and Freisen, Wallace V. and Ancoli, Sonia},
booktitle = {Journal of Personality and Social Psychology},
doi = {10.1037/h0077722},
file = {::},
issn = {0022-3514},
number = {6},
pages = {1125--1134},
title = {{Facial signs of emotional experience.}},
url = {http://content.apa.org/journals/psp/39/6/1125},
volume = {39},
year = {1980}
}
@article{Behrend2011,
abstract = {In this study, trainees worked with computerized trainer agents that were either similar to them or different regarding appearance or feedback-giving style. Similarity was assessed objectively, based on appearance and feedback style matching, and subjectively, based on participants’ self-reported perceptions of similarity. Appearance similarity had few effects. Objective feedback similarity led to higher scores on a declarative knowledge test and higher liking for the trainer. Subjective feedback similarity was related to reactions, engagement, and liking for the trainer. Overall, results indicated that subjective similarity is more important in predicting training outcomes than objective similarity, and that surfacelevel similarity is less important than deep-level similarity. These results shed new light on the dynamics between e-learners and trainer agents, and inform the design of agent-based training.},
author = {Behrend, Tara S. and Thompson, Lori Foster},
doi = {10.1016/j.chb.2010.12.016},
file = {::},
issn = {07475632},
journal = {Computers in Human Behavior},
keywords = {Intelligent agents Similarity-attraction E-learnin},
month = may,
number = {3},
pages = {1201--1206},
publisher = {Elsevier Ltd},
title = {{Similarity effects in online training: Effects with computerized trainer agents}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0747563211000033},
volume = {27},
year = {2011}
}
@article{Zeng2009,
abstract = {Automated analysis of human affective behavior has attracted increasing attention from researchers in psychology, computer science, linguistics, neuroscience, and related disciplines. However, the existing methods typically handle only deliberately displayed and exaggerated expressions of prototypical emotions despite the fact that deliberate behaviour differs in visual appearance, audio profile, and timing from spontaneously occurring behaviour. To address this problem, efforts to develop algorithms that can process naturally occurring human affective behaviour have recently emerged. Moreover, an increasing number of efforts are reported toward multimodal fusion for human affect analysis including audiovisual fusion, linguistic and paralinguistic fusion, and multi-cue visual fusion based on facial expressions, head movements, and body gestures. This paper introduces and surveys these recent advances. We first discuss human emotion perception from a psychological perspective. Next we examine available approaches to solving the problem of machine understanding of human affective behavior, and discuss important issues like the collection and availability of training and test data. We finally outline some of the scientific and engineering challenges to advancing human affect sensing technology.},
author = {Zeng, Zhihong and Pantic, Maja and Roisman, Glenn I and Huang, Thomas S},
doi = {10.1109/TPAMI.2008.52},
file = {::},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Affect,Affect: physiology,Algorithms,Artificial Intelligence,Automated,Automated: methods,Emotions,Emotions: physiology,Facial Expression,Monitoring,Pattern Recognition,Physiologic,Physiologic: methods,Sound Spectrography,Sound Spectrography: methods},
month = jan,
number = {1},
pages = {39--58},
pmid = {19029545},
title = {{A survey of affect recognition methods: audio, visual, and spontaneous expressions.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19029545},
volume = {31},
year = {2009}
}
@article{Nisbett1977,
abstract = {Reviews evidence which suggests that there may be little or no direct introspective access to higher order cognitive processes. Ss are sometimes (a) unaware of the existence of a stimulus that importantly influenced a response, (b) unaware of the existence of the response, and (c) unaware that the stimulus has affected the response. It is proposed that when people attempt to report on their cognitive processes, that is, on the processes mediating the effects of a stimulus on a response, they do not do so on the basis of any true introspection. Instead, their reports are based on a priori, implicit causal theories, or judgments about the extent to which a particular stimulus is a plausible cause of a given response. This suggests that though people may not be able to observe directly their cognitive processes, they will sometimes be able to report accurately about them. Accurate reports will occur when influential stimuli are salient and are plausible causes of the responses they produce, and will not occur when stimuli are not salient or are not plausible causes.},
author = {Nisbett, R E and Wilson, T D},
doi = {10.1037/0033-295X.84.3.231},
editor = {DeVivo, Anita and Silver, Amy and Felder, Deborah S and Hayward, Robert J and Patterson, Kendall C and Redman, Anne and Buchwald, Alexander and Falmagne, Rachel Jofffe and Krantz, David H and Olson, Gary M and Shiffrin, Richard M and Smith, Edward E and Theios, John and WIggins, Jerry S},
issn = {0033295X},
journal = {Psychological Review},
number = {3},
pages = {231--259},
pmid = {17882490},
publisher = {Psychol Rev},
title = {{Telling more than we can know: Verbal reports on mental processes}},
url = {http://psycnet.apa.org/journals/rev/84/3/231/},
volume = {84},
year = {1977}
}
@article{Huang2010,
author = {Huang, Lixing and Morency, Louis-Philippe and Gratch, Jonathan},
file = {::},
journal = {of the 9th International Conference on},
number = {Aamas},
pages = {10--14},
title = {{Parasocial consensus sampling: combining multiple perspectives to learn virtual human behavior}},
url = {http://dl.acm.org/citation.cfm?id=1838371},
year = {2010}
}
@article{Gray1985,
abstract = {Attempts to show that the experimental psychology of the rat and the neuropsychology of the rat's brain are of relevance to clinical psychology. It is suggested that there is a false dichotomy between the behaviorist and cognitive approaches to psychology and illustrates this by going from a behaviorist analysis of a psychological concept (anxiety) to a cognitive analysis of that concept, basing the argument on brain research: Damage to the septo-hippocampal system mimics the behavioral effects of the antianxiety drugs. The reason for this mimicry is probably that these drugs reduce the noradrenergic input to the septo-hippocampal system. The noradrenergic input is normally activated under conditions of stress and serves to increase the capacity of the septo-hippocampal system to handle information. It seems probable, therefore, that the state of anxiety is, to some degree at least, mediated by activity in the septo-hippocampal system. It is emphasized that there is no dichotomy between cognitive and behaviorist psychology because the brain controls both behavior and cognition.},
author = {Gray, J. A},
journal = {Bulletin of the British Psychological Society},
pages = {99--112},
title = {{The whole and its parts: Behaviour, the brain, cognition and emotion}},
volume = {38},
year = {1985}
}
@article{Jackson1992,
abstract = {OBJECTIVE: The purpose of this paper is the assessment of the healer's listening as an aspect of the history of caring and curing, with particular attention to its place in psychological healing. METHOD: An extensive range of philosophical, religious, and medical sources from antiquity to the present were studied. RESULTS: Over the centuries, listening has been a crucial aspect of the various endeavors undertaken by healers in the interest of acquiring information from, achieving understanding of, and bringing about healing effects for sufferers. Yet it has been vision rather than hearing that has been emphasized in knowing and understanding, and looking rather than listening that has been emphasized in healing endeavors. Only around the turn of the twentieth century did there emerge the focused study of care in listening, of listening beyond the words themselves, and of the significance of the interested listener as a soothing, empathic force. CONCLUSIONS: The place of listening in depth and with empathy is a crucial element in healing. While the emphasis on looking remains significant in the gathering and appraisal of data, at times it threatens to overwhelm the need for an attentive and concerned listener. There appears to be a natural tension between the two modes that has, in modern times, been translated into a tension between the two modes that has, in modern times, been translated into a tension between a scientific mode of gaining information and a humanistic mode of knowing sufferers. A healer neglects either one at his or her peril-and at the peril of his or her patients.},
author = {Jackson, S W},
institution = {Department of Psychiatry, Yale University School of Medicine, New Haven, CT 06510.},
journal = {The American Journal of Psychiatry},
number = {12},
pages = {1623--1632},
pmid = {1443239},
title = {{The listening healer in the history of psychological healing.}},
volume = {149},
year = {1992}
}
@article{Hodgson2002,
abstract = {Using the Alcohol Use Disorders Identification Test (AUDIT) as the gold standard, the Fast Alcohol Screening Test (FAST) was developed for use in busy medical settings. AUDIT questionnaires were completed by 666 patients in two London accident \& emergency (A\&E) departments. Using a principal components analysis, as well as sensitivity and specificity indices, a two-stage screening test was developed, using four of the AUDIT items. The first stage involved one item that identified >50\% of patients as either hazardous or non-hazardous drinkers. The second stage made use of the other three items to categorize the rest. The performance of this four-item questionnaire was then tested across a range of settings. Opportunistic samples of 100 patients completed AUDIT questionnaires in each of the following National Health Service settings: A\&E department, fracture clinic, primary health centre and a dental hospital. It was concluded that the four-item FAST questionnaire had good sensitivity and specificity, across a range of settings, when the AUDIT score was used as the gold standard. The FAST questionnaire is quick to administer, since >50\% of patients are categorized using just one question.},
author = {Hodgson, Ray and Alwyn, Tina and John, Bev and Thom, Betsy and Smith, Alyson},
institution = {University of Wales College of Medicine, Lansdowne Hospital, Cardiff CF11 8PL, UK.},
journal = {Alcohol and alcoholism Oxford Oxfordshire},
number = {1},
pages = {61--66},
publisher = {Oxford University Press},
title = {{The fast alcohol screening test.}},
url = {http://eprints.mdx.ac.uk/129/},
volume = {37},
year = {2002}
}
@article{Lang1995,
abstract = {Emotions are action dispositions--states of vigilant readiness that vary widely in reported affect, physiology, and behavior. They are driven, however, by only 2 opponent motivational systems, appetitive and aversive--subcortical circuits that mediate reactions to primary reinforcers. Using a large emotional picture library, reliable affective psychophysiologies are shown, defined by the judged valence (appetitive/pleasant or aversive/unpleasant) and arousal of picture percepts. Picture-evoked affects also modulate responses to independently presented startle probe stimuli. In other words, they potentiate startle reflexes during unpleasant pictures and inhibit them during pleasant pictures, and both effects are augmented by high picture arousal. Implications are elucidated for research in basic emotions, psychopathology, and theories of orienting and defense. Conclusions highlight both the approach's constraints and promising paths for future study.},
author = {Lang, P J},
file = {::},
issn = {0003-066X},
journal = {The American psychologist},
keywords = {Affect,Arousal,Attention,Blinking,Humans,Mental Disorders,Mental Disorders: psychology,Motivation,Startle Reaction},
month = may,
number = {5},
pages = {372--85},
pmid = {7762889},
title = {{The emotion probe. Studies of motivation and attention.}},
volume = {50},
year = {1995}
}
@article{Boukricha2007,
abstract = {Addressing user’s emotions in human-computer interaction significantly enhances the believability and lifelikeness of virtual humans. Emotion recognition and interpretation is realized in our approach by integrating empathy as a designated process within the agent’s cognitive architecture. In this paper we describe this empathy process which comprises of two interconnected components: a belief-desire-intention (BDI) based cognitive component and an affective component based on the emotion simulation system of the virtual human Max.},
author = {Boukricha, Hana and Becker-Asano, Christian},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Boukricha, Becker-Asano - 2007 - Simulating empathy for the virtual human max(3).pdf:pdf},
journal = {on Emotion and Computing in conj},
title = {{Simulating empathy for the virtual human max}},
year = {2007}
}
@inproceedings{Nguyen2009c,
author = {Nguyen, H. and Masthoff, Judith},
booktitle = {Proceedings of the 4th International Conference on Persuasive Technology},
file = {::},
isbn = {9781605583761},
keywords = {affective computing,design,experimentation,human factors},
pages = {7},
publisher = {ACM},
title = {{Designing empathic computers: the effect of multimodal empathic feedback using animated agent}},
url = {http://dl.acm.org/citation.cfm?id=1541958},
year = {2009}
}
@inproceedings{Ehrlich2000,
abstract = {Designers of video-mediated communication and affective computing applications must make tradeoffs to deal with limited bandwidth. Typically spatial resolution and color are preserved at the expense of temporal resolution and accuracy. Our data suggest that this may not be the appropriate tradeoff for communicating facial affect; preserving motion is critical and may even compensate for major losses in image realism.},
address = {NY},
author = {Ehrlich, Sheryl M and Schiano, Diane J and Sheridan, Kyle},
booktitle = {Proceedings of ACM CHI 2000 Conference on Human Factors in Computing Systems},
file = {::},
keywords = {Facial affect,face,facial expression of emotion,image degradation,nonverbal communication,video conferencing.},
pages = {252--253},
publisher = {ACM},
title = {{Communicating Facial Affect : It's Not the Realism, It's the Motion}},
year = {2000}
}
@inproceedings{Stoyanchev2011,
author = {Stoyanchev, Svetlana and Piwek, Paul and Prendinger, Helmut},
booktitle = {Intelligent Virtual Agents},
file = {::},
pages = {377--383},
publisher = {Springer},
title = {{Comparing modes of information presentation: text versus ECA and single versus two ECAs}},
url = {http://www.springerlink.com/index/H72521305G072173.pdf},
year = {2011}
}
@article{Lee2009,
author = {Lee, Jina and Prendinger, H},
file = {::},
isbn = {9781424447992},
journal = {Affective Computing},
title = {{Learning models of speaker head nods with affective information}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5349543},
year = {2009}
}
@inproceedings{Jiang2007,
author = {Jiang, Hong and Vidal, J.M. and Huhns, M.N.},
booktitle = {Proceedings of the 6th international joint conference on Autonomous agents and multiagent systems},
file = {::},
keywords = {agent architecture,belief-desire-intention,emotional agent},
pages = {11},
publisher = {ACM},
title = {{EBDI: an architecture for emotional agents}},
url = {http://dl.acm.org/citation.cfm?id=1329139},
year = {2007}
}
@article{Littlewort2011,
author = {Littlewort, Gwen C and Whitehill, Jacob and Wu, T},
doi = {10.1109/AFGR.2008.4813406},
file = {::},
isbn = {978-1-4244-2153-4},
journal = {Recognition and},
month = sep,
pages = {1--2},
publisher = {Ieee},
title = {{The computer expression recognition toolbox (CERT)}},
year = {2011}
}
@article{MillerRose2009,
abstract = {The widely-disseminated clinical method of motivational interviewing (MI) arose through a convergence of science and practice. Beyond a large base of clinical trials, advances have been made toward “looking under the hood” of MI to understand the underlying mechanisms by which it affects behavior change. Such specification of outcome-relevant aspects of practice is vital to theory development, and can inform both treatment delivery and clinical training. An emergent theory of MI is proposed, emphasizing two specific active components: a relational component focused on empathy and the interpersonal spirit of MI, and a technical component involving the differential evocation and reinforcement of client change talk A resulting causal chain model links therapist training, therapist and client responses during treatment sessions, and post-treatment outcomes.},
author = {Miller, William R. and Rose, Gary S.},
doi = {10.1037/a0016830},
file = {::},
journal = {American Psychologist},
keywords = {1938,behavior change,causal chain,client-centered,emphasis has been given,motivational interviewing,process,psychotherapy,theory,therapeutic,to what reichenbach,within psychological science much},
number = {6},
pages = {527--537},
title = {{Toward a Theory of Motivational Interviewing}},
volume = {64},
year = {2009}
}
@article{Robbins1994,
abstract = {To date, cognitive and affective influences on performance evaluations have been addressed separately, although it is likely that affect may influence ratings indirectly through its impact on the cognitive processing involved in the evaluation. 83 management students participated in a study of the influence of affect on the cognitive processing of performance information. Results suggest that an affect-consistency bias influences ratings even though the cognitive processes that require some judgment indicated a bias toward both affect-consistent and affect-inconsistent performance. Additional findings suggest that the practical utility of affect as something distinct from past performance perceptions may be limited in field settings. Job-related affect, past performance perceptions, and social affect had similar influences on the cognitive process and ratings in performance evaluations. (PsycINFO Database Record (c) 2003 APA, all rights reserved)},
author = {Robbins, Tina L and DeNisi, Angelo S},
doi = {10.1037//0021-9010.79.3.341},
issn = {00219010},
journal = {Journal of Applied Psychology},
number = {3},
pages = {341--353},
publisher = {Elsevier},
title = {{A closer look at interpersonal affect as a distinct influence on cognitive processing in performance evaluations}},
url = {http://www.apa.org},
volume = {79},
year = {1994}
}
@article{Cai2006,
abstract = {Empathic computing is an emergent paradigm that enables a system to understand human states and feelings and to share this intimate information. The new paradigm is made possible by the convergence of affordable sensors, embedded processors and wireless ad-hoc networks. The power law for multi-resolution channels and mobile-stationary sensor webs is introduced to resolve the information avalanche problems. As empathic computing is sensor-rich computing, particular models such as semantic differential expressions and inverse physics are discussed. A case study of a wearable sensor network for detection of a falling event is presented. It is found that the location of the wearable sensor is sensitive to the results. From the machine learning algorithm, the accuracy reaches up to 90\% from 21 simulated trials. Empathic computing is not limited to healthcare. It can also be applied to solve other everyday-life problems such as management of emails and stress.},
author = {Cai, Yang},
doi = {10.1007/11825890\_3},
file = {::},
journal = {Ambient Intelligence in Everyday Life, Lecture Notes in Computer Science},
pages = {67--85},
publisher = {Springer},
title = {{Empathic computing}},
url = {http://www.springerlink.com/index/l482m128476w5043.pdf},
volume = {3864/2006},
year = {2006}
}
@article{Murphy2010,
abstract = {The authors conducted two randomized clinical trials with ethnically diverse samples of college student drinkers in order to determine (a) the relative efficacy of two popular computerized interventions versus a more comprehensive motivational interview approach (BASICS) and (b) the mechanisms of change associated with these interventions. In Study 1, heavy drinking participants recruited from a student health center (N = 74, 59\% women, 23\% African American) were randomly assigned to receive BASICS or the Alcohol 101 CD-ROM program. BASICS was associated with greater post-session motivation to change and self-ideal and normative discrepancy relative to Alcohol 101, but there were no group differences in the primary drinking outcomes at 1-month follow-up. Pre to post session increases in motivation predicted lower follow-up drinking across both conditions. In Study 2, heavy drinking freshman recruited from a core university course (N = 133, 50\% women, 30\% African American) were randomly assigned to BASICS, a web-based feedback program (e-CHUG), or assessment-only. BASICS was associated with greater post-session self-ideal discrepancy than e-CHUG, but there were no differences in motivation or normative discrepancy. There was a significant treatment effect on typical weekly and heavy drinking, with participants in BASICS reporting significantly lower follow-up drinking relative to assessment only participants. In Study 2, change in the motivation or discrepancy did not predict drinking outcomes. Across both studies, African American students assigned to BASICS reported medium effect size reductions in drinking whereas African American students assigned to Alcohol 101, e-CHUG, or assessment did not reduce their drinking.},
author = {Murphy, James G and Dennhardt, Ashley a and Skidmore, Jessica R and Martens, Matthew P and McDevitt-Murphy, Meghan E},
doi = {10.1037/a0021347},
file = {::},
issn = {1939-1501},
journal = {Psychology of addictive behaviors : journal of the Society of Psychologists in Addictive Behaviors},
keywords = {Alcohol Drinking,Alcohol Drinking: therapy,Alcohol-Related Disorders,Alcohol-Related Disorders: therapy,Analysis of Variance,Female,Humans,Internet,Interviews as Topic,Male,Motivation,Psychotherapy, Brief,Psychotherapy, Brief: methods,Students,Therapy, Computer-Assisted,Treatment Outcome,Universities,Young Adult},
month = dec,
number = {4},
pages = {628--39},
pmid = {21198224},
title = {{Computerized versus motivational interviewing alcohol interventions: impact on discrepancy, motivation, and drinking.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21198224},
volume = {24},
year = {2010}
}
@article{Vanbaaren2004,
author = {Van baaren, Rick B. and Holland, Rob W. and Kawakami, Kerry and Knippenberg, Ad Van},
doi = {10.1111/j.0963-7214.2004.01501012.x},
file = {::},
issn = {0956-7976},
journal = {Psychological Science},
month = jan,
number = {1},
pages = {71--74},
title = {{Mimicry and Prosocial Behavior}},
url = {http://pss.sagepub.com/lookup/doi/10.1111/j.0963-7214.2004.01501012.x},
volume = {15},
year = {2004}
}
@article{Schneier2011,
author = {Schneier, B.},
file = {::},
journal = {Security \& Privacy, IEEE},
number = {5},
pages = {88--88},
publisher = {IEEE},
title = {{Empathy and Security}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6029366},
volume = {9},
year = {2011}
}
@article{Lafrance1979,
author = {Lafrance, Marianne},
file = {::},
journal = {Social Psychology},
number = {1},
pages = {66--70},
title = {{Nonverbal Synchrony Panel Technique: Analysis by the Cross-Lag and Rapport}},
volume = {42},
year = {1979}
}
@book{Dennett1987,
author = {Dennett, D C},
booktitle = {Technology},
publisher = {MIT Press},
title = {{The Intentional Stance}},
year = {1987}
}
@article{DiClemente2001,
abstract = {OBJECTIVE: To offer a taxonomy of types of feedback and describe potential mechanisms of action particularly in the area of addictive behaviors. METHOD: Reviewed the literature to examine support for types-Generic, Targeted, and Personalized-and for mechanisms of feedback. RESULTS: Although it is not clear how it works, feedback is thought to offer important information, to create a sense of caring and helping relationship, to reach more directly decisional considerations, to increase engagement in the materials, to increase motivation, or to provide social comparison and norms. CONCLUSIONS: Avenues for future research in search of the most effective manner of using feedback to promote health behavior change are discussed.},
author = {DiClemente, C C and Marinilli, A S and Singh, M and Bellino, L E},
institution = {Psychology Department, University of Maryland, Baltimore County, Baltimore 21250, USA. diclemen@umbc.edu},
journal = {American Journal of Health Behavior},
keywords = {addictive,addictive prevention \& control,addictive psychology,behavior,classification,feedback,health behavior,health education,health education classification,humans,mass screening,models,psychological,risk taking},
number = {3},
pages = {217--227},
pmid = {11322620},
publisher = {PNG Publications},
title = {{The role of feedback in the process of health behavior change.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11322620},
volume = {25},
year = {2001}
}
@incollection{Mora1999,
abstract = {Beliefs-Desires-Intentions models (or BDI models) of agents have been around for quit a long time. The purpose of these models is to characterize agents using anthropomorphic notions, such as mental states and actions. How- ever, despite the fact that many systems have been developed based on these mod- els, it is a general concern that there is a gap between those powerful BDI logics and practical systems. The purpose of this paper is to present a BDI model that, besides being a formal model of agents, is also suitable to be used to implement agents. Instead of defining a new BDI logic or choosing an existing one, and ex- tending it with an operational model, we define the notions of belief, desires and intentions using a logic formalism that is both well-defined and computational.},
author = {Mora, M and Lopes, J and Viccariz, R and Coelho, H},
booktitle = {Intelligent Agents V: Agents Theories, Architectures, and Languages},
chapter = {Section I},
doi = {10.1007/3-540-49057-4\_2},
editor = {Muller, J.P.},
file = {::},
keywords = {BDI models,agent architectures,logic program- ming.,mental states modeling},
pages = {11--27},
publisher = {Springer-Verlag Berlin Heidelberg},
title = {{BDI models and systems: Reducing the gap}},
url = {http://www.springerlink.com/index/m674631247x60251.pdf},
year = {1999}
}
@article{Meng2009,
author = {Meng, Qinggang and Lee, Mark},
doi = {10.1109/CASE.2009.156},
file = {::},
isbn = {978-0-7695-3728-3},
journal = {2009 IITA International Conference on Control, Automation and Systems Engineering (case 2009)},
keywords = {-home service robots,human-robot interaction},
month = jul,
pages = {220--224},
publisher = {Ieee},
title = {{Empathy between Human and Home Service Robots}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5194430},
year = {2009}
}
@incollection{Chartrand2005,
author = {Chartrand, T. L. and Maddux, W W and Lakin, J. L.},
booktitle = {The new unconscious},
file = {::},
pages = {334--361},
publisher = {Oxford University Press New York},
title = {{Beyond the perception-behavior link: The ubiquitous utility and motivational moderators of nonconscious mimicry}},
year = {2005}
}
@article{Litvack-Miller1997a,
abstract = {This study was an investigation of the structure and development of dispositional empathy during middle childhood and its relationship to altruism. A sample of 478 students from 2nd, 4th, and 6th grades completed an altruism questionnaire and a social desirability scale, both created for this study, and the Interpersonal Reactivity Index (Davis, 1980), adapted for this study. Teachers also rated the students on prosocial behaviors, such as sharing. In addition, as an experimental part of the study, the children could make monetary donations and volunteer time to raise funds. Results of a confirmatory factor analysis on the Interpersonal Reactivity Index supported Davis's (1980) findings that empathy comprises four components: perspective taking, fantasy, empathic concern, and personal distress. Factor intercorrelations, however, were not the same as those reported by Davis. MANOVAs were used to examine gender and age effects on empathy. Girls were more empathic in general than boys, and older children showed more empathic concern than younger children. Only empathic concern and perspective taking were significant predictors of prosocial behavior.},
author = {Litvack-Miller, W and McDougall, D and Romney, D M},
file = {::},
issn = {8756-7547},
journal = {Genetic, social, and general psychology monographs},
keywords = {Adolescent,Altruism,Child,Empathy,Female,Humans,Interpersonal Relations,Male,Questionnaires,Social Behavior,Social Desirability},
month = aug,
number = {3},
pages = {303--24},
pmid = {9259121},
title = {{The structure of empathy during middle childhood and its relationship to prosocial behavior.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21981037},
volume = {123},
year = {1997}
}
@book{Knapp2009,
abstract = {The most comprehensive, most readable compendium of research and theory on nonverbal communication available, NONVERBAL COMMUNICATION IN HUMAN INTERACTION uses the cross-disciplinary approaches of speech and social psychology to focus on how nonverbal communication research affects a wide variety of academic interests.},
author = {Knapp, Mark L and Hall, Judith A},
booktitle = {Dress as NonVerbal Communication},
editor = {Burgoon, Michael},
isbn = {9780495568698},
pages = {496},
publisher = {Wadsworth, Cengage Learning},
title = {{Nonverbal Communication in Human Interaction}},
url = {http://books.google.com/books?id=j5HIIfRUPm0C},
volume = {5},
year = {2009}
}
@article{Ambady1992,
abstract = {A meta-analysis was conducted on the accuracy of predictions of various objective outcomes in the areas of social and clinical psychology from short observations of expressive behavior (under 5 min). The overall effect size (ry for the accuracy of predictions for 38 different resu1ts was .39. Studies using longer periods of behavioral observation did not yield greater predictive accuracy; predictions based on observations under 112 min in length did not differ significantly from predictions based on 4- and 5-min observations. The type ofbehavioral channel (such as the face, speech, the body, tone ofvoic on which the ratings were based was not related to the accuracy of predictions. Accuracy did not vary significantly between behaviors rnanipulated in a laboratory and more naturally occurring behavior. L t effect sizes did not differ significantly for predictions in the areas of clinical psychology social psychology, and the accuracy of detecting deception.},
author = {Ambady, N and Rosenthal, Robert},
doi = {10.1037/0033-2909.111.2.256},
file = {::},
issn = {00332909},
journal = {Psychological Bulletin},
number = {2},
pages = {256--274},
publisher = {American Psychological Association},
title = {{Thin slices of expressive behavior as predictors of interpersonal consequences: A meta-analysis.}},
volume = {111},
year = {1992}
}
@book{Mowrer1960,
address = {New York},
author = {Mowrer, Orval Hobart},
pages = {555},
publisher = {Wiley},
title = {{Learning theory and behavior}},
year = {1960}
}
@article{Larimer2009,
abstract = {It is well established that college students have high rates of alcohol use and misuse and suffer the negative consequences of this behavior. Research evaluating the results of brief interventions with high-risk college students has shown these approaches to be successful in reducing alcohol con- sumption and/or related consequences. Several screening tools have been developed to detect the presence of problematic alcohol use and associated disorders, and some are designed specifically for use in a college student population. College campuses offer several opportunities to implement screening and interventions, including universal or large-scale assessments; health services, counsel- ing centers, or local emergency rooms; or via established judicial or grievance systems set up to deal with students who violate campus alcohol policies. Issues to consider when implementing screening and brief interventions in college populations include who should deliver the interventions—peer or professional counselors—and how students should be encouraged to participate in the interventions. Regardless of how the measures are implemented, the content and process of the brief interventions should be based on the available scientific evidence regarding established efficacious interventions.},
author = {Larimer, Mary E and Cronce, Jessica M and Lee, Christine M and Kilmer, Jason R},
file = {::},
journal = {Alcohol Research \& Health},
keywords = {AODD (alcohol and other drug use disorder),CAGE Questionnaire,Michigan Alcoholism Screening Test (MAST),Young Adult Alcohol Problems Screening Test (YAAPS,alcohol abuse,binge drinking,brief intervention,heavy drinking,identification and screening,interview,literature review,motivational interviewing,peer counseling,professional counseling,undergraduate student},
pages = {94--104},
title = {{Brief Intervention in College Settings}},
url = {?http://pubs.niaaa.nih.gov/publications/arh28 ?2/94?104 .htm},
volume = {28},
year = {2004}
}
@inproceedings{Broek2005,
abstract = {A new view on empathic agents is introduced, named: Empathic Agent Technology (EAT). It incorporates a speech analysis, which provides an indication for the amount of tension present in people. It is founded on an indirect physiological measure for the amount of experienced stress, defined as the variability of the fundamental frequency of the human voice. A thorough review of literature is provided on which the EAT is founded. In addition, the complete processing line of this measure is introduced. Hence, the first generally applicable, completely automated technique is introduced that enables the development of truly empathic agents.},
address = {Utrecht – The Netherlands},
author = {van den Broek, E. L.},
booktitle = {Proceedings of the AAMAS-05 Agent-Based Systems for Human Learning workshop (ABSHL 2005)},
editor = {Johnson, L. and Richards, D. and Sklar, E. and Wilensky, U.},
keywords = {affect,agents,emotion,empathy,fundamental frequency,pitch,speech,stress},
pages = {59--67},
publisher = {Brooklyn College},
title = {{Empathic agent technology}},
url = {http://eprints.eemcs.utwente.nl/21142/},
year = {2005}
}
@article{Saunier2010,
author = {Saunier, Julien and Jones, Hazael and Lourdeaux, Domitile},
doi = {10.1109/WI-IAT.2010.255},
file = {::},
isbn = {978-1-4244-8482-9},
journal = {2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology},
keywords = {emotions,empathy,multi-agent architecture,personality,placebo},
month = aug,
pages = {277--282},
publisher = {Ieee},
title = {{Empathy and Placebo for Autonomous Agents}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5616059},
year = {2010}
}
@article{Tickle-Degnen1990,
author = {Tickle-Degnen, L. and Rosenthal, Robert},
file = {::},
journal = {Psychological Inquiry},
number = {4},
pages = {285--293},
publisher = {Taylor \& Francis},
title = {{The nature of rapport and its nonverbal correlates}},
url = {http://www.tandfonline.com/doi/abs/10.1207/s15327965pli0104\_1},
volume = {1},
year = {1990}
}
@article{Taigman2011,
archivePrefix = {arXiv},
arxivId = {arXiv:1108.1122v1},
author = {Taigman, Yaniv and Wolf, Lior},
eprint = {arXiv:1108.1122v1},
file = {::},
journal = {Arxiv preprint arXiv:1108.1122},
number = {view 2},
pages = {1--7},
title = {{Leveraging Billions of Faces to Overcome Performance Barriers in Unconstrained Face Recognition}},
volume = {1},
year = {2011}
}
@article{Lee2009,
author = {Lee, Jina and Prendinger, H},
file = {::},
isbn = {9781424447992},
journal = {Affective Computing},
title = {{Learning models of speaker head nods with affective information}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5349543},
year = {2009}
}
@inproceedings{Denef2009,
abstract = {This thesis investigates the design of human computer interaction techniques for ubiquitous computing solutions in firefighting.},
address = {Uppsala, Sweden},
author = {Denef, Sebastian},
booktitle = {INTERACT '09 Proceedings of the 12th IFIP TC 13 International Conference on Human-Computer Interaction: Part II},
doi = {10.1007/978-3-642-03658-3\_97},
editor = {Gross, Tom and Gulliksen, Jan and Kotz\'{e}, Paula and Oestreicher, Lars and Palanque, Philippe and Prates, Raquel Oliveira and Winckler, Marco},
file = {::},
pages = {864--867},
publisher = {Springer Berlin / Heidelberg},
title = {{Human-Computer Interaction Techniques in Firefighting}},
url = {http://www.springerlink.com/index/n0688783567n3251.pdf http://dl.acm.org/citation.cfm?id=1616339},
year = {2009}
}
@article{Paiva2005,
author = {Paiva, Ana and Dias, Jo\~{a}o and Sobral, Daniel and Aylett, Ruth and Woods, Sarah and Hall, Lynne and Zoll, Carsten},
doi = {10.1080/08839510590910165},
file = {::},
issn = {0883-9514},
journal = {Applied Artificial Intelligence},
month = mar,
number = {3-4},
pages = {235--266},
title = {{Learning By Feeling: Evoking Empathy With Synthetic Characters}},
url = {http://www.tandfonline.com/doi/abs/10.1080/08839510590910165},
volume = {19},
year = {2005}
}
@inproceedings{Borutta2009,
abstract = {Emotional expressions are considered to be important for robotic and virtual agents to improve nonverbal communication in human-machine-interaction. In this paper we focus on a subset of emotional expressions, namely the smile and it's variations. The proposed concept for generating artificial smile sequences is based on the system-theoretic psychological model of smiling, which is based on the Zurich Model of Social Motivation. The model and seven different types of smiles are introduced and it is presented how to integrate this model in a virtual agent. The evaluation of the generated facial expressions shows that the seven types of smiles are distinguishable from each other and can be classified according to given categories.},
address = {Toyama, Japan},
author = {Borutta, Isabell and Sosnowski, Stefan and Zehetleitner, Michael},
booktitle = {The 18th IEEE International Symposium on Robot and Human Interactive Communication, 2009. RO-MAN 2009.},
doi = {10.1109/ROMAN.2009.5326255},
file = {::},
pages = {245 -- 250},
title = {{Generating artificial smile variations based on a psychological system-theoretic approach}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5326255},
year = {2009}
}
@article{Jaques2007,
abstract = {In this article we describe the use of mental states approach, more specifically the belief-desire-intention (BDI) model, to implement the process of affective diagnosis in an educational environment. We use the psychological OCC model, which is based on the cognitive theory of emotions and is possible to be imple- mented computationally, in order to infer the learners emotions from his actions in the system interface. In our work we profit from the reasoning capacity of the BDI model in order to infer the students appraisal (a cognitive evaluation of a person that elicits an emotion), which allows us to deduce students emotions. The system reasons about an emotion-generating situation and tries to infer the users emotion by using the OCC model. Besides, the BDI model is very adequate to infer and also model students affective states since the emotions have a dynamic nature.},
author = {Jaques, Patricia Augustin and Vicari, Rosa Maria},
doi = {10.1016/j.compedu.2005.09.002},
file = {::},
issn = {03601315},
journal = {Computers \& Education},
keywords = {architectures for educational technology,computer,distance education and telelearning,human,intelligent tutoring systems,interactive learning environments,interface,media in education,system},
month = sep,
number = {2},
pages = {360--384},
title = {{A BDI approach to infer student’s emotions in an intelligent learning environment}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0360131505001302},
volume = {49},
year = {2007}
}
@book{Frijda1986,
address = {New York},
author = {Frijda, Nico H.},
isbn = {9780521316002},
pages = {544},
publisher = {Cambridge University Press},
title = {{The Emotions}},
year = {1986}
}
@article{Tickle-Degnen1990,
author = {Tickle-Degnen, L. and Rosenthal, Robert},
file = {::},
journal = {Psychological Inquiry},
number = {4},
pages = {285--293},
publisher = {Taylor \& Francis},
title = {{The nature of rapport and its nonverbal correlates}},
url = {http://www.tandfonline.com/doi/abs/10.1207/s15327965pli0104\_1},
volume = {1},
year = {1990}
}
@article{Hess2001,
author = {Hess, Ursula and Blairy, Sylvie},
file = {::},
journal = {International Journal of Psychophysiology},
keywords = {emotion recognition,emotional contagion,facial mimicry},
pages = {129--141},
title = {{Facial mimicry and emotional contagion to dynamic emotional facial expressions and their influence on decoding accuracy}},
volume = {40},
year = {2001}
}
@article{Noar2007,
abstract = {Although there is a large and growing literature on tailored print health behavior change interventions, it is currently not known if or to what extent tailoring works. The current study provides a meta-analytic review of this literature, with a primary focus on the effects of tailoring. A comprehensive search strategy yielded 57 studies that met inclusion criteria. Those studies-which contained a cumulative N = 58,454-were subsequently meta-analyzed. The sample size-weighted mean effect size of the effects of tailoring on health behavior change was found to be r = .074. Variables that were found to significantly moderate the effect included (a) type of comparison condition, (b) health behavior, (c) type of participant population (both type of recruitment and country of sample), (d) type of print material, (e) number of intervention contacts, (f) length of follow-up, (g) number and type of theoretical concepts tailored on, and (h) whether demographics and/or behavior were tailored on. Implications of these results are discussed and future directions for research on tailored health messages and interventions are offered.},
author = {Noar, Seth M and Benac, Christina N and Harris, Melissa S},
institution = {Department of Communication, University of Kentucky, Lexington, KY 40506-0042, USA. snoar2@uky.edu},
journal = {Psychological Bulletin},
keywords = {adolescent,adult,aged,child,communication,female,health behavior,health education,health education methods,health promotion,health promotion methods,humans,male,middle aged,patient acceptance health care,patient acceptance health care psychology,teaching materials,united states},
number = {4},
pages = {673--693},
pmid = {17592961},
publisher = {American Psychological Association},
title = {{Does tailoring matter? Meta-analytic review of tailored print health behavior change interventions.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17592961},
volume = {133},
year = {2007}
}
@article{VanSwol2003,
author = {{Van Swol}, Lyn M.},
doi = {10.1177/0093650203253318},
file = {::},
issn = {00000000},
journal = {Communication Research},
month = aug,
number = {4},
pages = {461--480},
title = {{The Effects of Nonverbal Mirroring on Perceived Persuasiveness, Agreement with an Imitator, and Reciprocity in a Group Discussion}},
volume = {30},
year = {2003}
}
@article{Nisbett1977,
abstract = {Reviews evidence which suggests that there may be little or no direct introspective access to higher order cognitive processes. Ss are sometimes (a) unaware of the existence of a stimulus that importantly influenced a response, (b) unaware of the existence of the response, and (c) unaware that the stimulus has affected the response. It is proposed that when people attempt to report on their cognitive processes, that is, on the processes mediating the effects of a stimulus on a response, they do not do so on the basis of any true introspection. Instead, their reports are based on a priori, implicit causal theories, or judgments about the extent to which a particular stimulus is a plausible cause of a given response. This suggests that though people may not be able to observe directly their cognitive processes, they will sometimes be able to report accurately about them. Accurate reports will occur when influential stimuli are salient and are plausible causes of the responses they produce, and will not occur when stimuli are not salient or are not plausible causes.},
author = {Nisbett, R E and Wilson, T D},
doi = {10.1037/0033-295X.84.3.231},
editor = {DeVivo, Anita and Silver, Amy and Felder, Deborah S and Hayward, Robert J and Patterson, Kendall C and Redman, Anne and Buchwald, Alexander and Falmagne, Rachel Jofffe and Krantz, David H and Olson, Gary M and Shiffrin, Richard M and Smith, Edward E and Theios, John and WIggins, Jerry S},
issn = {0033295X},
journal = {Psychological Review},
number = {3},
pages = {231--259},
pmid = {17882490},
publisher = {Psychol Rev},
title = {{Telling more than we can know: Verbal reports on mental processes}},
url = {http://psycnet.apa.org/journals/rev/84/3/231/},
volume = {84},
year = {1977}
}
@article{Happ2011,
author = {Happ, Christian and Melzer, Andr\'{e}},
file = {::},
journal = {Ifip International Federation For Information Processing},
keywords = {1,1 prosocial and antisocial,aggression,anderson and his colleagues,confirmed that video game,effects of video games,empathy,furthermore,in a recent overview,prosocial behavior,related to indicators of,video games,violence exposure is positively},
pages = {371--374},
title = {{Bringing Empathy into Play: On the Effects of Empathy in Violent and Nonviolent Video Games}},
url = {http://www.springerlink.com/index/P76556V1HN316RK6.pdf},
year = {2011}
}
@article{Colineau2010b,
author = {Colineau, Nathalie and Paris, C\'{e}cile},
doi = {10.1007/s11257-010-9089-x},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Colineau, Paris - 2010 - Motivating reflection about health within the family the use of goal setting and tailored feedback.pdf:pdf},
issn = {0924-1868},
journal = {User Modeling and User-Adapted Interaction},
keywords = {evaluation,family support,goal setting theory,health behaviour,lifestyle and wellbeing,motivation strategies},
month = dec,
pages = {341--376},
title = {{Motivating reflection about health within the family: the use of goal setting and tailored feedback}},
url = {http://www.springerlink.com/index/10.1007/s11257-010-9089-x},
year = {2010}
}
@inproceedings{Pontier2008,
abstract = {Previous research indicates that self-help therapy is an effective method to prevent and treat unipolar depression. While web-based self-help therapy has many advantages, there are also disadvantages to self-help therapy, such as that it misses the possibility to regard the body language of the user, and the lack of personal feedback on the user responses. This study presents a virtual agent that guides the user through the Beck Depression Inventory (BDI) questionnaire, which is used to measure the severity of depression. The agent responds empathically to the answers given by the user, by changing its facial expression. This resembles face to face therapy more than existing web-based self-help therapies. A pilot experiment indicates that the virtual agent has added value for this application.},
author = {Pontier, Matthijs and Siddiqui, Ghazanfar F},
booktitle = {Proceedings of the 8th international conference on Intelligent Virtual Agents (IVA)},
doi = {10.1007/978-3-540-85483-8\_42},
editor = {{H. Prendinger, J. Lester}, and M. Ishizuka},
file = {::},
keywords = {Emotion modeling,Self-help therapy,Virtual agent},
pages = {417--425},
publisher = {Springer-Verlag Berlin Heidelberg},
title = {{A Virtual Therapist That Responds Empathically to Your Answers}},
year = {2008}
}
@article{Meng2009,
author = {Meng, Qinggang and Lee, Mark},
doi = {10.1109/CASE.2009.156},
file = {::},
isbn = {978-0-7695-3728-3},
journal = {2009 IITA International Conference on Control, Automation and Systems Engineering (case 2009)},
keywords = {-home service robots,human-robot interaction},
month = jul,
pages = {220--224},
publisher = {Ieee},
title = {{Empathy between Human and Home Service Robots}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5194430},
year = {2009}
}
@incollection{Juslin2005,
abstract = {(From the chapter) The aims of this chapter are manifold. First, it is intended as a general introduction to the field for the newcomer. Thus, the chapter offers hands-on information on how to conduct studies of vocal affect expression. Second, we hope to contribute to increased cumulativeness and comparability across studies, for instance with respect to definitions, classification categories, methods, and reporting. Third, we want to highlight new developments in the field that have occurred since a previous chapter on this subject was written (Scherer 1982). There has actually been reasonable progress on several issues, and it is crucial that future research proceeds from the current state of the art. Fourth, we hope to encourage using the voice as a tool in testing emotion theories. Fifth, we want to offer the reader examples of applications in various practical domains that involve vocal affect expression. Finally, and perhaps most importantly, the aim of the chapter is inspirational: throughout the text, we will try to convey the enthusiasm we have for this field of study. In our attempt to achieve these aims, we have opted for a chapter structure of a somewhat unusual kind. The chapter consists of a main text, which is interspersed with boxes (background material) and modules (practical guidelines) on particular topics that we refer to in the main text. We hope this will make it easier for the reader to quickly locate relevant information. The first section offers theoretical foundations. The following two sections focus on voice cues to affect and affect inferences from voice cues. In attempting such a broad review, it is difficult to avoid simplifying many complex issues and omitting certain aspects of the topics discussed. However, throughout the chapter, we will continually provide references for further reading. (PsycINFO Database Record (c) 2007 APA},
author = {Juslin, Patrick N and Scherer, Klaus R.},
booktitle = {The new handbook of Methods in Nonverbal Behavior Research},
chapter = {3},
editor = {Harrigan, J A and Rosenthal, R and Scherer, K R},
isbn = {0198529619},
pages = {65--135},
publisher = {Oxford University Press},
series = {The New Handbook of Methods in Nonverbal Behavior Research},
title = {{Vocal expression of affect}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=RTNNfOUI\_EIC\&amp;oi=fnd\&amp;pg=PA65\&amp;dq=Vocal+Expression+of+Affect\&amp;ots=0MYYmuwEi6\&amp;sig=npVRYBK6JtZcsjyJZbz3qjaLpuM},
year = {2005}
}
@inproceedings{Bartneck2008,
abstract = {This study emphasizes the need for standardized measurement tools for human robot interaction (HRI). If we are to make progress in this field then we must be able to compare the results from different studies. A literature review has been performed on the measurements of five key concepts in HRI: anthropomorphism, animacy, likeability, perceived intelligence, and perceived safety. The results have been distilled into five consistent questionnaires using semantic differential scales. We report reliability and validity indicators based on several empirical studies that used these questionnaires. It is our hope that these questionnaires can be used by robot developers to monitor their progress. Psychologists are invited to further develop the questionnaires by adding new concepts, and to conduct further validations where it appears necessary.},
address = {Amsterdam},
author = {Bartneck, Christoph and Kulic, Dana and Croft, Elizabeth},
booktitle = {Proceedings of the Metrics for Human-Robot Interaction Workshop in affiliation with the 3rd ACM/IEEE International Conference on Human-Robot Interaction (HRI 2008), Technical Report 471},
file = {::},
keywords = {Human factors,measurement,perception,robot},
pages = {37--44},
publisher = {University of Hertfordshire},
title = {{Measuring the anthropomorphism, animacy, likeability, perceived intelligence and perceived safety of robots}},
url = {http://ece.uwaterloo.ca/~dkulic/pubs/bartneckKulicCroft.pdf},
volume = {471},
year = {2008}
}
@article{Albrecht2005,
abstract = {We present an algorithm for generating facial expressions for a continuum of pure and mixed emotions of varying intensity. Based on the observation that in natural interaction among humans, shades of emotion are much more frequently encountered than expressions of basic emotions, a method to generate more than Ekman's six basic emotions (joy, anger, fear, sadness, disgust and surprise) is required. To this end, we have adapted the algorithm proposed by Tsapatsoulis et al. [1] to be applicable to a physics-based facial animation system and a single, integrated emotion model. A physics-based facial animation system was combined with an equally flexible and expressive text-to-speech synthesis system, based upon the same emotion model, to form a talking head capable of expressing non-basic emotions of varying intensities. With a variety of life-like intermediate facial expressions captured as snapshots from the system we demonstrate the appropriateness of our approach.},
author = {Albrecht, Irene and Schr\"{o}der, Marc and Haber, J\"{o}rg and Seidel, Hans-Peter},
doi = {10.1007/s10055-005-0153-5},
file = {::},
issn = {1359-4338},
journal = {Virtual Reality},
keywords = {continuous emotions \ae emotional,speech,synthesis \ae facial animation},
month = aug,
number = {4},
pages = {201--212},
title = {{Mixed feelings: expression of non-basic emotions in a muscle-based talking head}},
url = {http://www.springerlink.com/index/10.1007/s10055-005-0153-5},
volume = {8},
year = {2005}
}
@article{Rodrigues2009,
author = {Rodrigues, SH and Mascarenhas, SF},
file = {::},
isbn = {9781424447992},
journal = {and Workshops, 2009},
title = {{“ I can feel it too !”: Emergent empathic reactions between synthetic characters}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5349570},
year = {2009}
}
@incollection{Dautenhahn2002,
author = {Dautenhahn, Kerstin and Bond, Alan and Ca\~{n}amero, Lola and Edmonds, Bruce},
booktitle = {Socially Intelligent Agents: Creating Relationships with Computers and Robots},
chapter = {1},
editor = {Dautenhahn, Kerstin and Bond, Alan and Ca\~{n}amero, Lola and Edmonds, Bruce},
file = {::},
isbn = {978-1-4020-7057-0},
pages = {1--20},
publisher = {Springer},
title = {{Creating Relationships with Computers and Robots}},
url = {http://www.springerlink.com/index/V38H434X220766G8.pdf},
year = {2002}
}
@article{Vanbaaren2004,
author = {Van baaren, Rick B. and Holland, Rob W. and Kawakami, Kerry and Knippenberg, Ad Van},
doi = {10.1111/j.0963-7214.2004.01501012.x},
file = {::},
issn = {0956-7976},
journal = {Psychological Science},
month = jan,
number = {1},
pages = {71--74},
title = {{Mimicry and Prosocial Behavior}},
url = {http://pss.sagepub.com/lookup/doi/10.1111/j.0963-7214.2004.01501012.x},
volume = {15},
year = {2004}
}
@article{Cowell2005,
author = {Cowell, Andrew J. and Stanney, Kay M.},
doi = {10.1016/j.ijhcs.2004.11.008},
file = {::},
issn = {10715819},
journal = {International Journal of Human-Computer Studies},
month = feb,
number = {2},
pages = {281--306},
title = {{Manipulation of non-verbal interaction style and demographic embodiment to increase anthropomorphic computer character credibility}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1071581904001260},
volume = {62},
year = {2005}
}
@article{Fagerstrom1990,
author = {Fagerstrom, K O and Heatherton, T F and Kozlowski, L T},
institution = {Department of Psychology, Harvard University.},
journal = {Ear nose throat journal},
keywords = {*adverse effects,*diagnosis,*nicotine,*standards,alcoholism,complications,etiology,human,ph,prevention \& control,psyc,questionnaires,smoking,substance related disorders},
number = {11},
pages = {763--765},
pmid = {2276350},
title = {{Nicotine addiction and its assessment.}},
volume = {69},
year = {1990}
}
@inproceedings{Huang2010,
abstract = {Virtual humans are embodied software agents that should not only be realistic looking but also have natural and realistic behaviors. Traditional virtual human systems learn these interaction behaviors by observing how individuals respond in face-to-face situations (i.e., direct interaction). In contrast, this paper introduces a novel methodological approach called parasocial consensus sampling (PCS) which allows multiple individuals to vicariously experience the same situation to gain insight on the typical (i.e., consensus view) of human responses in social interaction. This approach can help tease apart what is idiosyncratic from what is essential and help reveal the strength of cues that elicit social responses. Our PCS approach has several advantages over traditional methods: (1) it integrates data from multiple independent listeners interacting with the same speaker, (2) it associates probability of how likely feedback will be given over time, (3) it can be used as a prior to analyze and understand the face-to-face interaction data, (4) it facilitates much quicker and cheaper data collection. In this paper, we apply our PCS approach to learn a predictive model of listener backchannel feedback. Our experiments demonstrate that a virtual human driven by our PCS approach creates significantly more rapport and is perceived as more believable than the virtual human driven by face-to-face interaction data.},
address = {Toronto, Canada},
author = {Huang, Lixing and Morency, Louis-Philippe and Gratch, Jonathan},
booktitle = {9th International Conference on Autonomous Agents and Multiagent Systems (AAMAS'2010)},
doi = {10.1145/1838206.1838371},
editor = {Hoek, Van Der and Kaminka and Lesperance and Luck and Sen},
file = {::},
keywords = {Backchannel Feedback,Parasocial,Rapport,Virtual Humans},
number = {Aamas},
pages = {10--14},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org)},
title = {{Parasocial consensus sampling: combining multiple perspectives to learn virtual human behavior}},
url = {http://dl.acm.org/citation.cfm?id=1838371},
year = {2010}
}
@article{Ochs2010a,
author = {Ochs, Magalie and Sadek, David and Pelachaud, Catherine},
doi = {10.1007/s10458-010-9156-z},
file = {::},
issn = {1387-2532},
journal = {Autonomous Agents and Multi-Agent Systems},
keywords = {affective computing,dialog,emotions,empathy,rational dialog agent},
month = nov,
number = {3},
pages = {410--440},
title = {{A formal model of emotions for an empathic rational dialog agent}},
url = {http://www.springerlink.com/index/10.1007/s10458-010-9156-z},
volume = {24},
year = {2010}
}
@article{Gratch2006,
author = {Gratch, Jonathan and Okhmatovskaia, Anna and Lamothe, Francois},
file = {::},
journal = {Intelligent Virtual},
title = {{Virtual rapport}},
url = {http://www.springerlink.com/index/k720537752657m81.pdf},
year = {2006}
}
@techreport{Gratch2010,
author = {Gratch, Jonathan and Kang, Sin-hwa and Wang, Ning},
booktitle = {Imagine},
file = {::},
institution = {University of Southern California},
number = {Chap X},
pages = {1--22},
title = {{Using social agents explore theories of rapport and emotional resonance}},
year = {2010}
}
@article{Larimer2007,
abstract = {The current study was designed to evaluate the efficacy of a mailed feedback and tips intervention as a universal prevention strategy for college drinking. Participants (N = 1,488) were randomly assigned to feedback or assessment-only control conditions. Results indicated that the mailed feedback intervention had a preventive effect on drinking rates overall, with participants in the feedback condition consuming less alcohol at follow-up in comparison with controls. In addition, abstainers in the feedback condition were twice as likely to remain abstinent from alcohol at follow-up in comparison with control participants (odds ratio = 2.02), and feedback participants were significantly more likely to refrain from heavy episodic drinking (odds ratio = 1.43). Neither gender nor severity of baseline drinking moderated the efficacy of the intervention in these analyses, but more conservative analyses utilizing last-observation carryforward suggested women and abstainers benefited more from this prevention approach. Protective behaviors mediated intervention efficacy, with participants who received the intervention being more likely to use strategies such as setting limits and alternating alcohol with nonalcoholic beverages. Implications of these findings for universal prevention of college drinking are discussed.},
author = {Larimer, Mary E and Lee, Christine M and Kilmer, Jason R and Fabiano, Patricia M and Stark, Christopher B and Geisner, Irene M and Mallett, Kimberly A and Lostutter, Ty W and Cronce, Jessica M and Feeney, Maggie and Neighbors, Clayton},
institution = {Department of Psychiatry and Behavioral Sciences, University of Washington, Seattle, WA 98105, USA. larimer@u.washington.edu},
journal = {Journal of Consulting and Clinical Psychology},
keywords = {adult,alcohol drinking,alcohol drinking epidemiology,alcohol drinking prevention \& control,communication,feedback,female,humans,male,motivation,postal service,students,students statistics \& numerical data,universities},
number = {2},
pages = {285--293},
pmid = {17469886},
publisher = {American Psychological Association. Journals Department, 750 First Street NE, Washington, DC 20002-4242. Tel: 800-374-2721; Tel: 202-336-5510; Fax: 202-336-5502; e-mail: order@apa.org; Web site: http://www.apa.org/publications},
title = {{Personalized mailed feedback for college drinking prevention: a randomized clinical trial.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17469886},
volume = {75},
year = {2007}
}
@article{Bellet1991,
abstract = {IN HIS RESEARCH on the physician-patient relationship, Cousins1 found that 85\% of people had changed physicians or were thinking of changing in the past 5 years. Many of those who changed did so because of their physician's poor communication skills. One of the qualities of effective communication is the use of empathy. Because some physicians have not learned to use empathy in their training as medical students and residents, they may be ineffective in the care of patients.2 In this article, we discuss the importance of empathy in medical practice and illustrate its use with two examples.},
author = {Bellet, P S and Maloney, M J},
doi = {10.1001/jama.1991.03470130111039},
file = {::},
issn = {0098-7484},
journal = {JAMA : the journal of the American Medical Association},
keywords = {Communication,Cost-Benefit Analysis,Empathy,Humans,Physician's Practice Patterns,Physician's Practice Patterns: economics,Physician-Patient Relations},
month = oct,
number = {13},
pages = {1831--2},
pmid = {1909761},
title = {{The importance of empathy as an interviewing skill in medicine}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/1909761},
volume = {266},
year = {1991}
}
@article{Littlewort2011,
author = {Littlewort, Gwen C and Whitehill, Jacob and Wu, T},
doi = {10.1109/AFGR.2008.4813406},
file = {::},
isbn = {978-1-4244-2153-4},
journal = {Recognition and},
month = sep,
pages = {1--2},
publisher = {Ieee},
title = {{The computer expression recognition toolbox (CERT)}},
year = {2011}
}
@article{Lisetti2003,
abstract = {Accountingfor a patient’s emotional state is integral in medical care. Tele-health research attests to the challenge clinicians must overcome in assessing patient emotional state when modalities are limited (J. Adv. Nurs. 36(5) 668). The extra effort involved in addressingthis challenge requires attention, skill, and time. Large caseloads may not afford tele-home health- care (tele-HHC) clinicians the time and focus necessary to accurately assess emotional states and trends. Unstructured interviews with experienced tele-HHC providers support the introduction of objective indicators of patients’ emotional status in a useful form to enhance patient care. We discuss our contribution to addressingthis challenge, which involves building user models not only of the physical characteristics of users—in our case patients—but also models of their emotions. We explain our research in progress on Affective Computing for tele-HHC applications, which includes: developinga system architecture for monitoringand respondingto human multimodal affect and emotions via multimedia and empathetic avatars; mapping of physiological signals to emotions and synthesizing the patient’s affective information for the health-care provider. Our results usinga wireless non-invasive wearable computer to collect physiological signals and mapping these to emotional states show the feasibility of our approach, for which we lastly discuss the future research issues that we have identified.},
author = {Lisetti, Christine L and Nasoz, F. and LeRouge, C. and Ozyer, O. and Alvarez, K.},
doi = {10.1016/S1071-5819(03)00051-X},
issn = {10715819},
journal = {International Journal of Human-Computer Studies},
keywords = {Affective computing,Emotions,Human factors of multimedia systems,Intelligent user interfaces,Tele-health,Tele-home health care,User modeling},
month = jul,
number = {1-2},
pages = {245--255},
title = {{Developing multimodal intelligent affective interfaces for tele-home health care}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S107158190300051X},
volume = {59},
year = {2003}
}
@inproceedings{Zwann2012,
abstract = {[1] J. M. van der Zwaan, V. Dignum, and C. M. Jonker, “A BDI Dialogue Agent for Social Support : Specification of Verbal Support Types ( Extended Abstract ) Categories and Subject Descriptors,” pp. 1183–1184.},
address = {Valencia, Spain},
author = {van der Zwaan, J.M. and Dignum, V. and Jonker, C.M.},
booktitle = {Proceedings of the 11th International Conference on Autonomous Agents and Multiagent Systems (AAMAS2012)},
file = {::},
keywords = {behavior,conversational agents,modeling cognition and socio-cultural,verbal and non-verbal expression},
pages = {1183--1184},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org)},
title = {{A BDI Dialogue Agent for Social Support : Specification of Verbal Support Types ( Extended Abstract ) Categories and Subject Descriptors}},
year = {2012}
}
@article{Neiberg2006,
author = {Neiberg, Daniel and Elenius, Kjell and Karlsson, Inger},
file = {::},
journal = {Working Papers of Lund University, Centre for Languages \& Literature, Dept. of Linguistics \& Phonetics},
pages = {101--104},
title = {{Emotion recognition in spontaneous speech}},
url = {http://nile.lub.lu.se/ojs/index.php/LWPL/article/viewFile/2306/1881},
volume = {52},
year = {2006}
}
@article{Caridakis2008,
abstract = {As input they consider the image sequence of the recorded human behavior. Computer vision and image processing techniques are incorporated in order to detect cues needed for expressivity features extraction. Using multimodalities, the virtual agent mimics the human expressions. The multimodality of the approach lies in the fact that both facial and gestural aspects of the user’s behavior are analyzed and processed. The mimicry consists of perception, interpretation, planning and animation of the expressions shown by the human, resulting not in an exact duplicate rather than an expressive model of the user’s original behavior.},
annote = {They use both facial and gestural aspects of the user’s behavior to mimic the user’s expressions. The introductory information and references about the psychological background of the mimicry in the paper are useful. But because most of the work is image processing, those sections would not be useful for our job.},
author = {Caridakis, George and Raouzaiou, Amaryllis and Bevacqua, Elisabetta and Mancini, Maurizio and Karpouzis, Kostas and Malatesta, Lori and Pelachaud, Catherine},
doi = {10.1007/s10579-007-9057-1},
file = {::},
issn = {1574-020X},
journal = {Language Resources and Evaluation},
keywords = {facial,gesture,mimicry,multimodal,virtual agent},
month = jan,
number = {3-4},
pages = {367--388},
title = {{Virtual agent multimodal mimicry of humans}},
url = {http://www.springerlink.com/index/10.1007/s10579-007-9057-1},
volume = {41},
year = {2008}
}
@article{Strecher1986,
abstract = {The concept of self-efficacy is receiving increasing recognition as a predictor of health behavior change and maintenance. The purpose of this article is to facilitate a clearer understanding of both the concept and its relevance for health education research and practice. Self-efficacy is first defined and distinguished from other related concepts. Next, studies of the self-efficacy concept as it relates to health practices are examined. This review focuses on cigarette smoking, weight control, contraception, alcohol abuse and exercise behaviors. The studies reviewed suggest strong relationships between self-efficacy and health behavior change and maintenance. Experimental manipulations of self-efficacy suggest that efficacy can be enhanced and that this enhancement is related to subsequent health behavior change. The findings from these studies also suggest methods for modifying health practices. These methods diverge from many of the current, traditional methods for changing health practices. Recommendations for incorporating the enhancement of self-efficacy into health behavior change programs are made in light of the reviewed findings.},
author = {Strecher, V J and DeVellis, B M and Becker, M H and Rosenstock, I M},
journal = {Health Education Quarterly},
number = {1},
pages = {73--92},
pmid = {3957687},
publisher = {Sage Publications},
title = {{The role of self-efficacy in achieving health behavior change.}},
url = {http://heb.sagepub.com/cgi/doi/10.1177/109019818601300108},
volume = {13},
year = {1986}
}
@article{Litvack-Miller1997a,
abstract = {This study was an investigation of the structure and development of dispositional empathy during middle childhood and its relationship to altruism. A sample of 478 students from 2nd, 4th, and 6th grades completed an altruism questionnaire and a social desirability scale, both created for this study, and the Interpersonal Reactivity Index (Davis, 1980), adapted for this study. Teachers also rated the students on prosocial behaviors, such as sharing. In addition, as an experimental part of the study, the children could make monetary donations and volunteer time to raise funds. Results of a confirmatory factor analysis on the Interpersonal Reactivity Index supported Davis's (1980) findings that empathy comprises four components: perspective taking, fantasy, empathic concern, and personal distress. Factor intercorrelations, however, were not the same as those reported by Davis. MANOVAs were used to examine gender and age effects on empathy. Girls were more empathic in general than boys, and older children showed more empathic concern than younger children. Only empathic concern and perspective taking were significant predictors of prosocial behavior.},
author = {Litvack-Miller, W and McDougall, D and Romney, D M},
file = {::},
issn = {8756-7547},
journal = {Genetic, social, and general psychology monographs},
keywords = {Adolescent,Altruism,Child,Empathy,Female,Humans,Interpersonal Relations,Male,Questionnaires,Social Behavior,Social Desirability},
month = aug,
number = {3},
pages = {303--24},
pmid = {9259121},
title = {{The structure of empathy during middle childhood and its relationship to prosocial behavior.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21981037},
volume = {123},
year = {1997}
}
@article{Grolleman2006,
abstract = {E-therapy offers new means to support smokers during their attempt to quit. An embodied conversational agent can support people as a virtual coach on the internet. In this paper requirements are formulated for such a virtual coach and a global design is proposed. The requirements and the design are based on an extensive analysis of the practice of individual coaching of the Dutch organization STIVORO. In addition, the outcomes of a survey research measuring the acceptance of such a virtual coach by a potential user group are described.},
author = {Grolleman, Jorne and {Van Dijk}, Betsy and Nijholt, Anton and {Van Emst}, Andr\'{e}e},
editor = {IJsselsteijn, Wijnand and {De Kort}, Yvonne and Midden, Cees and Eggen, Berry and {Van Den Hoven}, Elise},
journal = {Persuasive Technology},
pages = {133--141},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Break the Habit! Designing an e-Therapy Intervention Using a Virtual Coach in Aid of Smoking Cessation}},
url = {http://www.springerlink.com/index/6M1W6175693873T0.pdf},
volume = {3962},
year = {2006}
}
@article{Russell2003,
abstract = {A flurry of theoretical and empirical work concerning the production of and response to facial and vocal expressions has occurred in the past decade. That emotional expressions express emotions is a tautology but may not be a fact. Debates have centered on universality, the nature of emotion, and the link between emotions and expressions. Modern evolutionary theory is informing more models, emphasizing that expressions are directed at a receiver, that the interests of sender and receiver can conflict, that there are many determinants of sending an expression in addition to emotion, that expressions influence the receiver in a variety of ways, and that the receiver's response is more than simply decoding a message.},
author = {Russell, James a and Bachorowski, Jo-Anne and Fernandez-Dols, Jose-Miguel},
doi = {10.1146/annurev.psych.54.101601.145102},
file = {::},
issn = {0066-4308},
journal = {Annual review of psychology},
keywords = {Emotions,Expressed Emotion,Facial Expression,Humans,Interpersonal Relations,Nonverbal Communication,Personal Construct Theory,Social Perception,Speech Acoustics},
month = jan,
pages = {329--49},
pmid = {12415074},
title = {{Facial and vocal expressions of emotion.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12415074},
volume = {54},
year = {2003}
}
@article{Sebe2005a,
author = {Sebe, Nicu and Cohen, Ira and Huang, Thomas S.},
file = {::},
journal = {Handbook of Pattern Recognition and Computer Vision},
pages = {981--256},
publisher = {Citeseer},
title = {{Multimodal emotion recognition}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.110.1129\&amp;rep=rep1\&amp;type=pdf},
year = {2005}
}
@article{Moreno2006,
abstract = {College students learned about science with a multimedia program. One group (choice or C) chose to learn with or without an animated pedagogical agent (APA) representing a male or female of Wve diVerent ethnicities. Another group (no-choice or NC) was assigned an APA by the system. All participants in C group chose to learn with APAs and students of color chose signiWcantly more same-ethnicity APAs than White American students. A signiWcant interaction between choice and ethnic similarity factors revealed that group C produced lower retention, transfer, and program ratings when learning with same-ethnicity rather than diVerent-ethnicity APAs. Results support an interference hypothesis for students who choose to learn with same-ethnicity APAs.},
author = {Moreno, Roxana and Flowerday, Terri},
doi = {10.1016/j.cedpsych.2005.05.002},
file = {::},
issn = {0361476X},
journal = {Contemporary Educational Psychology},
keywords = {animated pedagogical agents,avect,choice,ethnicity,gender,learning,multimedia,science,similarity-attraction},
month = apr,
number = {2},
pages = {186--207},
title = {{Students’ choice of animated pedagogical agents in science learning: A test of the similarity-attraction hypothesis on gender and ethnicity}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0361476X05000317},
volume = {31},
year = {2006}
}
@article{O'Keefe1988,
abstract = {Offers models of 3 alternative message design logics and describes a general method of message analysis based on these models. The method of analysis is exemplified in a study of messages used in addressing a regulative communication task. 92 undergraduates were asked to provide messages they would address to a subordinate who failed to complete assigned work; these messages were classified in terms of the kind of goal set being pursued and the kind of reasoning reflected in their design. Male and female Ss differed systematically in the message design logic they employed, and there were significant relationships between interpersonal construct differentiation and message design logic and goal structure. ((c) 1997 APA/PsycINFO, all rights reserved)},
author = {O'Keefe, Barbara J},
journal = {Communication Monographs},
number = {1},
pages = {80--103},
title = {{The logic of message design: Individual differences in reasoning about communication}},
volume = {55},
year = {1988}
}
@techreport{Gratch2010,
author = {Gratch, Jonathan and Kang, Sin-hwa and Wang, Ning},
booktitle = {Imagine},
file = {::},
institution = {University of Southern California},
number = {Chap X},
pages = {1--22},
title = {{Using social agents explore theories of rapport and emotional resonance}},
year = {2010}
}
@inproceedings{Zanbaka2007,
abstract = {Do human-human social interactions carry over to human- virtual human social interactions? How does this affect future interface designers? We replicated classical tests of social influence known as the social facilitation and inhibition effects. Social facilitation/inhibition theory states that when in the presence of others, people perform simple tasks better and complex tasks worse. Participants were randomly assigned to perform both simple and complex tasks alone and in the presence of either a real human, a projected virtual human, or a virtual human in a head- mounted display. Our results showed participants were inhibited by the presence of others, whether real or virtual. That is, participants performed worse on the complex task, both in terms of percent correct and reaction times, when in the presence of others than when alone. Social facilitation did not occur with the real or virtual human. We discuss these results and their implications for future interface designers.},
address = {San Jose, California, USA},
author = {Zanbaka, Catherine and Ulinski, Amy and Goolkasian, Paula and Hodges, Larry F},
booktitle = {CHI 2007 Proceedings of Social Influence},
file = {::},
isbn = {9781595935939},
keywords = {Virtual humans,avatars,experimental studies,human-computer interaction,interface agents,social facilitation and inhibition,social influence,social psychology.},
pages = {1561--1570},
publisher = {ACM},
title = {{Social Responses to Virtual Humans : Implications for Future Interface Design}},
year = {2007}
}
@article{Vanbaaren2004,
author = {Van baaren, Rick B. and Holland, Rob W. and Kawakami, Kerry and Knippenberg, Ad Van},
doi = {10.1111/j.0963-7214.2004.01501012.x},
file = {::},
issn = {0956-7976},
journal = {Psychological Science},
month = jan,
number = {1},
pages = {71--74},
title = {{Mimicry and Prosocial Behavior}},
url = {http://pss.sagepub.com/lookup/doi/10.1111/j.0963-7214.2004.01501012.x},
volume = {15},
year = {2004}
}
@article{Gupta2012,
author = {Gupta, Prabodh and Jhala, Darshana and Jhala, Nirag},
doi = {10.1309/AJCPLAE62CRYYXNW},
file = {::},
issn = {1943-7722},
journal = {American journal of clinical pathology},
month = jan,
number = {1},
pages = {160},
pmid = {22180490},
title = {{Book review.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22180490},
volume = {137},
year = {2002}
}
@inproceedings{Caridakis2006,
author = {Caridakis, George and Malatesta, Lori and Kessous, Loic and Amir, Noam and Raouzaiou, Amaryllis and Karpouzis, Kostas},
booktitle = {Proceedings of the 8th international conference on Multimodal interfaces},
file = {::},
pages = {146--154},
publisher = {ACM},
title = {{Modeling naturalistic affective states via facial and vocal expressions recognition}},
year = {2006}
}
@article{Rebolledo-Mendez2009,
author = {Rebolledo-Mendez, Genaro and Freitas, Sara De and Gaona, Alma Rosa Garcia},
doi = {10.1109/VS-GAMES.2009.33},
file = {::},
isbn = {978-0-7695-3588-3},
journal = {2009 Conference in Games and Virtual Worlds for Serious Applications},
keywords = {- empathy,alma rosa garcia gaona,facultad de inform\'{a}tica,motivation,serious games,universidad veracruzana},
month = mar,
pages = {5--11},
publisher = {Ieee},
title = {{A Model of Motivation Based on Empathy for AI-Driven Avatars in Virtual Worlds}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5116547},
year = {2009}
}
@article{Sarrafzadeh2006,
author = {Sarrafzadeh, Abdolhossein and Alexander, Samuel and Dadgostar, Farhad and Fan, Chao and Bigdeli, Abbas},
doi = {10.1109/INNOVATIONS.2006.301981},
file = {::},
isbn = {1-4244-0673-0},
journal = {2006 Innovations in Information Technology},
keywords = {affective,affective computing,affective tutoring systems,agents,emotion detection,human computer,interaction,lifelike,new type of its,proposed by the authors},
month = nov,
pages = {1--5},
publisher = {Ieee},
title = {{See Me, Teach Me: Facial Expression and Gesture Recognition for Intelligent Tutoring Systems}},
year = {2006}
}
@book{Prendinger2004,
author = {Prendinger, Helmut and Ishizuka, M.},
editor = {Prendinger, Helmut and Ishizuka, M.},
isbn = {9783642056550},
publisher = {Springer-Verlag Berlin and Heidelberg GmbH \& Co. K},
title = {{Life-Like Characters. Cognitive Technologies}},
year = {2004}
}
@book{Frijda1986,
address = {New York},
author = {Frijda, Nico H.},
isbn = {9780521316002},
pages = {544},
publisher = {Cambridge University Press},
title = {{The Emotions}},
year = {1986}
}
@book{Ortony1988,
abstract = {What causes us to experience emotions? What makes emotions vary in intensity? How are different emotions related to one another and to the language used to talk about them? What are the information processing mechanisms and structures that underlie the elicitation and intensification of emotions? Despite an abundance of psychological research on emotions, many fundamental questions like these have yet to be answered. The Cognitive Structure of Emotions addresses such questions by presenting a systematic and detailed account of the cognitive antecedents of emotions. The authors propose three aspects of the world to which people can react emotionally. People can react to events of concern to them, to the actions of those they consider responsible for such events, and to objects. It is argued that these three classes of reactions lead to three classes of emotions, each based on evaluations in terms of different kinds of knowledge representations. The authors characterize a wide range of emotions, offering concrete proposals about the factors that influence the intensity of each. In doing so, they forge a clear separation between emotions themselves and the language of emotion, and offer the first systematic, comprehensive, and computationally tractable account of the cognitions that underlie distinct types of human emotions.},
address = {Cambridge, UK},
author = {Ortony, A and Clore, G L and Collins, A},
booktitle = {Contemporary Sociology},
doi = {10.1016/0004-3702(92)90091-B},
isbn = {0521353645},
number = {6},
pages = {957},
publisher = {Cambridge University Press},
title = {{The Cognitive Structure of Emotions}},
volume = {18},
year = {1988}
}
@article{Boukricha2011,
abstract = {Allowing virtual humans to align to others’ perceived emotions is believed to enhance their cooperative and communicative social skills. In our work, emotional alignment is realized by endowing a virtual human with the ability to empathize. Recent research shows that humans empathize with each other to different degrees depending on several factors including, among others, their mood, their personality, and their social relationships. Although providing virtual humans with features like affect, personality, and the ability to build social relationships, little attention has been devoted to the role of such features as factors modulating their empathic behavior. Supported by psychological models of empathy, we propose an approach to model empathy for the virtual human EMMA—an Empathic MultiModal Agent—consisting of three processing steps: First, the Empathy Mechanism by which an empathic emotion is produced. Second, the Empathy Modulation by which the empathic emotion is modulated. Third, the Expression of Empathy by which EMMA’s multiple modalities are triggered through the modulated empathic emotion. The proposed model of empathy is illustrated in a conversational agent scenario involving the virtual humans MAX and EMMA.},
author = {Boukricha, Hana and Wachsmuth, Ipke},
doi = {10.1007/s13218-011-0109-8},
file = {::},
issn = {0933-1875},
journal = {KI - K\"{u}nstliche Intelligenz},
keywords = {agent-agent interaction,empathic virtual humans,human-agent,internal simulation},
month = may,
number = {3},
pages = {195--204},
title = {{Empathy-Based Emotional Alignment for a Virtual Human: A Three-Step Approach}},
url = {http://www.springerlink.com/content/9322738p4101p94w/},
volume = {25},
year = {2011}
}
@article{Dinda2007,
author = {Dinda, Peter A and Dick, Robert P and Rossoff, Samuel},
file = {::},
isbn = {9781595937513},
journal = {ACM},
number = {June},
title = {{The User In Experimental Computer Systems Research Categories and Subject Descriptors}},
year = {2007}
}
@article{DeVignemont2006,
abstract = {Recent imaging results suggest that individuals automatically share the emotions of others when exposed to their emotions. We question the assumption of the automaticity and propose a contextual approach, suggesting several modulatory factors that might influence empathic brain responses. Contextual appraisal could occur early in emotional cue evaluation, which then might or might not lead to an empathic brain response, or not until after an empathic brain response is automatically elicited. We propose two major roles for empathy; its epistemological role is to provide information about the future actions of other people, and important environmental properties. Its social role is to serve as the origin of the motivation for cooperative and prosocial behavior, as well as help for effective social communication.},
author = {de Vignemont, Frederique and Singer, Tania},
doi = {10.1016/j.tics.2006.08.008},
file = {::},
issn = {1364-6613},
journal = {Trends in cognitive sciences},
keywords = {Automatism,Automatism: psychology,Brain,Brain Mapping,Brain: physiology,Cerebral,Cerebral Cortex,Cerebral Cortex: physiology,Cerebral: physiology,Communication,Cooperative Behavior,Cues,Dominance,Emotions,Emotions: physiology,Empathy,Female,Gyrus Cinguli,Gyrus Cinguli: physiology,Humans,Interpersonal Relations,Magnetic Resonance Imaging,Male,Motivation,Nerve Net,Nerve Net: physiology,Neurons,Neurons: physiology,Social Behavior,Social Environment},
month = oct,
number = {10},
pages = {435--41},
pmid = {16949331},
title = {{The empathic brain: how, when and why?}},
volume = {10},
year = {2006}
}
@article{Walters2007,
abstract = {OBJECTIVE: Alcohol consumption has been a growing concern at U.S. colleges, particularly among first-year students, who are at increased risk for problems. This study tested the efficacy of the "electronic Check-Up to Go" (e-CHUG), a commercially-available internet program, at reducing drinking among a group of at-risk college freshman. METHOD: The design was a randomized controlled trial: 106 freshmen students who reported heavy episodic drinking were randomly assigned to receive feedback or to assessment only. Assessment measures were completed at baseline, 8 weeks, and 16 weeks. RESULTS: At 8 weeks, the feedback group showed a significant decrease in drinks per week and peak BAC over control. By 16 weeks, the control group also declined to a point where there were no differences between groups. Changes in normative drinking estimates mediated the effect of the intervention. An additional 245 abstainers and light drinkers who were also randomized to condition did not show any intervention effect. CONCLUSIONS: This study provides preliminary support for the efficacy of this intervention at reducing short-term drinking among at-risk students.},
author = {Walters, Scott T and Vader, Amanda M and Harris, T Robert},
institution = {University of Texas School of Public Health, Dallas Regional Campus, Dallas, TX 75390-9128, USA. scott.walters@utsouthwestern.edu},
journal = {Prevention science the official journal of the Society for Prevention Research},
keywords = {adult,alcoholism,alcoholism prevention \& control,feedback,female,humans,internet,male,psychological,questionnaires,texas,universities},
number = {1},
pages = {83--88},
pmid = {17136461},
publisher = {University of Texas School of Public Health, Dallas Regional Campus, Dallas, TX 75390-9128, USA. scott.walters@utsouthwestern.edu},
title = {{A controlled trial of web-based feedback for heavy drinking college students.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17136461},
volume = {8},
year = {2007}
}
@article{Busso2004,
author = {Busso, Carlos and Deng, Zhigang and Yildirim, Serdar and Bulut, Murtaza},
file = {::},
isbn = {1581138903},
journal = {ICMI'04},
pages = {1--7},
title = {{Analysis of emotion recognition using facial expressions, speech and multimodal information}},
url = {http://dl.acm.org/citation.cfm?id=1027968},
year = {2004}
}
@incollection{Plutchik1980,
address = {New York},
author = {Plutchik, R},
booktitle = {Emotion: Theory, research, and experience},
chapter = {Theories o},
editor = {Plutchik, R and Kellerman, H},
number = {3},
pages = {3--33},
publisher = {Academic Press},
series = {Emotion: Theory, research, and experience: Vol. 1. Theories of emotion},
title = {{A general psychoevolutionary theory of emotion}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:A+general+psychoevolutionary+theory+of+emotion\#0},
volume = {1},
year = {1980}
}
@misc{Lisetti2004,
abstract = {The development of an autonomous social robot, Cherry, is occurring in tandem with studies gaining potential user preferences, likes, dislikes, and perceptions of her features. Thus far, results have indicated that individuals 1) believe that service robots with emotion and personality capabilities would make them more acceptable in everyday roles in human life, 2) prefer that robots communicate via both human-like facial expressions, voice, and text-based media, 3) become more positive about the idea of service and social robots after exposure to the technology, and 4) find the appearance and facial features of Cherry pleasing. The results of these studies provide the basis for future research efforts, which are discussed.},
author = {Lisetti, Christine L and Brown, S M Brown S M and Alvarez, K Alvarez K and Marpaung, A H Marpaung A H},
booktitle = {IEEE Transactions on Systems Man and Cybernetics Part C Applications and Reviews},
doi = {10.1109/TSMCC.2004.826278},
issn = {10946977},
number = {2},
pages = {195--209},
publisher = {IEEE},
title = {{A social informatics approach to human-robot interaction with a service social robot}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1291667},
volume = {34},
year = {2004}
}
@article{Heimgartner2011,
author = {Heimg\"{a}rtner, R\"{u}diger and Tiede, L.W. and Windl, Helmut},
file = {::},
journal = {Design, User Experience, and Usability. Theory, Methods, Tools and Practice},
keywords = {1 problems in hci,communication,cultural differences,culture,design caused by cultural,designing the functionality and,differences,empathy,intercultural communication,intercultural hci design,much cultural background has,to be considered when,understanding},
pages = {557--566},
publisher = {Springer},
title = {{Empathy as Key Factor for Successful Intercultural HCI Design}},
url = {http://www.springerlink.com/index/FG03081276H7K042.pdf},
year = {2011}
}
@inproceedings{Zanbaka2007,
abstract = {Do human-human social interactions carry over to human- virtual human social interactions? How does this affect future interface designers? We replicated classical tests of social influence known as the social facilitation and inhibition effects. Social facilitation/inhibition theory states that when in the presence of others, people perform simple tasks better and complex tasks worse. Participants were randomly assigned to perform both simple and complex tasks alone and in the presence of either a real human, a projected virtual human, or a virtual human in a head- mounted display. Our results showed participants were inhibited by the presence of others, whether real or virtual. That is, participants performed worse on the complex task, both in terms of percent correct and reaction times, when in the presence of others than when alone. Social facilitation did not occur with the real or virtual human. We discuss these results and their implications for future interface designers.},
address = {San Jose, California, USA},
author = {Zanbaka, Catherine and Ulinski, Amy and Goolkasian, Paula and Hodges, Larry F},
booktitle = {CHI 2007 Proceedings of Social Influence},
file = {::},
isbn = {9781595935939},
keywords = {Virtual humans,avatars,experimental studies,human-computer interaction,interface agents,social facilitation and inhibition,social influence,social psychology.},
pages = {1561--1570},
publisher = {ACM},
title = {{Social Responses to Virtual Humans : Implications for Future Interface Design}},
year = {2007}
}
@article{Paiva2005a,
author = {Paiva, Ana and Dias, Jo\~{a}o and Sobral, Daniel and Aylett, Ruth and Woods, Sarah and Hall, Lynne and Zoll, Carsten},
doi = {10.1080/08839510590910165},
file = {::},
issn = {0883-9514},
journal = {Applied Artificial Intelligence},
month = mar,
number = {3-4},
pages = {235--266},
title = {{Learning By Feeling: Evoking Empathy With Synthetic Characters}},
url = {http://www.tandfonline.com/doi/abs/10.1080/08839510590910165},
volume = {19},
year = {2005}
}
@incollection{Dautenhahn2002,
author = {Dautenhahn, Kerstin and Bond, Alan and Ca\~{n}amero, Lola and Edmonds, Bruce},
booktitle = {Socially Intelligent Agents: Creating Relationships with Computers and Robots},
chapter = {1},
editor = {Dautenhahn, Kerstin and Bond, Alan and Ca\~{n}amero, Lola and Edmonds, Bruce},
file = {::},
isbn = {978-1-4020-7057-0},
pages = {1--20},
publisher = {Springer},
title = {{Creating Relationships with Computers and Robots}},
url = {http://www.springerlink.com/index/V38H434X220766G8.pdf},
year = {2002}
}
@article{Bailenson2005,
abstract = {Previous research demonstrated social influence resulting from mimicry (the chameleon effect); a confederate who mimicked participants was more highly regarded than a confederate who did not, despite the fact that participants did not explicitly notice the mimicry. In the current study, participants interacted with an embodied artificial intelligence agent in immersive virtual reality. The agent either mimicked a participant's head movements at a 4-s delay or utilized prerecorded movements of another participant as it verbally presented an argument. Mimicking agents were more persuasive and received more positive trait ratings than nonmimickers, despite participants' inability to explicitly detect the mimicry. These data are uniquely powerful because they demonstrate the ability to use automatic, indiscriminate mimicking (i.e., a computer algorithm blindly applied to all movements) to gain social influence. Furthermore, this is the first study to demonstrate social influence effects with a nonhuman, nonverbal mimicker.},
author = {Bailenson, Jeremy N and Yee, Nick},
file = {::},
journal = {Psychological Science},
number = {10},
pages = {814--819},
title = {{Digital Chameleons: Automatic Assimilation of Nonverbal Gestures in Immersive Virtual Environments}},
volume = {16},
year = {2005}
}
@inproceedings{Wright2008,
author = {Wright, Peter and McCarthy, J.},
booktitle = {Proceeding of the twenty-sixth annual SIGCHI conference on Human factors in computing systems},
file = {::},
isbn = {9781605580111},
pages = {637--646},
publisher = {ACM},
title = {{Empathy and experience in HCI}},
url = {http://dl.acm.org/citation.cfm?id=1357156},
year = {2008}
}
@article{Meltzoff1977,
abstract = {Infants between 12 and 21 days of age can imitate both facial and manual gestures; this behavior cannot be explained in terms of either conditioning or innate releasing mechanisms. Such imitation implies that human neonates can equate their own unseen behaviors with gestures they see others perform.},
author = {Meltzoff, AN},
doi = {10.1126/science.198.4312.75},
file = {::},
issn = {0036-8075},
journal = {Science},
month = oct,
number = {4312},
pages = {75--8},
pmid = {17741897},
title = {{Imitation of facial and manual gestures by human neonates}},
volume = {198},
year = {1977}
}
@article{Paiva2005,
author = {Paiva, Ana and Dias, Jo\~{a}o and Sobral, Daniel and Aylett, Ruth and Woods, Sarah and Hall, Lynne and Zoll, Carsten},
doi = {10.1080/08839510590910165},
file = {::},
issn = {0883-9514},
journal = {Applied Artificial Intelligence},
month = mar,
number = {3-4},
pages = {235--266},
title = {{Learning By Feeling: Evoking Empathy With Synthetic Characters}},
url = {http://www.tandfonline.com/doi/abs/10.1080/08839510590910165},
volume = {19},
year = {2005}
}
@inproceedings{Striegnitz2005,
abstract = {When humans give route directions, they often use gestures to indicate the location of landmarks. The form of these gestures reflect one of several perspectives that speakers take when producing them. They may locate the landmark with respect to the speaker, with respect to the person following the route, or with respect to other landmarks. A corpus study shows that the perspective chosen is partly determined by the function of the discourse segment these gestures occur in. Since locating gestures are so prevalent in direction-giving, in this paper we address the kinds of dialogue information and knowledge representation that is needed to generate them automatically.},
address = {Delmenhorst, Germany},
author = {Striegnitz, Kristina and Tepper, Paul and Lovett, Andrew and Cassell, Justine},
booktitle = {Workshop on Spatial Language and Dialogue (5th Workshop on Language and Space)},
file = {::},
number = {Section 2},
title = {{Knowledge representation for generating locating gestures in route directions}},
year = {2005}
}
@article{Maurer1983,
author = {Maurer, R.E. and Tindall, J.H.},
file = {::},
journal = {Journal of Counseling Psychology},
number = {2},
pages = {158},
publisher = {American Psychological Association},
title = {{Effect of postural congruence on client's perception of counselor empathy.}},
volume = {30},
year = {1983}
}
@article{Ambady1992,
abstract = {A meta-analysis was conducted on the accuracy of predictions of various objective outcomes in the areas of social and clinical psychology from short observations of expressive behavior (under 5 min). The overall effect size (ry for the accuracy of predictions for 38 different resu1ts was .39. Studies using longer periods of behavioral observation did not yield greater predictive accuracy; predictions based on observations under 112 min in length did not differ significantly from predictions based on 4- and 5-min observations. The type ofbehavioral channel (such as the face, speech, the body, tone ofvoic on which the ratings were based was not related to the accuracy of predictions. Accuracy did not vary significantly between behaviors rnanipulated in a laboratory and more naturally occurring behavior. L t effect sizes did not differ significantly for predictions in the areas of clinical psychology social psychology, and the accuracy of detecting deception.},
author = {Ambady, N and Rosenthal, Robert},
doi = {10.1037/0033-2909.111.2.256},
file = {::},
issn = {00332909},
journal = {Psychological Bulletin},
number = {2},
pages = {256--274},
publisher = {American Psychological Association},
title = {{Thin slices of expressive behavior as predictors of interpersonal consequences: A meta-analysis.}},
volume = {111},
year = {1992}
}
@inproceedings{Bickmore2009,
abstract = {Ninety million Americans have inadequate health literacy, resulting in a reduced ability to read and follow directions in the healthcare environment. We describe an animated, empathic virtual nurse interface for design rationale, and two Boston University School of Medicine Boston Medical Center brian.jack@bmc.org educating and counseling hospital patients with inadequate health literacy in their hospital beds at the time of discharge. The development methodology, iterations of user testing are described. Results indicate that hospital patients with low health literacy found the system easy to use, reported high levels of satisfaction, and most said they preferred receiving the discharge information from the agent over their doctor or nurse. Patients also expressed appreciation for the time and attention provided by the virtual nurse, and felt that it provided an additional authoritative source for their medical information.},
address = {New York},
author = {Bickmore, Timothy W. and Pfeifer, Laura M and Jack, Brian W},
booktitle = {Proceedings of the 27th international ACM conference on Human factors in computing systems (CHI'09)},
file = {::},
isbn = {9781605582467},
keywords = {Access,Conversational Agent,Embodied,Health Literacy,Hospital Discharge,Patient Education,Patient Safety,Relational Agent,Universal},
pages = {1265--1274},
publisher = {ACM},
title = {{Taking the Time to Care : Empowering Low Health Literacy Hospital Patients with Virtual Nurse Agents}},
year = {2009}
}
@article{Rebolledo-Mendez2009,
author = {Rebolledo-Mendez, Genaro and Freitas, Sara De and Gaona, Alma Rosa Garcia},
doi = {10.1109/VS-GAMES.2009.33},
file = {::},
isbn = {978-0-7695-3588-3},
journal = {2009 Conference in Games and Virtual Worlds for Serious Applications},
keywords = {- empathy,alma rosa garcia gaona,facultad de inform\'{a}tica,motivation,serious games,universidad veracruzana},
month = mar,
pages = {5--11},
publisher = {Ieee},
title = {{A Model of Motivation Based on Empathy for AI-Driven Avatars in Virtual Worlds}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5116547},
year = {2009}
}
@inproceedings{Sullins2009,
abstract = {In this paper we explored the relationship between learning gains and affective displays of an animated pedagogical agent. Students read information on the topic of computer literacy while receiving either positive or negative affective responses from an on-screen animated agent. Analyses revealed that only students with low prior knowledge were influenced by the emotion displayed by the animated agent. We discuss the generalizability of our findings to other domains and the implications of these results on intelligent tutoring systems that are emotionally intelligent.},
author = {Sullins, Jeremiah and Craig, Scotty D and Graesser, Arthur C},
booktitle = {Proceedings of the 2009 conference on Artificial Intelligence in Education: Building Learning Systems that Care: From Knowledge Representation to Affective Modelling},
file = {::},
keywords = {affect,animated agents,emotion,prior knowledge},
pages = {677--679},
publisher = {IOS Press Amsterdam, The Netherlands},
title = {{Tough Love : The Influence of an Agent ’ s Negative Affect on Students ’ Learning}},
year = {2009}
}
@article{Warner1987,
author = {Warner, Rebecca M. and Malloy, Daniel and Schneider, Kathy and Knoth, Russell and Wilder, Bruce},
doi = {10.1007/BF00990958},
file = {::},
issn = {0191-5886},
journal = {Journal of Nonverbal Behavior},
number = {2},
pages = {57--74},
title = {{Rhythmic organization of social interaction and observer ratings of positive affect and involvement}},
url = {http://www.springerlink.com/index/10.1007/BF00990958},
volume = {11},
year = {1987}
}
@inproceedings{Nguyen2009c,
author = {Nguyen, H. and Masthoff, Judith},
booktitle = {Proceedings of the 4th International Conference on Persuasive Technology},
file = {::},
isbn = {9781605583761},
keywords = {affective computing,design,experimentation,human factors},
pages = {7},
publisher = {ACM},
title = {{Designing empathic computers: the effect of multimodal empathic feedback using animated agent}},
url = {http://dl.acm.org/citation.cfm?id=1541958},
year = {2009}
}
@article{Bradley2007,
abstract = {This handbook will help to advance research in emotion by encouraging researchers to take greater advantage of standard and well-researched approaches, which will increase both theproductivity in the field and the speed and accuracy with which},
author = {Bradley, Margaret M and Lang, P J},
institution = {University of Florida, Center for Research in Psychophysiology, Gainesville, Fl, USA.},
journal = {Emotion},
pages = {29--46},
publisher = {University of Florida},
title = {{The International Affective Digitized Sounds Affective Ratings of Sounds and Instruction Manual}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:The+International+Affective+Digitized+Sounds+Affective+Ratings+of+Sounds+and+Instruction+Manual\#1},
year = {2007}
}
@article{Noar2007,
abstract = {Although there is a large and growing literature on tailored print health behavior change interventions, it is currently not known if or to what extent tailoring works. The current study provides a meta-analytic review of this literature, with a primary focus on the effects of tailoring. A comprehensive search strategy yielded 57 studies that met inclusion criteria. Those studies-which contained a cumulative N = 58,454-were subsequently meta-analyzed. The sample size-weighted mean effect size of the effects of tailoring on health behavior change was found to be r = .074. Variables that were found to significantly moderate the effect included (a) type of comparison condition, (b) health behavior, (c) type of participant population (both type of recruitment and country of sample), (d) type of print material, (e) number of intervention contacts, (f) length of follow-up, (g) number and type of theoretical concepts tailored on, and (h) whether demographics and/or behavior were tailored on. Implications of these results are discussed and future directions for research on tailored health messages and interventions are offered.},
author = {Noar, Seth M and Benac, Christina N and Harris, Melissa S},
institution = {Department of Communication, University of Kentucky, Lexington, KY 40506-0042, USA. snoar2@uky.edu},
journal = {Psychological Bulletin},
keywords = {adolescent,adult,aged,child,communication,female,health behavior,health education,health education methods,health promotion,health promotion methods,humans,male,middle aged,patient acceptance health care,patient acceptance health care psychology,teaching materials,united states},
number = {4},
pages = {673--693},
pmid = {17592961},
publisher = {American Psychological Association},
title = {{Does tailoring matter? Meta-analytic review of tailored print health behavior change interventions.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17592961},
volume = {133},
year = {2007}
}
@inproceedings{Arrington2011,
abstract = {One of the many factors that contribute to the decline in Computer Science retention is poor performance in foundation programming courses. In the Introduction to Programming course here at UNC Charlotte, it has been observed that poor assessment performance is often attributed to students feeling they understand material when they often don’t. This iteration of the Dr. Chestr Show seeks to overcome this disconnection by assisting in the guidance of review based on routine lecture quiz performance. The Dr. Chestr show presents users with questions about the C++ programming language based on topics covered during lecture. This paper describes the design and implementation of the Dr. Chestr virtual human and his game show environment.},
address = {New York, New York, USA},
author = {Arrington, Carl and Wilson, Dale-Marie and Lehmann, Lorrie},
booktitle = {Proceedings of the 49th Annual Southeast Regional Conference on - ACM-SE '11},
doi = {10.1145/2016039.2016127},
file = {::},
isbn = {9781450306867},
keywords = {Design,Human Factors.},
pages = {320},
publisher = {ACM Press},
title = {{Improving performance and retention in computer science courses using a virtual game show}},
url = {http://dl.acm.org/citation.cfm?doid=2016039.2016127},
year = {2011}
}
@article{Riek2009,
author = {Riek, Laurel D. and Paul, Philip C. and Robinson, Peter},
doi = {10.1007/s12193-009-0028-2},
file = {::},
issn = {1783-7677},
journal = {Journal on Multimodal User Interfaces},
keywords = {19,affective computing,emotionally conveying,empathy,expressions,facial,forms of expressive empathy,human-robot interaction,is known as,of the most basic,one,social robotics,understand what others are},
month = nov,
number = {1-2},
pages = {99--108},
title = {{When my robot smiles at me: Enabling human-robot rapport via real-time head gesture mimicry}},
url = {http://www.springerlink.com/index/10.1007/s12193-009-0028-2},
volume = {3},
year = {2009}
}
@inproceedings{Cramer2010,
author = {Cramer, Henriette and Goddijn, Jorrit and Wielinga, Bob and Evers, Vanessa},
booktitle = {Proceeding of the 5th ACM/IEEE international conference on Human-robot interaction},
file = {::},
isbn = {9781424448937},
pages = {141--142},
publisher = {ACM},
title = {{Effects of (in) accurate empathy and situational valence on attitudes towards robots}},
url = {http://dl.acm.org/citation.cfm?id=1734513},
year = {2010}
}
@article{Pierre-Yves2003,
author = {Pierre-Yves, O},
doi = {10.1016/S1071-5819(02)00141-6},
file = {::},
issn = {10715819},
journal = {International Journal of Human-Computer Studies},
keywords = {emotion production,emotion recognition,emotions,robots,speech},
month = jul,
number = {1-2},
pages = {157--183},
title = {{The production and recognition of emotions in speech: features and algorithms}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1071581902001416},
volume = {59},
year = {2003}
}
@article{Paiva2004,
author = {Paiva, Ana and Dias, J. and Sobral, Daniel and Aylett, Ruth},
file = {::},
isbn = {1581138644},
journal = {on Autonomous Agents},
title = {{Caring for agents and agents that care: Building empathic relations with synthetic agents}},
url = {http://dl.acm.org/citation.cfm?id=1018754},
year = {2004}
}
@incollection{Gratch2006a,
author = {Gratch, Jonathan and Mao, W and Marsella, Stacy},
booktitle = {Cognition and Multi-Agent Interaction: From Cognitive Modeling to Social Simulation},
chapter = {9},
doi = {http://dx.doi.org/10.1017/CBO9780511610721.010},
editor = {Sun, Ron},
file = {::;::},
isbn = {9780511610721},
pages = {219--251},
publisher = {Cambridge University Press},
title = {{Modeling social emotions and social attributions}},
year = {2006}
}
@article{McQuiggan2008,
abstract = {Humans continuously assess one another’s situational context, modify their own affective state, and then respond based on these outcomes through empathetic expression. Virtual agents should be capable of similarly empathizing with users in interactive environments. A key challenge posed by empathetic reasoning in virtual agents is determining whether to respond with parallel or reactive empathy. Parallel empathy refers to mere replication of another’s affective state, whereas reactive empathy exhibits greater cognitive awareness and may lead to incongruent emotional responses (i.e., emotions different from the recipient’s and perhaps intended to alter negative affect). This paper proposes a unified inductive framework for modeling parallel and reactive empathy. Empathy models are used to drive runtime situation-appropriate empathetic behaviors by selecting suitable parallel or reactive empathetic expressions.},
annote = {- No automatic affect detection
- agent demographics are not taken into account.},
author = {McQuiggan, Scott W and Robison, Jennifer and Phillips, Robert},
file = {::},
journal = {on Autonomous agents},
number = {Aamas},
pages = {167--174},
title = {{Modeling parallel and reactive empathy in virtual agents: An inductive approach}},
year = {2008}
}
@article{Li2012,
author = {Li, Zheng and Mao, Xia},
doi = {10.1016/j.jvlc.2012.06.001},
file = {::},
issn = {1045926X},
journal = {Journal of Visual Languages \& Computing},
keywords = {Computer animation,Eye movement synthesis,Human–computer interaction,Virtual agents},
month = oct,
number = {5},
pages = {299--310},
publisher = {Elsevier},
title = {{Emotional eye movement generation based on Geneva Emotion Wheel for virtual agents}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1045926X1200047X},
volume = {23},
year = {2012}
}
@incollection{Davis2006,
address = {New York},
author = {Davis, Mark H.},
booktitle = {Handbook of the Socialogy of Emotions},
editor = {Stets, J. and Turner, J.},
publisher = {Springer Press},
title = {{Empathy}},
year = {2006}
}
@article{Boukricha2011,
author = {Boukricha, Hana and Wachsmuth, Ipke},
doi = {10.1007/s13218-011-0109-8},
file = {::},
issn = {0933-1875},
journal = {KI - K\"{u}nstliche Intelligenz},
keywords = {agent-agent interaction,empathic virtual humans,human-agent,internal simulation},
month = may,
number = {3},
pages = {195--204},
title = {{Empathy-Based Emotional Alignment for a Virtual Human: A Three-Step Approach}},
url = {http://www.springerlink.com/index/10.1007/s13218-011-0109-8},
volume = {25},
year = {2011}
}
@inproceedings{Doherty2004,
address = {Madison, WI},
author = {Doherty, William Joseph},
booktitle = {Policy Institute for Family Impact Seminars},
title = {{A family-focused approach to health care [Wisconsin Family Impact seminars]}},
year = {2004}
}
@article{Hingson2005,
author = {Hingson, Ralph and Heeren, Timothy and Winter, Michael and Wechsler, Henry},
journal = {Journal of Studies on Alcohol and Drugs},
pages = {12--20},
title = {{MAGNITUDE OF ALCOHOL-RELATED MORTALITY AND MORBIDITY AMONG U.S. COLLEGE STUDENTS AGES 18–24: Changes from 1999 to 2005}},
url = {http://www.jsad.com/},
volume = {16},
year = {2009}
}
@article{Gruen1986,
author = {Gruen, Rand J. and Mendelsohn, Gerald},
doi = {10.1037/0022-3514.51.3.609},
file = {::},
issn = {1939-1315},
journal = {Journal of Personality and Social Psychology},
number = {3},
pages = {609--614},
title = {{Emotional responses to affective displays in others: The distinction between empathy and sympathy.}},
volume = {51},
year = {1986}
}
@article{Peter2003,
author = {Sonnby-borgstr\"{o}m, Marianne and Jonsson, Peter and Svensson, Owe},
file = {::},
journal = {Journal of Nonverbal},
keywords = {emg,emotional contagion,empathy,facial expressions,facial mim-,icry,mirror neurons},
number = {1},
pages = {3--23},
title = {{Emotional empathy as related to mimicry reactions at different levels of information processing}},
url = {http://www.springerlink.com/index/P81X69QTH751V836.pdf},
volume = {27},
year = {2003}
}
@article{Hess2001,
author = {Hess, Ursula and Blairy, Sylvie},
file = {::},
journal = {International Journal of Psychophysiology},
keywords = {emotion recognition,emotional contagion,facial mimicry},
pages = {129--141},
title = {{Facial mimicry and emotional contagion to dynamic emotional facial expressions and their influence on decoding accuracy}},
volume = {40},
year = {2001}
}
@inproceedings{Higashinaka2008,
author = {Higashinaka, R. and Dohsaka, K. and Isozaki, H.},
booktitle = {Spoken Language Technology Workshop, 2008. SLT 2008. IEEE},
file = {::},
isbn = {9781424434725},
pages = {109--112},
publisher = {IEEE},
title = {{Effects of self-disclosure and empathy in human-computer dialogue}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4777852},
year = {2008}
}
@inproceedings{Ochs2008,
abstract = {Recent research has shown that virtual agents expressing empathic emotions toward users have the potentiality to en- hance human-machine interaction. To identify under which circumstances a virtual agent should express empathic emo- tions, we have analyzed real human-machine dialog situa- tions that have led users to express emotion. The results of this empirical study have been combined with theoretical descriptions of emotions to construct a model of empathic emotions. Based on this model, a module of emotions has been implemented as a plug-in for JSA agents. It determines the empathic emotions (their types and intensity) of such agents in real time. It has been used to develop a demon- strator where users can interact with an empathic dialog agent to obtain information on their emails. An evaluation of this agent has enabled us to both validate the proposed model of empathic emotions and highlight the positive user’s perception of the virtual agent.},
address = {Estoril, Portugal},
author = {Ochs, Magalie and Pelachaud, Catherine and Sadek, David},
booktitle = {Proceeding of 7th International Conference on Autonomous Agents and Multiagent Systems (AAMAS2008)},
file = {::},
pages = {89--96},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org)},
title = {{An empathic virtual dialog agent to improve human-machine interaction}},
url = {http://jmvidal.cse.sc.edu/library/AAMAS-08/proceedings/pdf/paper/AAMAS08\_0526.pdf},
year = {2008}
}
@article{Lafrance1979,
author = {Lafrance, Marianne},
file = {::},
journal = {Social Psychology},
number = {1},
pages = {66--70},
title = {{Nonverbal Synchrony Panel Technique: Analysis by the Cross-Lag and Rapport}},
volume = {42},
year = {1979}
}
@inproceedings{Heerink2009,
author = {Heerink, Marcel and Krose, B. and Evers, Vanessa and Wielinga, Bob},
booktitle = {Robot and Human Interactive Communication, 2009. RO-MAN 2009. The 18th IEEE International Symposium on},
file = {::},
pages = {528--533},
publisher = {IEEE},
title = {{Measuring acceptance of an assistive social robot: a suggested toolkit}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5326320},
year = {2009}
}
@article{Kessous2009,
author = {Kessous, Loic and Castellano, Ginevra and Caridakis, George},
doi = {10.1007/s12193-009-0025-5},
file = {::},
issn = {1783-7677},
journal = {Journal on Multimodal User Interfaces},
keywords = {affective body language,affective speech,emotion recognition,facial expression,multimodal},
month = dec,
number = {1-2},
pages = {33--48},
title = {{Multimodal emotion recognition in speech-based interaction using facial expression, body gesture and acoustic analysis}},
url = {http://www.springerlink.com/index/10.1007/s12193-009-0025-5},
volume = {3},
year = {2009}
}
@article{Shimoda2000,
author = {Shimoda, H. and Kunihiro, T. and Yang, D. and Yoshikawa, H.},
doi = {10.1109/IECON.2000.972406},
file = {::},
isbn = {0-7803-6456-2},
journal = {2000 26th Annual Conference of the IEEE Industrial Electronics Society. IECON 2000. 2000 IEEE International Conference on Industrial Electronics, Control and Instrumentation. 21st Century Technologies and Industrial Opportunities (Cat. No.00CH37141)},
pages = {2589--2594},
publisher = {Ieee},
title = {{Design of affective interface for realizing human-machine empathy}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=972406},
volume = {4},
year = {2000}
}
@inproceedings{Gonsior2011,
address = {Atlanta},
author = {Gonsior, Barbara and Sosnowski, Stefan and Mayer, Christoph and Blume, Jiirgen and Radig, B. and Wollherr, D. and Kuhnlenz, K.},
booktitle = {RO-MAN, 2011 IEEE, 20th IEEE International Symposium on Robot and Human Interactive Communication},
file = {::},
isbn = {9781457715730},
pages = {350--356},
publisher = {IEEE},
title = {{Improving aspects of empathy and subjective performance for HRI through mirroring facial expressions}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6005294},
year = {2011}
}
@inproceedings{Paiva2004,
address = {Washington, DC, USA},
author = {Paiva, Ana and Dias, J. and Sobral, Daniel and Aylett, Ruth},
booktitle = {AAMAS '04 Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems},
doi = {10.1109/AAMAS.2004.82},
file = {::},
isbn = {1581138644},
pages = {194--201},
publisher = {IEEE Computer Society},
title = {{Caring for agents and agents that care: Building empathic relations with synthetic agents}},
url = {http://dl.acm.org/citation.cfm?id=1018754 http://dx.doi.org/10.1109/AAMAS.2004.82},
year = {2004}
}
@article{Cai2006,
abstract = {Empathic computing is an emergent paradigm that enables a system to understand human states and feelings and to share this intimate information. The new paradigm is made possible by the convergence of affordable sensors, embedded processors and wireless ad-hoc networks. The power law for multi-resolution channels and mobile-stationary sensor webs is introduced to resolve the information avalanche problems. As empathic computing is sensor-rich computing, particular models such as semantic differential expressions and inverse physics are discussed. A case study of a wearable sensor network for detection of a falling event is presented. It is found that the location of the wearable sensor is sensitive to the results. From the machine learning algorithm, the accuracy reaches up to 90\% from 21 simulated trials. Empathic computing is not limited to healthcare. It can also be applied to solve other everyday-life problems such as management of emails and stress.},
author = {Cai, Yang},
doi = {10.1007/11825890\_3},
file = {::},
journal = {Ambient Intelligence in Everyday Life, Lecture Notes in Computer Science},
pages = {67--85},
publisher = {Springer},
title = {{Empathic computing}},
url = {http://www.springerlink.com/index/l482m128476w5043.pdf},
volume = {3864/2006},
year = {2006}
}
@article{Noar2007,
abstract = {Although there is a large and growing literature on tailored print health behavior change interventions, it is currently not known if or to what extent tailoring works. The current study provides a meta-analytic review of this literature, with a primary focus on the effects of tailoring. A comprehensive search strategy yielded 57 studies that met inclusion criteria. Those studies-which contained a cumulative N = 58,454-were subsequently meta-analyzed. The sample size-weighted mean effect size of the effects of tailoring on health behavior change was found to be r = .074. Variables that were found to significantly moderate the effect included (a) type of comparison condition, (b) health behavior, (c) type of participant population (both type of recruitment and country of sample), (d) type of print material, (e) number of intervention contacts, (f) length of follow-up, (g) number and type of theoretical concepts tailored on, and (h) whether demographics and/or behavior were tailored on. Implications of these results are discussed and future directions for research on tailored health messages and interventions are offered.},
author = {Noar, Seth M and Benac, Christina N and Harris, Melissa S},
institution = {Department of Communication, University of Kentucky, Lexington, KY 40506-0042, USA. snoar2@uky.edu},
journal = {Psychological Bulletin},
keywords = {adolescent,adult,aged,child,communication,female,health behavior,health education,health education methods,health promotion,health promotion methods,humans,male,middle aged,patient acceptance health care,patient acceptance health care psychology,teaching materials,united states},
number = {4},
pages = {673--693},
pmid = {17592961},
publisher = {American Psychological Association},
title = {{Does tailoring matter? Meta-analytic review of tailored print health behavior change interventions.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17592961},
volume = {133},
year = {2007}
}
@article{Gratch2004,
author = {Gratch, Jonathan and Marsella, Stacy C},
file = {::;::},
journal = {Cognitive Systems Research},
number = {4},
pages = {269--306},
publisher = {Elsevier},
title = {{A domain-independent framework for modeling emotion}},
volume = {5},
year = {2004}
}

@inproceedings{Janarthanam2011,
 author = {Janarthanam, Srinivasan and Hastie, Helen and Lemon, Oliver and Liu, Xingkun},
 title = {"The day after the day after tomorrow?": a machine learning approach to adaptive temporal expression generation: training and evaluation with real users},
 booktitle = {Proceedings of the SIGDIAL 2011 Conference},
 series = {SIGDIAL '11},
 year = {2011},
 isbn = {978-1-937284-10-7},
 location = {Portland, Oregon},
 pages = {142--151},
 numpages = {10},
 url = {http://dl.acm.org/citation.cfm?id=2132890.2132907},
 acmid = {2132907},
 publisher = {Association for Computational Linguistics},
 address = {Stroudsburg, PA, USA},
} 

@inproceedings{Thomson2007,
 author = {Thomson, Blaise and Schatzmann, Jost and Weilhammer, Karl and Ye, Hui and Young, Steve},
 title = {Training a real-world POMDP-based dialogue system},
 booktitle = {Proceedings of the Workshop on Bridging the Gap: Academic and Industrial Research in Dialog Technologies},
 series = {NAACL-HLT-Dialog '07},
 year = {2007},
 location = {Rochester, New York},
 pages = {9--16},
 numpages = {8},
 url = {http://dl.acm.org/citation.cfm?id=1556328.1556330},
 acmid = {1556330},
 publisher = {Association for Computational Linguistics},
 address = {Stroudsburg, PA, USA},
} 

@inproceedings{Janarthanam2008,
    author = {Janarthanam, Srinivasan and Lemon, Oliver},
    booktitle = {Proceedings of LONDIAL: The 12th SEMDIAL Workshop},
    citeulike-article-id = {4882876},
    keywords = {dialogue-management, knowledge-alignment, reinforcement-learning},
    posted-at = {2009-06-17 18:57:00},
    priority = {2},
    title = {{User simulations for online adaptation and knowledge-alignment inTroubleshooting dialogue systems}},
    year = {2008}
}



@INPROCEEDINGS{Ai07,
    author = {Hua Ai and Diane J. Litman},
    title = {Knowledge Consistent User Simulations for Dialog Systems},
    booktitle = {In Proc. of Interspeech},
    year = {2007}
}

@article{Mauriello2011,
abstract = {This paper describes pilot test findings of an Internet-based, Transtheoretical Model-based, computer tailored intervention for adults who exceed national guidelines for low-risk drinking. In a pilot test, 166 adults recruited from worksites completed one session and evaluated the program. Pre and post assessments indicate intention to make behavioral changes. Importantly, 94.3\% of participants indicated that they would recommend the program. Ratings were positive with the majority of participants ‘agreeing’ or ‘strongly agreeing’ with all 14 evaluation items. Feasibility was demonstrated by recruiting and engaging employed adults. This program is a cost-effective prevention program promoting responsible drinking to adults.},
author = {Mauriello, Leanne M. and G\"{o}kbayrak, N. Simay and Marter, Deborah F. Van and Paiva, Andrea L. and Prochaska, Janice M.},
doi = {10.1080/07347324.2012.635528.An},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mauriello - 2011 - An Internet-Based Computer-Tailored Intervention to Promote Responsible Drinking Findings from a Pilot Test with Employed Adults.pdf:pdf},
journal = {Alcoholism Treatment},
keywords = {employed adults,internet-based intervention,responsible drinking},
number = {1},
pages = {1--15},
title = {{An Internet-Based Computer-Tailored Intervention to Promote Responsible Drinking: Findings from a Pilot Test with Employed Adults}},
url = {http://www.tandfonline.com/doi/abs/10.1080/07347324.2012.635528},
volume = {30},
year = {2011}
}
@article{Mehrabian1967a,
abstract = {DEALT WITH INCONSISTENT COMMUNICATION OF ATTITUDE IN 2 COMPONENTS OF A MESSAGE. POSITIVE, NEUTRAL, OR NEGATIVE ATTITUDES COMMUNICATED IN SINGLE-WORD CONTENTS WERE EACH COMBINED WITH 3 DEGREES OF ATTITUDE COMMUNICATED IN TONE OF VOICE. IT WAS FOUND, CONSISTENT WITH THE PROPOSED HYPOTHESIS, THAT THE VARIABILITY OF INFERENCES ABOUT COMMUNICATOR ATTITUDE ON THE BASIS OF INFORMATION AVAILABLE IN CONTENT AND TONE COMBINED IS MAINLY CONTRIBUTED BY VARIATIONS IN TONE ALONE. FOR EXAMPLE, WHEN THE ATTITUDE COMMUNICATED IN CONTENT CONTRADICTED THE ATTITUDE COMMUNICATED BY A NEGATIVE TONE, THE TOTAL MESSAGE WAS JUDGED AS COMMUNICATING A NEGATIVE ATTITUDE. THE LIMITATIONS OF THE FINDINGS, AS WELL AS THEIR IMPLICATIONS FOR THE DOUBLE-BLIND THEORY OF SCHIZOPHRENIA, ARE DISCUSSED. (PsycINFO Database Record (c) 2006 APA, all rights reserved)},
author = {Mehrabian, Albert and Wiener, M},
journal = {Journal of Personality and Social Psychology},
keywords = {attitude,communication,cues,humans,schizophrenic psychology,voice},
number = {1},
pages = {109--114},
pmid = {6032751},
title = {{Decoding of inconsistent communications.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/6032751},
volume = {6},
year = {1967}
}
@article{Davis1983,
author = {Davis, Mark H.},
doi = {10.1037/0022-3514.44.1.113},
file = {::},
issn = {0022-3514},
journal = {Journal of Personality and Social Psychology},
number = {1},
pages = {113--126},
title = {{Measuring individual differences in empathy: Evidence for a multidimensional approach.}},
volume = {44},
year = {1983}
}
@article{Nisbett1977,
abstract = {Reviews evidence which suggests that there may be little or no direct introspective access to higher order cognitive processes. Ss are sometimes (a) unaware of the existence of a stimulus that importantly influenced a response, (b) unaware of the existence of the response, and (c) unaware that the stimulus has affected the response. It is proposed that when people attempt to report on their cognitive processes, that is, on the processes mediating the effects of a stimulus on a response, they do not do so on the basis of any true introspection. Instead, their reports are based on a priori, implicit causal theories, or judgments about the extent to which a particular stimulus is a plausible cause of a given response. This suggests that though people may not be able to observe directly their cognitive processes, they will sometimes be able to report accurately about them. Accurate reports will occur when influential stimuli are salient and are plausible causes of the responses they produce, and will not occur when stimuli are not salient or are not plausible causes.},
author = {Nisbett, R E and Wilson, T D},
doi = {10.1037/0033-295X.84.3.231},
editor = {DeVivo, Anita and Silver, Amy and Felder, Deborah S and Hayward, Robert J and Patterson, Kendall C and Redman, Anne and Buchwald, Alexander and Falmagne, Rachel Jofffe and Krantz, David H and Olson, Gary M and Shiffrin, Richard M and Smith, Edward E and Theios, John and WIggins, Jerry S},
issn = {0033295X},
journal = {Psychological Review},
number = {3},
pages = {231--259},
pmid = {17882490},
publisher = {Psychol Rev},
title = {{Telling more than we can know: Verbal reports on mental processes}},
url = {http://psycnet.apa.org/journals/rev/84/3/231/},
volume = {84},
year = {1977}
}
@article{Greenson1960,
author = {Greenson, Ralph R},
journal = {International Journal of PsychoAnalysis},
pages = {418--424},
title = {{Empathy and its vicissitudes}},
volume = {41},
year = {1960}
}
@article{Zeng2009,
abstract = {Automated analysis of human affective behavior has attracted increasing attention from researchers in psychology, computer science, linguistics, neuroscience, and related disciplines. However, the existing methods typically handle only deliberately displayed and exaggerated expressions of prototypical emotions despite the fact that deliberate behaviour differs in visual appearance, audio profile, and timing from spontaneously occurring behaviour. To address this problem, efforts to develop algorithms that can process naturally occurring human affective behaviour have recently emerged. Moreover, an increasing number of efforts are reported toward multimodal fusion for human affect analysis including audiovisual fusion, linguistic and paralinguistic fusion, and multi-cue visual fusion based on facial expressions, head movements, and body gestures. This paper introduces and surveys these recent advances. We first discuss human emotion perception from a psychological perspective. Next we examine available approaches to solving the problem of machine understanding of human affective behavior, and discuss important issues like the collection and availability of training and test data. We finally outline some of the scientific and engineering challenges to advancing human affect sensing technology.},
author = {Zeng, Zhihong and Pantic, Maja and Roisman, Glenn I and Huang, Thomas S},
doi = {10.1109/TPAMI.2008.52},
file = {::},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Affect,Affect: physiology,Algorithms,Artificial Intelligence,Automated,Automated: methods,Emotions,Emotions: physiology,Facial Expression,Monitoring,Pattern Recognition,Physiologic,Physiologic: methods,Sound Spectrography,Sound Spectrography: methods},
month = jan,
number = {1},
pages = {39--58},
pmid = {19029545},
title = {{A survey of affect recognition methods: audio, visual, and spontaneous expressions.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19029545},
volume = {31},
year = {2009}
}
@article{Calvo2010,
author = {Calvo, R.A. and D'Mello, S.},
file = {::},
journal = {Affective Computing, IEEE Transactions on},
number = {1},
pages = {18--37},
publisher = {IEEE},
title = {{Affect detection: An interdisciplinary review of models, methods, and their applications}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5520655},
volume = {1},
year = {2010}
}
@misc{Putten2009,
abstract = {This study investigates whether humans perceive a higher degree of social presence when interacting with an animated character that displays natural as opposed to no listening behaviors and whether this interacts with people’s believe that they are interacting with an agent or an avatar. In a 2x2 between subjects experimental design 83 participants were either made believe that they encounter an agent, or that they communicate with another participant mediated by an avatar. In fact, in both conditions the communication partner was an autonomous agent that either exhibited high or low behavioral realism. We found that participants experienced equal amounts of presence, regardless of Behavioral interacting realism, however, had with an agent or an avatar. an impact on the subjective feeling of presence: people confronted with a character displaying high behavioral realism reported a higher degree of mutual awareness.},
author = {P\"{u}tten, Astrid M Von Der and Kr\"{a}mer, Nicole C and Gratch, Jonathan},
booktitle = {Design},
file = {::},
keywords = {avatars,behavioral realism,experimental study,virtual agents},
pages = {1--7},
title = {{Who's there? Can a Virtual Agent Really Elicit Social Presence?}},
year = {2009}
}
@article{Prendinger2005,
abstract = {They designed an animated interface agent that accompanies the user in the setting of a virtual job interview. This interface application takes physiological data (skin conductance and electromyography) of a user in realtime, interprets them as emotions, and addresses the user’s affective states in the form of empathic feedback by employing embodied characters.},
annote = {They take physiological data (skin conductance and electromyography) of a user in real-time, interpret them as emotions, and address the user’s affective states by empathic feedback. A decision making agent relates these signals and the user’s answer to arousal and valence to infer the user’s emotional state by applying the model of Lang (1995) (Lang claims that all emotions can be characterized in terms of valence (pleasant or unpleasant) and arousal (calm or aroused)). Then it selects empathetic actions that maximize some utility function. They use text-based empathetic actions in addition to a small full body character.We can use the decision-theoretic agent aspect in our empathy model.
The empathy is mainly expressed in a text-base fashion in their job. The embodied agent that they have is so small and no facial expressions are used. There are some gestural expressions.
As shown in this paper and many other ones, text-base empathy expression can be effective. So we can use that too.
      },
author = {Prendinger, H and Ishizuka, M.},
file = {::;::},
journal = {Applied Artificial Intelligence},
keywords = {electromyography,physiological signals,skin conductance},
number = {3-4},
pages = {267--286},
publisher = {Citeseer},
title = {{The Empathic Companion - A Character-based Interface that Addresses Users’ Affective States}},
url = {citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.79.4710\&rep=rep1\&type=pdf},
volume = {19},
year = {2005}
}
@inproceedings{Gordon1985,
abstract = {Despite the almost complete lack of research addressing a theoretical understanding of empathy or ways to increase human empathy, empathy is a central component of effective human communication. Seen as a key social science phenomenon, it is viewed, along with power, as an inextricable component of human dynamics, and, in its relationship with altruism, possibly plays a causal role. A problem with research on empathy has been a lack of conceptual clarity. Three ways to improve empathetic listening are to avoid judgment, give the speaker time to speak without interruption, and focus on the speaker. Many of the helping professions have attempted training programs aimed at increasing the empathetic communication skills of practitioners in these fields. However, being told to listen empathetically is not the same as being taught to listen with empathy; and in critique of the empathy skills programs that are conducted within the helping professions, a significantly raised test score does not mean that empathy has been attained. Although empathetic communication is a complex subject matter, skills associated with empathy and active listening have been perceived as being more important than skills associated with critical or deliberative listening.},
address = {Baguio, Philippines},
annote = {Three ways to improve empathetic listening are to 
1.      Avoid judgment: the empathetic communicator must avoid making comparisons or passing moral judgments. 
2.      Give the speaker time to speak without interruption 
3.      Focus on the speaker: the empathetic communicator needs to focus his or her attention on the speaker, and not distract from this focus by verbally calling undue attention to oneself or one’s own situation [14]. },
author = {Gordon, Ronald D.},
booktitle = {International Conference of the World Communication Association},
file = {::},
keywords = {Communication (thought transfer),empathhy,interpersonal communication,listening,listening habits,listening skills,speech communication},
pages = {1--16},
title = {{Empathy: The State of the Art and Science}},
year = {1985}
}
@misc{Putten2009,
abstract = {This study investigates whether humans perceive a higher degree of social presence when interacting with an animated character that displays natural as opposed to no listening behaviors and whether this interacts with people’s believe that they are interacting with an agent or an avatar. In a 2x2 between subjects experimental design 83 participants were either made believe that they encounter an agent, or that they communicate with another participant mediated by an avatar. In fact, in both conditions the communication partner was an autonomous agent that either exhibited high or low behavioral realism. We found that participants experienced equal amounts of presence, regardless of Behavioral interacting realism, however, had with an agent or an avatar. an impact on the subjective feeling of presence: people confronted with a character displaying high behavioral realism reported a higher degree of mutual awareness.},
author = {P\"{u}tten, Astrid M Von Der and Kr\"{a}mer, Nicole C and Gratch, Jonathan},
booktitle = {Design},
file = {::},
keywords = {avatars,behavioral realism,experimental study,virtual agents},
pages = {1--7},
title = {{Who's there? Can a Virtual Agent Really Elicit Social Presence?}},
year = {2009}
}
@incollection{Chung2007,
abstract = {The present paper focuses on the influence of avatar creation in a video game. More specifically, this study investigates the effects of avatar creation on attitude towards avatar, empathy, presence, and para-social interaction of female non-game users. As a cyber-self, an avatar is a graphic character representing a user in cyberspace. Avatars are primarily used in the entertainment industry as high-tech novelties, controlled by game users, for high-end video games. Some games provide game characters by default that users cannot change, but other games provide various options gamers can choose. What if game users can create their own avatars? Do they have more psychological closeness with their avatars as their cyber-selves? This study tested the differences of attitude, empathy, presence, and para-social interaction of female non-game users between an avatar creation group and a non-avatar creation group and resulted in no difference.},
author = {Chung, Donghun and DeBuys, Brahm and Nam, Chang},
booktitle = {Human-Computer Interaction. Interaction Design and Usability},
doi = {10.1007/978-3-540-73105-4\_78},
file = {::},
isbn = {978-3-540-73104-7},
keywords = {Avatar - Attitude - Empathy - Presence - Para-Soci},
pages = {711--720},
publisher = {Springer Berlin / Heidelberg},
title = {{Influence of avatar creation on attitude, empathy, presence, and para-social interaction}},
url = {http://www.springerlink.com/index/9518116J51670433.pdf},
year = {2007}
}
@misc{Lisetti2004,
abstract = {The development of an autonomous social robot, Cherry, is occurring in tandem with studies gaining potential user preferences, likes, dislikes, and perceptions of her features. Thus far, results have indicated that individuals 1) believe that service robots with emotion and personality capabilities would make them more acceptable in everyday roles in human life, 2) prefer that robots communicate via both human-like facial expressions, voice, and text-based media, 3) become more positive about the idea of service and social robots after exposure to the technology, and 4) find the appearance and facial features of Cherry pleasing. The results of these studies provide the basis for future research efforts, which are discussed.},
author = {Lisetti, Christine L and Brown, S M Brown S M and Alvarez, K Alvarez K and Marpaung, A H Marpaung A H},
booktitle = {IEEE Transactions on Systems Man and Cybernetics Part C Applications and Reviews},
doi = {10.1109/TSMCC.2004.826278},
issn = {10946977},
number = {2},
pages = {195--209},
publisher = {IEEE},
title = {{A social informatics approach to human-robot interaction with a service social robot}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1291667},
volume = {34},
year = {2004}
}
@article{LaFrance1982,
abstract = {The relationship between client-perceived rapport (as measured from a standardized client) and physical mirroring and the standard counsellor posture was investigated with interviews performed by 59 post-graduate students (47 females and 12 males, aged 21-60 yrs) in counselling psychology. Videotaped recordings were used to code counsellor posture in the categories of: total postural mirroring, mirroring of the hands and arms, mirroring of the legs, mirroring of the torso, and the frequency of the standard counsellor posture across each minute of the interviews. These minutes were classified as 'high' in rapport or 'low' in rapport as measured by the standardized client. Results indicated that there was significantly more postural mirroring of the torso during high versus low minutes, but that the counsellor standard posture occurred significantly more frequently during low rapport minutes than in high rapport minutes. However, when examined over the entire length of the interviews, these data were able to be understood in terms of counsellor 'flexibility' of response rather than simply whether these postural behaviors were present or not. Implications for counsellor training are discussed. (PsycINFO Database Record (c) 2009 APA},
author = {Lafrance, Marianne},
doi = {10.1080/09515070110088843},
issn = {09515070},
journal = {Counselling Psychology Quarterly},
number = {4},
pages = {267--280},
publisher = {Human Sciences Press},
title = {{Posture mirroring and rapport}},
volume = {14},
year = {1982}
}
@article{Mehrabian1967,
author = {Mehrabian, Albert and Ferris, S R},
journal = {Journal of Consulting Psychology},
keywords = {attitude,communication,facial expression,female,humans,verbal behavior},
number = {3},
pages = {248--252},
pmid = {6046577},
title = {{Inference of attitudes from nonverbal communication in two channels.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/6046577},
volume = {31},
year = {1967}
}
@article{Spurgeon2010,
abstract = {There has been a recent acceleration in the development and testing of programs for computer-assisted cognitive-behavioral therapy (CCBT). Programs are now available for treatment of depression, anxiety disorders, and other psychiatric conditions. Technology for delivery of CCBT includes multimedia programs, virtual reality, and handheld devices. Research on CCBT generally has supported the efficacy of computer-assisted therapy and has shown patient acceptance of computer tools for psychotherapy. Completion rates and treatment efficacy typically have been higher when clinicians prescribe and support the use of psychotherapeutic computer programs than when programs are delivered in a self-help format without clinician involvement. CCBT seems to have the potential to improve access to evidence-based therapies while reducing the demand for clinician time.},
author = {Spurgeon, Joyce a and Wright, Jesse H},
doi = {10.1007/s11920-010-0152-4},
file = {::},
isbn = {1192001001},
issn = {1535-1645},
journal = {Current psychiatry reports},
keywords = {Anxiety Disorders,Anxiety Disorders: therapy,Cognitive Therapy,Depressive Disorder,Depressive Disorder: therapy,Humans,Therapy, Computer-Assisted,Treatment Outcome},
month = dec,
number = {6},
pages = {547--52},
pmid = {20872100},
title = {{Computer-assisted cognitive-behavioral therapy.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20872100},
volume = {12},
year = {2010}
}
@inproceedings{Pontier2009,
abstract = {There is a growing belief that the environment plays an important role in the healing process of patients, supported by empirical findings. Previous research showed that psychological stress caused by loneliness can be reduced by artificial companions. As a pilot application for this purpose, this paper presents an affective agent playing tic-tac-toe with the user. Experimenting with a number of agents under different parameter settings shows the agent is able to show human-like emotional behavior, and can make decisions based on rationality as well as on affective influences. After discussing the application with clinical experts and making improvements where needed, the application can be tested in a clinical setting in future research.},
author = {Pontier, Matthijs and Siddiqui, Ghazanfar Farooq},
booktitle = {PRIMA '09 Proceedings of the 12th International Conference on Principles of Practice in Multi-Agent Systems},
editor = {et al. (Eds.):, J.-J. Yang},
file = {::},
keywords = {cognitive modeling,emotion modeling,healing environment},
pages = {33--47},
publisher = {Springer-Verlag Berlin Heidelberg},
title = {{An Affective Agent Playing Tic-Tac-Toe as Part of a}},
year = {2009}
}
@techreport{Gratch2010,
author = {Gratch, Jonathan and Kang, Sin-hwa and Wang, Ning},
booktitle = {Imagine},
file = {::},
institution = {University of Southern California},
number = {Chap X},
pages = {1--22},
title = {{Using social agents explore theories of rapport and emotional resonance}},
year = {2010}
}
@inproceedings{Paiva2004a,
author = {Paiva, Ana and Dias, J. and Sobral, D. and Woods, S. and Hall, L.},
booktitle = {Workshop on Empathic Agents, AAMAS04},
title = {{Building empathic life-like characters: the proximity factor}},
year = {2004}
}
@article{Lee2009,
author = {Lee, Jina and Prendinger, Helmut},
file = {::},
isbn = {9781424447992},
journal = {Affective Computing},
title = {{Learning models of speaker head nods with affective information}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5349543},
year = {2009}
}
@book{Widmark1981,
address = {Davis, California},
author = {Widmark, Erik Matteo Prochet},
isbn = {0931890071, 9780931890079},
pages = {163},
publisher = {Biomedical Publications},
title = {{Principles and Applications of Medicolegal Alcohol Determination}},
year = {1981}
}
@book{Greene2003,
abstract = {Providing a thorough review and synthesis of work on communication skills and skill enhancement, this "Handbook" serves as a comprehensive and contemporary survey of theory and research on social interaction skills. Editors John O. Greene and Brant R. Burleson have brought together preeminent researchers and writers to contribute to this volume, establishing a foundation on which future study and research will build. The handbook chapters are organized into five major units: general theoretical and methodological issues (models of skill acquisition, methods of skill assessment); fundamental interaction skills (both transfunctional and transcontextual); function-focused skills (informing, persuading, supporting); skills used in management of diverse personal relationships (friendships, romances, marriages); and skills used in varied venues of public and professional life (managing leading, teaching). Distinctive features of this handbook include: broad, comprehensive treatment of work on social interaction skills and skill acquisition; up-to-date reviews of research in each area; and emphasis on empirically supported strategies for developing and enhancing specific skills. Researchers in communication studies, psychology, family studies, business management, and related areas will find this volume a comprehensive, authoritative source on communications skills and their enhancement, and it will be essential reading for scholars and students across the spectrum of disciplines studying social interaction.},
author = {Greene, John O and Burleson, Brant Raney},
booktitle = {Communication},
editor = {Greene, John O and Burleson, Brant R},
isbn = {0805834176},
pages = {1051},
publisher = {Lawrence Erlbaum Associates, Inc., Publishers},
title = {{Handbook of Communication and Social Interaction Skills}},
year = {2003}
}
@article{Pelachaud2009,
abstract = {Over the past few years we have been developing an expressive embodied conversational agent system. In particular, we have developed a model of multimodal behaviours that includes dynamism and complex facial expressions. The first feature refers to the qualitative execution of behaviours. Our model is based on perceptual studies and encompasses several parameters that modulate multimodal behaviours. The second feature, the model of complex expressions, follows a componential approach where a new expression is obtained by combining facial areas of other expressions. Lately we have been working on adding temporal dynamism to expressions. So far they have been designed statically, typically at their apex. Only full-blown expressions could be modelled. To overcome this limitation, we have defined a representation scheme that describes the temporal evolution of the expression of an emotion. It is no longer represented by a static definition but by a temporally ordered sequence of multimodal signals.},
author = {Pelachaud, Catherine},
doi = {10.1098/rstb.2009.0186},
file = {::},
issn = {1471-2970},
journal = {Philosophical transactions of the Royal Society of London. Series B, Biological sciences},
keywords = {Computer Simulation,Emotions,Emotions: physiology,Facial Expression,Humans,Models, Psychological,Social Behavior},
month = dec,
number = {1535},
pages = {3539--48},
pmid = {19884148},
title = {{Modelling multimodal expression of emotion in a virtual agent.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2781894\&tool=pmcentrez\&rendertype=abstract},
volume = {364},
year = {2009}
}
@inproceedings{Hernandez-Trapote2008,
abstract = {In this article we present a research scheme which aims to analyze the use of Embodied Conversational Agent (ECA) technology to improve the robustness and acceptability of speaker enrolment and verification dialogues designed to provide secure access through natural and intuitive speaker recognition. In order to find out the possible effects of the visual information channel provided by the ECA, tests were carried out in which users were divided into two groups, each interacting with a different interface (metaphor): an ECA Metaphor group -with an ECA-, and a VOICE Metaphor group -without an ECA-. Our evaluation methodology is based on the ITU-T P.851 recommendation for spoken dialogue system evaluation, which we have complemented to cover particular aspects with regard to the two major extra elements we have incorporated: secure access and an ECA. Our results suggest that likeability-type factors and system capabilities are perceived more positively by the ECA metaphor users than by the VOICE metaphor users. However, the ECA’s presence seems to intensify users’ privacy concerns.},
address = {New York, New York, USA},
author = {Hern\'{a}ndez-Trapote, \'{A}lvaro and L\'{o}pez-Menc\'{\i}a, Beatriz and D\'{\i}az, David and Fern\'{a}ndez-Pozo, Rub\'{e}n and Caminero, Javier},
booktitle = {Proceedings of the 10th international conference on Multimodal interfaces - IMCI '08},
doi = {10.1145/1452392.1452454},
file = {::},
isbn = {9781605581989},
keywords = {Conversational Agent,Embodied biometrics interfaces,Experimentation,Human Factors,Multimodal evaluation,Security,Standardization,Verification.,voice authentication.},
pages = {305},
publisher = {ACM Press},
title = {{Embodied conversational agents for voice-biometric interfaces}},
url = {http://portal.acm.org/citation.cfm?doid=1452392.1452454},
year = {2008}
}
@inproceedings{Jiang2007,
author = {Jiang, Hong and Vidal, J.M. and Huhns, M.N.},
booktitle = {Proceedings of the 6th international joint conference on Autonomous agents and multiagent systems},
file = {::},
keywords = {agent architecture,belief-desire-intention,emotional agent},
pages = {11},
publisher = {ACM},
title = {{EBDI: an architecture for emotional agents}},
url = {http://dl.acm.org/citation.cfm?id=1329139},
year = {2007}
}
@article{Roberts1996,
author = {Roberts, William and Strayer, Janet},
doi = {10.2307/1131826},
file = {::},
issn = {00093920},
journal = {Child Development},
month = apr,
number = {2},
pages = {449},
title = {{Empathy, Emotional Expressiveness, and Prosocial Behavior}},
url = {http://www.jstor.org/stable/1131826?origin=crossref},
volume = {67},
year = {1996}
}
@article{Paiva2005,
author = {Paiva, Ana and Dias, Jo\~{a}o and Sobral, Daniel and Aylett, Ruth and Woods, Sarah and Hall, Lynne and Zoll, Carsten},
doi = {10.1080/08839510590910165},
file = {::},
issn = {0883-9514},
journal = {Applied Artificial Intelligence},
month = mar,
number = {3-4},
pages = {235--266},
title = {{Learning By Feeling: Evoking Empathy With Synthetic Characters}},
url = {http://www.tandfonline.com/doi/abs/10.1080/08839510590910165},
volume = {19},
year = {2005}
}
@article{Becker2008,
author = {Becker-Asano, Christian and Prendinger, H and Ishizuka, M.},
file = {::},
isbn = {0780390350},
journal = {Data Processing},
keywords = {embodied conversational agents,empa-},
title = {{Empathy for Max}},
url = {http://www.techfak.uni-bielefeld.de/~cbecker/becker-helmut-amt05.pdf},
year = {2008}
}
@inproceedings{Kang2008a,
author = {Kang, Sin-hwa and Gratch, Jonathan and Wang, Ning and Watt, J.},
booktitle = {Intelligent Virtual Agents},
file = {::},
keywords = {evaluation,nonverbal feedback,personality,rapport,virtual agents},
pages = {253--261},
publisher = {Springer},
title = {{Agreeable people like agreeable virtual humans}},
url = {http://www.springerlink.com/index/DT61V8556710VW13.pdf},
year = {2008}
}
@article{Jackson1992,
abstract = {OBJECTIVE: The purpose of this paper is the assessment of the healer's listening as an aspect of the history of caring and curing, with particular attention to its place in psychological healing. METHOD: An extensive range of philosophical, religious, and medical sources from antiquity to the present were studied. RESULTS: Over the centuries, listening has been a crucial aspect of the various endeavors undertaken by healers in the interest of acquiring information from, achieving understanding of, and bringing about healing effects for sufferers. Yet it has been vision rather than hearing that has been emphasized in knowing and understanding, and looking rather than listening that has been emphasized in healing endeavors. Only around the turn of the twentieth century did there emerge the focused study of care in listening, of listening beyond the words themselves, and of the significance of the interested listener as a soothing, empathic force. CONCLUSIONS: The place of listening in depth and with empathy is a crucial element in healing. While the emphasis on looking remains significant in the gathering and appraisal of data, at times it threatens to overwhelm the need for an attentive and concerned listener. There appears to be a natural tension between the two modes that has, in modern times, been translated into a tension between the two modes that has, in modern times, been translated into a tension between a scientific mode of gaining information and a humanistic mode of knowing sufferers. A healer neglects either one at his or her peril-and at the peril of his or her patients.},
author = {Jackson, S W},
institution = {Department of Psychiatry, Yale University School of Medicine, New Haven, CT 06510.},
journal = {The American Journal of Psychiatry},
number = {12},
pages = {1623--1632},
pmid = {1443239},
title = {{The listening healer in the history of psychological healing.}},
volume = {149},
year = {1992}
}
@article{Arapakis2009a,
author = {Arapakis, Ioannis and Konstas, Ioannis and Jose, Joemon M},
file = {::},
isbn = {9781605586083},
keywords = {affective feedback,all or part of,facial expression analysis,is granted without fee,or hard copies of,permission to make digital,personal or classroom use,physiological,provided that copies are,this work for},
pages = {461--470},
title = {{Using Facial Expressions and Peripheral Physiological Signals as Implicit Indicators of Topical Relevance Categories and Subject Descriptors}},
url = {http://dx.doi.org/10.1145/1631272.1631336},
year = {2009}
}
@incollection{Wallbott1995,
author = {Wallbott, H G},
booktitle = {In I Eds pp 8298},
chapter = {Congruence},
editor = {Markova, I and Graumann, C F and Foppa, K},
pages = {82--98},
publisher = {Cambridge University Press},
title = {{Mutualities in dialogue}},
volume = {Cambridge},
year = {1995}
}
@article{Blairy1999,
abstract = {Lipps (1907) presented a model of empathy which had an important influence on later formulations. According to Lipps, individuals tend to mimic an interaction partner's behavior, and this nonverbal mimicry induces—via a feedback process—the corresponding affective state in the observer. The resulting shared affect is believed to foster the understanding of the observed person's self. The present study tested this model in the context of judgments of emotional facial expressions. The results confirm that individuals mimic emotional facial expressions, and that the decoding of facial expressions is accompanied by shared affect. However, no evidence that emotion recognition accuracy or shared affect are mediated by mimicry was found. Yet, voluntary mimicry was found to have some limited influence on observer' s assessment of the observed person's personality. The implications of these results with regard to Lipps' original hypothesis are discussed.},
author = {Blairy, Sylvie and Herrera, Pedro and Hess, Ursula},
doi = {10.1023/A:1021370825283},
file = {::},
journal = {Journal of Nonverbal Behavior},
number = {1},
pages = {5--41},
title = {{Mimicry and the Judgment of Emotional Facial Expressions}},
url = {http://www.springerlink.com/content/unx02r46695w7651/ http://dx.doi.org/10.1023/A:1021370825283},
volume = {23},
year = {1999}
}
@article{Sebe2005a,
author = {Sebe, Nicu and Cohen, Ira and Huang, Thomas S.},
file = {::},
journal = {Handbook of Pattern Recognition and Computer Vision},
pages = {981--256},
publisher = {Citeseer},
title = {{Multimodal emotion recognition}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.110.1129\&amp;rep=rep1\&amp;type=pdf},
year = {2005}
}
@article{Hunsdahl1967,
author = {Hunsdahl, JB},
doi = {10.1016/0022-1910(58)90015-5},
issn = {00221910},
journal = {Journal of the History of the Behavioral},
number = {4},
pages = {298--312},
title = {{Concerning Einf\"{u}hlung (empathy): A concept analysis of its origin and early development}},
volume = {2},
year = {1967}
}
@article{Heimgartner2011,
author = {Heimg\"{a}rtner, R\"{u}diger and Tiede, L.W. and Windl, Helmut},
file = {::},
journal = {Design, User Experience, and Usability. Theory, Methods, Tools and Practice},
keywords = {1 problems in hci,communication,cultural differences,culture,design caused by cultural,designing the functionality and,differences,empathy,intercultural communication,intercultural hci design,much cultural background has,to be considered when,understanding},
pages = {557--566},
publisher = {Springer},
title = {{Empathy as Key Factor for Successful Intercultural HCI Design}},
url = {http://www.springerlink.com/index/FG03081276H7K042.pdf},
year = {2011}
}
@book{Kipp2005,
author = {Kipp, Michael},
isbn = {1581122551, 9781581122558},
publisher = {Universal-Publishers},
title = {{Gesture Generation By Imitation: From Human Behavior To Computer Character Animation}},
year = {2005}
}
@article{Dias2005,
author = {Dias, J. and Paiva, Ana},
file = {::},
journal = {Progress in artificial intelligence},
pages = {127--140},
publisher = {Springer},
title = {{Feeling and reasoning: A computational model for emotional characters}},
url = {http://www.springerlink.com/index/YQ18H62602413554.pdf},
year = {2005}
}
@inproceedings{Zakharov2007,
abstract = {We describe the design and evaluation of an affective pedagogical agent persona for Intelligent Tutoring Systems. The goal of our research was to develop an agent embodying a persona of a caring mentor interested in the learner's progress. The agent's behaviour is guided by a set of rules that are triggered by the states of the session history. Four agents were integrated with EER-Tutor for a formative evaluation study. The mentor persona secured strong rapport with the users; the audible narration was seen as a strong feature of the agents.},
author = {Zakharov, Konstantin and Mitrovic, Antonija and Johnston, Lucy},
booktitle = {Proceedings of the 2007 conference on Artificial Intelligence in Education: Building Technology Rich Learning Contexts That Work},
file = {::},
pages = {59--66},
publisher = {IOS Press Amsterdam, The Netherlands},
title = {{Pedagogical Agents Trying on a Caring Mentor Role}},
url = {http://dl.acm.org/citation.cfm?id=1563616},
year = {2007}
}
@article{Boukricha2011b,
author = {Boukricha, Hana and Nguyen, Nhung},
file = {::},
journal = {Intelligent Virtual Agents},
pages = {350--362},
title = {{Sharing Emotions and Space – Empathy as a Basis for}},
url = {http://www.springerlink.com/index/Q22784632U008337.pdf},
year = {2011}
}
@article{Edinger1983,
author = {Edinger, Joyce a. and Patterson, Miles L.},
doi = {10.1037//0033-2909.93.1.30},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Edinger, Patterson - 1983 - Nonverbal involvement and social control.pdf:pdf},
issn = {0033-2909},
journal = {Psychological Bulletin},
number = {1},
pages = {30--56},
title = {{Nonverbal involvement and social control.}},
url = {http://content.apa.org/journals/bul/93/1/30},
volume = {93},
year = {1983}
}
@article{Fabri2007,
author = {Fabri, Marc and Elzouki, SYA},
file = {::},
journal = {of the 12th international conference on},
keywords = {autism,avatar,education,emotion,empathy,facial expression,instant,messaging,therapeutic intervention,virtual reality},
pages = {275--285},
title = {{Emotionally expressive avatars for chatting, learning and therapeutic intervention}},
url = {http://dl.acm.org/citation.cfm?id=1769621},
year = {2007}
}
@article{Strecher1986,
abstract = {The concept of self-efficacy is receiving increasing recognition as a predictor of health behavior change and maintenance. The purpose of this article is to facilitate a clearer understanding of both the concept and its relevance for health education research and practice. Self-efficacy is first defined and distinguished from other related concepts. Next, studies of the self-efficacy concept as it relates to health practices are examined. This review focuses on cigarette smoking, weight control, contraception, alcohol abuse and exercise behaviors. The studies reviewed suggest strong relationships between self-efficacy and health behavior change and maintenance. Experimental manipulations of self-efficacy suggest that efficacy can be enhanced and that this enhancement is related to subsequent health behavior change. The findings from these studies also suggest methods for modifying health practices. These methods diverge from many of the current, traditional methods for changing health practices. Recommendations for incorporating the enhancement of self-efficacy into health behavior change programs are made in light of the reviewed findings.},
author = {Strecher, V J and DeVellis, B M and Becker, M H and Rosenstock, I M},
journal = {Health Education Quarterly},
number = {1},
pages = {73--92},
pmid = {3957687},
publisher = {Sage Publications},
title = {{The role of self-efficacy in achieving health behavior change.}},
url = {http://heb.sagepub.com/cgi/doi/10.1177/109019818601300108},
volume = {13},
year = {1986}
}
@article{Meltzoff1977,
abstract = {Infants between 12 and 21 days of age can imitate both facial and manual gestures; this behavior cannot be explained in terms of either conditioning or innate releasing mechanisms. Such imitation implies that human neonates can equate their own unseen behaviors with gestures they see others perform.},
author = {Meltzoff, AN},
doi = {10.1126/science.198.4312.75},
file = {::},
issn = {0036-8075},
journal = {Science},
month = oct,
number = {4312},
pages = {75--8},
pmid = {17741897},
title = {{Imitation of facial and manual gestures by human neonates}},
volume = {198},
year = {1977}
}
@article{Barkham2001,
abstract = {To complement the evidence-based practice paradigm, the authors argued for a core outcome measure to provide practice-based evidence for the psychological therapies. Utility requires instruments that are acceptable scientifically, as well as to service users, and a coordinated implementation of the measure at a national level. The development of the Clinical Outcomes in Routine Evaluation-Outcome Measure (CORE-OM) is summarized. Data are presented across 39 secondary-care services (n = 2,710) and within an intensively evaluated single service (n = 1,455). Results suggest that the CORE-OM is a valid and reliable measure for multiple settings and is acceptable to users and clinicians as well as policy makers. Baseline data levels of patient presenting problem severity, including risk, are reported in addition to outcome benchmarks that use the concept of reliable and clinically significant change. Basic quality improvement in outcomes for a single service is considered.},
author = {Barkham, M and Margison, F and Leach, C and Lucock, M and Mellor-Clark, J and Evans, C and Benson, L and Connell, J and Audin, K and McGrath, G},
issn = {0022006X},
journal = {Journal of Consulting and Clinical Psychology},
number = {2},
pages = {184--96},
title = {{Service profiling and outcomes benchmarking using the CORE-OM: toward practice-based evidence in the psychological therapies. Clinical Outcomes in Routine Evaluation-Outcome Measures}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11393596?ordinalpos=17\&itool=EntrezSystem2.PEntrez.Pubmed.Pubmed\_ResultsPanel.Pubmed\_RVDocSum},
volume = {69},
year = {2001}
}
@article{Prendinger2005,
abstract = {They designed an animated interface agent that accompanies the user in the setting of a virtual job interview. This interface application takes physiological data (skin conductance and electromyography) of a user in realtime, interprets them as emotions, and addresses the user’s affective states in the form of empathic feedback by employing embodied characters.},
annote = {They take physiological data (skin conductance and electromyography) of a user in real-time, interpret them as emotions, and address the user’s affective states by empathic feedback. A decision making agent relates these signals and the user’s answer to arousal and valence to infer the user’s emotional state by applying the model of Lang (1995) (Lang claims that all emotions can be characterized in terms of valence (pleasant or unpleasant) and arousal (calm or aroused)). Then it selects empathetic actions that maximize some utility function. They use text-based empathetic actions in addition to a small full body character.We can use the decision-theoretic agent aspect in our empathy model.
The empathy is mainly expressed in a text-base fashion in their job. The embodied agent that they have is so small and no facial expressions are used. There are some gestural expressions.
As shown in this paper and many other ones, text-base empathy expression can be effective. So we can use that too.
      },
author = {Prendinger, H and Ishizuka, M.},
file = {::;::},
journal = {Applied Artificial Intelligence},
keywords = {electromyography,physiological signals,skin conductance},
number = {3-4},
pages = {267--286},
publisher = {Citeseer},
title = {{The Empathic Companion - A Character-based Interface that Addresses Users’ Affective States}},
volume = {19},
year = {2005}
}
@inproceedings{Cramer2010,
author = {Cramer, Henriette and Goddijn, Jorrit and Wielinga, Bob and Evers, Vanessa},
booktitle = {Proceeding of the 5th ACM/IEEE international conference on Human-robot interaction},
file = {::},
isbn = {9781424448937},
pages = {141--142},
publisher = {ACM},
title = {{Effects of (in) accurate empathy and situational valence on attitudes towards robots}},
url = {http://dl.acm.org/citation.cfm?id=1734513},
year = {2010}
}
@inproceedings{Lee2009a,
abstract = {During face-to-face conversation, the speaker’s head is con- tinually in motion. These movements serve a variety of im- portant communicative functions. Our goal is to develop a model of the speaker’s head movements that can be used to generate head movements for virtual agents based on a ges- ture annotation corpora. In this paper, we focus on the first step of the head movement generation process: predicting when the speaker should use head nods. We describe our machine-learning approach that creates a head nod model from annotated corpora of face-to-face human interaction, relying on the linguistic features of the surface text. We also describe the feature selection process, training process, and the evaluation of the learned model with test data in detail. The result shows that the model is able to predict head nods with high precision and recall.},
address = {Budapest, Hungary},
author = {Lee, Jina and Marsella, Stacy C},
booktitle = {8th Int. Conf. on Autonomous Agents and Multiagent Systems (AAMAS 2009)},
editor = {Decker and Sichman and Sierra and Castelfranchi},
file = {::},
keywords = {bal behaviors,embodied conversational agents,head nods,machine learning,nonver-,virtual agents},
number = {Aamas},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org)},
title = {{Learning a Model of Speaker Head Nods using Gesture Corpora}},
year = {2009}
}
@inproceedings{Lisetti2008,
abstract = {In this article, we explore how Embodied Conversational Agents (ECAs) or avatars could be used as social orthotics defined as therapeutic computer- based social companions aimed at promoting healthy behaviors. We review some of the latest related progress and identify specific features of ECAs that are important – if not necessary – to include in the design of social orthotic systems.},
author = {Lisetti, Christine L},
booktitle = {Proceedings of the CHI 2008 Conference Workshop on Technology in Mental Health},
file = {::},
keywords = {affective computing,agents,avatars,embodied conversational,psychotherapy,social orthotics},
pages = {1--12},
publisher = {ACM},
title = {{Embodied Conversational Agents for Psychotherapy}},
year = {2008}
}
@article{Peters2005,
abstract = {One of the major problems of user's interaction with Embodied Conversational Agents (ECAs) is to have the conversation last more than few second: after being amused and intrigued by the ECAs, users may find rapidly the restrictions and limitations of the dialog systems, they may perceive the repetition of the ECAs animation, they may find the behaviors of ECAs to be inconsistent and implausible, etc. We believe that some special links, or bonds, have to be established between users and ECAs during interaction. It is our view that showing and/or perceiving interest is the necessary premise to establish a relationship. In this paper we present a model of an ECA able to establish, maintain and end the conversation based on its perception of the level of interest of its interlocutor.},
author = {Peters, Christopher and Pelachaud, Catherine and Bevacqua, Elisabetta and Mancini, Maurizio and Poggi, Isabella},
doi = {10.1007/11550617\_20},
editor = {Panayiotopoulos, Themis and Gratch, Jonathan and Aylett, Ruth and Ballin, Daniel and Olivier, Patrick and Rist, Thomas},
isbn = {9783540287384},
journal = {Intelligent Virtual Agents},
pages = {229--240},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{A model of attention and interest using gaze behavior}},
url = {http://www.springerlink.com/index/8gqh2c9phmhb12jd.pdf},
volume = {3661},
year = {2005}
}
@article{Larsen1992,
abstract = {TOC The structural bases of emotional behavior James R. Averill - Promises and problems with the circumplex model of emotion Randy J. Larsen and Edward Diener - The complexity of intensity Nico H. Frijda, Andrew Ortony, Joep Sonnemans, and Gerald L. Clore - The behavioral ecology and sociality of human faces Alan J. Firdlund - Appraisal as a cause of emotion Brian Parkinson and A.S.R. Manstead - Affective dynamics Robert Mauro - Cross-cultural similarities and differences in emotion and its representation Phillip R. Shaver, Shelley Wu, and Judith C. Schwartz - The process of emotional experience James D. Laird and Charles Bresler - Inhibitory effects of awareness on affective responding Robert F. Bornstein - A functional analysis of the role of mood in affective systems William N. Morris - Differentiating affect, mood, and emotion C. Daniel Batson, Laura L. Shaw, and Kathryn C. Oleson},
author = {Larsen, Randy J and Diener, Edward},
chapter = {2},
editor = {Clark, Margaret S},
isbn = {0803946139},
journal = {Review of Personality and Social Psychology},
number = {13},
pages = {25--59},
publisher = {Sage},
series = {Review of personality and social psychology; No. 13; 0270-1987},
title = {{Promises and problems with the circumplex model of emotion}},
url = {http://psycnet.apa.org/psycinfo/1992-97396-002},
volume = {13},
year = {1992}
}
@article{Suchman1997,
abstract = {To formulate an empirically derived model of empathic communication in medical interviews by describing the specific behaviors and patterns of interaction associated with verbal expressions of emotion.},
author = {Suchman, a L and Markakis, K and Beckman, H B and Frankel, R},
file = {::},
issn = {0098-7484},
journal = {JAMA : the journal of the American Medical Association},
keywords = {Communication,Empathy,Humans,Interviews as Topic,Models,Physician-Patient Relations,Psychological},
month = feb,
number = {8},
pages = {678--82},
pmid = {9039890},
title = {{A model of empathic communication in the medical interview.}},
volume = {277},
year = {1997}
}
@article{DiClemente2001,
abstract = {OBJECTIVE: To offer a taxonomy of types of feedback and describe potential mechanisms of action particularly in the area of addictive behaviors. METHOD: Reviewed the literature to examine support for types-Generic, Targeted, and Personalized-and for mechanisms of feedback. RESULTS: Although it is not clear how it works, feedback is thought to offer important information, to create a sense of caring and helping relationship, to reach more directly decisional considerations, to increase engagement in the materials, to increase motivation, or to provide social comparison and norms. CONCLUSIONS: Avenues for future research in search of the most effective manner of using feedback to promote health behavior change are discussed.},
author = {DiClemente, C C and Marinilli, A S and Singh, M and Bellino, L E},
institution = {Psychology Department, University of Maryland, Baltimore County, Baltimore 21250, USA. diclemen@umbc.edu},
journal = {American Journal of Health Behavior},
keywords = {addictive,addictive prevention \& control,addictive psychology,behavior,classification,feedback,health behavior,health education,health education classification,humans,mass screening,models,psychological,risk taking},
number = {3},
pages = {217--227},
pmid = {11322620},
publisher = {PNG Publications},
title = {{The role of feedback in the process of health behavior change.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11322620},
volume = {25},
year = {2001}
}
@article{Emmons2001,
abstract = {Motivational interviewing (MI) has been well studied in specialist settings. There has been considerable interest in applying MI to community health care settings. Such settings represent a significant departure from the more traditional, specialist settings in which MI has been developed and tested. The purpose of this paper is to provide a brief overview of MI and to identify and discuss the key issues that are likely to arise when adapting this approach to health care and public health settings. This paper provides an overview of important issues to consider in adapting an effective counseling strategy to new settings, and is intended to begin a dialogue about the use of MI in community health care settings.},
author = {Emmons, K M and Rollnick, S},
file = {::},
issn = {0749-3797},
journal = {American journal of preventive medicine},
keywords = {Adult,Attitude of Health Personnel,Community Health Services,Community Health Services: standards,Community Health Services: trends,Female,Health Care Surveys,Humans,Interviews as Topic,Interviews as Topic: methods,Male,Motivation,Outcome Assessment (Health Care),Preventive Medicine,Preventive Medicine: standards,Preventive Medicine: trends,United States},
month = jan,
number = {1},
pages = {68--74},
pmid = {11137778},
title = {{Motivational interviewing in health care settings. Opportunities and limitations.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11137778},
volume = {20},
year = {2001}
}
@article{Martino2006,
abstract = {AIMS: This pilot study examined the efficacy of a two-session motivational interview adapted for dually diagnosed psychotic and drug-related disordered patients (DDMI) in comparison to a two-session standard psychiatric interview (SI). DESIGN: The study used a randomized controlled trial design. Participants received either DDMI or SI and were assessed at baseline, 4-, 8- and 12-week follow-up points. The principal analysis for examination of treatment effects across time was a random effects regression model. SETTING: Both DDMI and SI interviews served as pre-admission intake interventions to an ambulatory specialty dual diagnosis intensive out-patient and partial hospital program. PARTICIPANTS: Forty-four treatment-seeking participants (DDMI = 24; SI = 20) who had co-occurring psychotic and drug-related disorders were assigned randomly to the treatment conditions. Measurements Primary outcomes were days of primary drug use, secondary drug use, alcohol use and psychotropic medication adherence, proportion of participants admitted into the program and days of attendance. FINDINGS AND CONCLUSIONS: DDMI and SI resulted in improved treatment outcomes, but there were no main effects for the sample as a whole. Separate examination of primary cocaine and primary marijuana using subsamples, however, suggested that DDMI resulted in significantly better primary drug treatment outcomes for the cocaine-using group, whereas SI resulted in significantly better primary drug treatment outcomes for the marijuana-using group. These findings indicate that MI may not work equally well for all types of psychotic disordered dually diagnosed patients and that alternative approaches may be as effective in fostering improved substance use treatment outcomes for subgroups of these individuals.},
author = {Martino, Steve and Carroll, Kathleen M and Nich, Charla and Rounsaville, Bruce J},
institution = {Yale Psychosocial Substance Abuse Research Center and Yale University School of Medicine, West Haven, CT 06516, USA. steve.martino@yale.edu},
journal = {Addiction Abingdon England},
keywords = {adult,diagnosis,dual (psychiatry),female,follow up studies,humans,interview,male,motivation,patient compliance,pilot projects,psychological,psychological methods,psychotic disorders,psychotic disorders diagnosis,substance related disorders,substance related disorders diagnosis,treatment outcome},
number = {10},
pages = {1479--1492},
title = {{A randomized controlled pilot study of motivational interviewing for patients with psychotic and drug use disorders.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16968350},
volume = {101},
year = {2006}
}
@inproceedings{Pasquariello2001,
author = {Pasquariello, Stefano and Pelachaud, Catherine},
booktitle = {Proceedings 6th Online World Conference on Soft Computing in Industrial Appications Session on Soft Computing for Intelligent 3D Agents},
title = {{Greta: A Simple Facial Animation Engine}},
year = {2001}
}
@phdthesis{Sze2005,
author = {Sze, Ian},
booktitle = {Ambient Intelligence in Everyday Life},
file = {::},
school = {UNIVERSITY OF NEW SOUTH WALES},
title = {{Empathic computing}},
year = {2005}
}
@book{Stueber2006,
author = {Stueber, Karsten},
edition = {1},
isbn = {026219550X},
publisher = {MIT Press},
title = {{Rediscovering Empathy: Agency, Folk Psychology, and the Human Sciences}},
year = {2006}
}
@inproceedings{Krauss1996,
address = {San Diego, CA, US},
author = {Krauss, Robert M. and Chen, Yihsiu and Chawla, Purnima},
booktitle = {Advances in experimental social psychology},
doi = {10.1016/S0065-2601(08)60241-5},
editor = {Zanna, Mark P.},
file = {::},
pages = {389--450},
publisher = {Academic Press},
title = {{Nonverbal behavior and nonverbal communication: What do conversational hand gestures tell us?}},
url = {http://www.sciencedirect.com/science/article/pii/S0065260108602415},
volume = {28},
year = {1996}
}
@inproceedings{Bartlett2004,
author = {Bartlett, M.S. and Littlewort, G. and Lainscsek, C. and Fasel, I. and Movellan, J.},
booktitle = {2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No.04CH37583)},
doi = {10.1109/ICSMC.2004.1398364},
file = {::},
isbn = {0-7803-8567-5},
keywords = {1 real-time face detection,2,adaboost,chines,facial action cod-,facial expression recognition,feature selection,ing,linear discriminant analysis,machine learning,support vector ma-},
pages = {592--597},
publisher = {IEEE},
title = {{Machine learning methods for fully automatic recognition of facial expressions and facial actions}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1398364},
volume = {1},
year = {2004}
}
@article{Page2002,
abstract = {In the Ultimatum Game, two players are asked to split a prize. The first player, the proposer, makes an offer of how to split the prize. The second player, the responder, either accepts the offer, in which case the prize is split as agreed, or rejects it, in which case neither player receives anything. The rational strategy suggested by classical game theory is for the proposer to offer the smallest possible positive share and for the responder to accept. Humans do not play this way, however, and instead tend to offer 50\% of the prize and to reject offers below 20\%. Here we study the Ultimatum Game in an evolutionary context and show that empathy can lead to the evolution of fairness. Empathy means that individuals make offers which they themselves would be prepared to accept.},
author = {Page, Karen M and Nowak, Martin a},
doi = {10.1006/bulm.2002.0321},
file = {::},
issn = {0092-8240},
journal = {Bulletin of mathematical biology},
keywords = {Biological Evolution,Choice Behavior,Empathy,Games, Experimental,Humans,Models, Psychological,Social Behavior},
month = nov,
number = {6},
pages = {1101--16},
pmid = {12508533},
title = {{Empathy leads to fairness.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12508533},
volume = {64},
year = {2002}
}
@article{Liu2005,
author = {Liu, Zhen},
file = {::},
journal = {Affective Computing and Intelligent Interaction},
title = {{An emotion model of 3D virtual characters in intelligent virtual environment}},
url = {http://www.springerlink.com/index/p232574rm3036237.pdf},
year = {2005}
}
@article{Calvo2010,
abstract = {This survey describes recent progress in the field of Affective Computing (AC), with a focus on affect detection. Although many AC researchers have traditionally attempted to remain agnostic to the different emotion theories proposed by psychologists, the affective technologies being developed are rife with theoretical assumptions that impact their effectiveness. Hence, an informed and integrated examination of emotion theories from multiple areas will need to become part of computing practice if truly effective real-world systems are to be achieved. This survey discusses theoretical perspectives that view emotions as expressions, embodiments, outcomes of cognitive appraisal, social constructs, products of neural circuitry, and psychological interpretations of basic feelings. It provides meta-analyses on existing reviews of affect detection systems that focus on traditional affect detection modalities like physiology, face, and voice, and also reviews emerging research on more novel channels such as text, body language, and complex multimodal systems. This survey explicitly explores the multidisciplinary foundation that underlies all AC applications by describing how AC researchers have incorporated psychological theories of emotion and how these theories affect research questions, methods, results, and their interpretations. In this way, models and methods can be compared, and emerging insights from various disciplines can be more expertly integrated.},
author = {Calvo, R.A. and D'Mello, S.},
doi = {10.1109/T-AFFC.2010.1},
file = {::},
journal = {IEEE Transactions on Affective Computing},
keywords = {Affective computing,affect sensing and analysis,emotion detection,emotion theory,multimodal recognition},
number = {1},
pages = {18--37},
publisher = {IEEE},
title = {{Affect detection: An interdisciplinary review of models, methods, and their applications}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5520655},
volume = {1},
year = {2010}
}
@phdthesis{Sze2005,
author = {Sze, Ian},
booktitle = {Ambient Intelligence in Everyday Life},
file = {::},
school = {UNIVERSITY OF NEW SOUTH WALES},
title = {{Empathic computing}},
year = {2005}
}
@article{Barrett2006,
abstract = {Laypeople and scientists alike believe that they know anger, or sadness, or fear, when they see it. These emotions and a few others are presumed to have specific causal mechanisms in the brain and properties that are observable (on the face, in the voice, in the body, or in experience)—that is, they are assumed to be natural kinds. If a given emotion is a natural kind and can be identified objectively, then it is possible to make discoveries about that emotion. Indeed, the scientific study of emotion is founded on this assumption. In this article, I review the accumulating empirical evidence that is inconsistent with the view that there are kinds of emotion with boundaries that are carved in nature. I then consider what moving beyond a natural-kind view might mean for the scientific understanding of emotion.},
author = {Barrett, Lisa Feldman},
doi = {10.1111/j.1745-6916.2006.00003.x},
journal = {Perspectives on Psychological Science},
pages = {28--58},
title = {{Are Emotions Natural Kinds?}},
volume = {1},
year = {2006}
}
@book{Fussell2002,
author = {Fussell, Susan R.},
file = {::},
isbn = {0805836896},
publisher = {Lawrence Erlbaum},
title = {{The verbal communication of emotions: Interdisciplinary perspectives}},
year = {2002}
}
@article{Albrecht2005,
abstract = {We present an algorithm for generating facial expressions for a continuum of pure and mixed emotions of varying intensity. Based on the observation that in natural interaction among humans, shades of emotion are much more frequently encountered than expressions of basic emotions, a method to generate more than Ekman's six basic emotions (joy, anger, fear, sadness, disgust and surprise) is required. To this end, we have adapted the algorithm proposed by Tsapatsoulis et al. [1] to be applicable to a physics-based facial animation system and a single, integrated emotion model. A physics-based facial animation system was combined with an equally flexible and expressive text-to-speech synthesis system, based upon the same emotion model, to form a talking head capable of expressing non-basic emotions of varying intensities. With a variety of life-like intermediate facial expressions captured as snapshots from the system we demonstrate the appropriateness of our approach.},
author = {Albrecht, Irene and Schr\"{o}der, Marc and Haber, J\"{o}rg and Seidel, Hans-Peter},
doi = {10.1007/s10055-005-0153-5},
file = {::},
issn = {1359-4338},
journal = {Virtual Reality},
keywords = {continuous emotions \ae emotional,speech,synthesis \ae facial animation},
month = aug,
number = {4},
pages = {201--212},
title = {{Mixed feelings: expression of non-basic emotions in a muscle-based talking head}},
url = {http://www.springerlink.com/index/10.1007/s10055-005-0153-5},
volume = {8},
year = {2005}
}
@article{Paiva2005a,
author = {Paiva, Ana and Dias, Jo\~{a}o and Sobral, Daniel and Aylett, Ruth and Woods, Sarah and Hall, Lynne and Zoll, Carsten},
doi = {10.1080/08839510590910165},
file = {::},
issn = {0883-9514},
journal = {Applied Artificial Intelligence},
month = mar,
number = {3-4},
pages = {235--266},
title = {{Learning By Feeling: Evoking Empathy With Synthetic Characters}},
url = {http://www.tandfonline.com/doi/abs/10.1080/08839510590910165},
volume = {19},
year = {2005}
}
@article{Berry1997,
author = {Berry, D S and Pennebaker, J W and Mueller, J S and Hiller, W S},
doi = {10.1177/0146167297235008},
issn = {01461672},
journal = {Personality and Social Psychology Bulletin},
number = {5},
pages = {526--537},
title = {{Linguistic Bases of Social Perception}},
url = {http://psp.sagepub.com/cgi/doi/10.1177/0146167297235008},
volume = {23},
year = {1997}
}
@article{Neiberg2006,
author = {Neiberg, Daniel and Elenius, Kjell and Karlsson, Inger},
file = {::},
journal = {Working Papers of Lund University, Centre for Languages \& Literature, Dept. of Linguistics \& Phonetics},
pages = {101--104},
title = {{Emotion recognition in spontaneous speech}},
url = {http://nile.lub.lu.se/ojs/index.php/LWPL/article/viewFile/2306/1881},
volume = {52},
year = {2006}
}
@inproceedings{Courgeon2008,
address = {Estoril, Portugal},
annote = {The user reports his/her affective state in real-time with changing the position of a 3D point in PAD space using a joystick. The system captures the position of that point and maps it to a blend of 8 selected emotions. },
author = {Courgeon, Matthieu and Martin, Jean-claude and Jacquemin, Christian},
booktitle = {Proc. of 7th Int. Conf. on Autonomous Agents and Multiagent Systems (AAMAS 2008)},
file = {::},
number = {Aamas},
pages = {1237--1240},
title = {{User ’ s Gestural Exploration of Different Virtual Agents ’ Expressive Profiles ( Short Paper )}},
year = {2008}
}
@book{Prendinger2004a,
abstract = {Life-like characters is one of the most exciting technologies for human-computer interface applications today. They convincingly take the roles of virtual presenters, synthetic actors and sales personas, teammates and tutors. A common characteristic underlying their life-likeness or believability as virtual conversational partners is computational models that provide them with affective functions such as synthetic emotions and personalities and implement human interactive behavior. The wide dissemination of life-like characters in multimedia systems, however, will greatly depend on the availability of control languages and tools that facilitate scripting of intelligent conversational behaviour. This book presents the first comprehensive collection of the latest developments in scripting and representation languages for life-like characters, rounded off with an in-depth comparison and synopsis of the major approaches. Introducing toolkits for authoring animated characters further supports the ease of use of this new interface technology. Life-like characters being a vibrant research area, various applications have been designed and implemented. This book offers coverage of the most successful and promising applications, ranging from product presentation and student training to knowledge integration and interactive gaming. It also discusses the key challenges in the area and provides design guidelines for employing life-like characters.},
author = {{Helmut Prendinger}, Mitsuru Ishizuka},
isbn = {3540008675, 9783540008675},
publisher = {Springer},
title = {{Life-Like Characters: Tools, Affective Functions, and Applications}},
year = {2004}
}
@techreport{Hester2005,
abstract = {Sixty-one problem drinkers were randomly assigned to either immediate treatment or a 4-week wait-list control group. Treatment consisted of a computer-based brief motivational intervention, the Drinker's Check-up (DCU). Outcomes strongly support the experimental hypotheses and long-term effectiveness of the treatment. Overall, participants reduced the quantity and frequency of drinking by 50\%, and had similar reductions in alcohol-related problems that were sustained through 12-month follow-up. The DCU seems to be effective in enhancing problem drinkers' motivation for change.},
author = {Hester, Reid K and Squires, Daniel D and Delaney, Harold D},
booktitle = {Journal of Substance Abuse Treatment},
institution = {Research Division, Behavior Therapy Associates, LLP, Albuquerque, NM 87112, USA. reidhester@behaviortherapy.com},
keywords = {*alcoholism,*motivation,*software,*therapy,adult,alcohol drinking,alcoholism,bl [blood],computer assisted,ep [epidemiology],ethanol,female,follow up studies,humans,male,middle aged,outcome assessment (health care),patient compliance,patient dropouts,personality assessment,psychometrics,px [psychology],rh [rehabilitation],sn [statistics \&,sn [statistics \& numer,sn [statistics \& numerical,sn [statistics \& numerical data,sn [statistics \& numerical data],united states,waiting lists},
number = {2},
pages = {159--169},
pmid = {15780546},
publisher = {Research Division, Behavior Therapy Associates, LLP, Albuquerque, NM 87112, USA. reidhester@behaviortherapy.com},
title = {{The Drinker's Check-up: 12-month outcomes of a controlled clinical trial of a stand-alone software program for problem drinkers.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15780546},
volume = {28},
year = {2005}
}
@article{DiMatteo1980,
abstract = {The relationship between physicians' nonverbal communication skills (their ability to communicate and to understand facial expression, body movement and voice tone cues to emotion) and their patients' satisfaction with medical care was examined in 2 studies. The research involved 71 residents in internal medicine and 462 of their ambulatory and hospitalized patients. Standardized, reliable and valid measures of nonverbal communication skills were administered to the physicians. Their scores on these tests were correlated with ratings they received from a sample of their patients on measures of satisfaction with the technical aspects and the socioemotional aspects (or art) of the medical care they received. While the nonverbal communication skills of the physicians bore little relationship to patients' ratings of the technical quality of care, measures of these skills did predict patient satisfaction with the art of medical care received. Across both samples, physicians who were more sensitive to body movement and posture cues to emotion (the channel suggested by nonverbal researchers as the one in which true affect can be perceived) received higher ratings from their patients on the art of care than did less sensitive physicians. In addition, physicians who were successful at expressing emotion through their nonverbal communications tended to receive higher ratings from patients on the art of care than did physicians who were less effective communicators. The implications of successfully identifying characteristics of physicians with whom patients are satisfied are discussed.},
author = {DiMatteo, M R and Taranta, a and Friedman, H S and Prince, L M},
file = {::},
issn = {0025-7079},
journal = {Medical care},
keywords = {Adult,Consumer Satisfaction,Evaluation Studies as Topic,Female,Humans,Male,Nonverbal Communication,Physician-Patient Relations},
month = apr,
number = {4},
pages = {376--87},
pmid = {7401698},
title = {{Predicting patient satisfaction from physicians' nonverbal communication skills.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/7401698},
volume = {18},
year = {1980}
}
@inproceedings{Nguyen2009,
abstract = {Experiencing emotional distress is the number one reason why people who are undergoing behaviour modification (e.g. quitting smoking, dieting) suffer from relapses. Providing emotional support is an effective way to help them overcome the unpleasant effects of negative affect and adhere to their regimen. Building computers with such ability has grabbed the attention of the HCI community in recent years. This paper presents the results of a 2 (modality: animated vs. no visual) by 3 (intervention: non-empathy vs. empathy vs. empathy and expressivity) between-subjects study that investigates the impact of two important factors and their interaction in the design of such systems: (1) different ways of expressing empathy, and (2) the modality of delivering such content.},
annote = {They investigate: 
1-      Different ways of expressing empathy 
2-      Modality of delivering such content. 
        
They define empathy as the ability to detect what others feel and to experience that emotion ourselves (seems like mimicry).
        
Empirical evidence indicates that expressing accurate empathy can lead to positive psychological, physical and health outcomes.
        
Their results show: 
1. The positive attitude of the users toward active support (active empathy). 
2.  The positive outcome of an empathic system regardless of its representation. 
3.  A system represented by a human-like representation is expected to be empathic.
        
they believe, adding a mechanism to allow the users to freely express themselves does not improve the effectiveness or liking of an empathic system.
      },
author = {Nguyen, H. and Masthoff, Judith},
booktitle = {Proceedings of the 4th International Conference on Persuasive Technology},
file = {::},
isbn = {9781605583761},
keywords = {affective computing,design,experimentation,human factors},
pages = {7},
publisher = {ACM},
title = {{Designing empathic computers: the effect of multimodal empathic feedback using animated agent}},
url = {http://portal.acm.org/citation.cfm?id=1541958},
year = {2009}
}
@article{Cai2006,
author = {Cai, Yang},
file = {::},
journal = {Ambient Intelligence in Everyday Life},
pages = {67--85},
publisher = {Springer},
title = {{Empathic computing}},
url = {http://www.springerlink.com/index/l482m128476w5043.pdf},
year = {2006}
}
@article{Scherer2007,
abstract = {In earlier work, the authors analyzed emotion portrayals by professional actors separately for facial expression, vocal expression, gestures, and body movements. In a secondary analysis of the combined data set for all these modalities, the authors now examine to what extent actors use prototypical multimodal configurations of expressive actions to portray different emotions, as predicted by basic emotion theories claiming that expressions are produced by fixed neuromotor affect programs. Although several coherent unimodal clusters are identified, the results show only 3 multimodal clusters: agitation, resignation, and joyful surprise, with only the latter being specific to a particular emotion. Finding variable expressions rather than prototypical patterns seems consistent with the notion that emotional expression is differentially driven by the results of sequential appraisal checks, as postulated by componential appraisal theories.},
author = {Scherer, Klaus R and Ellgring, Heiner},
doi = {10.1037/1528-3542.7.1.158},
file = {::},
issn = {1528-3542},
journal = {Emotion (Washington, D.C.)},
keywords = {Adult,Affect,Facial Expression,Female,Gestures,Humans,Judgment,Male,Psychomotor Performance,Speech Acoustics,Voice},
month = feb,
number = {1},
pages = {158--71},
pmid = {17352571},
title = {{Multimodal expression of emotion: affect programs or componential appraisal patterns?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17352571},
volume = {7},
year = {2007}
}
@article{Prendinger2005,
abstract = {They designed an animated interface agent that accompanies the user in the setting of a virtual job interview. This interface application takes physiological data (skin conductance and electromyography) of a user in realtime, interprets them as emotions, and addresses the user’s affective states in the form of empathic feedback by employing embodied characters.},
annote = {They take physiological data (skin conductance and electromyography) of a user in real-time, interpret them as emotions, and address the user’s affective states by empathic feedback. A decision making agent relates these signals and the user’s answer to arousal and valence to infer the user’s emotional state by applying the model of Lang (1995) (Lang claims that all emotions can be characterized in terms of valence (pleasant or unpleasant) and arousal (calm or aroused)). Then it selects empathetic actions that maximize some utility function. They use text-based empathetic actions in addition to a small full body character.We can use the decision-theoretic agent aspect in our empathy model.
The empathy is mainly expressed in a text-base fashion in their job. The embodied agent that they have is so small and no facial expressions are used. There are some gestural expressions.
As shown in this paper and many other ones, text-base empathy expression can be effective. So we can use that too.
      },
author = {Prendinger, H and Ishizuka, M.},
file = {::;::},
journal = {Applied Artificial Intelligence},
keywords = {electromyography,physiological signals,skin conductance},
number = {3-4},
pages = {267--286},
publisher = {Citeseer},
title = {{The Empathic Companion - A Character-based Interface that Addresses Users’ Affective States}},
volume = {19},
year = {2005}
}
@inproceedings{Sourina2011,
address = {New York, New York, USA},
author = {Sourina, Olga and Liu, Y. and Nguyen, Minh Khoa},
booktitle = {SIGGRAPH Asia 2011 Posters on - SA '11},
doi = {10.1145/2073304.2073315},
file = {::},
isbn = {9781450311373},
pages = {1},
publisher = {ACM Press},
title = {{Emotion-enabled EEG-based interaction}},
url = {http://dl.acm.org/citation.cfm?doid=2073304.2073315},
year = {2011}
}
@article{VanSwol2003,
author = {{Van Swol}, Lyn M.},
doi = {10.1177/0093650203253318},
file = {::},
issn = {00000000},
journal = {Communication Research},
month = aug,
number = {4},
pages = {461--480},
title = {{The Effects of Nonverbal Mirroring on Perceived Persuasiveness, Agreement with an Imitator, and Reciprocity in a Group Discussion}},
volume = {30},
year = {2003}
}
@article{James1884,
abstract = {The physiologists who , during the past few years , have been so industriously exploring the functions of the brain , have limited their attempts at explanation to its cognitive and volitional per- formances . Dividing the brain into sensorial and motor centers , they have found their division to be exactly paralleled by the analysis made by empirical psychology , of the perceptive and volitional parts of the mind into their simplest elements . But the aesthetic sphere of the mind , its longings , its pleasures and pains , and its emotions , have been so ignored in all these researches that one is tempted to suppose that if either Dr . Ferrier or Dr . Munk were asked for a theory in brain-terms of the latter mental facts , they might both reply , either that they had as yet bestowed no thought upon the subject , or that they had found it so difficult to make distinct hypotheses , that the matter lay for them among the problems of the future , only to be taken up after the simpler ones of the present should have been definitely solved . And yet it is even now certain that of two things concerning the emotions , one must be true . Either separate and special centers affected to them alone , are their brain-seat , or else they correspond to processes occurring in the motor and sensory centers , already assigned , or in others like them , not yet mapped out . If the for- mer be the case we must deny the current view , and hold the cortex to be something more than the surface of projection for every sensitive spot and every muscle in the body . If the latter be the case , we must ask whether the emotional process in the sensory or motor center be an altogether peculiar one , or whether it resembles the ordinary perceptive processes of which those centers are already recognized to be the seat . The purpose of the following pages is to show that the last alternative comes nearest to the truth , and that the emotional brain-processes not only},
author = {James, William},
chapter = {188},
issn = {00264423},
journal = {Mind},
number = {34},
pages = {188--205},
publisher = {JSTOR},
title = {{What is an Emotion?}},
url = {http://www.jstor.org/stable/2246769},
volume = {9},
year = {1884}
}
@article{Vanbaaren2004,
author = {Van baaren, Rick B. and Holland, Rob W. and Kawakami, Kerry and Knippenberg, Ad Van},
doi = {10.1111/j.0963-7214.2004.01501012.x},
file = {::},
issn = {0956-7976},
journal = {Psychological Science},
month = jan,
number = {1},
pages = {71--74},
title = {{Mimicry and Prosocial Behavior}},
url = {http://pss.sagepub.com/lookup/doi/10.1111/j.0963-7214.2004.01501012.x},
volume = {15},
year = {2004}
}
@inproceedings{Schipor2011,
author = {Schipor, O.A. and Pentiuc, S.G. and Schipor, M.D.},
booktitle = {Speech Technology and Human-Computer Dialogue (SpeD), 2011 6th Conference on},
file = {::},
isbn = {9781457704413},
keywords = {-computer assisted,multimodal interfaces,recognition},
pages = {1--6},
publisher = {IEEE},
title = {{Towards a multimodal emotion recognition framework to be integrated in a Computer Based Speech Therapy System}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5940727},
year = {2011}
}
@article{Hodgson2002,
abstract = {Using the Alcohol Use Disorders Identification Test (AUDIT) as the gold standard, the Fast Alcohol Screening Test (FAST) was developed for use in busy medical settings. AUDIT questionnaires were completed by 666 patients in two London accident \& emergency (A\&E) departments. Using a principal components analysis, as well as sensitivity and specificity indices, a two-stage screening test was developed, using four of the AUDIT items. The first stage involved one item that identified >50\% of patients as either hazardous or non-hazardous drinkers. The second stage made use of the other three items to categorize the rest. The performance of this four-item questionnaire was then tested across a range of settings. Opportunistic samples of 100 patients completed AUDIT questionnaires in each of the following National Health Service settings: A\&E department, fracture clinic, primary health centre and a dental hospital. It was concluded that the four-item FAST questionnaire had good sensitivity and specificity, across a range of settings, when the AUDIT score was used as the gold standard. The FAST questionnaire is quick to administer, since >50\% of patients are categorized using just one question.},
author = {Hodgson, Ray and Alwyn, Tina and John, Bev and Thom, Betsy and Smith, Alyson},
institution = {University of Wales College of Medicine, Lansdowne Hospital, Cardiff CF11 8PL, UK.},
journal = {Alcohol and alcoholism Oxford Oxfordshire},
number = {1},
pages = {61--66},
publisher = {Oxford University Press},
title = {{The fast alcohol screening test.}},
url = {http://eprints.mdx.ac.uk/129/},
volume = {37},
year = {2002}
}
@article{Saunier2010,
author = {Saunier, Julien and Jones, Hazael and Lourdeaux, Domitile},
doi = {10.1109/WI-IAT.2010.255},
file = {::},
isbn = {978-1-4244-8482-9},
journal = {2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology},
keywords = {emotions,empathy,multi-agent architecture,personality,placebo},
month = aug,
pages = {277--282},
publisher = {Ieee},
title = {{Empathy and Placebo for Autonomous Agents}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5616059},
year = {2010}
}
@inproceedings{Pontier2010,
abstract = {In earlier studies, user involvement with an embodied software agent and willingness to use that agent were partially determined by the aesthetics of the design and the moral fiber of the character. We used these empirical results to model agents that in their turn would build up affect for their users much the same way as humans do for agents. Through simulations, we tested these models for internal consistency and were successful in establishing the relationships among the factors as suggested by the earlier user studies. This paper reports on the first confrontation of our agent system with real users to check whether users recognize that our agents function in similar ways as humans do. Through a structured questionnaire, users informed us whether our agents evaluated the user's aesthetics and moral stance while building up a level of involvement with the user and a degree of willingness to interact with the user again.},
author = {Pontier, Matthijs and Siddiqui, Ghazanfar and Hoorn, Johan F},
booktitle = {Proceedings of the 10th international conference on Intelligent virtual agents (IVA)},
file = {::},
keywords = {cognitive modeling,emotion modeling,empirical testing,humans,speed dating,virtual},
pages = {91--103},
publisher = {Springer-Verlag Berlin, Heidelberg},
title = {{Speed Dating with an Affective Virtual Agent - Developing a Testbed for Emotion Models}},
url = {http://dl.acm.org/citation.cfm?id=1889087},
year = {2010}
}
@article{Cowell2005,
abstract = {For years, people have sought more natural means of communicating with their computers. Many have suggested that interaction with a computer should be as easy as interacting with other people, taking advantage of the multimodal nature of human communication. While users should, in theory, gravitate to such anthropomorphic embodiments, quite the contrary has been experienced; users generally have been dissatisfied and abandoned their use. This suggests a disconnect between factors that make human-human communication engaging and those used by designers to support human-agent interaction. This paper discusses a set of empirical studies that attempted to replicate human-human non-verbal behavior. The focus revolved around behaviors that portray a credible fa\c{c}ade, thereby helping embodied conversational agents (ECAs) to form a successful cooperative dyad with users. Based on a review of the non-verbal literature, a framework was created that identified trustworthy and credible non-verbal behaviors across five areas and formed design guidelines for character interaction. The design suggestions for those areas emanating from the facial region were experimentally supported but there was no concordant increase in perceived trust when bodily regions (posture, gesture) were added. In addition, in examining the importance of demographic elements in embodiment, it was found that users prefer to interact with characters that match their ethnicity and are young looking. There was no significant preference for gender. The implications of these results, as well as other interesting consequences are discussed.},
author = {Cowell, Andrew J. and Stanney, Kay M.},
doi = {10.1016/j.ijhcs.2004.11.008},
file = {::},
issn = {10715819},
journal = {International Journal of Human-Computer Studies - Special issue: Subtle expressivity for characters and robots},
keywords = {Anthropomorphic interfaces,Interface agents,Non-verbal behavior},
month = feb,
number = {2},
pages = {281--306},
title = {{Manipulation of non-verbal interaction style and demographic embodiment to increase anthropomorphic computer character credibility}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1071581904001260 http://ocw.tudelft.nl/fileadmin/ocw/opener/Manipulation\_of\_non-verbal\_interaction\_style\_and\_demographic\_embodiment\_to\_increase\_anthropomorphic\_computer\_character\_credibility.pdf},
volume = {62},
year = {2005}
}
@book{Andreassi2009,
author = {Andreassi, John L.},
edition = {5},
publisher = {Taylor \& Francis},
title = {{Psychophysiology: Human Behavior and Physiological Response}},
year = {2009}
}
@inproceedings{Heerink2009,
author = {Heerink, Marcel and Krose, B. and Evers, Vanessa and Wielinga, Bob},
booktitle = {Robot and Human Interactive Communication, 2009. RO-MAN 2009. The 18th IEEE International Symposium on},
file = {::},
pages = {528--533},
publisher = {IEEE},
title = {{Measuring acceptance of an assistive social robot: a suggested toolkit}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5326320},
year = {2009}
}
@inproceedings{Doherty2004,
address = {Madison, WI},
author = {Doherty, William Joseph},
booktitle = {Policy Institute for Family Impact Seminars},
title = {{A family-focused approach to health care [Wisconsin Family Impact seminars]}},
year = {2004}
}
@inproceedings{Hubal2003,
abstract = {This paper describes lessons learned in developing the linguistic, cognitive, emotional, and gestural models underlying virtual human behavior in a training application designed to train civilian police officers how to recognize gestures and verbal cues indicating different forms of mental illness and how to verbally interact with the mentally ill. Schizophrenia, paranoia, and depression were all modeled for the application. For linguistics, the application has quite complex language grammars that captured a range of syntactic structures and semantic categories. For cognition, there is a great deal of augmentation to a plan-based transition network needed to model the virtual human’s knowledge. For emotions and gestures, virtual human behavior is based on expert-validated mapping tables specific to each mental illness. The paper presents five areas demanding continued research to improve virtual human behavior for use in training applications.},
address = {Miami, FL, US},
author = {Hubal, Robert C and Frank, Geoffrey A and Guinn, Curry I},
booktitle = {Proceedings of the 2003 International Conference on Intelligent User Interfaces (IUI'03)},
file = {::},
isbn = {1581135866},
keywords = {agents,behavior modeling,interaction skills training,managing encounters with the,mentally ill,responsive virtual humans},
pages = {85--92},
publisher = {ACM},
title = {{Lessons Learned in Modeling Schizophrenic and Depressed Responsive Virtual Humans for Training}},
year = {2003}
}
@article{Silverman2001,
abstract = {The goal of this research is to determine whether a computer based training game (HEART-SENSE) can improve recognition of heart attack symptoms and shift behavioral issues so as to reduce pre-hospitalization delay in seeking treatment. Since treatment delay correlates with adverse outcomes, this research could reduce myocardial infarction mortality and morbidity. In Phase I we created and evaluated a prototype virtual village in which users encounter and help convince synthetic personas to deal appropriately with a variety of heart attack scenarios and delay issues. Innovations made here are: (1) a design for a generic simulator package for promoting health behavior shifts, and (2) algorithms for animated pedagogical agents to reason about how their emotional state ties to patient condition and user progress. Initial results show that users of the game exhibit a significant shift in intention to call 9-1-1 and avoid delay, that multi-media versions of the game foster vividness and memory retention as well as a better understanding of both symptoms and of the need to manage time during a heart attack event. Also, results provide insight into areas where emotive pedagogical agents help and hinder user performance. Finally, we conclude with next steps that will help improve the game and the field of pedagogical agents and tools for simulated worlds for healthcare education and promotion.},
author = {Silverman, B G and Holmes, J and Kimmel, S and Branas, C and Ivins, D and Weaver, R and Chen, Y},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Silverman et al. - 2001 - Modeling emotion and behavior in animated personas to facilitate human behavior change the case of the HEART-SENSE game(4).pdf:pdf},
issn = {1386-9620},
journal = {Health care management science},
keywords = {Algorithms,Behavior Therapy,Computer Simulation,Computer-Assisted Instruction,Emotions,Experimental,Games,Humans,Models,Myocardial Infarction,Myocardial Infarction: diagnosis,Myocardial Infarction: physiopathology,Myocardial Infarction: psychology,Patient Acceptance of Health Care,Patient Acceptance of Health Care: psychology,Psychological,Software,United States},
month = sep,
number = {3},
pages = {213--28},
pmid = {11519847},
title = {{Modeling emotion and behavior in animated personas to facilitate human behavior change: the case of the HEART-SENSE game.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11519847},
volume = {4},
year = {2001}
}
@article{Cassell1999,
abstract = {In this article we describe results froman experiment of user interaction with autonomous , human - like ( humanoid ) conversational agents . We hypothesize that for embodied conversational agents , nonverbal behaviors related to the process of conversation , what we call envelope feedback, is much more important than other feedback , such as emotional expression . We test this hypothesis by having subjects interact with three autonomous agents , all capable of full - duplex multimodal interaction: able to generate and recognize speech , intonation , facial displays , and gesture . Each agent , however , gave a different kind of feedback: ( 1 ) content - related only , ( 2 ) content + envelope feedback , and ( 3 ) content + emotional . Content-related feedback includes answering questions and executing commands; envelope feedback includes behaviors such as gaze , manual beat gesture , and head movements; emotional feedback includes smiles and looks of puzzlement . Subjects' evaluations of the systemwere collected with a questionnaire , and videotapes of their speech patterns and behaviors were scored according to how often the users repeated themselves , how often they hesitated , and how often they got frustrated . The results confirmour hypothesis that envelope feedback is more important in interaction than emotional feedback and that envelope feedback plays a crucial role in supporting the process of dialog . A secondary result fromthis study shows that users give our multimodal conversational humanoids very high ratings of lifelikeness and fluidity of interaction when the agents are capable of giving such feedback .},
author = {Cassell, Justine and Thorisson, K.R.},
doi = {10.1080/088395199117360},
file = {::},
journal = {Applied Artificial Intelligence},
number = {4-5},
pages = {519--538},
publisher = {Taylor \& Francis},
title = {{The power of a nod and a glance: Envelope vs. emotional feedback in animated conversational agents}},
url = {http://www.tandfonline.com/doi/abs/10.1080/088395199117360},
volume = {13},
year = {1999}
}
@inproceedings{Cassell2001,
abstract = {The Behavior Expression Animation Toolkit (BEAT) allows animators to input typed text that they wish to be spoken by an animated human figure, and to obtain as output appropriate and synchronized nonverbal behaviors and synthesized speech in a form that can be sent to a number of different animation systems. The nonverbal behaviors are assigned on the basis of actual linguistic and contextual analysis of the typed text, relying on rules derived from extensive research into human conversational behavior. The toolkit is extensible, so that new rules can be quickly added. It is designed to plug into larger systems that may also assign personality profiles, motion characteristics, scene constraints, or the animation styles of particular animators.},
author = {Cassell, Justine and Vilhj\'{a}lmsson, HH and Bickmore, Timothy W.},
booktitle = {Proceedings of the 28th annual conference on Computer graphics and interactive techniques (SIGGRAPH '01)},
doi = {10.1145/383259.383315},
file = {::},
keywords = {animation systems,facial animation,gesture,speech synthesis},
pages = {477--486},
publisher = {ACM},
title = {{BEAT: the behavior expression animation toolkit}},
url = {http://dl.acm.org/citation.cfm?id=383315},
year = {2001}
}
@article{Shimoda2000,
author = {Shimoda, H. and Kunihiro, T. and Yang, D. and Yoshikawa, H.},
doi = {10.1109/IECON.2000.972406},
file = {::},
isbn = {0-7803-6456-2},
journal = {2000 26th Annual Conference of the IEEE Industrial Electronics Society. IECON 2000. 2000 IEEE International Conference on Industrial Electronics, Control and Instrumentation. 21st Century Technologies and Industrial Opportunities (Cat. No.00CH37141)},
pages = {2589--2594},
publisher = {Ieee},
title = {{Design of affective interface for realizing human-machine empathy}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=972406},
volume = {4},
year = {2000}
}
@inproceedings{Polajnar2011,
author = {Polajnar, Jernej and Dalvandi, B. and Polajnar, D.},
booktitle = {Cognitive Informatics \& Cognitive Computing (ICCI'CC'11), 2011 10th IEEE International Conference on},
file = {::},
isbn = {9781457716973},
pages = {96--102},
publisher = {IEEE},
title = {{Does empathy between artificial agents improve agent teamwork?}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6016126},
year = {2011}
}
@article{Prendinger2006,
annote = {they have tested 4 different empathic behaviours in a competitive card game.
1- Non-Emotional2- Self-Centered Emotional
3- Negative Empathic 
4- Positive Empathic 
They found out that:
 - absence of the agent's display of negative emotions is arousing for the user and highers his/her stress.
 - valence of users' emotional response is congruent with the valence of the emotion expressed by the agent.},
author = {Prendinger, H and Becker-Asano, Christian},
file = {::},
journal = {International Journal of Humanoid},
keywords = {affective behavior,empathy,evaluation,life-like characters,physiological user information},
number = {3},
pages = {371--391},
title = {{A STUDY IN USERS'S;PHYSIOLOGICAL RESPONSE TO AN EMPATHIC INTERFACE AGENT}},
volume = {3},
year = {2006}
}
@article{Breemen2005,
author = {van Breemen, A and Yan, X},
file = {::},
journal = {Proceedings of the fourth},
pages = {143--144},
title = {{iCat: an animated user-interface robot with personality}},
url = {http://dl.acm.org/citation.cfm?id=1082823},
year = {2005}
}
@inproceedings{Smith2010,
abstract = {The development of Embodied Conversational Agents (ECA) as Companions brings several challenges for both affective and conversational dialogue. These include challenges in generating appropriate affective responses, selecting the overall shape of the dialogue, providing prompt system response times and handling interruptions. We present an implementation of such a Companion showing the development of individual modules that attempt to address these challenges. Further, to resolve resulting conflicts, we present encompassing interaction strategies that attempt to balance the competing requirements. Finally, we present dialogues from our working prototype to illustrate these interaction strategies in operation.},
author = {Smith, Cameron and Crook, Nigel and Boye, Johan and Charlton, Daniel and Dobnik, Simon and Pizzi, David and Cavazza, Marc and Pulman, Stephen},
booktitle = {IVA'10 Proceedings of the 10th international conference on Intelligent virtual agents},
file = {::},
keywords = {affective dialogue,companion,conversational dialogue,embodied conversational agents,interaction strategies,interruptions},
pages = {301--314},
publisher = {Springer-Verlag Berlin, Heidelberg},
title = {{Interaction Strategies for an Affective Conversational Agent}},
year = {2010}
}
@article{Meijer1989,
abstract = {The present study was designed to assess the contribution of general features of gross body movements to the attribution of emotions. Eighty-five adult subjects were shown ninety-six videotaped body movements, performed by three actors. Each movement was determined by seven general dimensions: trunk movement, arm movement, vertical direction, sagittal direction, force, velocity and directness. Using rating scales, the subjects judged the compatibility of each movement with each of twelve emotion categories. The results showed which movement features predicted particular ratings. Emotion categories differed as to the amount, type, and weights of predicting movement features. Three factors were extracted from the original ratings and interpreted as Rejection-Acceptance, Withdrawal-Approach, and Preparation-Defeatedness.},
author = {Meijer, Marco},
doi = {10.1007/BF00990296},
issn = {01915886},
journal = {Journal of Nonverbal Behavior},
number = {4},
pages = {247--268},
publisher = {Springer},
title = {{The contribution of general features of body movement to the attribution of emotions}},
url = {http://www.springerlink.com/index/10.1007/BF00990296},
volume = {13},
year = {1989}
}
@article{Baldassarri2008,
abstract = {This paper presents a powerful animation engine for developing applications with embodied animated agents called Maxine. The engine, based on open source tools, allowsmanagement of scenes and virtual characters, and pays special attention to multimodal and emotional interaction with the user. Virtual actors are endowed with facial expressions, lip-synch, emotional voice, and they can vary their answers depending on their own emotional state and the relationship with the user during conversation. Maxine virtual agents have been used in several applications: a virtual presenterwas employed in MaxinePPT, a specific application developed to allow non-programmers to create 3D presentations easily using classical PowerPoint presentations; a virtual character was also used as an interactive interface to communicate with and control a domotic environment; finally, an interactive pedagogical agent was used to simplify and improve the teaching and practice of Computer Graphics subjects.},
annote = {Summery: 
        
Their system is an animating engine which allows management of scenes and virtual characters. It provides multimodal emotional interaction with the user. The virtual characters have different emotional facial expressions, lip-synch, and emotional voice. The expressions are selected based on the character's emotional state and the relationship with the user during conversation.
        
In this research they focus on the interactive virtual agents that support multimodal and emotional interaction in order to establish more effective communication with the user. So, the character captures the user’s emotional facial expressions through a camera, and responds with appropriate emotional facial expressions and voices.
        
They use Ekman’s emotional facial classification for recognition and expression: happiness, sadness, anger, fear, surprise, disgust, and neutral.
        
Positive points:
        
 - Good references for us: 
        
"most research on social interfaces is related to the design of embodied conversational agents (ECAs) [1]".
        
"Virtual characters equipped with these new features can be used in a wide range of contexts [2,3], including education and learning [4–8], sign language interpretation [9], therapy [10], persuasion [11,12],entertainment [13,14], among others".
        
"In order to achieve a more natural and realistic interaction,
virtual agents must be capable of appropriately responding to users with affective feedback [15]".
        
 - another application that we can add to the future grants:
we can use our system to interact with with disabled clients (for example, the hearing-impaired or paraplegics) if we add appropriate voice recognition, NLP, and body languages to the system.
        
 - they use a voice recognition engine built on the commercial Loquendo ASR software [22] which we can use too. 
        
- They use the same model as our system for the character's feedbacks. There are 2 kinds of character feedbacks in their system: 1- Purely reactive: For example, if the user keys something in, the virtual character will interrupt the presentation; or if the user changes his or her position, the character’s look/ orientation will change; if a lot of background noise is detected, it will request silence, etc. 
        
2- Deliberative: The choice of the virtual character’s reaction needs more complex analysis.
 - They use emotional voice as another modality by modifying the tone, frequency scale, volume and speed. We can do the same to add the another modality to the emotion expression of our system. 
        
        
Negative points:
        
 - It is not clear what avatar system they use. It looks like Haptek, but because of the way they talk about animating the character it might be another system.
        
 - They don't present their model of feedback in details. So we don't know how their system decides what to express based on the inputs (mouse, keyboard, user emotions, character emotions, user position).
        
      },
author = {Baldassarri, Sandra and Cerezo, Eva and Seron, Francisco J.},
doi = {10.1016/j.cag.2008.04.006},
file = {::},
issn = {00978493},
journal = {Computers \& Graphics},
keywords = {Animated characters,Multimodal interfaces,Natural interaction,Virtual worlds},
month = aug,
number = {4},
pages = {430--437},
title = {{Maxine: A platform for embodied animated agents}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0097849308000472},
volume = {32},
year = {2008}
}
@article{Resnicow2002,
author = {Resnicow, Ken and DiIorio, Colleen and Soet, Johanna E. and Borrelli, Belinda and Hecht, Jacki and Ernst, Denise},
doi = {10.1037//0278-6133.21.5.444},
file = {::},
issn = {0278-6133},
journal = {Health Psychology},
keywords = {and,behavioral medicine,counseling,fully discussed in a,health promotion,health psychology,in 1983 and more,mi,motivational interviewing,originally described by miller,public health,seminal text by miller},
number = {5},
pages = {444--451},
title = {{Motivational interviewing in health promotion: It sounds like something is changing.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0278-6133.21.5.444},
volume = {21},
year = {2002}
}
@book{Preston2007,
author = {Preston, SD},
booktitle = {Empathy in mental illness},
file = {::},
isbn = {0521847346},
pages = {428--447},
publisher = {Cambridge University Press},
title = {{Empathy in Mental Illness}},
url = {http://www-personal.umich.edu/~prestos/Downloads/Preston2007\_MI.pdf},
year = {2007}
}
@inproceedings{Schipor2011,
author = {Schipor, O.A. and Pentiuc, S.G. and Schipor, M.D.},
booktitle = {Speech Technology and Human-Computer Dialogue (SpeD), 2011 6th Conference on},
file = {::},
isbn = {9781457704413},
keywords = {-computer assisted,multimodal interfaces,recognition},
pages = {1--6},
publisher = {IEEE},
title = {{Towards a multimodal emotion recognition framework to be integrated in a Computer Based Speech Therapy System}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5940727},
year = {2011}
}
@article{CoanJr1984,
abstract = {Rapport is a characteristic of a relationship if there is a high degree of empathy, attention, and shared understanding and expectations. Rapport should be enhanced when the salesperson and the customer are comembers of the same group. Also, rapport should aid persuasion and help increase consumer satisfaction. Both observational and paper-and-pencil techniques can be used to measure rapport.},
author = {{Coan Jr}, G.},
file = {::},
journal = {Advances in Consumer Research},
pages = {333--336},
title = {{RAPPORT: DEFINITION AND DIMENSIONS}},
url = {http://www.acrwebsite.org/volumes/display.asp?id=6269},
volume = {11},
year = {1984}
}
@misc{TheMendeleySupportTeam2011,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/The Mendeley Support Team - 2011 - Getting Started with Mendeley(4).pdf:pdf},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@inproceedings{Nguyen2009a,
abstract = {Experiencing emotional distress is the number one reason why people who are undergoing behaviour modification (e.g. quitting smoking, dieting) suffer from relapses. Providing emotional support is an effective way to help them overcome the unpleasant effects of negative affect and adhere to their regimen. Building computers with such ability has grabbed the attention of the HCI community in recent years. This paper presents the results of a 2 (modality: animated vs. no visual) by 3 (intervention: non-empathy vs. empathy vs. empathy and expressivity) between-subjects study that investigates the impact of two important factors and their interaction in the design of such systems: (1) different ways of expressing empathy, and (2) the modality of delivering such content.},
annote = {They investigate: 
1-      Different ways of expressing empathy 
2-      Modality of delivering such content. 
        
They define empathy as the ability to detect what others feel and to experience that emotion ourselves (seems like mimicry).
        
Empirical evidence indicates that expressing accurate empathy can lead to positive psychological, physical and health outcomes.
        
Their results show: 
1. The positive attitude of the users toward active support (active empathy). 
2.  The positive outcome of an empathic system regardless of its representation. 
3.  A system represented by a human-like representation is expected to be empathic.
        
they believe, adding a mechanism to allow the users to freely express themselves does not improve the effectiveness or liking of an empathic system.
      },
author = {Nguyen, H. and Masthoff, Judith},
booktitle = {Proceedings of the 4th International Conference on Persuasive Technology},
file = {::},
isbn = {9781605583761},
keywords = {affective computing,design,experimentation,human factors},
pages = {7},
publisher = {ACM},
title = {{Designing empathic computers: the effect of multimodal empathic feedback using animated agent}},
url = {http://portal.acm.org/citation.cfm?id=1541958},
year = {2009}
}
@article{Huang2010,
author = {Huang, Lixing and Morency, Louis-Philippe and Gratch, Jonathan},
file = {::},
journal = {of the 9th International Conference on},
number = {Aamas},
pages = {10--14},
title = {{Parasocial consensus sampling: combining multiple perspectives to learn virtual human behavior}},
url = {http://dl.acm.org/citation.cfm?id=1838371},
year = {2010}
}
@article{Segal2011,
author = {Segal, Elizabeth},
doi = {10.1080/01488376.2011.564040},
file = {::},
issn = {0148-8376},
journal = {Journal of Social Service Research},
keywords = {a dedication to justice,a nation that proclaims,and social well-being and,civic involvement,empathy,scapegoating,social empathy,social responsibility,the united states is},
month = may,
number = {3},
pages = {266--277},
title = {{Social Empathy: A Model Built on Empathy, Contextual Understanding, and Social Responsibility That Promotes Social Justice}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/01488376.2011.564040\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {37},
year = {2011}
}
@book{Frijda1986,
address = {New York},
author = {Frijda, Nico H.},
isbn = {9780521316002},
pages = {544},
publisher = {Cambridge University Press},
title = {{The Emotions}},
year = {1986}
}
@article{Zeng2009,
abstract = {Automated analysis of human affective behavior has attracted increasing attention from researchers in psychology, computer science, linguistics, neuroscience, and related disciplines. However, the existing methods typically handle only deliberately displayed and exaggerated expressions of prototypical emotions despite the fact that deliberate behaviour differs in visual appearance, audio profile, and timing from spontaneously occurring behaviour. To address this problem, efforts to develop algorithms that can process naturally occurring human affective behaviour have recently emerged. Moreover, an increasing number of efforts are reported toward multimodal fusion for human affect analysis including audiovisual fusion, linguistic and paralinguistic fusion, and multi-cue visual fusion based on facial expressions, head movements, and body gestures. This paper introduces and surveys these recent advances. We first discuss human emotion perception from a psychological perspective. Next we examine available approaches to solving the problem of machine understanding of human affective behavior, and discuss important issues like the collection and availability of training and test data. We finally outline some of the scientific and engineering challenges to advancing human affect sensing technology.},
author = {Zeng, Zhihong and Pantic, Maja and Roisman, Glenn I and Huang, Thomas S.},
doi = {10.1109/TPAMI.2008.52},
file = {::},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Affect,Affect: physiology,Algorithms,Artificial Intelligence,Automated,Automated: methods,Emotions,Emotions: physiology,Facial Expression,Monitoring,Pattern Recognition,Physiologic,Physiologic: methods,Sound Spectrography,Sound Spectrography: methods},
month = jan,
number = {1},
pages = {39--58},
pmid = {19029545},
title = {{A survey of affect recognition methods: audio, visual, and spontaneous expressions.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19029545},
volume = {31},
year = {2009}
}
@incollection{WeinerBGraham1984,
address = {New York},
author = {{Weiner B Graham}, S},
booktitle = {Emotions, cognition, and behavior},
editor = {Izard, Carroll E and Kagan, J and Zajonc, Robert B},
pages = {167--191},
publisher = {Cambridge University Press},
title = {{An attributional approach to emotional development}},
year = {1984}
}
@article{Lakin2003,
abstract = {The “chameleon effect” refers to the tendency to adopt the postures, gestures, and mannerisms of interaction partners (Chartrand \& Bargh, 1999). This type of mimicry occurs outside of conscious awareness, and without any intent to mimic or imitate. Empirical evidence suggests a bi-directional relationship between nonconscious mimicry on the one hand, and liking, rapport, and affiliation on the other. That is, nonconscious mimicry creates affiliation, and affiliation can be ex- pressed through nonconscious mimicry. We argue that mimicry played an impor- tant role in human evolution. Initially, mimicry may have had survival value by helping humans communicate. We propose that the purpose of mimicry has now evolved to serve a social function. Nonconscious behavioral mimicry increases af- filiation, which serves to foster relationships with others. We review current re- search in light of this proposed framework and suggest future areas of research.},
annote = {nonconscious mimicry creates affiliation, and affiliation can be expressed through nonconscious mimicry.
Initially, mimicry may have had survival value by helping humans communicate. The purpose of mimicry has now evolved to serve a social function. Nonconscious behavioral mimicry increases affiliation, which serves to foster relationships with others.
Empathic individuals mimic people more that people low in empathy.},
author = {Lakin, J. L. and Jefferis, VE and Cheng, CM},
file = {::},
journal = {Journal of nonverbal Behavior},
keywords = {affiliation,chameleon effect,human evolution,mimicry},
number = {3},
pages = {145--162},
title = {{The chameleon effect as social glue: Evidence for the evolutionary significance of nonconscious mimicry}},
volume = {27},
year = {2003}
}
@article{James1884,
abstract = {The physiologists who , during the past few years , have been so industriously exploring the functions of the brain , have limited their attempts at explanation to its cognitive and volitional per- formances . Dividing the brain into sensorial and motor centers , they have found their division to be exactly paralleled by the analysis made by empirical psychology , of the perceptive and volitional parts of the mind into their simplest elements . But the aesthetic sphere of the mind , its longings , its pleasures and pains , and its emotions , have been so ignored in all these researches that one is tempted to suppose that if either Dr . Ferrier or Dr . Munk were asked for a theory in brain-terms of the latter mental facts , they might both reply , either that they had as yet bestowed no thought upon the subject , or that they had found it so difficult to make distinct hypotheses , that the matter lay for them among the problems of the future , only to be taken up after the simpler ones of the present should have been definitely solved . And yet it is even now certain that of two things concerning the emotions , one must be true . Either separate and special centers affected to them alone , are their brain-seat , or else they correspond to processes occurring in the motor and sensory centers , already assigned , or in others like them , not yet mapped out . If the for- mer be the case we must deny the current view , and hold the cortex to be something more than the surface of projection for every sensitive spot and every muscle in the body . If the latter be the case , we must ask whether the emotional process in the sensory or motor center be an altogether peculiar one , or whether it resembles the ordinary perceptive processes of which those centers are already recognized to be the seat . The purpose of the following pages is to show that the last alternative comes nearest to the truth , and that the emotional brain-processes not only},
author = {James, William},
chapter = {188},
issn = {00264423},
journal = {Mind},
number = {34},
pages = {188--205},
publisher = {JSTOR},
title = {{What is an Emotion?}},
url = {http://www.jstor.org/stable/2246769},
volume = {9},
year = {1884}
}
@article{Welch2002,
author = {Welch, G. and Guthrie, D. W.},
doi = {10.2337/diaspect.15.3.203},
file = {::},
issn = {1040-9165},
journal = {Diabetes Spectrum},
month = jul,
number = {3},
pages = {203--207},
title = {{Supporting Lifestyle Change With a Computerized Psychosocial Assessment Tool}},
url = {http://spectrum.diabetesjournals.org/cgi/doi/10.2337/diaspect.15.3.203},
volume = {15},
year = {2002}
}
@article{Schneier2011,
author = {Schneier, B.},
file = {::},
journal = {Security \& Privacy, IEEE},
number = {5},
pages = {88--88},
publisher = {IEEE},
title = {{Empathy and Security}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6029366},
volume = {9},
year = {2011}
}
@book{Scherer2001,
address = {New York, NY, US},
author = {Scherer, Klaus R},
editor = {{Scherer, Klaus R. and Schorr, Angela and Johnstone}, Tom},
isbn = {0-19-513007-3},
keywords = {appraisal,cognitive-motivational-relational theory of emotio,coping,emotions,psychological stress,theory development},
pages = {478},
publisher = {Oxford University Press},
title = {{Appraisal processes in emotion: Theory, methods, research}},
year = {2001}
}
@inproceedings{Higashinaka2008,
author = {Higashinaka, R. and Dohsaka, K. and Isozaki, H.},
booktitle = {Spoken Language Technology Workshop, 2008. SLT 2008. IEEE},
file = {::},
isbn = {9781424434725},
pages = {109--112},
publisher = {IEEE},
title = {{Effects of self-disclosure and empathy in human-computer dialogue}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4777852},
year = {2008}
}
@article{Stockwell1983,
author = {Stockwell, T and Murphy, D and Hodgson, R},
journal = {British journal of addiction},
number = {2},
pages = {145--155},
pmid = {6135435},
title = {{The severity of alcohol dependence questionnaire: its use, reliability and validity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/6135435},
volume = {78},
year = {1983}
}
@article{Hatfield2009,
author = {Hatfield, Elaine and Rapson, Richard L. and Le, Yen-Chi L.},
file = {::},
journal = {The social neuroscience of empathy},
pages = {1--20},
title = {{Emotional Contagion and Empathy}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=KLvJKTN\_nDoC\&amp;oi=fnd\&amp;pg=PA19\&amp;dq=Emotional+Contagion+and+Empathy\&amp;ots=gC929Xij3X\&amp;sig=IFpRxpx1igOlZl86Jr837oVgfhY},
year = {2009}
}
@article{Mehrabian1972,
author = {Mehrabian, Albert and Epstein, N},
file = {::},
journal = {Journal of Personality},
number = {4},
pages = {525--543},
pmid = {4642390},
publisher = {Wiley Online Library},
title = {{A measure of emotional empathy.}},
volume = {40},
year = {1972}
}
@article{Campbell2005,
author = {Campbell, K.S.},
doi = {10.1109/IPCC.2005.1494206},
file = {::},
isbn = {0-7803-9027-X},
journal = {IPCC 2005. Proceedings. International Professional Communication Conference, 2005.},
keywords = {communication,face-to-face interaction,health,medical interviews,sociolinguistics,verbal communication},
pages = {422--432},
publisher = {Ieee},
title = {{The rapport management model: how physicians build relationships with patients}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1494206},
year = {2005}
}
@article{Sharma1998,
author = {Sharma, R. and Pavlovic, V.I. and Huang, Thomas S.},
file = {::},
journal = {Proceedings of the IEEE},
keywords = {computer interface,human,multimodality,sensor},
number = {5},
pages = {853--869},
publisher = {IEEE},
title = {{Toward multimodal human-computer interface}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=664275},
volume = {86},
year = {1998}
}
@article{Feshbach1968,
author = {Feshbach, N D and Roe, K},
journal = {Child Development},
number = {1},
pages = {133--145},
pmid = {5645790},
title = {{Empathy in six- and seven-year-olds.}},
volume = {39},
year = {1968}
}
@article{Prendinger2006,
annote = {they have tested 4 different empathic behaviours in a competitive card game.
1- Non-Emotional2- Self-Centered Emotional
3- Negative Empathic 
4- Positive Empathic 
They found out that:
 - absence of the agent's display of negative emotions is arousing for the user and highers his/her stress.
 - valence of users' emotional response is congruent with the valence of the emotion expressed by the agent.},
author = {Prendinger, H and Becker, Christian},
file = {::},
journal = {International Journal of Humanoid},
keywords = {affective behavior,empathy,evaluation,life-like characters,physiological user information},
number = {3},
pages = {371--391},
title = {{A STUDY IN USERS'S;PHYSIOLOGICAL RESPONSE TO AN EMPATHIC INTERFACE AGENT}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.77.9379\&amp;rep=rep1\&amp;type=pdf},
volume = {3},
year = {2006}
}
@incollection{Wispe1987,
author = {Wisp\'{e}, L},
booktitle = {Empathy and its development},
chapter = {2},
editor = {Einsenberg, Nancy and Strayer, Janet},
isbn = {0521326095},
issn = {05213260},
pages = {17--37},
publisher = {Cambridge University Press},
title = {{History of the concept of empathy}},
year = {1987}
}
@article{Linke2004,
abstract = {Abstract—Aims: To conduct a pilot study of the usefulness of Down Your Drink (DYD), a web-based intervention to encourage excessive drinkers to adopt a healthy pattern of drinking and reduce alcohol-associated harm. The DYD website was structured as a 6-week programme, derived from a manual which included elements of motivational approaches and cognitive behavioural therapy. Methods: Visitors whose responses to the Fast Alcohol Screening Test were positive, and those indicating excessive alcohol con- sumption, were encouraged to register. Users completed alcohol dependence and mental health questionnaires before the programme, and a drinking diary at each of the weekly sessions. Follow-up questionnaires were sent electronically to those who completed the programme, or who missed three or more sessions. Results: During the 6-month study there were 7581 visits to the site and 1319 registrations. Of the registrants, 61.8\% completed week 1, and 6.0\% stayed with the programme until the end. The 6\% who stayed for 6 weeks provided encouraging feedback about the value of the site. Little information was obtained from those who dropped out, but some reported that the programme was too time-consuming. Conclusions: Web site interventions for excessive drinkers are feasible and merit evaluation of their effectiveness.},
author = {Linke, S.},
doi = {10.1093/alcalc/agh004},
file = {::},
issn = {1464-3502},
journal = {Alcohol and Alcoholism},
month = jan,
number = {1},
pages = {29--32},
title = {{Down Your Drink: a Web-Based Intervention for People With Excessive Alcohol Consumption}},
url = {http://www.alcalc.oupjournals.org/cgi/doi/10.1093/alcalc/agh004},
volume = {39},
year = {2004}
}
@article{Bryant2008,
author = {Bryant, Gregory a. and Barrett, H. Clark},
doi = {10.1163/156770908X289242},
file = {::},
issn = {15677095},
journal = {Journal of Cognition and Culture},
keywords = {and can include bodily,com-,cross-cultural comparisons,deployed physical displays with,emotional expressions are strategically,evolutionary psychology,facial movements and,gestures,municative function,speech,universals,vocal emotion},
month = apr,
number = {1},
pages = {135--148},
title = {{Vocal Emotion Recognition Across Disparate Cultures}},
url = {http://openurl.ingenta.com/content/xref?genre=article\&issn=1567-7095\&volume=8\&issue=1\&spage=135},
volume = {8},
year = {2008}
}
@incollection{Bavelas1987,
address = {Cambridge, UK},
author = {Bavelas, Janet Beavin and Black, Alex and Lemery, Charles R. and Mullett, Jennifer},
booktitle = {Motor mimicry as primitive empathy},
editor = {Eisenberg, Nancy and Strayer, Janet},
file = {::},
pages = {317--338},
publisher = {Cambridge University Press},
title = {{Empathy and its developement}},
year = {1987}
}
@article{Benamara2007,
abstract = {To date, there is almost no work on the use of adverbs in sentiment analysis, nor has there been any work on the use of adverb-adjective combinations (AACs). We propose an AAC-based sentiment analysis technique that uses a linguistic analysis of adverbs of degree. We define a set of general axioms (based on a classification of adverbs of degree into five categories) that all adverb scoring techniques must satisfy. Instead of aggregating scores of both adverbs and adjectives using simple scoring functions, we propose an axiomatic treatment of AACs based on the linguistic classification of adverbs. Three specific AAC scoring methods that satisfy the axioms are presented. We describe the results of experiments on an annotated set of 200 news articles (annotated by 10 students) and compare our algorithms with some existing sentiment analysis algorithms. We show that our results lead to higher accuracy based on Pearson correlation with human subjects.},
author = {Benamara, Farah and Irit, Sabatier and Cesarano, Carmine and Federico, Napoli and Reforgiato, Diego},
journal = {In Proc of Int Conf on Weblogs and Social Media},
keywords = {adverb adjective combina,adverbs degree,sentiment analysis},
pages = {1--4},
title = {{Sentiment Analysis : Adjectives and Adverbs are better than Adjectives Alone}},
url = {http://www.icwsm.org/papers/3--Benamara-Cesarano-Picariello-Reforgiato-Subrahmanian.pdf},
year = {2007}
}
@incollection{Catucci2006,
abstract = {Empathy is a distributed environment for the generation of emotions and other related affective phenomena like moods and temperaments. Empathy has been conceived as an object-oriented reusable framework entirely written in Java and realized for the purpose of studying the direct influences of emotions on behaviors and on decision-making processes of autonomous agents, interacting in complex or real environments. It allows for the realization of custom emotional agents, usable in several different domains, from the educational applications (e.g. entertainment, video games, intelligent tutoring systems.) to control systems in autonomous robots.},
author = {Catucci, Graziano and Abbattista, Fabio and Gadaleta, R. and Guaccero, Domenico and Semeraro, Giovanni},
booktitle = {Applied Soft Computing Technologies: The Challenge of Complexity},
doi = {10.1007/3-540-31662-0\_21},
file = {::},
isbn = {978-3-540-31649-7},
keywords = {autonomous agents,emotional agents,synthetic characters},
pages = {265--277},
publisher = {Springer Berlin / Heidelberg},
title = {{Empathy: A computational framework for emotion generation}},
url = {http://www.springerlink.com/index/LJ26L065L0072722.pdf http://dx.doi.org/10.1007/3-540-31662-0\_21},
year = {2006}
}
@article{Kiesler2008,
author = {Kiesler, Sara and Powers, Aaron and Fussell, Susan R. and Torrey, Cristen},
doi = {10.1521/soco.2008.26.2.169},
file = {::},
issn = {0278-016X},
journal = {Social Cognition},
month = apr,
number = {2},
pages = {169--181},
title = {{Anthropomorphic Interactions with a Robot and Robot–like Agent}},
url = {http://guilfordjournals.com/doi/abs/10.1521/soco.2008.26.2.169},
volume = {26},
year = {2008}
}
@article{Paiva2000,
author = {Paiva, Ana},
file = {::},
journal = {Affective interactions},
pages = {1--8},
title = {{Affective interactions: toward a new generation of computer interfaces?}},
url = {http://www.springerlink.com/index/826w110p65762167.pdf},
year = {2000}
}
@inproceedings{Neviarouskaya2007a,
abstract = {In this paper, we focus on affect recognition from text in order to facilitate sensitive and expressive communication in computer-mediated environments. Our model for analyzing affect conveyed by text is tailored to handle the style and specifics of informal online conversations. The motivation behind our approach is to improve social interactivity and emotional expressiveness of real-time messaging. In order to estimate affect in text, our model processes symbolic cues, such as emoticons, detects and transforms abbreviations, and employs natural language processing techniques for word/phrase/sentence-level analysis, e.g. by considering relations among words in a sentence. As a result of the analysis, text can be categorized into emotional states and communicative functions. A designed graphical repre- sentation of a user (avatar) displays emotions and social behaviour driven by text and performs natural idle move- ments. The proposed system shows promising results on affect recognition in real examples of online conversation.},
address = {Honolulu, Hawaii, USA},
author = {Neviarouskaya, Alena and Prendinger, Helmut and Ishizuka, Mitsuru},
booktitle = {Proceedings of the 12th international conference on Intelligent user interfaces - IUI '07},
doi = {10.1145/1216295.1216346},
file = {::},
isbn = {1595934812},
keywords = {Affective computing,affective user interface,avatar,emotions,online communication},
pages = {278--281},
publisher = {ACM Press},
title = {{Analysis of affect expressed through the evolving language of online communication}},
url = {http://portal.acm.org/citation.cfm?doid=1216295.1216346},
year = {2007}
}
@phdthesis{Sze2005,
author = {Sze, Ian},
booktitle = {Ambient Intelligence in Everyday Life},
file = {::},
school = {UNIVERSITY OF NEW SOUTH WALES},
title = {{Empathic computing}},
year = {2005}
}
@article{Orozco2010,
author = {Orozco, H. and Thalmann, Daniel and Ramos, F.},
file = {::},
journal = {Proceedings of 11th Computer Graphics International, CGI},
title = {{Making empathetic virtual humans in human–computer interaction scenarios}},
url = {http://cgi2010.miralab.unige.ch/short/SP09/SP09.pdf},
volume = {10},
year = {2010}
}
@article{Hine2009,
author = {Hine, Michael J. and Murphy, Steven a. and Weber, Michael and Kersten, Gregory},
doi = {10.1007/s10726-008-9151-9},
file = {::},
issn = {0926-2644},
journal = {Group Decision and Negotiation},
keywords = {computer mediated communication,electronic negotiation,emotion,logistic regression},
month = jan,
number = {3},
pages = {193--211},
title = {{The Role of Emotion and Language in Dyadic E-negotiations}},
url = {http://www.springerlink.com/index/10.1007/s10726-008-9151-9},
volume = {18},
year = {2009}
}
@inproceedings{Cavazza2010a,
abstract = {We demonstrate a “Companion” ECA, which is able to provide advice and support to the user, taking into account emotions expressed by her through dialogue. The integration of all required multimodal I/O components is based on interaction strategies defining the shape of dialogue, on the ECA’s response times, and on the underlying affective strategy. The system supports free conversation on an everyday life scenario in which the user comments her day at the office.},
address = {Toronto, Canada,},
author = {Cavazza, Marc and Vargas, C Emilio},
booktitle = {Proc. of and Multiagent 9th Int. Systems Conf. on Autonomous Agents (AAMAS 2010)},
editor = {van der Hoek, Kaminka and Lesp\'{e}rance, Luck and Sen},
file = {::},
keywords = {Affective Interfaces,Embodied Conversational Agents,Human- Computer Dialogue.},
number = {Aamas},
pages = {1629--1630},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org)},
title = {{How Was Your Day ? A Companion ECA}},
year = {2010}
}
@article{Walters2005,
abstract = {In response to the persistent problem of college drinking, universities have instituted a range of alcohol intervention programs for students. Motivational feedback is one intervention that has garnered support in the literature and been adopted on college campuses. This article reviews published outcome studies that have utilized feedback as a major component of an alcohol intervention for college students. Overall, 11 of the 13 reviewed studies (77\%) found a significant reduction in drinking as compared to a control or comparison group. While the studies varied widely in terms of population, follow-up period, and feedback content, it appears that feedback can be effective whether delivered by mail, the Internet, or via a face-to-face motivational interview. Feedback seems to change normative perceptions of drinking and may be more effective among students who drink for social reasons. The addition of a group or individual counseling session does not appear to increase the short-term impact of the feedback.},
author = {Walters, Scott T and Neighbors, Clayton},
doi = {10.1016/j.addbeh.2004.12.005},
issn = {0306-4603},
journal = {Addictive behaviors},
keywords = {Alcohol-Related Disorders,Alcohol-Related Disorders: rehabilitation,Biofeedback, Psychology,Biofeedback, Psychology: methods,Humans,Motivation,Student Health Services,Student Health Services: methods,Students,Students: psychology},
month = jul,
number = {6},
pages = {1168--82},
pmid = {15925126},
title = {{Feedback interventions for college alcohol misuse: what, why and for whom?}},
url = {http://dx.doi.org/10.1016/j.addbeh.2004.12.005},
volume = {30},
year = {2005}
}
@article{Grahe1999,
author = {Grahe, JE},
file = {::},
journal = {Journal of Nonverbal behavior},
number = {4},
pages = {253--269},
title = {{The importance of nonverbal cues in judging rapport}},
url = {http://www.springerlink.com/index/V8U30855W38M4673.pdf},
volume = {23},
year = {1999}
}
@inproceedings{Polajnar2011,
author = {Polajnar, Jernej and Dalvandi, B. and Polajnar, D.},
booktitle = {Cognitive Informatics \& Cognitive Computing (ICCI'CC'11), 2011 10th IEEE International Conference on},
file = {::},
isbn = {9781457716973},
pages = {96--102},
publisher = {IEEE},
title = {{Does empathy between artificial agents improve agent teamwork?}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6016126},
year = {2011}
}
@inproceedings{Legaspi2008,
author = {Legaspi, Roberto and Kurihara, Satoshi and Fukui, K.I. and Moriyama, Koichi and Numao, Masayuki},
booktitle = {Human system interactions, 2008 conference on},
file = {::},
isbn = {1424415438},
keywords = {empathic computing,interfaces,machine learning,user modeling and user-adaptive},
pages = {209--214},
publisher = {IEEE},
title = {{An empathy learning problem for HSI: To be empathic, self-improving and ambient}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4581435},
year = {2008}
}
@inproceedings{Boukricha2009,
abstract = {a system for simulating emotional facial expressions for a virtual human has been evolved. This system consists of two parts: (1) a control ar- chitecture for simulating emotional facial expressions with respect to Pleasure, Arousal, and Dominance (PAD) val- ues, (2) an expressive output component for animating the virtual human’s facial muscle actions called Action Units (AUs), modeled following the Facial Action Coding Sys- tem (FACS). A large face repertoire of about 6000 faces arranged in PAD-space with respect to two dominance val- ues (dominant vs. submissive) is obtained as a result of the empirical study. Using the face repertoire an approach to- wards realizing facial mimicry for a virtual human based on backward mapping AUs displaying an emotional facial expression on PAD-values is outlined.},
annote = {- For automatic recognition, the mapping of AUs to PAD may be only useful once you can identify the active AUs and their intensity on the face (which you won't be able with image processing teckniques).
- For the expression, if you have an avatar which has control on the AUs, you don’t need to map the AUs to PAD. But, if you have an avatar which expresses based on PAD, then this mapping is useful. 
- Mapping of AUs to PAD is helpful when you want to fuse multiple modalities where other modalities are in PAD values. },
author = {Boukricha, Hana and Wachsmuth, Ipke and Hofstatter, A. and Grammer, Karl},
booktitle = {Affective Computing and Intelligent Interaction and Workshops, 2009. ACII 2009. 3rd International Conference on},
file = {::},
isbn = {9781424447992},
pages = {1--7},
publisher = {IEEE},
title = {{Pleasure-arousal-dominance driven facial expression simulation}},
year = {2009}
}
@inproceedings{Jiang2007,
author = {Jiang, Hong and Vidal, J.M. and Huhns, M.N.},
booktitle = {Proceedings of the 6th international joint conference on Autonomous agents and multiagent systems},
file = {::},
keywords = {agent architecture,belief-desire-intention,emotional agent},
pages = {11},
publisher = {ACM},
title = {{EBDI: an architecture for emotional agents}},
url = {http://dl.acm.org/citation.cfm?id=1329139},
year = {2007}
}
@article{Segal2011,
author = {Segal, Elizabeth},
doi = {10.1080/01488376.2011.564040},
file = {::},
issn = {0148-8376},
journal = {Journal of Social Service Research},
keywords = {a dedication to justice,a nation that proclaims,and social well-being and,civic involvement,empathy,scapegoating,social empathy,social responsibility,the united states is},
month = may,
number = {3},
pages = {266--277},
title = {{Social Empathy: A Model Built on Empathy, Contextual Understanding, and Social Responsibility That Promotes Social Justice}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10\%2e1080\%2f01488376\%2e2011\%2e564040\&magic=crossref\%7c\%7cD404A21C5BB053405B1A640AFFD44AE3},
volume = {37},
year = {2011}
}
@article{Watson1985,
abstract = {Reanalyses of 7 studies of self-reported mood by researchers such as M. A. Lebo and J. R. Nesselroade (see record 1979-30118-001) and J. A. Russell and D. Ridgeway (see record 1984-03807-001) indicate that Positive Affect and Negative Affect consistently emerge as the 1st 2 varimax rotated dimensions in orthogonal factor analyses or as the 1st 2 2nd-order factors derived from oblique solutions. The 2 factors emerged with varying sets of descriptors and were even replicated in several data sets characterized by possible methodological problems (e.g., acquiescence response bias, inappropriate response formats) noted by earlier authors. The results thus attest to the stability and robustness of Positive and Negative Affect in self-report. Because this same 2-dimensional configuration has also been consistently identified in most other major lines of mood research, it is now firmly established as the basic structure of English-language affect at the general factor level.},
author = {Watson, D and Tellegen, A},
journal = {Psychological Bulletin},
number = {2},
pages = {219--235},
pmid = {3901060},
publisher = {bepress},
title = {{Toward a consensual structure of mood.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/3901060},
volume = {98},
year = {1985}
}
@inproceedings{Kang2008a,
author = {Kang, Sin-hwa and Gratch, Jonathan and Wang, Ning and Watt, J.},
booktitle = {Intelligent Virtual Agents},
file = {::},
keywords = {evaluation,nonverbal feedback,personality,rapport,virtual agents},
pages = {253--261},
publisher = {Springer},
title = {{Agreeable people like agreeable virtual humans}},
url = {http://www.springerlink.com/index/DT61V8556710VW13.pdf},
year = {2008}
}
@inproceedings{Lisetti2012a,
abstract = {We discuss the design and implementation of the prototype of an avatar-based health system aimed at providing people access to an effective behavior change intervention which can help them to find and cultivate motivation to change unhealthy lifestyles. An empathic Embodied Conversational Agent (ECA) delivers the intervention. The health dialog is directed by a computational model of Motivational Interviewing, a novel effective face-to-face patient-centered counseling style which respects an individual’s pace toward behavior change. Although conducted on a small sample size, results of a preliminary user study to asses users’ acceptance of the avatar counselor indicate that the system prototype is well accepted by 75\% of users.},
address = {Miami, FL, US},
author = {Lisetti, Christine L and Yasavur, Ugan and Leon, Claudia De and Amini, Reza and Rishe, Napthali},
booktitle = {Preceeding of FLAIRS'2012 Association for the Advancement of Artificial Intelligence (www.aaai.org)},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lisetti et al. - 2012 - Building an On-demand Avatar-based Health Intervention for Behavior Change(5).pdf:pdf},
number = {Mi},
title = {{Building an On-demand Avatar-based Health Intervention for Behavior Change}},
year = {2012}
}
@article{Liu2005,
author = {Liu, Zhen},
file = {::},
journal = {Affective Computing and Intelligent Interaction},
title = {{An emotion model of 3D virtual characters in intelligent virtual environment}},
url = {http://www.springerlink.com/index/p232574rm3036237.pdf},
year = {2005}
}
@article{Catucci2006,
author = {Catucci, Graziano and Abbattista, Fabio and Gadaleta, R. and Guaccero, Domenico and Semeraro, Giovanni},
file = {::},
journal = {Applied Soft Computing Technologies: The Challenge of Complexity},
keywords = {autonomous agents,emotional agents,synthetic characters},
pages = {265--277},
publisher = {Springer},
title = {{Empathy: A computational framework for emotion generation}},
url = {http://www.springerlink.com/index/LJ26L065L0072722.pdf},
year = {2006}
}
@article{Chuang2004,
author = {Chuang, ZJ},
file = {::},
journal = {International Journal of Computational},
number = {2},
pages = {45--62},
title = {{Multi-modal emotion recognition from speech and text}},
url = {http://www.mendeley.com/research/multimodal-emotion-recognition-from-speech-and-text/},
volume = {9},
year = {2004}
}
@article{Boukricha2007a,
abstract = {Addressing user’s emotions in human-computer interaction significantly enhances the believability and lifelikeness of virtual humans. Emotion recognition and interpretation is realized in our approach by integrating empathy as a designated process within the agent’s cognitive architecture. In this paper we describe this empathy process which comprises of two interconnected components: a belief-desire-intention (BDI) based cognitive component and an affective component based on the emotion simulation system of the virtual human Max.},
author = {Boukricha, Hana and Becker, Christian},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Boukricha, Becker-Asano - 2007 - Simulating empathy for the virtual human max(3).pdf:pdf},
journal = {on Emotion and Computing in conj},
title = {{Simulating empathy for the virtual human max}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.133.7516\&amp;rep=rep1\&amp;type=pdf},
year = {2007}
}
@article{Cooper2003,
abstract = {BACKGROUND: African-American patients who visit physicians of the same race rate their medical visits as more satisfying and participatory than do those who see physicians of other races. Little research has investigated the communication process in race-concordant and race-discordant medical visits. OBJECTIVES: To compare patient-physician communication in race-concordant and race-discordant visits and examine whether communication behaviors explain differences in patient ratings of satisfaction and participatory decision making. DESIGN: Cohort study with follow-up using previsit and postvisit surveys and audiotape analysis. SETTING: 16 urban primary care practices. PATIENTS: 252 adults (142 African-American patients and 110 white patients) receiving care from 31 physicians (of whom 18 were African-American and 13 were white). MEASUREMENTS: Audiotape measures of patient-centeredness, patient ratings of physicians' participatory decision-making styles, and overall satisfaction. RESULTS: Race-concordant visits were longer (2.15 minutes 95\% CI, 0.60 to 3.71) and had higher ratings of patient positive affect (0.55 point, 95\% CI, 0.04 to 1.05) compared with race-discordant visits. Patients in race-concordant visits were more satisfied and rated their physicians as more participatory (8.42 points 95\% CI, 3.23 to 13.60). Audiotape measures of patient-centered communication behaviors did not explain differences in participatory decision making or satisfaction between race-concordant and race-discordant visits. CONCLUSIONS: Race-concordant visits are longer and characterized by more patient positive affect. Previous studies link similar communication findings to continuity of care. The association between race concordance and higher patient ratings of care is independent of patient-centered communication, suggesting that other factors, such as patient and physician attitudes, may mediate the relationship. Until more evidence is available regarding the mechanisms of this relationship and the effectiveness of intercultural communication skills programs, increasing ethnic diversity among physicians may be the most direct strategy to improve health care experiences for members of ethnic minority groups.},
author = {Cooper, Lisa A and Roter, Debra L and Johnson, Rachel L and Ford, Daniel E and Steinwachs, Donald M and Powe, Neil R},
institution = {Johns Hopkins University School of Medicine and the Welch Center for Prevention, Epidemiology, and Clinical Research, Johns Hopkins University, Baltimore, Maryland 21205-2223, USA. lisa.cooper@jhmi.edu},
journal = {Annals of Internal Medicine},
keywords = {empirical approach,professional patient relationship},
number = {11},
pages = {907--915},
pmid = {14644893},
title = {{Patient-centered communication, ratings of care, and concordance of patient and physician race.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/14644893},
volume = {139},
year = {2003}
}
@incollection{Burke2002,
address = {New-York,NY},
author = {Burke, B. L. and Arkowitz, H. and Dunn, C.},
booktitle = {Motivational Interviewing: Preparing People for Change},
edition = {2nd},
pages = {217--250},
publisher = {Guilford Press},
title = {{The Efficacy of Motivational Interviewing and Its Adaptation}},
year = {2002}
}
@book{Greene2003,
abstract = {Providing a thorough review and synthesis of work on communication skills and skill enhancement, this "Handbook" serves as a comprehensive and contemporary survey of theory and research on social interaction skills. Editors John O. Greene and Brant R. Burleson have brought together preeminent researchers and writers to contribute to this volume, establishing a foundation on which future study and research will build. The handbook chapters are organized into five major units: general theoretical and methodological issues (models of skill acquisition, methods of skill assessment); fundamental interaction skills (both transfunctional and transcontextual); function-focused skills (informing, persuading, supporting); skills used in management of diverse personal relationships (friendships, romances, marriages); and skills used in varied venues of public and professional life (managing leading, teaching). Distinctive features of this handbook include: broad, comprehensive treatment of work on social interaction skills and skill acquisition; up-to-date reviews of research in each area; and emphasis on empirically supported strategies for developing and enhancing specific skills. Researchers in communication studies, psychology, family studies, business management, and related areas will find this volume a comprehensive, authoritative source on communications skills and their enhancement, and it will be essential reading for scholars and students across the spectrum of disciplines studying social interaction.},
author = {Greene, John O and Burleson, Brant Raney},
booktitle = {Communication},
editor = {Greene, John O and Burleson, Brant R},
isbn = {0805834176},
pages = {1051},
publisher = {Routledge},
title = {{Handbook of Communication and Social Interaction Skills}},
url = {http://books.google.com/books?id=B0BAStlhpWQC\&pgis=1},
year = {2003}
}
@phdthesis{Sidorova2007,
author = {Sidorova, Julia},
booktitle = {Speech communication},
file = {::},
school = {Universitat Pompeu Fabra},
title = {{Speech emotion recognition using hidden Markov models}},
year = {2007}
}
@book{Fussell2002,
author = {Fussell, Susan R.},
file = {::},
isbn = {0805836896},
publisher = {Lawrence Erlbaum},
title = {{The verbal communication of emotions: Interdisciplinary perspectives}},
year = {2002}
}
@incollection{Catucci2006,
abstract = {Empathy is a distributed environment for the generation of emotions and other related affective phenomena like moods and temperaments. Empathy has been conceived as an object-oriented reusable framework entirely written in Java and realized for the purpose of studying the direct influences of emotions on behaviors and on decision-making processes of autonomous agents, interacting in complex or real environments. It allows for the realization of custom emotional agents, usable in several different domains, from the educational applications (e.g. entertainment, video games, intelligent tutoring systems.) to control systems in autonomous robots.},
author = {Catucci, Graziano and Abbattista, Fabio and Gadaleta, R. and Guaccero, Domenico and Semeraro, Giovanni},
booktitle = {Applied Soft Computing Technologies: The Challenge of Complexity},
doi = {10.1007/3-540-31662-0\_21},
file = {::},
isbn = {978-3-540-31649-7},
keywords = {autonomous agents,emotional agents,synthetic characters},
pages = {265--277},
publisher = {Springer Berlin / Heidelberg},
title = {{Empathy: A computational framework for emotion generation}},
url = {http://www.springerlink.com/index/LJ26L065L0072722.pdf http://dx.doi.org/10.1007/3-540-31662-0\_21},
year = {2006}
}
@article{Campbell2005,
author = {Campbell, K.S.},
doi = {10.1109/IPCC.2005.1494206},
file = {::},
isbn = {0-7803-9027-X},
journal = {IPCC 2005. Proceedings. International Professional Communication Conference, 2005.},
keywords = {communication,face-to-face interaction,health,medical interviews,sociolinguistics,verbal communication},
pages = {422--432},
publisher = {Ieee},
title = {{The rapport management model: how physicians build relationships with patients}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1494206},
year = {2005}
}
@article{Dautenhahn2002,
author = {Dautenhahn, Kerstin and Bond, Alan},
file = {::},
journal = {Socially Intelligent},
pages = {1--20},
publisher = {Springer},
title = {{Socially intelligent agents}},
url = {http://www.springerlink.com/index/V38H434X220766G8.pdf},
year = {2002}
}
@inproceedings{Legaspi2008,
author = {Legaspi, Roberto and Kurihara, Satoshi and Fukui, K.I. and Moriyama, Koichi and Numao, Masayuki},
booktitle = {Human system interactions, 2008 conference on},
file = {::},
isbn = {1424415438},
keywords = {empathic computing,interfaces,machine learning,user modeling and user-adaptive},
pages = {209--214},
publisher = {IEEE},
title = {{An empathy learning problem for HSI: To be empathic, self-improving and ambient}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4581435},
year = {2008}
}
@article{DiMatteo1980,
abstract = {The relationship between physicians' nonverbal communication skills (their ability to communicate and to understand facial expression, body movement and voice tone cues to emotion) and their patients' satisfaction with medical care was examined in 2 studies. The research involved 71 residents in internal medicine and 462 of their ambulatory and hospitalized patients. Standardized, reliable and valid measures of nonverbal communication skills were administered to the physicians. Their scores on these tests were correlated with ratings they received from a sample of their patients on measures of satisfaction with the technical aspects and the socioemotional aspects (or art) of the medical care they received. While the nonverbal communication skills of the physicians bore little relationship to patients' ratings of the technical quality of care, measures of these skills did predict patient satisfaction with the art of medical care received. Across both samples, physicians who were more sensitive to body movement and posture cues to emotion (the channel suggested by nonverbal researchers as the one in which true affect can be perceived) received higher ratings from their patients on the art of care than did less sensitive physicians. In addition, physicians who were successful at expressing emotion through their nonverbal communications tended to receive higher ratings from patients on the art of care than did physicians who were less effective communicators. The implications of successfully identifying characteristics of physicians with whom patients are satisfied are discussed.},
author = {DiMatteo, M R and Taranta, A and Friedman, H S and Prince, L M},
file = {::},
issn = {0025-7079},
journal = {Medical care},
keywords = {Adult,Consumer Satisfaction,Evaluation Studies as Topic,Female,Humans,Male,Nonverbal Communication,Physician-Patient Relations},
month = apr,
number = {4},
pages = {376--387},
pmid = {7401698},
title = {{Predicting patient satisfaction from physicians' nonverbal communication skills}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/7401698},
volume = {18},
year = {1980}
}
@article{Campbell1994,
abstract = {OBJECTIVES. To achieve the Healthy People 2000 objectives, public health professionals must develop effective dietary interventions that address psychosocial and behavioral components of change. This study tested the effect of individually computer-tailored messages designed to decrease fat intake and increase fruit and vegetable intake. METHODS. Adult patients from four North Carolina family practices were surveyed at baseline and then randomly assigned to one of two interventions or to a control group. The first intervention consisted of individually computer-tailored nutrition messages; the second consisted of nontailored nutrition information based on the 1990 Dietary Guidelines for Americans. Patients were resurveyed 4 months postintervention. RESULTS. The tailored intervention produced significant decreases in total fat and saturated fat scores compared with those of the control group (P < .05). Total fat was decreased in the tailored group by 23\%, in the nontailored group by 9\%, and in the control group by 3\%. Fruit and vegetable consumption did not increase in any study group. Seventy-three percent of the tailored intervention group recalled receiving a message, compared with 33\% of the nontailored intervention group. CONCLUSIONS. Tailored nutrition messages are effective in promoting dietary fat reduction for disease prevention.},
author = {Campbell, M K and DeVellis, B M and Strecher, V J and Ammerman, A S and DeVellis, R F and Sandler, R S},
institution = {Department of Health Behavior, Department of Nutrition, School of Public Health, University of North Carolina, Chapel Hill 27599-7400.},
journal = {American Journal of Public Health},
number = {5},
pages = {783--787},
title = {{Improving dietary behavior: the effectiveness of tailored messages in primary care settings.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1615043\&tool=pmcentrez\&rendertype=abstract},
volume = {84},
year = {1994}
}
@article{Shimoda2000,
author = {Shimoda, H. and Kunihiro, T. and Yang, D. and Yoshikawa, H.},
doi = {10.1109/IECON.2000.972406},
file = {::},
isbn = {0-7803-6456-2},
journal = {2000 26th Annual Conference of the IEEE Industrial Electronics Society. IECON 2000. 2000 IEEE International Conference on Industrial Electronics, Control and Instrumentation. 21st Century Technologies and Industrial Opportunities (Cat. No.00CH37141)},
pages = {2589--2594},
publisher = {Ieee},
title = {{Design of affective interface for realizing human-machine empathy}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=972406},
volume = {4},
year = {2000}
}
@inproceedings{Steunebrink2009,
author = {Steunebrink, B.R. and Dastani, Mehdi and Meyer, J.J.C.},
booktitle = {Proceedings of the 4th Workshop on Emotion and Computing},
file = {::},
title = {{The OCC model revisited}},
url = {http://www.idsia.ch/~steunebrink/Publications/KI09\_OCC\_revisited.pdf},
year = {2009}
}
@article{Archer1977,
author = {Archer, Dane and Akert, Robin M},
journal = {Journal of Personality and Social Psychology},
number = {6},
pages = {443--449},
title = {{Words and everything else: Verbal and nonverbal cues in social interpretation}},
volume = {35},
year = {1977}
}
@article{VanSwol2003,
author = {{Van Swol}, Lyn M.},
doi = {10.1177/0093650203253318},
file = {::},
issn = {00000000},
journal = {Communication Research},
month = aug,
number = {4},
pages = {461--480},
title = {{The Effects of Nonverbal Mirroring on Perceived Persuasiveness, Agreement with an Imitator, and Reciprocity in a Group Discussion}},
volume = {30},
year = {2003}
}
@misc{Lisetti2004,
abstract = {The development of an autonomous social robot, Cherry, is occurring in tandem with studies gaining potential user preferences, likes, dislikes, and perceptions of her features. Thus far, results have indicated that individuals 1) believe that service robots with emotion and personality capabilities would make them more acceptable in everyday roles in human life, 2) prefer that robots communicate via both human-like facial expressions, voice, and text-based media, 3) become more positive about the idea of service and social robots after exposure to the technology, and 4) find the appearance and facial features of Cherry pleasing. The results of these studies provide the basis for future research efforts, which are discussed.},
author = {Lisetti, Christine L and Brown, S M Brown S M and Alvarez, K Alvarez K and Marpaung, A H Marpaung A H},
booktitle = {IEEE Transactions on Systems Man and Cybernetics Part C Applications and Reviews},
doi = {10.1109/TSMCC.2004.826278},
issn = {10946977},
number = {2},
pages = {195--209},
publisher = {IEEE},
title = {{A social informatics approach to human-robot interaction with a service social robot}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1291667},
volume = {34},
year = {2004}
}
@book{Andreassi2009,
author = {Andreassi, John L.},
edition = {5},
isbn = {978-0805828337},
pages = {488},
publisher = {Taylor \& Francis},
title = {{Psychophysiology: Human Behavior and Physiological Response}},
year = {2009}
}
@inproceedings{Hernandez2007,
abstract = {In this paper we explore the possibilities that conversational agent technology offers for the improvement of the quality of hu- man-machine interaction in a concrete area of application: the multimodal biometric authentication system. Our approach looks at the user perception effects related to the system interface rather than to the perform- ance of the biometric technology itself. For this purpose we have created a multibio- metric user test environment with two dif- ferent interfaces or interaction metaphors: one with an embodied conversational agent and the other with on-screen text messages only. We present the results of an explora- tory experiment that reveals interesting ef- fects, related to the presence of a conversa- tional agent, on the user’s perception of pa- rameters such as privacy, ease of use, inva- siveness or system security.},
address = {Prague, Czech Republic},
author = {Hern\'{a}ndez, \'{A}lvaro and L\'{o}pez, Beatriz and D\'{\i}az, David and Fern\'{a}ndez, Rub\'{e}n and Hern\'{a}ndez, Luis and Caminero, Javier},
booktitle = {Proceedings of the Workshop on Embodied Language Processing},
file = {::},
pages = {33--40},
publisher = {Association for Computational Linguistics},
title = {{A “ person ” in the interface : effects on user perceptions of multibiometrics}},
year = {2007}
}
@incollection{Ekman1982,
address = {New York},
author = {Ekman, Paul and Friesen, W V and Ellsworth, P},
booktitle = {Emotion in the human face},
editor = {Ekman, Paul},
pages = {39--55},
publisher = {Cambridge University Press},
title = {{What emotion categories or dimensions can observers judge from facial behavior?}},
year = {1982}
}
@article{Litvack-Miller1997,
abstract = {This study was an investigation of the structure and development of dispositional empathy during middle childhood and its relationship to altruism. A sample of 478 students from 2nd, 4th, and 6th grades completed an altruism questionnaire and a social desirability scale, both created for this study, and the Interpersonal Reactivity Index (Davis, 1980), adapted for this study. Teachers also rated the students on prosocial behaviors, such as sharing. In addition, as an experimental part of the study, the children could make monetary donations and volunteer time to raise funds. Results of a confirmatory factor analysis on the Interpersonal Reactivity Index supported Davis's (1980) findings that empathy comprises four components: perspective taking, fantasy, empathic concern, and personal distress. Factor intercorrelations, however, were not the same as those reported by Davis. MANOVAs were used to examine gender and age effects on empathy. Girls were more empathic in general than boys, and older children showed more empathic concern than younger children. Only empathic concern and perspective taking were significant predictors of prosocial behavior.},
author = {Litvack-Miller, W and McDougall, D and Romney, D M},
doi = {10.1037/0022-3514.45.6.1299},
file = {::},
issn = {8756-7547},
journal = {Genetic, social, and general psychology monographs},
keywords = {Adolescent,Altruism,Child,Empathy,Female,Humans,Interpersonal Relations,Male,Questionnaires,Social Behavior,Social Desirability},
month = aug,
number = {3},
pages = {303--24},
pmid = {9259121},
title = {{The structure of empathy during middle childhood and its relationship to prosocial behavior.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21981037},
volume = {123},
year = {1997}
}
@article{Poh2010,
author = {Poh, MZ and McDuff, DJ},
file = {::},
journal = {Optics Express},
number = {10},
pages = {10762--10774},
title = {{Non-contact, automated cardiac pulse measurements using video imaging and blind source separation}},
volume = {18},
year = {2010}
}
@inproceedings{Zakharov2007,
abstract = {We describe the design and evaluation of an affective pedagogical agent persona for Intelligent Tutoring Systems. The goal of our research was to develop an agent embodying a persona of a caring mentor interested in the learner's progress. The agent's behaviour is guided by a set of rules that are triggered by the states of the session history. Four agents were integrated with EER-Tutor for a formative evaluation study. The mentor persona secured strong rapport with the users; the audible narration was seen as a strong feature of the agents.},
author = {Zakharov, Konstantin and Mitrovic, Antonija and Johnston, Lucy},
booktitle = {Proceedings of the 2007 conference on Artificial Intelligence in Education: Building Technology Rich Learning Contexts That Work},
file = {::},
pages = {59--66},
publisher = {IOS Press Amsterdam, The Netherlands},
title = {{Pedagogical Agents Trying on a Caring Mentor Role}},
url = {http://dl.acm.org/citation.cfm?id=1563616},
year = {2007}
}
@article{Lakin2003,
abstract = {The “chameleon effect” refers to the tendency to adopt the postures, gestures, and mannerisms of interaction partners (Chartrand \& Bargh, 1999). This type of mimicry occurs outside of conscious awareness, and without any intent to mimic or imitate. Empirical evidence suggests a bi-directional relationship between nonconscious mimicry on the one hand, and liking, rapport, and affiliation on the other. That is, nonconscious mimicry creates affiliation, and affiliation can be expressed through nonconscious mimicry. We argue that mimicry played an important role in human evolution. Initially, mimicry may have had survival value by helping humans communicate. We propose that the purpose of mimicry has now evolved to serve a social function. Nonconscious behavioral mimicry increases affiliation, which serves to foster relationships with others.},
annote = {nonconscious mimicry creates affiliation, and affiliation can be expressed through nonconscious mimicry.
Initially, mimicry may have had survival value by helping humans communicate. The purpose of mimicry has now evolved to serve a social function. Nonconscious behavioral mimicry increases affiliation, which serves to foster relationships with others.
Empathic individuals mimic people more that people low in empathy.},
author = {Lakin, JL and Jefferis, VE and Cheng, CM},
file = {::},
journal = {Journal of nonverbal},
keywords = {1994,1999,2000,2001a,affiliation,and sometimes from,animals,aronson,caporael,chameleon effect,dusk to dawn,ehrlich,from dawn to dusk,human beings are social,human evolution,mimicry,our lives are filled,we talk to signif-,with social interactions,wright},
number = {3},
pages = {145--162},
title = {{The chameleon effect as social glue: Evidence for the evolutionary significance of nonconscious mimicry}},
url = {http://www.springerlink.com/index/R16K6T278246H656.pdf},
volume = {27},
year = {2003}
}
@inproceedings{Legaspi2008,
author = {Legaspi, Roberto and Kurihara, Satoshi and Fukui, K.I. and Moriyama, Koichi and Numao, Masayuki},
booktitle = {Human system interactions, 2008 conference on},
file = {::},
isbn = {1424415438},
keywords = {empathic computing,interfaces,machine learning,user modeling and user-adaptive},
pages = {209--214},
publisher = {IEEE},
title = {{An empathy learning problem for HSI: To be empathic, self-improving and ambient}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4581435},
year = {2008}
}
@inproceedings{McQuiggan2008,
abstract = {Humans continuously assess one another’s situational context, modify their own affective state, and then respond based on these outcomes through empathetic expression. Virtual agents should be capable of similarly empathizing with users in interactive environments. A key challenge posed by empathetic reasoning in virtual agents is determining whether to respond with parallel or reactive empathy. Parallel empathy refers to mere replication of another’s affective state, whereas reactive empathy exhibits greater cognitive awareness and may lead to incongruent emotional responses (i.e., emotions different from the recipient’s and perhaps intended to alter negative affect). This paper proposes a unified inductive framework for modeling parallel and reactive empathy. Empathy models are used to drive runtime situation-appropriate empathetic behaviors by selecting suitable parallel or reactive empathetic expressions.},
annote = {- No automatic affect detection
- agent demographics are not taken into account.},
author = {McQuiggan, Scott W and Robison, Jennifer and Phillips, Robert},
booktitle = {Autonomous agents},
file = {::},
number = {Aamas},
pages = {167--174},
title = {{Modeling parallel and reactive empathy in virtual agents: An inductive approach}},
year = {2008}
}
@inproceedings{Gordon1985,
abstract = {Despite the almost complete lack of research addressing a theoretical understanding of empathy or ways to increase human empathy, empathy is a central component of effective human communication. Seen as a key social science phenomenon, it is viewed, along with power, as an inextricable component of human dynamics, and, in its relationship with altruism, possibly plays a causal role. A problem with research on empathy has been a lack of conceptual clarity. Three ways to improve empathetic listening are to avoid judgment, give the speaker time to speak without interruption, and focus on the speaker. Many of the helping professions have attempted training programs aimed at increasing the empathetic communication skills of practitioners in these fields. However, being told to listen empathetically is not the same as being taught to listen with empathy; and in critique of the empathy skills programs that are conducted within the helping professions, a significantly raised test score does not mean that empathy has been attained. Although empathetic communication is a complex subject matter, skills associated with empathy and active listening have been perceived as being more important than skills associated with critical or deliberative listening.},
address = {Baguio, Philippines},
annote = {Three ways to improve empathetic listening are to 
1.      Avoid judgment: the empathetic communicator must avoid making comparisons or passing moral judgments. 
2.      Give the speaker time to speak without interruption 
3.      Focus on the speaker: the empathetic communicator needs to focus his or her attention on the speaker, and not distract from this focus by verbally calling undue attention to oneself or one’s own situation [14]. },
author = {Gordon, Ronald D.},
booktitle = {International Conference of the World Communication Association},
file = {::},
keywords = {Communication (thought transfer),empathhy,interpersonal communication,listening,listening habits,listening skills,speech communication},
pages = {1--16},
title = {{Empathy: The State of the Art and Science}},
year = {1985}
}
@inproceedings{Boukricha2011b,
abstract = {Empathy is believed to play a major role as a basis for humans’ cooperative behavior. Recent research shows that humans empathize with each other to different degrees depending on several modulation factors including, among others, their social relationships, their mood, and the situational context. In human spatial interaction, partners share and sustain a space that is equally and exclusively reachable to them, the so-called interaction space. In a cooperative interaction scenario of relocating objects in interaction space, we introduce an approach for triggering and modulating a virtual humans cooperative spatial behavior by its degree of empathy with its interaction partner. That is, spatial distances like object distances as well as distances of arm and body movements while relocating objects in interaction space are modulated by the virtual human’s degree of empathy. In this scenario, the virtual human’s empathic emotion is generated as a hypothesis about the partner’s emotional state as related to the physical effort needed to perform a goal directed spatial behavior.},
address = {Berlin, Heidelberg},
author = {Boukricha, Hana and Nguyen, H.},
booktitle = {Proceedings of the 10th international conference on Intelligent virtual agents IVA'11},
doi = {10.1007/978-3-642-23974-8\_38},
editor = {Kopp, Stefan and Marsella, Stacy and Thorisson, Kristinn and Vilhjalmsson, Hannes},
file = {::},
pages = {350--362},
publisher = {Springer-Verlag},
title = {{Sharing Emotions and Space – Empathy as a Basis for Cooperative Spatial Interaction}},
url = {http://www.springerlink.com/content/q22784632u008337/},
year = {2011}
}
@article{Oatley1987,
abstract = {A theory is proposed that emotions are cognitively based states which co-ordinate quasi-autonomous processes in the nervous system. Emotions provide a biological solution to certain problems of transition between plans, in systems with multiple goals. Their function is to accomplish and maintain these transitions, and to communicate them to ourselves and others. Transitions occur at significant junctures of plans when the evaluation of success in a plan changes. Complex emotions are derived from a small number of basic emotions and arise at junctures of social plans.},
author = {Oatley, Keith and Johnson-laird, P N},
doi = {10.1080/02699938708408362},
isbn = {0269993114640600},
issn = {02699931},
journal = {Cognition \& Emotion},
number = {1},
pages = {29--50},
publisher = {Psychology Press},
title = {{Towards a Cognitive Theory of Emotions}},
url = {http://www.tandfonline.com/doi/abs/10.1080/02699938708408362?journalCode=pcem20},
volume = {1},
year = {1987}
}
@article{Spurgeon2010,
abstract = {There has been a recent acceleration in the development and testing of programs for computer-assisted cognitive-behavioral therapy (CCBT). Programs are now available for treatment of depression, anxiety disorders, and other psychiatric conditions. Technology for delivery of CCBT includes multimedia programs, virtual reality, and handheld devices. Research on CCBT generally has supported the efficacy of computer-assisted therapy and has shown patient acceptance of computer tools for psychotherapy. Completion rates and treatment efficacy typically have been higher when clinicians prescribe and support the use of psychotherapeutic computer programs than when programs are delivered in a self-help format without clinician involvement. CCBT seems to have the potential to improve access to evidence-based therapies while reducing the demand for clinician time.},
author = {Spurgeon, Joyce a and Wright, Jesse H},
doi = {10.1007/s11920-010-0152-4},
file = {::},
isbn = {1192001001},
issn = {1535-1645},
journal = {Current psychiatry reports},
keywords = {Anxiety Disorders,Anxiety Disorders: therapy,Cognitive Therapy,Depressive Disorder,Depressive Disorder: therapy,Humans,Therapy, Computer-Assisted,Treatment Outcome},
month = dec,
number = {6},
pages = {547--52},
pmid = {20872100},
title = {{Computer-assisted cognitive-behavioral therapy.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20872100},
volume = {12},
year = {2010}
}
@article{Robison2010,
abstract = {affective interventions can both positively and negatively influence learning experiences. In this paper we investigate the role of student personality, including goal orienta- tion and empathetic tendencies, in estimating confidence in the benefits of an affective intervention strategy. The results indicate that student personality profiles can serve as a powerful tool for informing affective feedback models.},
annote = {We can use the same way of menu base self-report affective state recognition (in addition to automatic) and text-base empathic feedback. Then after each feedback we can evaluate the feedback with another user self-report.},
author = {Robison, Jennifer and McQuiggan, Scott W and Lester, James and Carolina, North},
keywords = {affect,affective computing,pedagogical agents},
pages = {285--295},
title = {{Developing Empirically Based Student Personality Profiles for Affective Feedback Models}},
year = {2010}
}
@article{Littlewort2011,
author = {Littlewort, Gwen C and Whitehill, Jacob and Wu, T},
doi = {10.1109/AFGR.2008.4813406},
file = {::},
isbn = {978-1-4244-2153-4},
journal = {Recognition and},
month = sep,
pages = {1--2},
publisher = {Ieee},
title = {{The computer expression recognition toolbox (CERT)}},
year = {2011}
}
@article{VanSwol2003,
author = {{Van Swol}, Lyn M.},
doi = {10.1177/0093650203253318},
file = {::},
issn = {00000000},
journal = {Communication Research},
month = aug,
number = {4},
pages = {461--480},
title = {{The Effects of Nonverbal Mirroring on Perceived Persuasiveness, Agreement with an Imitator, and Reciprocity in a Group Discussion}},
volume = {30},
year = {2003}
}
@article{Warner1987,
author = {Warner, Rebecca M. and Malloy, Daniel and Schneider, Kathy and Knoth, Russell and Wilder, Bruce},
doi = {10.1007/BF00990958},
file = {::},
issn = {0191-5886},
journal = {Journal of Nonverbal Behavior},
number = {2},
pages = {57--74},
title = {{Rhythmic organization of social interaction and observer ratings of positive affect and involvement}},
url = {http://www.springerlink.com/index/10.1007/BF00990958},
volume = {11},
year = {1987}
}
@inproceedings{Campbell2005,
abstract = {Building relationships is a central concern for professionals (e.g., physicians, engineers, sales representatives, managers, etc.) because relationships promote a client's trust and loyalty. Rapport is a concept used to describe relationship quality and has two facets: enjoyable interactions and personal connection. Prior research has described the communication strategies of leaders for building better relationships with their subordinates and sales representatives with their customers by borrowing concepts from rapport management in sociolinguistics. The goal of this paper is to extend that work by demonstrating how rapport management applies to interaction between physicians and patients. The rapport management model helps us explain how professionals succeed or fail to build relationships with clients based on their verbal communication behavior.},
address = {Limerick, Ireland},
author = {Campbell, K.S.},
booktitle = {Proceedings in International Professional Communication Conference IPCC2005},
doi = {10.1109/IPCC.2005.1494206},
file = {::},
isbn = {0-7803-9027-X},
keywords = {communication,face-to-face interaction,health,medical interviews,sociolinguistics,verbal communication},
pages = {422--432},
publisher = {IEEE},
title = {{The rapport management model: how physicians build relationships with patients}},
url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=1494206},
year = {2005}
}
@article{Happ2011,
author = {Happ, Christian and Melzer, Andr\'{e}},
file = {::},
journal = {Ifip International Federation For Information Processing},
keywords = {1,1 prosocial and antisocial,aggression,anderson and his colleagues,confirmed that video game,effects of video games,empathy,furthermore,in a recent overview,prosocial behavior,related to indicators of,video games,violence exposure is positively},
pages = {371--374},
title = {{Bringing Empathy into Play: On the Effects of Empathy in Violent and Nonviolent Video Games}},
url = {http://www.springerlink.com/index/P76556V1HN316RK6.pdf},
year = {2011}
}
@inproceedings{Nguyen2009,
abstract = {Experiencing emotional distress is the number one reason why people who are undergoing behaviour modification (e.g. quitting smoking, dieting) suffer from relapses. Providing emotional support is an effective way to help them overcome the unpleasant effects of negative affect and adhere to their regimen. Building computers with such ability has grabbed the attention of the HCI community in recent years. This paper presents the results of a 2 (modality: animated vs. no visual) by 3 (intervention: non-empathy vs. empathy vs. empathy and expressivity) between-subjects study that investigates the impact of two important factors and their interaction in the design of such systems: (1) different ways of expressing empathy, and (2) the modality of delivering such content.},
address = {Claremont, California, USA},
annote = {They investigate: 
1-      Different ways of expressing empathy 
2-      Modality of delivering such content. 
        
They define empathy as the ability to detect what others feel and to experience that emotion ourselves (seems like mimicry).
        
Empirical evidence indicates that expressing accurate empathy can lead to positive psychological, physical and health outcomes.
        
Their results show: 
1. The positive attitude of the users toward active support (active empathy). 
2.  The positive outcome of an empathic system regardless of its representation. 
3.  A system represented by a human-like representation is expected to be empathic.
        
they believe, adding a mechanism to allow the users to freely express themselves does not improve the effectiveness or liking of an empathic system.
      },
author = {Nguyen, H. and Masthoff, Judith},
booktitle = {Proceedings of the 4th International Conference on Persuasive Technology (Persuasive’09)},
file = {::},
isbn = {9781605583761},
keywords = {affective computing,design,experimentation,human factors},
publisher = {ACM},
title = {{Designing empathic computers: the effect of multimodal empathic feedback using animated agent}},
year = {2009}
}
@article{Boukricha2007,
abstract = {Addressing user’s emotions in human-computer interaction significantly enhances the believability and lifelikeness of virtual humans. Emotion recognition and interpretation is realized in our approach by integrating empathy as a designated process within the agent’s cognitive architecture. In this paper we describe this empathy process which comprises of two interconnected components: a belief-desire-intention (BDI) based cognitive component and an affective component based on the emotion simulation system of the virtual human Max.},
author = {Boukricha, Hana and Becker, Christian},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Boukricha, Becker-Asano - 2007 - Simulating empathy for the virtual human max(3).pdf:pdf},
journal = {on Emotion and Computing in conj},
title = {{Simulating empathy for the virtual human max}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.133.7516\&amp;rep=rep1\&amp;type=pdf},
year = {2007}
}
@inproceedings{Gilroy2011,
address = {New York, New York, USA},
author = {Gilroy, Stephen W. and Cavazza, Marc O. and Vervondel, Valentin},
booktitle = {Proceedings of the 16th international conference on Intelligent user interfaces - IUI '11},
doi = {10.1145/1943403.1943413},
file = {::},
isbn = {9781450304191},
pages = {53--62},
publisher = {ACM Press},
title = {{Evaluating multimodal affective fusion using physiological signals}},
url = {http://portal.acm.org/citation.cfm?doid=1943403.1943413},
year = {2011}
}
@book{Picard1997,
address = {Cambridge, Massachusetts},
author = {Picard, Rosalind W},
isbn = {0-262-16170-2},
publisher = {The MIT Press},
title = {{Affective Computing}},
year = {1997}
}
@inproceedings{Gordon1985,
address = {Baguio, Philippines},
annote = {Three ways to improve empathetic listening are to 
1.      Avoid judgment: the empathetic communicator must avoid making comparisons or passing moral judgments. 
2.      Give the speaker time to speak without interruption 
3.      Focus on the speaker: the empathetic communicator needs to focus his or her attention on the speaker, and not distract from this focus by verbally calling undue attention to oneself or one’s own situation [14]. },
author = {Gordon, Ronald D.},
booktitle = {International COnference of the World Communication Association},
pages = {1--16},
title = {{Empathy: The State of the Art and Science}},
year = {1985}
}
@inproceedings{Krauss1996,
address = {San Diego, CA, US},
author = {Krauss, Robert M. and Chen, Yihsiu and Chawla, Purnima},
booktitle = {Advances in experimental social psychology},
doi = {10.1016/S0065-2601(08)60241-5},
editor = {Zanna, Mark P.},
file = {::},
pages = {389--450},
publisher = {Academic Press},
title = {{Nonverbal behavior and nonverbal communication: What do conversational hand gestures tell us?}},
url = {http://www.sciencedirect.com/science/article/pii/S0065260108602415},
volume = {28},
year = {1996}
}
@article{Carberry2008a,
author = {Carberry, Sandra and Rosis, Fiorella},
doi = {10.1007/s11257-007-9044-7},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Carberry, Rosis - 2008 - Introduction to special Issue on ‘Affective modeling and adaptation’(2).pdf:pdf},
issn = {0924-1868},
journal = {User Modeling and User-Adapted Interaction},
month = jan,
number = {1-2},
pages = {1--9},
title = {{Introduction to special Issue on ‘Affective modeling and adaptation’}},
url = {http://www.springerlink.com/index/10.1007/s11257-007-9044-7},
volume = {18},
year = {2008}
}
@book{Babor2001,
abstract = {This manual introduces the AUDIT, the Alcohol Use Disorders Identification Test, and describes how to use it to identify persons with hazardous and harmful patterns of alcohol consumption. The AUDIT was developed by the World Health Organization (WHO) as a simple method of screening for excessive drinking and to assist in brief assessment. It can help in identifying excessive drinking as the cause of the presenting illness. It also provides a framework for intervention to help hazardous and harmful drinkers reduce or cease alcohol consumption and thereby avoid the harmful consequences of their drinking. The first edition of this manual was published in 1989 (Document No. WHO/MNH/DAT/89.4) and was subsequently updated in 1992 (WHO/PSA/92.4). Since that time it has enjoyed widespread use by both health workers and alcohol researchers. With the growing use of alcohol screening and the international popularity of the AUDIT, there was a need to revise the manual to take into account advances in research and clinical experience. This manual is written primarily for health care practitioners, but other professionals who encounter persons with alcohol-related problems may also find it useful. It is designed to be used in conjunction with a companion document that provides complementary information about early intervention procedures, entitled “Brief Intervention for Hazardous and Harmful Drinking: A Manual for Use in Primary Care”. Together these manuals describe a comprehensive approach to screening and brief intervention for alcohol-related problems in primary health care.},
author = {Babor, Thomas F. and Higgins-Biddle, John C. and Saunders, John B. and Monteiro, Maristela G.},
edition = {2},
pages = {39},
publisher = {World Health Organization, Department of Mental Health and Substance Dependence},
title = {{AUDIT: The Alcohol Use Disorders Identification Test. Guidelines for use in primary health care}},
year = {2001}
}
@article{Rebolledo-Mendez2009,
author = {Rebolledo-Mendez, Genaro and Freitas, Sara De and Gaona, Alma Rosa Garcia},
doi = {10.1109/VS-GAMES.2009.33},
file = {::},
isbn = {978-0-7695-3588-3},
journal = {2009 Conference in Games and Virtual Worlds for Serious Applications},
keywords = {- empathy,alma rosa garcia gaona,facultad de inform\'{a}tica,motivation,serious games,universidad veracruzana},
month = mar,
pages = {5--11},
publisher = {Ieee},
title = {{A Model of Motivation Based on Empathy for AI-Driven Avatars in Virtual Worlds}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5116547},
year = {2009}
}
@article{Gupta2012,
author = {Gupta, Prabodh and Jhala, Darshana and Jhala, Nirag},
doi = {10.1309/AJCPLAE62CRYYXNW},
file = {::},
issn = {1943-7722},
journal = {American journal of clinical pathology},
month = jan,
number = {1},
pages = {160},
pmid = {22180490},
title = {{Book review.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22180490},
volume = {137},
year = {2002}
}
@article{Becker-Asano2009,
abstract = {We introduce theWASABI ([W]ASABI [A]ffect [S]imulation for [A]gents with [B]elievable [I]nteractivity)Affect SimulationArchitecture, in which a virtual human’s cog- nitive reasoning capabilities are combined with simulated embodiment to achieve the sim- ulation of primary and secondary emotions. In modeling primary emotions we follow the idea of “Core Affect” in combination with a continuous progression of bodily feeling in three-dimensional emotion space (PADspace), that is subsequently categorized into discrete emotions. In humans, primary emotions are understood as onto-genetically earlier emotions, which directly influence facial expressions. Secondary emotions, in contrast, afford the abil- ity to reason about current events in the light of experiences and expectations.},
author = {Becker-Asano, Christian and Wachsmuth, Ipke},
doi = {10.1007/s10458-009-9094-9},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Becker-Asano, Wachsmuth - 2009 - Affective computing with primary and secondary emotions in a virtual human(3).pdf:pdf},
issn = {1387-2532},
journal = {Autonomous Agents and Multi-Agent Systems},
keywords = {affect simulation,affective computing,affective gaming,architecture,aware emotions,bdi-based architecture,embodied agent,emotion dynamics,emotion expression,emotion modeling,pad emotion space,primary and secondary emotions,reality,virtual,virtual human},
month = may,
number = {1},
pages = {32--49},
title = {{Affective computing with primary and secondary emotions in a virtual human}},
volume = {20},
year = {2009}
}
@article{Gray1985,
abstract = {Attempts to show that the experimental psychology of the rat and the neuropsychology of the rat's brain are of relevance to clinical psychology. It is suggested that there is a false dichotomy between the behaviorist and cognitive approaches to psychology and illustrates this by going from a behaviorist analysis of a psychological concept (anxiety) to a cognitive analysis of that concept, basing the argument on brain research: Damage to the septo-hippocampal system mimics the behavioral effects of the antianxiety drugs. The reason for this mimicry is probably that these drugs reduce the noradrenergic input to the septo-hippocampal system. The noradrenergic input is normally activated under conditions of stress and serves to increase the capacity of the septo-hippocampal system to handle information. It seems probable, therefore, that the state of anxiety is, to some degree at least, mediated by activity in the septo-hippocampal system. It is emphasized that there is no dichotomy between cognitive and behaviorist psychology because the brain controls both behavior and cognition.},
author = {Gray, J. A},
journal = {Bulletin of the British Psychological Society},
pages = {99--112},
title = {{The whole and its parts: Behaviour, the brain, cognition and emotion}},
volume = {38},
year = {1985}
}
@article{Prochaska1997,
abstract = {The transtheoretical model posits that health behavior change involves progress through six stages of change: precontemplation, contemplation, preparation, action, maintenance, and termination. Ten processes of change have been identified for producing progress along with decisional balance, self-efficacy, and temptations. Basic research has generated a rule of thumb for at-risk populations: 40\% in precontemplation, 40\% in contemplation, and 20\% in preparation. Across 12 health behaviors, consistent patterns have been found between the pros and cons of changing and the stages of change. Applied research has demonstrated dramatic improvements in recruitment, retention, and progress using stage-matched interventions and proactive recruitment procedures. The most promising outcomes to data have been found with computer-based individualized and interactive interventions. The most promising enhancement to the computer-based programs are personalized counselors. One of the most striking results to date for stage-matched programs is the similarity between participants reactively recruited who reached us for help and those proactively recruited who we reached out to help. If results with stage-matched interventions continue to be replicated, health promotion programs will be able to produce unprecedented impacts on entire at-risk populations.},
author = {Prochaska, J O and Velicer, W F},
chapter = {5},
doi = {10.4278/0890-1171-12.1.38},
editor = {Shumaker, S A and Schron, E B},
institution = {Cancer Prevention Research Center, University of Rhode Island, Kingston 02881-0808, USA. JOP@URIACC.URI.EDU},
issn = {08901171},
journal = {American Journal Of Health Promotion},
number = {1},
pages = {38--48},
publisher = {American Journal of Health Promotion P.O. Box 1897, 810 East 10th Street, Lawrence, KS 66044-8897},
title = {{The transtheoretical model of health behavior change}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10170434},
volume = {12},
year = {1997}
}
@article{Lakin2003b,
author = {Lakin, J. L. and Chartrand, T. L.},
doi = {10.1111/1467-9280.14481},
file = {::},
issn = {0956-7976},
journal = {Psychological Science},
month = jul,
number = {4},
pages = {334--339},
title = {{Using Nonconscious Behavioral Mimicry to Create Affiliation and Rapport}},
url = {http://pss.sagepub.com/lookup/doi/10.1111/1467-9280.14481},
volume = {14},
year = {2003}
}
@article{Stockwell1983,
author = {Stockwell, T and Murphy, D and Hodgson, R},
journal = {British journal of addiction},
number = {2},
pages = {145--155},
pmid = {6135435},
title = {{The severity of alcohol dependence questionnaire: its use, reliability and validity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/6135435},
volume = {78},
year = {1983}
}
@article{LiuPicard2005,
author = {Liu, K},
file = {::},
journal = {Workshop on HCI Challenges in Health Assessment},
keywords = {empathy,health assessement},
pages = {1--4},
title = {{Embedded empathy in continuous, interactive health assessment}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.67.7721\&amp;rep=rep1\&amp;type=pdf},
year = {2005}
}
@inproceedings{Boukricha2011c,
abstract = {Empathy is believed to play a prominent role in contributing to an efficient and satisfying cooperative social interaction by adjusting one's own behavior to that of others. Thus, endowing virtual humans with the ability to empathize not only enhances their cooperative social skills, but also makes them more likeable, trustworthy, and caring. Supported by psychological models of empathy, we propose an approach to model empathy for EMMA - an Empathic MultiModal Agent - based on three processing steps: First, the Empathy Mechanism consists of an internal simulation of perceived emotional facial expressions and results in an internal emotional feedback that represents the empathic emotion. Second, the Empathy Modulation consists of modulating the empathic emotion through different predefined modulation factors. Third, the Expression of Empathy consists of triggering EMMA's multiple modalities like facial and verbal behaviors. In a conversational agent scenario involving the virtual humans MAX and EMMA, we illustrate our proposed model of empathy and we introduce a planned empirical evaluation of EMMA's empathic behavior.},
address = {Paris, France},
author = {Boukricha, Hana and Wachsmuth, Ipke},
booktitle = {Proceedings of the IEEE SSCI2011 - Symposium Series on Computational Intelligence, Workshop on Affective Computational Intelligence (WACI)},
doi = {10.1109/WACI.2011.5953146},
file = {::},
isbn = {9781612840840},
pages = {30 -- 37},
publisher = {IEEE},
title = {{Mechanism, modulation, and expression of empathy in a virtual human}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5953146},
year = {2011}
}
@article{Gruen1986,
author = {Gruen, Rand J. and Mendelsohn, Gerald},
doi = {10.1037/0022-3514.51.3.609},
file = {::},
issn = {1939-1315},
journal = {Journal of Personality and Social Psychology},
number = {3},
pages = {609--614},
title = {{Emotional responses to affective displays in others: The distinction between empathy and sympathy.}},
volume = {51},
year = {1986}
}
@book{Izard1977,
address = {New York},
author = {Izard, Carroll Ellis},
editor = {Izard, Carroll Ellis},
isbn = {9780306309861},
pages = {495},
publisher = {Plenum Press},
title = {{Human Emotions}},
year = {1977}
}
@incollection{Tomkins1984,
address = {Hillsdale, NJ},
author = {Tomkins, S S},
booktitle = {Approaches to emotion},
editor = {Scherer, Klaus R and Ekman, Paul},
isbn = {0898594065},
pages = {163--195},
publisher = {Erlbaum},
title = {{Affect theory}},
volume = {163},
year = {1984}
}
@inproceedings{McQuiggan2008,
abstract = {Humans continuously assess one another’s situational context, modify their own affective state, and then respond based on these outcomes through empathetic expression. Virtual agents should be capable of similarly empathizing with users in interactive environments. A key challenge posed by empathetic reasoning in virtual agents is determining whether to respond with parallel or reactive empathy. Parallel empathy refers to mere replication of another’s affective state, whereas reactive empathy exhibits greater cognitive awareness and may lead to incongruent emotional responses (i.e., emotions different from the recipient’s and perhaps intended to alter negative affect). This paper proposes a unified inductive framework for modeling parallel and reactive empathy. Empathy models are used to drive runtime situation-appropriate empathetic behaviors by selecting suitable parallel or reactive empathetic expressions.},
address = {Estoril, Portugal},
annote = {- No automatic affect detection
- agent demographics are not taken into account.},
author = {McQuiggan, Scott W and Robison, Jennifer and Phillips, Robert},
booktitle = {Proceedings of 7th Int. Conf. on Autonomous Agents and Multiagent Systems (AAMAS 2008)},
editor = {{Padgham, Parkes}, M\"{u}ller and Parsons},
file = {::},
keywords = {Affective Reasoning,Empathy,Human-Computer Interaction,Intelligent Virtual Agents,Machine Learning},
number = {Aamas},
pages = {167--174},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org)},
title = {{Modeling parallel and reactive empathy in virtual agents: An inductive approach}},
year = {2008}
}
@article{Termine1988,
author = {Termine, NT},
file = {::},
journal = {Developmental Psychology},
number = {2},
pages = {223--229},
title = {{Infants' responses to their mothers'; expressions of joy and sadness}},
volume = {24},
year = {1988}
}
@article{Decety2004,
abstract = {Empathy accounts for the naturally occurring subjective experience of similarity between the feelings expressed by self and others without loosing sight of whose feelings belong to whom. Empathy involves not only the affective experience of the other person's actual or inferred emotional state but also some minimal recognition and understanding of another's emotional state. In light of multiple levels of analysis ranging from developmental psychology, social psychology, cognitive neuroscience, and clinical neuropsychology, this article proposes a model of empathy that involves parallel and distributed processing in a number of dissociable computational mechanisms. Shared neural representations, self-awareness, mental flexibility, and emotion regulation constitute the basic macrocomponents of empathy, which are underpinned by specific neural systems. This functional model may be used to make specific predictions about the various empathy deficits that can be encountered in different forms of social and neurological disorders.},
author = {Decety, Jean and Jackson, Philip L},
doi = {10.1177/1534582304267187},
file = {::},
isbn = {1534582304267},
issn = {1534-5823},
journal = {Behavioral and cognitive neuroscience reviews},
keywords = {Adaptation, Psychological,Adolescent,Adult,Awareness,Awareness: physiology,Cerebral Cortex,Cerebral Cortex: physiology,Child,Child, Preschool,Emotions,Emotions: physiology,Empathy,Humans,Infant,Models, Neurological,Models, Psychological,Perception,Perception: physiology,Self Concept,Social Behavior},
month = jun,
number = {2},
pages = {71--100},
pmid = {15537986},
title = {{The functional architecture of human empathy.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15537986},
volume = {3},
year = {2004}
}
@inproceedings{Cairco2007,
address = {Newport Beach, California, USA},
author = {Cairco, Lauren and Babu, Sabarish and Ulinski, Amy and Zanbaka, Catherine and Hodges, Larry F.},
booktitle = {Proceedings of the 2007 ACM symposium on Virtual reality software and technology (VRST '07)},
doi = {10.1145/1315184.1315239},
file = {::},
isbn = {9781595938633},
pages = {239--240},
publisher = {ACM Press},
title = {{Shakespearean karaoke}},
url = {http://portal.acm.org/citation.cfm?doid=1315184.1315239},
year = {2007}
}
@article{Cliffordson2002,
abstract = {The purpose of the present study was to examine the structure of empathy using a hierarchical approach, and to compare the dimensions of empathy with measures of social functioning, in order to contribute to the understanding of the nature of empathy. The dimensionality of the Interpersonal Reactivity Index, which comprises four subscales (empathic concern, perspective taking, fantasy and personal distress) was examined using confirmatory factor analysis. Relations with the Social Skills Inventory were also investigated. A sample of 127 applicants for places on nursing and social work undergraduate programs participated in the study. The study findings indicate that empathy is hierarchically organized, with one general dimension at the apex. The general factor is identical to empathic concern and this dimension overlaps to a great extent with perspective taking and fantasy. The findings also indicate that the general dimension constitutes an integrated entirety, with its main emphasis on emotional reactivity by also involving cognitive processes.},
author = {Cliffordson, Christina},
file = {::},
issn = {0036-5564},
journal = {Scandinavian journal of psychology},
keywords = {Empathy,Factor Analysis,Humans,Social Behavior,Statistical},
month = feb,
number = {1},
pages = {49--59},
pmid = {11885760},
title = {{The hierarchical structure of empathy: dimensional organization and relations to social functioning.}},
volume = {43},
year = {2002}
}
@article{Taigman2011,
archivePrefix = {arXiv},
arxivId = {arXiv:1108.1122v1},
author = {Taigman, Yaniv and Wolf, Lior},
eprint = {arXiv:1108.1122v1},
file = {::},
journal = {Arxiv preprint arXiv:1108.1122},
number = {view 2},
pages = {1--7},
title = {{Leveraging Billions of Faces to Overcome Performance Barriers in Unconstrained Face Recognition}},
volume = {1},
year = {2011}
}
@article{Lee2009,
author = {Lee, Jina and Prendinger, Helmut},
file = {::},
isbn = {9781424447992},
journal = {Affective Computing},
title = {{Learning models of speaker head nods with affective information}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5349543},
year = {2009}
}
@article{Prendinger2005a,
abstract = {They designed an animated interface agent that accompanies the user in the setting of a virtual job interview. This interface application takes physiological data (skin conductance and electromyography) of a user in realtime, interprets them as emotions, and addresses the user’s affective states in the form of empathic feedback by employing embodied characters.},
annote = {They take physiological data (skin conductance and electromyography) of a user in real-time, interpret them as emotions, and address the user’s affective states by empathic feedback. A decision making agent relates these signals and the user’s answer to arousal and valence to infer the user’s emotional state by applying the model of Lang (1995) (Lang claims that all emotions can be characterized in terms of valence (pleasant or unpleasant) and arousal (calm or aroused)). Then it selects empathetic actions that maximize some utility function. They use text-based empathetic actions in addition to a small full body character.We can use the decision-theoretic agent aspect in our empathy model.
The empathy is mainly expressed in a text-base fashion in their job. The embodied agent that they have is so small and no facial expressions are used. There are some gestural expressions.
As shown in this paper and many other ones, text-base empathy expression can be effective. So we can use that too.
      },
author = {Prendinger, Helmut and Ishizuka, M.},
file = {::;::},
journal = {Applied Artificial Intelligence},
keywords = {electromyography,physiological signals,skin conductance},
number = {3-4},
pages = {267--286},
publisher = {Citeseer},
title = {{The Empathic Companion - A Character-based Interface that Addresses Users’ Affective States}},
url = {citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.79.4710\&rep=rep1\&type=pdf},
volume = {19},
year = {2005}
}
@incollection{Cassell1999a,
abstract = {This paper addresses the problem of designing conversational agents that exhibit appropriate gaze behavior during dialogues with human users. Previous research on gaze behavior has concentrated on its relationship to turn-taking phenomena 4,5,6. Recent work has incorporated some of these findings into the design of autonomous human-like conversational agents and interactive communicative humanoids 1,14. However, none of this research has examined the relationship between information structure and gaze behavior. In this paper we discuss why turn- taking is not an adequate explanation for gaze behavior in conversation and why information structure should be integrated with turn-taking as an explanation for this behavior. We then examine the relationship of gaze behavior to information structure and turn-taking through an empirical analysis of discourse transcripts for several dyadic conversations. A simple algorithm for assigning gaze behavior is proposed on the basis of the findings of this empirical analysis. We describe work in progress on implementing this algorithm in an autonomous conversational humanoid agent with the goal of producing more natural gaze behavior related to propositional content in human- computer conversations.},
author = {Cassell, Justine and Torres, Obed E and Prevost, Scott},
booktitle = {Machine Conversations},
editor = {Wilks, Y},
pages = {143--154},
publisher = {Kluwer},
title = {{Turn Taking vs. Discourse Structure: How Best to Model Multimodal Conversation}},
url = {http://citeseer.ist.psu.edu/cassell98turn.html},
year = {1999}
}
@inproceedings{Nguyen2009,
abstract = {Experiencing emotional distress is the number one reason why people who are undergoing behaviour modification (e.g. quitting smoking, dieting) suffer from relapses. Providing emotional support is an effective way to help them overcome the unpleasant effects of negative affect and adhere to their regimen. Building computers with such ability has grabbed the attention of the HCI community in recent years. This paper presents the results of a 2 (modality: animated vs. no visual) by 3 (intervention: non-empathy vs. empathy vs. empathy and expressivity) between-subjects study that investigates the impact of two important factors and their interaction in the design of such systems: (1) different ways of expressing empathy, and (2) the modality of delivering such content.},
annote = {They investigate: 
1-      Different ways of expressing empathy 
2-      Modality of delivering such content. 
        
They define empathy as the ability to detect what others feel and to experience that emotion ourselves (seems like mimicry).
        
Empirical evidence indicates that expressing accurate empathy can lead to positive psychological, physical and health outcomes.
        
Their results show: 
1. The positive attitude of the users toward active support (active empathy). 
2.  The positive outcome of an empathic system regardless of its representation. 
3.  A system represented by a human-like representation is expected to be empathic.
        
they believe, adding a mechanism to allow the users to freely express themselves does not improve the effectiveness or liking of an empathic system.
      },
author = {Nguyen, H. and Masthoff, Judith},
booktitle = {Proceedings of the 4th International Conference on Persuasive Technology},
file = {::},
isbn = {9781605583761},
keywords = {affective computing,design,experimentation,human factors},
publisher = {ACM},
title = {{Designing empathic computers: the effect of multimodal empathic feedback using animated agent}},
year = {2009}
}
@inproceedings{Dinda2007,
abstract = {Experimental computer systems research typically ignores the end-user, modeling him, if at all, in overly simple ways. We argue that this (1) results in inadequate performance evaluation of the systems, and (2) ignores opportunities. We summarize our experiences with (a) directly evaluating user satisfaction and (b) incorporating user feedback in different areas of client/server computing, and use our experiences to motivate principles for that domain. Specifically, we report on user studies to measure user satisfaction with resource borrowing and with different clock frequencies in desktop computing, the development and evaluation of user interfaces to integrate user feedback into scheduling and clock frequency decisions in this context, and results in predicting user action and system response in a remote display system. We also present initial results on extending our work to user control of scheduling and mapping of virtual machines in a virtualization-based distributed computing environment. We then generalize (a) and (b) as recommendations for incorporating the user into experimental computer systems research.},
address = {New York, USA},
author = {Dinda, Peter A and Dick, Robert P and Rossoff, Samuel},
booktitle = {ExpCS '07 Proceedings of the 2007 workshop on Experimental computer science ACM},
doi = {10.1145/1281700.1281710},
file = {::},
isbn = {9781595937513},
keywords = {Autonomic Systems,Design,Experimentation,Human Directed Adaptation,Human Factors,Measurement,Performance,Speculative Remote Display,User Comfort With Resource Borrowing,User-driven Power Management,User-driven Scheduling},
number = {June},
pages = {1--12},
title = {{The User In Experimental Computer Systems Research}},
url = {http://dl.acm.org/citation.cfm?id=1281710},
year = {2007}
}
@inproceedings{Kang2008a,
author = {Kang, Sin-hwa and Gratch, Jonathan and Wang, Ning and Watt, J.},
booktitle = {Intelligent Virtual Agents},
file = {::},
keywords = {evaluation,nonverbal feedback,personality,rapport,virtual agents},
pages = {253--261},
publisher = {Springer},
title = {{Agreeable people like agreeable virtual humans}},
url = {http://www.springerlink.com/index/DT61V8556710VW13.pdf},
year = {2008}
}
@article{Denef2009,
author = {Denef, Sebastian},
file = {::},
journal = {Human-Computer Interaction–INTERACT 2009},
pages = {864--867},
publisher = {Springer},
title = {{Human-Computer Interaction Techniques in Firefighting}},
url = {http://www.springerlink.com/index/n0688783567n3251.pdf},
year = {2009}
}
@article{Prendinger2006,
abstract = {This paper presents a novel method for evaluating the impact of animated interface agents with affective and empathic behavior. While previous studies relied on question- naires in order to assess the user’s overall experience with the interface agent, we will analyze users’ physiological response (skin conductance and electromyography), which allows us to estimate affect-related user experiences on a moment-by-moment basis with- out interfering with the primary interaction task. As an interaction scenario, a card game has been implemented where the user plays against a virtual opponent. The findings of our study indicate that within a competitive gaming scenario, (i) the absence of the agent’s display of negative emotions is conceived as arousing or stress-inducing, and (ii) the valence of users’ emotional response is congruent with the valence of the emotion expressed by the agent. Our results for skin conductance could also be reproduced by assuming a local rather than a global baseline.},
annote = {they have tested 4 different empathic behaviours in a competitive card game.
1- Non-Emotional2- Self-Centered Emotional
3- Negative Empathic 
4- Positive Empathic 
They found out that:
 - absence of the agent's display of negative emotions is arousing for the user and highers his/her stress.
 - valence of users' emotional response is congruent with the valence of the emotion expressed by the agent.},
author = {Prendinger, Helmut and Becker-Asano, Christian},
file = {::},
journal = {International Journal of Humanoid},
keywords = {affective behavior,empathy,evaluation,life-like characters,physiological user information},
number = {3},
pages = {371--391},
title = {{A Study in User's Physiological Response to an Empathic Interface Agent}},
volume = {3},
year = {2006}
}
@book{Izard1977,
address = {New York},
author = {Izard, Carroll Ellis},
editor = {Izard, Carroll Ellis},
isbn = {9780306309861},
pages = {495},
publisher = {Plenum Press},
title = {{Human Emotions}},
year = {1977}
}
@inproceedings{Becker2005,
abstract = {This paper first describes two independently conducted research strands on affective human-computer interaction: one on an emotion simulation system for an expressive 3D humanoid agent called Max, which was designed at the University of Bielefeld; the other one on a real-time system for empathic (agent) feedback that is based on human emotional states derived from physiological information, and developed at the University of Tokyo and the National Institute of Informatics. Then, the integration of both systems is suggested for the purpose of realizing a highly believable agent with empathic qualities.},
address = {Takamatsu, Kagawa, Japan},
author = {Becker-Asano, Christian and Prendinger, Helmut and Ishizuka, M.},
booktitle = {Proceedings of the 2005 International Conference on Active Media Technology, 2005. (AMT 2005)},
doi = {10.1109/AMT.2005.1505417},
file = {::},
isbn = {0780390350},
keywords = {embodied conversational agents,empa-},
pages = {541 -- 545},
title = {{Empathy for Max}},
url = {http://www.techfak.uni-bielefeld.de/~cbecker/becker-helmut-amt05.pdf},
year = {2005}
}
@inproceedings{Pasquariello2001,
author = {Pasquariello, Stefano and Pelachaud, Catherine},
booktitle = {Proceedings 6th Online World Conference on Soft Computing in Industrial Appications Session on Soft Computing for Intelligent 3D Agents},
title = {{Greta: A Simple Facial Animation Engine}},
year = {2001}
}
@inproceedings{Hegel2006,
author = {Hegel, Frank and Spexard, Torsten and Wrede, Britta and Horstmann, G. and Vogt, T.},
booktitle = {Humanoid Robots, 2006 6th IEEE-RAS International Conference on},
file = {::},
isbn = {142440200X},
pages = {56--61},
publisher = {IEEE},
title = {{Playing a different imitation game: Interaction with an Empathic Android Robot}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4115580},
year = {2006}
}
@article{Suchman1997,
abstract = {To formulate an empirically derived model of empathic communication in medical interviews by describing the specific behaviors and patterns of interaction associated with verbal expressions of emotion.},
author = {Suchman, a L and Markakis, K and Beckman, H B and Frankel, R},
file = {::},
issn = {0098-7484},
journal = {JAMA : the journal of the American Medical Association},
keywords = {Communication,Empathy,Humans,Interviews as Topic,Models,Physician-Patient Relations,Psychological},
month = feb,
number = {8},
pages = {678--82},
pmid = {9039890},
title = {{A model of empathic communication in the medical interview.}},
volume = {277},
year = {1997}
}
@article{CoanJr1984,
abstract = {Rapport is a characteristic of a relationship if there is a high degree of empathy, attention, and shared understanding and expectations. Rapport should be enhanced when the salesperson and the customer are comembers of the same group. Also, rapport should aid persuasion and help increase consumer satisfaction. Both observational and paper-and-pencil techniques can be used to measure rapport.},
author = {{Coan Jr}, G.},
file = {::},
journal = {Advances in Consumer Research},
pages = {333--336},
title = {{RAPPORT: DEFINITION AND DIMENSIONS}},
url = {http://www.acrwebsite.org/volumes/display.asp?id=6269},
volume = {11},
year = {1984}
}
@article{Caridakis2008,
abstract = {As input they consider the image sequence of the recorded human behavior. Computer vision and image processing techniques are incorporated in order to detect cues needed for expressivity features extraction. Using multimodalities, the virtual agent mimics the human expressions. The multimodality of the approach lies in the fact that both facial and gestural aspects of the user’s behavior are analyzed and processed. The mimicry consists of perception, interpretation, planning and animation of the expressions shown by the human, resulting not in an exact duplicate rather than an expressive model of the user’s original behavior.},
annote = {They use both facial and gestural aspects of the user’s behavior to mimic the user’s expressions. The introductory information and references about the psychological background of the mimicry in the paper are useful. But because most of the work is image processing, other sections would not be useful for our job.
Their system does not work in real time because they use a recorded video or sequence of images (limitation).},
author = {Caridakis, George and Raouzaiou, Amaryllis and Bevacqua, Elisabetta and Mancini, Maurizio and Karpouzis, Kostas and Malatesta, Lori and Pelachaud, Catherine},
doi = {10.1007/s10579-007-9057-1},
file = {::},
issn = {1574-020X},
journal = {Language Resources and Evaluation},
keywords = {facial,gesture,mimicry,multimodal,virtual agent},
month = jan,
number = {3-4},
pages = {367--388},
title = {{Virtual agent multimodal mimicry of humans}},
url = {http://www.springerlink.com/index/10.1007/s10579-007-9057-1},
volume = {41},
year = {2008}
}
@incollection{Miller1986,
abstract = {The matching hypothesis proposes that clients problem-drinkers who are matched to appropriate treatments will show greater improvement than will those who are unmatched or mismatched undifferentiated treatment: the status quo research strategies predictor studies differential studies problem severity cognitive style neuropsychological status self-esteem social stability client choice (PsycINFO Database Record (c) 2006 APA, all rights reserved)},
author = {Miller, William R. and Hester, Reid K},
booktitle = {Treating addictive behaviors Processes of change},
editor = {Miller, William R and Heather, Nick},
isbn = {0306422484},
pages = {175--203},
publisher = {Plenum Press},
title = {{Matching problem drinkers with optimal treatments.}},
year = {1986}
}
@inproceedings{Fabri2007,
abstract = {We present our work on emotionally expressive avatars, animated virtual characters that can express emotions via facial expressions. Because these avatars are highly distinctive and easily recognizable, they may be used in a range of applications. In the first part of the paper we present their use in computer mediated communication where two or more people meet in virtual space, each represented by an avatar. Study results suggest that social interaction behavior from the real-world is readily transferred to the virtual world. Empathy is identified as a key component for creating a more enjoyable experience and greater harmony between users. In the second part of the paper we discuss the use of avatars as an assistive, educational and therapeutic technology for people with autism. Based on the results of a preliminary study, we provide pointers regarding how people with autism may overcome some of the limitations that characterize their condition.},
address = {Beijing, China},
author = {Fabri, Marc and Elzouki, SYA},
booktitle = {Human-Computer Interaction, HCI Intelligent Multimodal Interaction Environments 12th International Conference},
doi = {10.1007/978-3-540-73110-8},
editor = {Jacko, Julie A.},
file = {::},
keywords = {Emotion,autism,avatar,education,empathy,facial messaging,therapeutic intervention,virtual reality},
pages = {275--285},
publisher = {Springer Berlin / Heidelberg},
title = {{Emotionally expressive avatars for chatting, learning and therapeutic intervention}},
url = {http://dl.acm.org/citation.cfm?id=1769621 http://www.springerlink.com/content/7gju6n38605hp3h2/},
year = {2007}
}
@article{Niewiadomski2008,
author = {Niewiadomski, Radoslaw and Ochs, Magalie},
file = {::},
journal = {Intelligent Virtual Agents},
keywords = {eca,empathy,facial expressions},
pages = {37--44},
title = {{Expressions of empathy in ECAs}},
url = {http://www.springerlink.com/index/618982507263X720.pdf},
year = {2008}
}
@misc{Putten2009,
abstract = {This study investigates whether humans perceive a higher degree of social presence when interacting with an animated character that displays natural as opposed to no listening behaviors and whether this interacts with people’s believe that they are interacting with an agent or an avatar. In a 2x2 between subjects experimental design 83 participants were either made believe that they encounter an agent, or that they communicate with another participant mediated by an avatar. In fact, in both conditions the communication partner was an autonomous agent that either exhibited high or low behavioral realism. We found that participants experienced equal amounts of presence, regardless of Behavioral interacting realism, however, had with an agent or an avatar. an impact on the subjective feeling of presence: people confronted with a character displaying high behavioral realism reported a higher degree of mutual awareness.},
author = {P\"{u}tten, Astrid M Von Der and Kr\"{a}mer, Nicole C and Gratch, Jonathan},
booktitle = {Design},
file = {::},
keywords = {avatars,behavioral realism,experimental study,virtual agents},
pages = {1--7},
title = {{Who's there? Can a Virtual Agent Really Elicit Social Presence?}},
year = {2009}
}
@article{Warner1987,
author = {Warner, Rebecca M. and Malloy, Daniel and Schneider, Kathy and Knoth, Russell and Wilder, Bruce},
doi = {10.1007/BF00990958},
file = {::},
issn = {0191-5886},
journal = {Journal of Nonverbal Behavior},
number = {2},
pages = {57--74},
title = {{Rhythmic organization of social interaction and observer ratings of positive affect and involvement}},
url = {http://www.springerlink.com/index/10.1007/BF00990958},
volume = {11},
year = {1987}
}
@article{Riek2008,
abstract = {Expressing empathy is a key component of human social communication. One common way people convey empathy is via facial expression mirroring. It may be helpful for machines intended to interact with people to also convey empathy in this manner. We have thus created Virgil, an expression-mimicking robot. We hypothesize that if people feel like a machine is empathizing with them they will be more likely to rate the interaction positively. We conducted a pilot study to test our hypothesis, and through quantitative and qualitative analysis of our results found some support for it.},
author = {Riek, Laurel D. and Robinson, Peter},
file = {::},
journal = {ACM Workshop on Affective Interaction in Natural Environments AFFINE at the International ACM Conference on Multimodal Interfaces ICMI 08},
pages = {1--5},
publisher = {ACM},
title = {{Real-time empathy: Facial mimicry on a robot}},
year = {2008}
}
@article{Davis1983,
author = {Davis, Mark H.},
doi = {10.1037/0022-3514.44.1.113},
file = {::},
issn = {0022-3514},
journal = {Journal of Personality and Social Psychology},
number = {1},
pages = {113--126},
title = {{Measuring individual differences in empathy: Evidence for a multidimensional approach.}},
volume = {44},
year = {1983}
}
@phdthesis{Lisetti2011,
author = {Lisetti, Christine L},
school = {Florida International University},
title = {{What Kind of Emotions Are There? Structure of Emotion}},
type = {Lecture},
year = {2011}
}
@incollection{Rogers1959,
address = {New York},
author = {Rogers, C R},
booktitle = {Psychology: the Study of a Science},
chapter = {3},
editor = {Koch, S},
pages = {184--256},
publisher = {McGraw-Hill},
title = {{A theory of therapy, personality and interpersonal relationships as developed in the client-centered framework}},
volume = {3},
year = {1959}
}
@article{DiMatteo1980,
abstract = {The relationship between physicians' nonverbal communication skills (their ability to communicate and to understand facial expression, body movement and voice tone cues to emotion) and their patients' satisfaction with medical care was examined in 2 studies. The research involved 71 residents in internal medicine and 462 of their ambulatory and hospitalized patients. Standardized, reliable and valid measures of nonverbal communication skills were administered to the physicians. Their scores on these tests were correlated with ratings they received from a sample of their patients on measures of satisfaction with the technical aspects and the socioemotional aspects (or art) of the medical care they received. While the nonverbal communication skills of the physicians bore little relationship to patients' ratings of the technical quality of care, measures of these skills did predict patient satisfaction with the art of medical care received. Across both samples, physicians who were more sensitive to body movement and posture cues to emotion (the channel suggested by nonverbal researchers as the one in which true affect can be perceived) received higher ratings from their patients on the art of care than did less sensitive physicians. In addition, physicians who were successful at expressing emotion through their nonverbal communications tended to receive higher ratings from patients on the art of care than did physicians who were less effective communicators. The implications of successfully identifying characteristics of physicians with whom patients are satisfied are discussed.},
author = {DiMatteo, M R and Taranta, a and Friedman, H S and Prince, L M},
file = {::},
issn = {0025-7079},
journal = {Medical care},
keywords = {Adult,Consumer Satisfaction,Evaluation Studies as Topic,Female,Humans,Male,Nonverbal Communication,Physician-Patient Relations},
month = apr,
number = {4},
pages = {376--87},
pmid = {7401698},
title = {{Predicting patient satisfaction from physicians' nonverbal communication skills.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/7401698},
volume = {18},
year = {1980}
}
@article{Rodrigues2009,
author = {Rodrigues, SH and Mascarenhas, SF},
file = {::},
isbn = {9781424447992},
journal = {and Workshops, 2009},
title = {{“ I can feel it too !”: Emergent empathic reactions between synthetic characters .}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5349570},
year = {2009}
}
@article{Cassell2001a,
abstract = {Prior research into embodied interface agents has found that users like them and find them engaging. However, results on the effectiveness of these interfaces for task completion have been mixed. In this paper, we argue that embodiment can serve an even stronger function if system designers use actual human conversational protocols in the design of the interface. Communicative behaviors such as salutations and farewells, conversational turn-taking with interruptions, and describing objects using hand gestures are examples of protocols that all native speakers of a language already know how to perform and can thus be leveraged in an intelligent interface. We discuss how these protocols are integrated into Rea, an embodied, multi-modal interface agent who acts as a real-estate salesperson, and we show why embodiment is required for their successful implementation.},
author = {Cassell, Justine},
doi = {10.1016/S0950-7051(00)00102-7},
issn = {09507051},
journal = {Knowledge-Based Systems},
keywords = {communicative behavior,embodied conversational agent,embodied interface agent,rea},
number = {1-2},
pages = {55--64},
publisher = {Elsevier},
title = {{More than just a pretty face: conversational protocols and the affordances of embodiment}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0950705100001027},
volume = {14},
year = {2001}
}
@misc{TheMendeleySupportTeam2011,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/The Mendeley Support Team - 2011 - Getting Started with Mendeley(4).pdf:pdf},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@article{Strecher1986,
abstract = {The concept of self-efficacy is receiving increasing recognition as a predictor of health behavior change and maintenance. The purpose of this article is to facilitate a clearer understanding of both the concept and its relevance for health education research and practice. Self-efficacy is first defined and distinguished from other related concepts. Next, studies of the self-efficacy concept as it relates to health practices are examined. This review focuses on cigarette smoking, weight control, contraception, alcohol abuse and exercise behaviors. The studies reviewed suggest strong relationships between self-efficacy and health behavior change and maintenance. Experimental manipulations of self-efficacy suggest that efficacy can be enhanced and that this enhancement is related to subsequent health behavior change. The findings from these studies also suggest methods for modifying health practices. These methods diverge from many of the current, traditional methods for changing health practices. Recommendations for incorporating the enhancement of self-efficacy into health behavior change programs are made in light of the reviewed findings.},
author = {Strecher, V J and DeVellis, B M and Becker, M H and Rosenstock, I M},
journal = {Health Education Quarterly},
number = {1},
pages = {73--92},
pmid = {3957687},
publisher = {Sage Publications},
title = {{The role of self-efficacy in achieving health behavior change.}},
url = {http://heb.sagepub.com/cgi/doi/10.1177/109019818601300108},
volume = {13},
year = {1986}
}
@article{Gratch2007a,
author = {Gratch, Jonathan and Wang, Ning and Gerten, Jillian and Fast, Edward},
file = {::},
journal = {Intelligent Virtual Agents},
keywords = {evaluation,rapport,virtual agents},
title = {{Creating rapport with virtual agents}},
url = {http://www.springerlink.com/index/X568357400058UM7.pdf},
year = {2007}
}
@article{Miller2010,
abstract = {The widely-disseminated clinical method of motivational interviewing (MI) arose through a convergence of science and practice. Beyond a large base of clinical trials, advances have been made toward “looking under the hood” of MI to understand the underlying mechanisms by which it affects behavior change. Such specification of outcome-relevant aspects of practice is vital to theory development, and can inform both treatment delivery and clinical training. An emergent theory of MI is proposed, emphasizing two specific active components: a relational component focused on empathy and the interpersonal spirit of MI, and a technical component involving the differential evocation and reinforcement of client change talk A resulting causal chain model links therapist training, therapist and client responses during treatment sessions, and post-treatment outcomes.},
author = {Miller, William R. and Rose, Gary S.},
doi = {10.1037/a0016830},
file = {::},
journal = {American Psychologist},
keywords = {Behavior change,Causal chain,Client-centered,Motivational interviewing,Psychotherapy,Theory,Therapeutic process},
number = {6},
pages = {527--537},
title = {{Toward a Theory of Motivational Interviewing}},
volume = {64},
year = {2010}
}
@article{Scherer2007,
abstract = {In earlier work, the authors analyzed emotion portrayals by professional actors separately for facial expression, vocal expression, gestures, and body movements. In a secondary analysis of the combined data set for all these modalities, the authors now examine to what extent actors use prototypical multimodal configurations of expressive actions to portray different emotions, as predicted by basic emotion theories claiming that expressions are produced by fixed neuromotor affect programs. Although several coherent unimodal clusters are identified, the results show only 3 multimodal clusters: agitation, resignation, and joyful surprise, with only the latter being specific to a particular emotion. Finding variable expressions rather than prototypical patterns seems consistent with the notion that emotional expression is differentially driven by the results of sequential appraisal checks, as postulated by componential appraisal theories.},
author = {Scherer, Klaus R and Ellgring, Heiner},
doi = {10.1037/1528-3542.7.1.158},
file = {::},
issn = {1528-3542},
journal = {Emotion (Washington, D.C.)},
keywords = {Adult,Affect,Facial Expression,Female,Gestures,Humans,Judgment,Male,Psychomotor Performance,Speech Acoustics,Voice},
month = feb,
number = {1},
pages = {158--71},
pmid = {17352571},
title = {{Multimodal expression of emotion: affect programs or componential appraisal patterns?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17352571},
volume = {7},
year = {2007}
}
@techreport{Gratch2010,
author = {Gratch, Jonathan and Kang, Sin-hwa and Wang, Ning},
booktitle = {Imagine},
file = {::},
institution = {University of Southern California},
number = {Chap X},
pages = {1--22},
title = {{Using social agents explore theories of rapport and emotional resonance}},
year = {2010}
}
@article{DeRosis2006,
abstract = {In this paper, we describe our experience with the design and implementation of an embodied conversational agent (ECA) that converses with users to change their dietary behavior. Our intent is to develop a system that dynamically models the agent and the user and adapts the agent's counseling dialog accordingly. Towards this end, we discuss our efforts to automatically determine the user's dietary behavior stage of change and attitude towards the agent on the basis of unconstrained typed text dialog, first with another person and then with an ECA controlled by an experimenter in a wizard of Oz study. We describe how the results of these studies have been incorporated into an algorithm that combines the results from simple parsing rules together with contextual features using a Bayesian network to determine user stage and attitude automatically.},
author = {de Rosis, Fiorella and Novielli, Nicole and Carofiglio, Valeria and Cavalluzzi, Addolorata and {De Carolis}, Berardina},
doi = {10.1016/j.jbi.2006.01.001},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/de Rosis et al. - 2006 - User modeling and adaptation in health promotion dialogs with an animated character(3).pdf:pdf},
issn = {1532-0480},
journal = {Journal of biomedical informatics},
keywords = {Artificial Intelligence,Communication,Health Promotion,Health Promotion: methods,Humans,Information Storage and Retrieval,Information Storage and Retrieval: methods,User-Computer Interface},
month = oct,
number = {5},
pages = {514--31},
pmid = {16524784},
title = {{User modeling and adaptation in health promotion dialogs with an animated character.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16524784},
volume = {39},
year = {2006}
}
@article{Grasso2011,
author = {Grasso, Floriana and Paris, C\'{e}cile},
doi = {10.1007/s11257-011-9099-3},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Grasso, Paris - 2011 - Preface to the special issue on personalization for e-health.pdf:pdf},
isbn = {1125701190993},
issn = {0924-1868},
journal = {User Modeling and User-Adapted Interaction},
month = may,
number = {4-5},
pages = {333--340},
title = {{Preface to the special issue on personalization for e-health}},
url = {http://www.springerlink.com/index/10.1007/s11257-011-9099-3},
volume = {21},
year = {2011}
}
@article{BienMiller1993,
author = {{Bien TH., and Miller WR., and Tonigan}, JS.},
journal = {Addiction},
keywords = {[PubMed: 8461850],brief intervention},
mendeley-tags = {[PubMed: 8461850]},
pages = {315--336},
title = {{Brief interventions for alcohol problems: A review.}},
volume = {88},
year = {1993}
}
@inproceedings{Boukricha2011b,
abstract = {Empathy is believed to play a major role as a basis for humans’ cooperative behavior. Recent research shows that humans empathize with each other to different degrees depending on several modulation factors including, among others, their social relationships, their mood, and the situational context. In human spatial interaction, partners share and sustain a space that is equally and exclusively reachable to them, the so-called interaction space. In a cooperative interaction scenario of relocating objects in interaction space, we introduce an approach for triggering and modulating a virtual humans cooperative spatial behavior by its degree of empathy with its interaction partner. That is, spatial distances like object distances as well as distances of arm and body movements while relocating objects in interaction space are modulated by the virtual human’s degree of empathy. In this scenario, the virtual human’s empathic emotion is generated as a hypothesis about the partner’s emotional state as related to the physical effort needed to perform a goal directed spatial behavior.},
address = {Berlin, Heidelberg},
author = {Boukricha, Hana and Nguyen, H.},
booktitle = {Proceedings of the 10th international conference on Intelligent virtual agents IVA'11},
doi = {10.1007/978-3-642-23974-8\_38},
editor = {Kopp, Stefan and Marsella, Stacy and Thorisson, Kristinn and Vilhjalmsson, Hannes},
file = {::},
pages = {350--362},
publisher = {Springer-Verlag},
title = {{Sharing Emotions and Space – Empathy as a Basis for Cooperative Spatial Interaction}},
url = {http://www.springerlink.com/content/q22784632u008337/},
year = {2011}
}
@article{Fehr1984,
author = {Fehr, B. and Russell, S.J.},
journal = {Journal of experimental psychology. General},
pages = {464 -- 486},
title = {{Concept of emotion viewed from a prototype perspective}},
volume = {113},
year = {1984}
}
@article{Hatfield2009,
author = {Hatfield, Elaine and Rapson, Richard L. and Le, Yen-Chi L.},
file = {::},
journal = {The social neuroscience of empathy},
pages = {1--20},
title = {{Emotional Contagion and Empathy}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=KLvJKTN\_nDoC\&amp;oi=fnd\&amp;pg=PA19\&amp;dq=Emotional+Contagion+and+Empathy\&amp;ots=gC929Xij3X\&amp;sig=IFpRxpx1igOlZl86Jr837oVgfhY},
year = {2009}
}
@article{Rebolledo-Mendez2009,
author = {Rebolledo-Mendez, Genaro and Freitas, Sara De and Gaona, Alma Rosa Garcia},
doi = {10.1109/VS-GAMES.2009.33},
file = {::},
isbn = {978-0-7695-3588-3},
journal = {2009 Conference in Games and Virtual Worlds for Serious Applications},
keywords = {- empathy,alma rosa garcia gaona,facultad de inform\'{a}tica,motivation,serious games,universidad veracruzana},
month = mar,
pages = {5--11},
publisher = {Ieee},
title = {{A Model of Motivation Based on Empathy for AI-Driven Avatars in Virtual Worlds}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5116547},
year = {2009}
}
@article{Mehrabian1996,
author = {Mehrabian, Albert},
file = {::},
journal = {Current Psychology},
number = {4},
pages = {261--292},
title = {{Pleasure-arousal-dominance: A general framework for describing and measuring individual differences in temperament}},
volume = {14},
year = {1996}
}
@book{Lang1997,
abstract = {A simple and rapid liquid chromatographic assay for the evaluation of potentially counterfeit oseltamivir (Tamiflu has been developed and assessed. The assay uses approximately 1mg Tamiflu powder when used for authentication and content estimate. The procedure was validated using 50 replicates analysed during five independent series with a total R.S.D. of 11.2\%. The assay can also be used to monitor the exact content of oseltamivir in Tamiflu capsules. One Tamiflu capsule was transferred to a 250mL volumetric flask and 150mL water was added. The flask was placed in an ultrasonic bath at 40 degrees C for 20min to dissolve the capsule. The solution was allowed to cool to room temperature before the flask was filled up to the mark (250mL). A small aliquot was centrifuged and then directly injected into the LC-system for quantification. Oseltamivir was analysed by liquid chromatography with UV detection on a Hypersil Gold column (150mmx4.6mm) using a mobile phase containing methanol-phosphate buffer (pH 2.5; 0.1M) (50:50, v/v) at a flow rate of 1.0mL/min. The assay was implemented for the analysis of Tamiflu purchased over the Internet and at local pharmacies in Thailand and Vietnam.},
author = {Lang, P J and Bradley, Margaret M and Cuthbert, B N},
booktitle = {Psychology},
doi = {10.1016/j.epsr.2006.03.016},
institution = {University of Florida},
issn = {07317085},
number = {4},
pages = {1--5},
pmid = {8625375},
publisher = {The Center for Research in Psychophysiology, University of Florida},
title = {{International Affective Picture System (IAPS): Technical Manual and Affective Ratings}},
url = {http://www.unifesp.br/dpsicobio/adap/instructions.pdf},
volume = {77},
year = {1997}
}
@article{Krumhuber2012,
abstract = {In this article, we present FACSGen 2.0, new animation software for creating static and dynamic three-dimensional facial expressions on the basis of the Facial Action Coding System (FACS). FACSGen permits total control over the action units (AUs), which can be animated at all levels of intensity and applied alone or in combination to an infinite number of faces. In two studies, we tested the validity of the software for the AU appearance defined in the FACS manual and the conveyed emotionality of FACSGen expressions. In Experiment 1, four FACS-certified coders evaluated the complete set of 35 single AUs and 54 AU combinations for AU presence or absence, appearance quality, intensity, and asymmetry. In Experiment 2, lay participants performed a recognition task on emotional expressions created with FACSGen software and rated the similarity of expressions displayed by human and FACSGen faces. Results showed good to excellent classification levels for all AUs by the four FACS coders, suggesting that the AUs are valid exemplars of FACS specifications. Lay participants' recognition rates for nine emotions were high, and comparisons of human and FACSGen expressions were very similar. The findings demonstrate the effectiveness of the software in producing reliable and emotionally valid expressions, and suggest its application in numerous scientific areas, including perception, emotion, and clinical and neuroscience research. (PsycINFO Database Record (c) 2012 APA, all rights reserved).},
author = {Krumhuber, Eva G and Tamarit, Lucas and Roesch, Etienne B and Scherer, Klaus R.},
doi = {10.1037/a0026632},
file = {::},
issn = {1931-1516},
journal = {Emotion},
keywords = {and recognition of emotions,animation,emotion,expressions,expressive stimuli has contributed,facial action coding system,facial expression,facsgen,knowledge of the perception,last years,much to our,over the,several databases of emotion-specific,the use of facial},
month = jan,
number = {2},
pages = {351--363},
pmid = {22251045},
title = {{FACSGen 2.0 animation software: Generating three-dimensional FACS-valid facial expressions for emotion research.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22251045},
volume = {12},
year = {2012}
}
@misc{Facebook,
title = {{Facebook}},
url = {http://www.facebook.com/}
}
@inproceedings{Gonsior2011,
abstract = {In this paper, the impact of facial expressions on HRI is explored. To determine their influence on empathy of a human towards a robot and perceived subjective performance, an experimental setup is created, in which participants engage in a dialog with the robot head EDDIE. The web-based gaming application “Akinator” serves as a backbone for the dialog structure. In this game, the robot tries to guess a thought-of person chosen by the human by asking various questions about the person. In our experimental evaluation, the robot reacts in various ways to the human's facial expressions, either ignoring them, mirroring them, or displaying its own facial expression based on a psychological model for social awareness. In which way this robot behavior influences human perception of the interaction is investigated by a questionnaire. Our results support the hypothesis that the robot behavior during interaction heavily influences the extent of empathy by a human towards a robot and perceived subjective task-performance, with the adaptive modes clearly leading compared to the non-adaptive mode.},
address = {Atlanta, GA, USA},
author = {Gonsior, Barbara and Sosnowski, Stefan and Mayer, Christoph and Blume, Jiirgen and Radig, B. and Wollherr, D. and Kuhnlenz, K.},
booktitle = {RO-MAN, 20th IEEE International Symposium on Robot and Human Interactive Communication},
doi = {10.1109/ROMAN.2011.6005294},
file = {::},
isbn = {9781457715730},
pages = {350--356},
publisher = {IEEE},
title = {{Improving aspects of empathy and subjective performance for HRI through mirroring facial expressions}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6005294},
year = {2011}
}
@inproceedings{Panagiotis2009,
abstract = {Emotion identification is beginning to be considered as an essential feature in human-computer interaction. However, most of the studies are mainly focused on facial expression classifications and speech recognition and not much attention has been paid until recently to physiological pattern recognition. In this paper, an integrative approach is proposed to emotional interaction by fusing multi-modal signals. Subjects are exposed to pictures selected from the International Affective Picture System (IAPS). A feature extraction procedure is used to discriminate between four affective states by means of a Mahalanobis distance classifier. The average classifications rate (74.11\%) was encouraging. Thus, the induced affective state is mirrored through an avatar by changing its facial characteristics and generating a voice message sympathising with the user’s mood. It is argued that multi-physiological patterning in combination with anthropomorphic avatars may contribute to the enhancement of affective multi-modal interfaces and the advancement of machine emotional intelligence.},
address = {San Diego, CA, USA},
author = {Panagiotis, D and Christos, A and Evdokimos, I and Manousos, A},
booktitle = {Ambient, Ubiquitous and Intelligent Interaction. 13th International Conference on Human-Computer Interaction},
doi = {10.1007/978-3-642-02580-8},
file = {::},
isbn = {9783642025808},
keywords = {Affective Computing,Avatar,EEG,Emotion,Mahalanobis,Skin Conductance,classifier},
number = {July},
pages = {565--574},
publisher = {Springer},
title = {{An integrated approach to emotion recognition for advanced emotional intelligence}},
year = {2009}
}
@article{Tickle-Degnen1990,
author = {Tickle-Degnen, L. and Rosenthal, Robert},
file = {::},
journal = {Psychological Inquiry},
number = {4},
pages = {285--293},
publisher = {Taylor \& Francis},
title = {{The nature of rapport and its nonverbal correlates}},
url = {http://www.tandfonline.com/doi/abs/10.1207/s15327965pli0104\_1},
volume = {1},
year = {1990}
}
@article{Lang1995,
abstract = {Emotions are action dispositions--states of vigilant readiness that vary widely in reported affect, physiology, and behavior. They are driven, however, by only 2 opponent motivational systems, appetitive and aversive--subcortical circuits that mediate reactions to primary reinforcers. Using a large emotional picture library, reliable affective psychophysiologies are shown, defined by the judged valence (appetitive/pleasant or aversive/unpleasant) and arousal of picture percepts. Picture-evoked affects also modulate responses to independently presented startle probe stimuli. In other words, they potentiate startle reflexes during unpleasant pictures and inhibit them during pleasant pictures, and both effects are augmented by high picture arousal. Implications are elucidated for research in basic emotions, psychopathology, and theories of orienting and defense. Conclusions highlight both the approach's constraints and promising paths for future study.},
author = {Lang, P J},
file = {::},
issn = {0003-066X},
journal = {The American psychologist},
keywords = {Affect,Arousal,Attention,Blinking,Humans,Mental Disorders,Mental Disorders: psychology,Motivation,Startle Reaction},
month = may,
number = {5},
pages = {372--85},
pmid = {7762889},
title = {{The emotion probe. Studies of motivation and attention.}},
volume = {50},
year = {1995}
}
@incollection{Stueber2008,
author = {Stueber, Karsten},
booktitle = {The Stanford Encyclopedia of Philosophy},
edition = {Fall 2008},
editor = {Zalta, Edward N.},
title = {{Empathy}},
url = {http://plato.stanford.edu/archives/fall2008/entries/empathy/},
year = {2008}
}
@inproceedings{Lisetti2012,
address = {Miami, FLorida},
author = {Lisetti, Christine L},
booktitle = {IHI2012 International Health Informatics Sysmposium},
file = {::},
title = {{10 Advantages of using Avatars in Patient-Centered Computer-based Interventions for Behavior Change}},
year = {2012}
}
@article{Page2002,
abstract = {In the Ultimatum Game, two players are asked to split a prize. The first player, the proposer, makes an offer of how to split the prize. The second player, the responder, either accepts the offer, in which case the prize is split as agreed, or rejects it, in which case neither player receives anything. The rational strategy suggested by classical game theory is for the proposer to offer the smallest possible positive share and for the responder to accept. Humans do not play this way, however, and instead tend to offer 50\% of the prize and to reject offers below 20\%. Here we study the Ultimatum Game in an evolutionary context and show that empathy can lead to the evolution of fairness. Empathy means that individuals make offers which they themselves would be prepared to accept.},
author = {Page, Karen M and Nowak, Martin a},
doi = {10.1006/bulm.2002.0321},
file = {::},
issn = {0092-8240},
journal = {Bulletin of mathematical biology},
keywords = {Biological Evolution,Choice Behavior,Empathy,Games, Experimental,Humans,Models, Psychological,Social Behavior},
month = nov,
number = {6},
pages = {1101--16},
pmid = {12508533},
title = {{Empathy leads to fairness.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12508533},
volume = {64},
year = {2002}
}
@article{Spurgeon2010,
abstract = {There has been a recent acceleration in the development and testing of programs for computer-assisted cognitive-behavioral therapy (CCBT). Programs are now available for treatment of depression, anxiety disorders, and other psychiatric conditions. Technology for delivery of CCBT includes multimedia programs, virtual reality, and handheld devices. Research on CCBT generally has supported the efficacy of computer-assisted therapy and has shown patient acceptance of computer tools for psychotherapy. Completion rates and treatment efficacy typically have been higher when clinicians prescribe and support the use of psychotherapeutic computer programs than when programs are delivered in a self-help format without clinician involvement. CCBT seems to have the potential to improve access to evidence-based therapies while reducing the demand for clinician time.},
author = {Spurgeon, Joyce a and Wright, Jesse H},
doi = {10.1007/s11920-010-0152-4},
file = {::},
isbn = {1192001001},
issn = {1535-1645},
journal = {Current psychiatry reports},
keywords = {Anxiety Disorders,Anxiety Disorders: therapy,Cognitive Therapy,Depressive Disorder,Depressive Disorder: therapy,Humans,Therapy, Computer-Assisted,Treatment Outcome},
month = dec,
number = {6},
pages = {547--52},
pmid = {20872100},
title = {{Computer-assisted cognitive-behavioral therapy.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20872100},
volume = {12},
year = {2010}
}
@book{Hojat2007,
author = {Hojat, Mohammadreza},
booktitle = {Patient Care},
file = {::},
isbn = {9780387336077},
publisher = {Springer Verlag},
title = {{Empathy in patient care: antecedents, development, measurement, and outcomes}},
year = {2007}
}
@article{Watson1985,
abstract = {Reanalyses of 7 studies of self-reported mood by researchers such as M. A. Lebo and J. R. Nesselroade (see record 1979-30118-001) and J. A. Russell and D. Ridgeway (see record 1984-03807-001) indicate that Positive Affect and Negative Affect consistently emerge as the 1st 2 varimax rotated dimensions in orthogonal factor analyses or as the 1st 2 2nd-order factors derived from oblique solutions. The 2 factors emerged with varying sets of descriptors and were even replicated in several data sets characterized by possible methodological problems (e.g., acquiescence response bias, inappropriate response formats) noted by earlier authors. The results thus attest to the stability and robustness of Positive and Negative Affect in self-report. Because this same 2-dimensional configuration has also been consistently identified in most other major lines of mood research, it is now firmly established as the basic structure of English-language affect at the general factor level.},
author = {Watson, D and Tellegen, A},
journal = {Psychological Bulletin},
number = {2},
pages = {219--235},
pmid = {3901060},
publisher = {bepress},
title = {{Toward a consensual structure of mood.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/3901060},
volume = {98},
year = {1985}
}
@inproceedings{Gordon1985,
address = {Baguio, Philippines},
annote = {Three ways to improve empathetic listening are to 
1.      Avoid judgment: the empathetic communicator must avoid making comparisons or passing moral judgments. 
2.      Give the speaker time to speak without interruption 
3.      Focus on the speaker: the empathetic communicator needs to focus his or her attention on the speaker, and not distract from this focus by verbally calling undue attention to oneself or one’s own situation [14]. },
author = {Gordon, Ronald D.},
booktitle = {International COnference of the World Communication Association},
pages = {1--16},
title = {{Empathy: The State of the Art and Science}},
year = {1985}
}
@article{Cox1988a,
author = {Cox, W M and Klinger, E},
file = {::},
issn = {0021-843X},
journal = {Journal of abnormal psychology},
keywords = {Affect,Alcoholism,Alcoholism: psychology,Animals,Decision Making,Ethanol,Ethanol: pharmacology,Humans,Models, Psychological,Motivation,Rats,Rats, Inbred Strains},
month = may,
number = {2},
pages = {168--80},
pmid = {3290306},
title = {{A motivational model of alcohol use.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22051204},
volume = {97},
year = {1988}
}
@article{Riek2009,
author = {Riek, Laurel D. and Paul, Philip C. and Robinson, Peter},
doi = {10.1007/s12193-009-0028-2},
file = {::},
issn = {1783-7677},
journal = {Journal on Multimodal User Interfaces},
keywords = {19,affective computing,emotionally conveying,empathy,expressions,facial,forms of expressive empathy,human-robot interaction,is known as,of the most basic,one,social robotics,understand what others are},
month = nov,
number = {1-2},
pages = {99--108},
title = {{When my robot smiles at me: Enabling human-robot rapport via real-time head gesture mimicry}},
url = {http://www.springerlink.com/index/10.1007/s12193-009-0028-2},
volume = {3},
year = {2009}
}
@inproceedings{Ehrlich2000,
abstract = {Designers of video-mediated communication and affective computing applications must make tradeoffs to deal with limited bandwidth. Typically spatial resolution and color are preserved at the expense of temporal resolution and accuracy. Our data suggest that this may not be the appropriate tradeoff for communicating facial affect; preserving motion is critical and may even compensate for major losses in image realism.},
address = {NY},
author = {Ehrlich, Sheryl M and Schiano, Diane J and Sheridan, Kyle},
booktitle = {Proceedings of ACM CHI 2000 Conference on Human Factors in Computing Systems},
file = {::},
keywords = {Facial affect,face,facial expression of emotion,image degradation,nonverbal communication,video conferencing.},
pages = {252--253},
publisher = {ACM},
title = {{Communicating Facial Affect : It ' s Not the Realism , It ' s the Motion}},
year = {2000}
}
@inproceedings{Wright2008,
author = {Wright, Peter and McCarthy, J.},
booktitle = {Proceeding of the twenty-sixth annual SIGCHI conference on Human factors in computing systems},
file = {::},
isbn = {9781605580111},
pages = {637--646},
publisher = {ACM},
title = {{Empathy and experience in HCI}},
url = {http://dl.acm.org/citation.cfm?id=1357156},
year = {2008}
}
@article{Roberts1996,
author = {Roberts, William and Strayer, Janet},
doi = {10.2307/1131826},
file = {::},
issn = {00093920},
journal = {Child Development},
month = apr,
number = {2},
pages = {449},
title = {{Empathy, Emotional Expressiveness, and Prosocial Behavior}},
url = {http://www.jstor.org/stable/1131826?origin=crossref},
volume = {67},
year = {1996}
}
@article{DeRosis2006,
abstract = {In this paper, we describe our experience with the design and implementation of an embodied conversational agent (ECA) that converses with users to change their dietary behavior. Our intent is to develop a system that dynamically models the agent and the user and adapts the agent's counseling dialog accordingly. Towards this end, we discuss our efforts to automatically determine the user's dietary behavior stage of change and attitude towards the agent on the basis of unconstrained typed text dialog, first with another person and then with an ECA controlled by an experimenter in a wizard of Oz study. We describe how the results of these studies have been incorporated into an algorithm that combines the results from simple parsing rules together with contextual features using a Bayesian network to determine user stage and attitude automatically.},
author = {de Rosis, Fiorella and Novielli, Nicole and Carofiglio, Valeria and Cavalluzzi, Addolorata and {De Carolis}, Berardina},
doi = {10.1016/j.jbi.2006.01.001},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/de Rosis et al. - 2006 - User modeling and adaptation in health promotion dialogs with an animated character(3).pdf:pdf},
issn = {1532-0480},
journal = {Journal of biomedical informatics},
keywords = {Artificial Intelligence,Communication,Health Promotion,Health Promotion: methods,Humans,Information Storage and Retrieval,Information Storage and Retrieval: methods,User-Computer Interface},
month = oct,
number = {5},
pages = {514--31},
pmid = {16524784},
title = {{User modeling and adaptation in health promotion dialogs with an animated character.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16524784},
volume = {39},
year = {2006}
}
@article{Meltzoff1977,
abstract = {Infants between 12 and 21 days of age can imitate both facial and manual gestures; this behavior cannot be explained in terms of either conditioning or innate releasing mechanisms. Such imitation implies that human neonates can equate their own unseen behaviors with gestures they see others perform.},
author = {Meltzoff, AN},
doi = {10.1126/science.198.4312.75},
file = {::},
issn = {0036-8075},
journal = {Science},
month = oct,
number = {4312},
pages = {75--8},
pmid = {17741897},
title = {{Imitation of facial and manual gestures by human neonates}},
volume = {198},
year = {1977}
}
@misc{TheMendeleySupportTeam2011,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/The Mendeley Support Team - 2011 - Getting Started with Mendeley(4).pdf:pdf},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@inproceedings{Heerink2009,
author = {Heerink, Marcel and Krose, B. and Evers, Vanessa and Wielinga, Bob},
booktitle = {Robot and Human Interactive Communication, 2009. RO-MAN 2009. The 18th IEEE International Symposium on},
file = {::},
pages = {528--533},
publisher = {Ieee},
title = {{Measuring acceptance of an assistive social robot: a suggested toolkit}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5326320},
year = {2009}
}
@article{Maurer1983,
author = {Maurer, R.E. and Tindall, J.H.},
file = {::},
journal = {Journal of Counseling Psychology},
number = {2},
pages = {158},
publisher = {American Psychological Association},
title = {{Effect of postural congruence on client's perception of counselor empathy.}},
volume = {30},
year = {1983}
}
@article{Ochs2010,
author = {Ochs, Magalie and Sadek, David and Pelachaud, Catherine},
doi = {10.1007/s10458-010-9156-z},
file = {::},
issn = {1387-2532},
journal = {Autonomous Agents and Multi-Agent Systems},
keywords = {affective computing,dialog,emotions,empathy,rational dialog agent},
month = nov,
title = {{A formal model of emotions for an empathic rational dialog agent}},
url = {http://www.springerlink.com/index/10.1007/s10458-010-9156-z},
year = {2010}
}
@inproceedings{Courgeon2008,
abstract = {Designing affective user interfaces involving expressive characters raises several questions. The system should be able to display facial expressions of complex emotions as dynamic and realtime reactions to user’s inputs. From a cognitive point of view, designers need to know how the user will perceive the dynamics of these facial expressions as a function of his/her input. We aim at evaluating if users can perceive different expressive profiles of a virtual character by manually controlling its expressions and observing its reaction to his/her input. This paper describes our platform that enables a virtual character to display blended facial expressions of emotions as realtime continuous reactions to users’ gesture input. We explain the techniques underlying the computation of intermediate facial expressions of emotion, and their control in the 3D space PAD (Pleasure, Arousal, Dominance) using gesture input. Preliminary results of a perceptive study show the potential of such an approach for assessing the dynamics of the perception of emotional expressions during gesture interaction with virtual characters endowed with different expressive profiles.},
address = {Estoril, Portugal},
annote = {The user reports his/her affective state in real-time with changing the position of a 3D point in PAD space using a joystick. The system captures the position of that point and maps it to a blend of 8 selected emotions. },
author = {Courgeon, Matthieu and Martin, Jean-claude and Jacquemin, Christian},
booktitle = {AAMAS '08 Proceedings of the 7th international joint conference on Autonomous agents and multiagent systems - Volume 3},
doi = {10.1.1.149.8130},
editor = {Padgham and Parkes and M\"{u}ller and Parsons},
file = {::},
keywords = {Expressive agent,facial expressions,realtime interaction},
number = {Aamas},
pages = {1237--1240},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
title = {{User’s Gestural Exploration of Different Virtual Agents ’ Expressive Profiles (Short Paper)}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.149.8130},
year = {2008}
}
@incollection{Miller1986,
abstract = {The matching hypothesis proposes that clients problem-drinkers who are matched to appropriate treatments will show greater improvement than will those who are unmatched or mismatched undifferentiated treatment: the status quo research strategies predictor studies differential studies problem severity cognitive style neuropsychological status self-esteem social stability client choice (PsycINFO Database Record (c) 2006 APA, all rights reserved)},
author = {Miller, William R. and Hester, Reid K},
booktitle = {Treating addictive behaviors Processes of change},
editor = {Miller, William R and Heather, Nick},
isbn = {0306422484},
pages = {175--203},
publisher = {Plenum Press},
title = {{Matching problem drinkers with optimal treatments.}},
year = {1986}
}
@book{McDougall1926,
address = {Boston},
author = {McDougall, William},
publisher = {Luce},
title = {{An introduction to social psychology}},
year = {1926}
}
@incollection{Bavelas1987,
address = {Cambridge, UK},
author = {Bavelas, Janet Beavin and Black, Alex and Lemery, Charles R. and Mullett, Jennifer},
booktitle = {Motor mimicry as primitive empathy},
editor = {Eisenberg, Nancy and Strayer, Janet},
file = {::},
pages = {317--338},
publisher = {Cambridge University Press},
title = {{Empathy and its developement}},
year = {1987}
}
@inproceedings{Knoppel2008,
abstract = {DEIRA is a virtual agent commenting on virtual horse races in real time. DEIRA analyses the state of the race, acts emotionally and comments about the situation in a believable and engaging way, using synthesized speech and facial expressions. In this paper we discuss the challenges, explain the computational models for the cognitive, emotional and communicative behavior, and account on implementation and feedback from users.},
address = {Estoril, Portugal},
author = {Knoppel, Fran\c{c}ois L A and Tigelaar, Almer S and Bos, Danny Oude and Alofs, Thijs and Ruttkay, Zs\'{o}fia},
booktitle = {7th international joint conference on Autonomous agents and multiagent systems},
editor = {Padgham and Parkes and M\"{u}ller and Parsons},
file = {::},
keywords = {emotion,facial expressions,intelligent virtual agent,modeling,multimodal communication,synthetic speech},
pages = {112--119},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org)},
title = {{Trackside DEIRA : A Dynamic Engaging Intelligent Reporter Agent}},
url = {http://dl.acm.org/citation.cfm?id=1402404},
year = {2008}
}
@article{Scherer2003,
author = {Scherer, Klaus R},
doi = {10.1016/S0167-6393(02)00084-5},
file = {::},
issn = {01676393},
journal = {Speech communication},
month = apr,
number = {1-2},
pages = {227--256},
title = {{Vocal communication of emotion: A review of research paradigms}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167639302000845 http://www.sciencedirect.com/science/article/pii/S0167639302000845},
volume = {40},
year = {2003}
}
@article{Szymanski2012,
abstract = {Psycholinguistic theories of semantic memory form the basis of understanding of natural language concepts. These theories are used here as an inspiration for implementing a computational model of semantic memory in the form of semantic network. Combining this network with a vector-based object-relation-feature value representation of concepts that includes also weights for confidence and sup- port, allows for recognition of concepts by referring to their features, enabling a semantic search algorithm. This algorithm has been used for word games, in particular the 20-question game in which the program tries to guess a concept that a human player thinks about. The game facilitates lexical knowledge validation and acquisition through the interaction with humans via supervised dialog templates. The elementary linguistic competencies of the proposed model have been evaluated assessing how well it can represent the meaning of lin- guistic concepts. To study properties of information retrieval based on this type of semantic representation in contexts derived from on-going dialogs experiments in limited domains have been performed. Several similarity measures have been used to compare the com- pleteness of knowledge retrieved automatically and corrected through active dialogs to a “golden standard”. Comparison of semantic search with human performance has been made in a series of 20-question games. On average results achieved by human players were better than those obtained by semantic search, but not by a wide margin.},
author = {Szymański, Julian and Duch, Wlodzislaw},
doi = {10.1016/j.cogsys.2011.02.002},
file = {::},
issn = {13890417},
journal = {Cognitive Systems Research},
keywords = {corresponding author at,department of informatics,leading to low precision,nicolaus,that is returning},
month = apr,
number = {1},
pages = {84--100},
title = {{Information retrieval with semantic memory model}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1389041711000179},
volume = {14},
year = {2012}
}
@article{Kessous2009,
author = {Kessous, Loic and Castellano, Ginevra and Caridakis, George},
doi = {10.1007/s12193-009-0025-5},
file = {::},
issn = {1783-7677},
journal = {Journal on Multimodal User Interfaces},
keywords = {affective body language,affective speech,emotion recognition,facial expression,multimodal},
month = dec,
number = {1-2},
pages = {33--48},
title = {{Multimodal emotion recognition in speech-based interaction using facial expression, body gesture and acoustic analysis}},
url = {http://www.springerlink.com/index/10.1007/s12193-009-0025-5},
volume = {3},
year = {2009}
}
@article{Fagerstrom1990,
author = {Fagerstrom, K O and Heatherton, T F and Kozlowski, L T},
institution = {Department of Psychology, Harvard University.},
journal = {Ear nose throat journal},
keywords = {*adverse effects,*diagnosis,*nicotine,*standards,alcoholism,complications,etiology,human,ph,prevention \& control,psyc,questionnaires,smoking,substance related disorders},
number = {11},
pages = {763--765},
pmid = {2276350},
title = {{Nicotine addiction and its assessment.}},
volume = {69},
year = {1990}
}
@article{Yacoub2003,
author = {Yacoub, Sherif and Simske, Steve and Lin, Xiaofan and Burns, John},
file = {::},
journal = {8th European Conference on Speech Communication and Technology},
number = {September},
pages = {1--4},
title = {{Recognition of emotions in interactive voice response systems}},
url = {http://www.isca-speech.org/archive/eurospeech\_2003/e03\_0729.html},
year = {2003}
}
@inproceedings{Partala2000,
abstract = {This paper investigated in two experiments pupillary responses to emotionally provocative sound stimuli. In experiment one, 30 subjects' pupillary responses were measured while listening to 10 negatively and 10 positively arousing sounds, and 10 emotionally neutral sounds. In addition, the subjects rated their subjective experiences to these stimuli. The results showed that the pupil size was significantly larger after highly arousing positive and negative stimuli than after neutral stimuli with medium arousal. In experiment two, the contents of the stimuli were more controlled than in experiment one. 22 subjects' pupillary responses were measured while listening to four negatively and four positively arousing sounds, and four emotionally neutral sounds. The results showed that the pupil size was significantly larger during negative highly arousing stimuli than during moderately arousing positive stimuli. The pupil size was alsosignificantly larger after highly arousing negative stimuli than after moderately arousing neutral and positive stimuli. The results of the two experiments suggest that pupil size discriminates during and after different kinds of emotional stimuli. Thus, the measurement of pupil size variation may be a potentially useful computer input signal, for example, for affective computing.},
author = {Partala, Timo and Jokiniemi, Maria and Surakka, Veikko},
booktitle = {of the 2000 symposium on Eye},
doi = {10.1145/355017.355042},
isbn = {1581132808},
pages = {123--129},
publisher = {ACM},
title = {{Pupillary responses to emotionally provocative stimuli}},
url = {http://dl.acm.org/citation.cfm?id=355042},
year = {2000}
}
@article{VanSwol2003,
author = {{Van Swol}, Lyn M.},
doi = {10.1177/0093650203253318},
file = {::},
issn = {00000000},
journal = {Communication Research},
month = aug,
number = {4},
pages = {461--480},
title = {{The Effects of Nonverbal Mirroring on Perceived Persuasiveness, Agreement with an Imitator, and Reciprocity in a Group Discussion}},
volume = {30},
year = {2003}
}
@article{Neighbors2004,
abstract = {The authors evaluated the efficacy of a computer-delivered personalized normative feedback intervention in reducing alcohol consumption among heavy-drinking college students. Participants included 252 students who were randomly assigned to an intervention or control group following a baseline assessment. Immediately after completing measures of reasons for drinking, perceived norms, and drinking behavior, participants in the intervention condition were provided with computerized information detailing their own drinking behavior, their perceptions of typical student drinking, and actual typical student drinking. Results indicated that normative feedback was effective in changing perceived norms and alcohol consumption at 3- and 6-month follow-up assessments. In addition, the intervention was somewhat more effective at 3-month follow-up among participants who drank more for social reasons.},
author = {C, Neighbors and ME, Larimer and MA, Lewis},
doi = {10.1037/0022-006X .72.3.434},
journal = {Journal of Consulting and Clinical Psychology},
number = {3},
pages = {434--447},
title = {{Targeting misperceptions of descriptive drinking norms: efficacy of a computer-delivered personalized normative feedback intervention}},
volume = {72},
year = {2004}
}
@article{Pelachaud2009,
abstract = {Over the past few years we have been developing an expressive embodied conversational agent system. In particular, we have developed a model of multimodal behaviours that includes dynamism and complex facial expressions. The first feature refers to the qualitative execution of behaviours. Our model is based on perceptual studies and encompasses several parameters that modulate multimodal behaviours. The second feature, the model of complex expressions, follows a componential approach where a new expression is obtained by combining facial areas of other expressions. Lately we have been working on adding temporal dynamism to expressions. So far they have been designed statically, typically at their apex. Only full-blown expressions could be modelled. To overcome this limitation, we have defined a representation scheme that describes the temporal evolution of the expression of an emotion. It is no longer represented by a static definition but by a temporally ordered sequence of multimodal signals.},
author = {Pelachaud, Catherine},
doi = {10.1098/rstb.2009.0186},
file = {::},
issn = {1471-2970},
journal = {Philosophical transactions of the Royal Society of London. Series B, Biological sciences},
keywords = {Computer Simulation,Emotions,Emotions: physiology,Facial Expression,Humans,Models, Psychological,Social Behavior},
month = dec,
number = {1535},
pages = {3539--48},
pmid = {19884148},
title = {{Modelling multimodal expression of emotion in a virtual agent.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2781894\&tool=pmcentrez\&rendertype=abstract},
volume = {364},
year = {2009}
}
@article{XinLuo2007,
abstract = {The present study investigated the ability of normal-hearing listeners and cochlear implant users to recognize vocal emotions. Sentences were produced by 1 male and 1 female talker according to 5 target emotions: angry, anxious, happy, sad, and neutral. Overall amplitude differences between the stimuli were either preserved or normalized. In experiment 1, vocal emotion recognition was measured in normal-hearing and cochlear implant listeners; cochlear implant subjects were tested using their clinically assigned processors. When overall amplitude cues were preserved, normal-hearing listeners achieved near-perfect performance, whereas listeners with cochlear implant recognized less than half of the target emotions. Removing the overall amplitude cues significantly worsened mean normal-hearing and cochlear implant performance. In experiment 2, vocal emotion recognition was measured in listeners with cochlear implant as a function of the number of channels (from 1 to 8) and envelope filter cutoff frequency (50 vs 400 Hz) in experimental speech processors. In experiment 3, vocal emotion recognition was measured in normal-hearing listeners as a function of the number of channels (from 1 to 16) and envelope filter cutoff frequency (50 vs 500 Hz) in acoustic cochlear implant simulations. Results from experiments 2 and 3 showed that both cochlear implant and normal-hearing performance significantly improved as the number of channels or the envelope filter cutoff frequency was increased. The results suggest that spectral, temporal, and overall amplitude cues each contribute to vocal emotion recognition. The poorer cochlear implant performance is most likely attributable to the lack of salient pitch cues and the limited functional spectral resolution.},
author = {{Xin Luo} and Fu, Qian-Jie and Galvin, John J},
doi = {10.1177/1084713807305301},
file = {::},
issn = {1084-7138},
journal = {Trends in amplification},
keywords = {Aged,Auditory Perception,Cochlear Implants,Cues,Emotions,Female,Hearing Disorders,Hearing Disorders: psychology,Hearing Disorders: surgery,Hearing Impaired Persons,Humans,Male,Middle Aged,Pitch Perception,Rehabilitation of Hearing Impaired,Speech Acoustics,Speech Perception,Time Factors},
month = dec,
number = {4},
pages = {301--15},
pmid = {18003871},
title = {{Vocal emotion recognition by normal-hearing listeners and cochlear implant users.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3210149\&tool=pmcentrez\&rendertype=abstract},
volume = {11},
year = {2007}
}
@book{Hojat2007,
author = {Hojat, M.},
booktitle = {Patient Care},
file = {::},
isbn = {9780387336077},
publisher = {Springer Verlag},
title = {{Empathy in patient care: antecedents, development, measurement, and outcomes}},
year = {2007}
}
@article{Bailenson2005,
abstract = {Previous research demonstrated social influence resulting from mimicry (the chameleon effect); a confederate who mimicked participants was more highly regarded than a confederate who did not, despite the fact that participants did not explicitly notice the mimicry. In the current study, participants interacted with an embodied artificial intelligence agent in immersive virtual reality. The agent either mimicked a participant's head movements at a 4-s delay or utilized prerecorded movements of another participant as it verbally presented an argument. Mimicking agents were more persuasive and received more positive trait ratings than nonmimickers, despite participants' inability to explicitly detect the mimicry. These data are uniquely powerful because they demonstrate the ability to use automatic, indiscriminate mimicking (i.e., a computer algorithm blindly applied to all movements) to gain social influence. Furthermore, this is the first study to demonstrate social influence effects with a nonhuman, nonverbal mimicker.},
author = {Bailenson, Jeremy N and Yee, Nick},
file = {::},
journal = {Psychological Science},
number = {10},
pages = {814--819},
title = {{Digital Chameleons: Automatic Assimilation of Nonverbal Gestures in Immersive Virtual Environments}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16181445},
volume = {16},
year = {2005}
}
@article{Lafrance1976,
author = {Lafrance, Marianne and Broadbent, M.},
doi = {10.1177/105960117600100307},
file = {::},
isbn = {1059601176},
issn = {1059-6011},
journal = {Group \& Organization Management},
month = sep,
number = {3},
pages = {328--333},
title = {{Group Rapport: Posture Sharing as a Nonverbal Indicator}},
volume = {1},
year = {1976}
}
@book{Miller1995a,
author = {Miller, William R. and Tonigan, JS and Longabaugh, R},
booktitle = {Psychology},
editor = {Mattson, Margaret E},
pages = {98},
publisher = {National Institute on Alcohol Abuse and Alcoholism},
series = {Project MATCH Monograph Series},
title = {{The Drinker Inventory of Consequences (DrInC): An Instrument for Assessing Adverse Consequences of Alcohol Abuse}},
url = {http://scholar.google.com/scholar?q=The+Drinker+Inventory+of+Consequences+(DrInC).+An+Instrument+for+Assessing+Adverse+Consequences+of+Alcohol+Abuse\&hl=en\&btnG=Search\&as\_sdt=2001\&as\_sdtp=on\#1},
volume = {4},
year = {1995}
}
@article{Cowell2005,
abstract = {For years, people have sought more natural means of communicating with their computers. Many have suggested that interaction with a computer should be as easy as interacting with other people, taking advantage of the multimodal nature of human communication. While users should, in theory, gravitate to such anthropomorphic embodiments, quite the contrary has been experienced; users generally have been dissatisfied and abandoned their use. This suggests a disconnect between factors that make human-human communication engaging and those used by designers to support human-agent interaction. This paper discusses a set of empirical studies that attempted to replicate human-human non-verbal behavior. The focus revolved around behaviors that portray a credible fa\c{c}ade, thereby helping embodied conversational agents (ECAs) to form a successful cooperative dyad with users. Based on a review of the non-verbal literature, a framework was created that identified trustworthy and credible non-verbal behaviors across five areas and formed design guidelines for character interaction. The design suggestions for those areas emanating from the facial region were experimentally supported but there was no concordant increase in perceived trust when bodily regions (posture, gesture) were added. In addition, in examining the importance of demographic elements in embodiment, it was found that users prefer to interact with characters that match their ethnicity and are young looking. There was no significant preference for gender. The implications of these results, as well as other interesting consequences are discussed.},
author = {Cowell, Andrew J. and Stanney, Kay M.},
doi = {10.1016/j.ijhcs.2004.11.008},
file = {::},
issn = {10715819},
journal = {International Journal of Human-Computer Studies - Special issue: Subtle expressivity for characters and robots},
keywords = {Anthropomorphic interfaces,Interface agents,Non-verbal behavior},
month = feb,
number = {2},
pages = {281--306},
title = {{Manipulation of non-verbal interaction style and demographic embodiment to increase anthropomorphic computer character credibility}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1071581904001260 http://ocw.tudelft.nl/fileadmin/ocw/opener/Manipulation\_of\_non-verbal\_interaction\_style\_and\_demographic\_embodiment\_to\_increase\_anthropomorphic\_computer\_character\_credibility.pdf},
volume = {62},
year = {2005}
}
@article{Shamay-Tsoory2011,
abstract = {Human empathy relies on the ability to share emotions as well as the ability to understand the other's thoughts, desires, and feelings. Recent evidence points to 2 separate systems for empathy: an emotional system that supports our ability to empathize emotionally and a cognitive system that involves cognitive understanding of the other's perspective. A neural network that includes the inferior frontal gyrus and the inferior parietal lobule is necessary for emotion recognition and emotional contagion. Although the emotional and cognitive systems appear to work independently, every empathic response may still evoke both components to some extent, depending on the social context.},
annote = {Difference between cognitive empathy and emotional empathy is explained in this paper. Also they talk about the active brain parts in each empathy type.},
author = {Shamay-Tsoory, Simone G},
doi = {10.1177/1073858410379268},
file = {::},
issn = {1089-4098},
journal = {The Neuroscientist : a review journal bringing neurobiology, neurology and psychiatry},
keywords = {Brain,Brain: physiology,Empathy,Empathy: physiology,Humans,Neural Pathways,Neural Pathways: physiology},
month = feb,
number = {1},
pages = {18--24},
pmid = {21071616},
title = {{The neural bases for empathy.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21071616},
volume = {17},
year = {2011}
}
@article{Novielli2010,
abstract = {We describe how the interaction mode with an embodied conversational agent (ECA) affects the users’ perception of the agent and their behavior during interaction, and propose a method to recognize the social attitude of users towards the agent from their verbal behavior. A corpus of human–ECA dialogues was collected with a Wizard-of-Oz study in which the input mode of the user moves was varied (written vs. speech-based). After labeling the corpus, we evaluated the relationship between input mode and social attitude of users towards the agent. The results show that, by increasing naturalness of interaction, spoken input produces a warmer attitude of users and a richer language: this effect is more evident for users with a background in humanities. Recognition of signs of social attitude is needed for adapting the ECA’s verbal and nonverbal behavior.},
author = {Novielli, Nicole and de Rosis, Fiorella and Mazzotta, Irene},
doi = {10.1016/j.pragma.2009.12.016},
file = {::},
issn = {03782166},
journal = {Journal of Pragmatics},
keywords = {evaluation of artificial agents,natural language user interfaces,user-centered design},
month = sep,
number = {9},
pages = {2385--2397},
publisher = {Elsevier B.V.},
title = {{User attitude towards an embodied conversational agent: Effects of the interaction mode}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0378216609003324},
volume = {42},
year = {2010}
}
@misc{Gordon1985a,
annote = {Three ways to improve empathetic listening are to 
1.      Avoid judgment: the empathetic communicator must avoid making comparisons or passing moral judgments. 
2.      Give the speaker time to speak without interruption 
3.      Focus on the speaker: the empathetic communicator needs to focus his or her attention on the speaker, and not distract from this focus by verbally calling undue attention to oneself or one’s own situation [14]. },
author = {Gordon, Ronald D.},
file = {::},
pages = {1--16},
title = {{Empathy- The State of the Art and Science.pdf}},
year = {1985}
}
@article{Gratch2006,
author = {Gratch, Jonathan and Okhmatovskaia, Anna and Lamothe, Francois},
file = {::},
journal = {Intelligent Virtual},
title = {{Virtual rapport}},
url = {http://www.springerlink.com/index/k720537752657m81.pdf},
year = {2006}
}
@article{Prochaska1997,
abstract = {The transtheoretical model posits that health behavior change involves progress through six stages of change: precontemplation, contemplation, preparation, action, maintenance, and termination. Ten processes of change have been identified for producing progress along with decisional balance, self-efficacy, and temptations. Basic research has generated a rule of thumb for at-risk populations: 40\% in precontemplation, 40\% in contemplation, and 20\% in preparation. Across 12 health behaviors, consistent patterns have been found between the pros and cons of changing and the stages of change. Applied research has demonstrated dramatic improvements in recruitment, retention, and progress using stage-matched interventions and proactive recruitment procedures. The most promising outcomes to data have been found with computer-based individualized and interactive interventions. The most promising enhancement to the computer-based programs are personalized counselors. One of the most striking results to date for stage-matched programs is the similarity between participants reactively recruited who reached us for help and those proactively recruited who we reached out to help. If results with stage-matched interventions continue to be replicated, health promotion programs will be able to produce unprecedented impacts on entire at-risk populations.},
author = {Prochaska, J O and Velicer, W F},
chapter = {5},
doi = {10.4278/0890-1171-12.1.38},
editor = {Shumaker, S A and Schron, E B},
institution = {Cancer Prevention Research Center, University of Rhode Island, Kingston 02881-0808, USA. JOP@URIACC.URI.EDU},
issn = {08901171},
journal = {American Journal Of Health Promotion},
number = {1},
pages = {38--48},
publisher = {American Journal of Health Promotion P.O. Box 1897, 810 East 10th Street, Lawrence, KS 66044-8897},
title = {{The transtheoretical model of health behavior change}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10170434},
volume = {12},
year = {1997}
}
@article{D&39;Mello2006,
author = {Mello, Sidney D' and Graesser, Arthur C},
file = {::},
journal = {Intelligent Virtual Agents},
pages = {54--67},
title = {{Affect detection from human-computer dialogue with an intelligent tutoring system}},
url = {http://www.springerlink.com/index/b574kpu6nl719408.pdf},
year = {2006}
}
@article{Gunes2010,
author = {Gunes, Hatice and Pantic, Maja},
doi = {10.4018/jse.2010101605},
file = {::},
issn = {1947-9093},
journal = {International Journal of Synthetic Emotions},
keywords = {bodily expression,continuous emotion recognition,dimensional emotion modelling,emotional acoustic and bio-signals,facial expression,multimodal fusion},
month = jan,
number = {1},
pages = {68--99},
title = {{Automatic, Dimensional and Continuous Emotion Recognition}},
volume = {1},
year = {2010}
}
@article{Rodrigues2009,
author = {Rodrigues, SH and Mascarenhas, SF},
file = {::},
isbn = {9781424447992},
journal = {and Workshops, 2009},
title = {{“ I can feel it too !”: Emergent empathic reactions between synthetic characters}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5349570},
year = {2009}
}
@article{Bickmore2005,
author = {Bickmore, TW},
journal = {ACM Transactions on Computer-Human},
pages = {617--638},
title = {{Establishing and maintaining long-term human-computer relationships}},
url = {http://dl.acm.org/citation.cfm?id=1067860.1067867},
year = {2005}
}
@article{Picard2001,
author = {Picard, Rosalind W and Vyzas, E. and Healey, J.},
doi = {10.1109/34.954607},
file = {::},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {10},
pages = {1175--1191},
title = {{Toward machine emotional intelligence: analysis of affective physiological state}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=954607},
volume = {23},
year = {2001}
}
@article{Cassell1999,
abstract = {In this article we describe results froman experiment of user interaction with autonomous , human - like ( humanoid ) conversational agents . We hypothesize that for embodied conversational agents , nonverbal behaviors related to the process of conversation , what we call envelope feedback, is much more important than other feedback , such as emotional expression . We test this hypothesis by having subjects interact with three autonomous agents , all capable of full - duplex multimodal interaction: able to generate and recognize speech , intonation , facial displays , and gesture . Each agent , however , gave a different kind of feedback: ( 1 ) content - related only , ( 2 ) content + envelope feedback , and ( 3 ) content + emotional . Content-related feedback includes answering questions and executing commands; envelope feedback includes behaviors such as gaze , manual beat gesture , and head movements; emotional feedback includes smiles and looks of puzzlement . Subjects' evaluations of the systemwere collected with a questionnaire , and videotapes of their speech patterns and behaviors were scored according to how often the users repeated themselves , how often they hesitated , and how often they got frustrated . The results confirmour hypothesis that envelope feedback is more important in interaction than emotional feedback and that envelope feedback plays a crucial role in supporting the process of dialog . A secondary result fromthis study shows that users give our multimodal conversational humanoids very high ratings of lifelikeness and fluidity of interaction when the agents are capable of giving such feedback .},
author = {Cassell, Justine and Thorisson, K.R.},
doi = {10.1080/088395199117360},
file = {::},
journal = {Applied Artificial Intelligence},
number = {4-5},
pages = {519--538},
publisher = {Taylor \& Francis},
title = {{The power of a nod and a glance: Envelope vs. emotional feedback in animated conversational agents}},
url = {http://www.tandfonline.com/doi/abs/10.1080/088395199117360},
volume = {13},
year = {1999}
}
@article{Becker-Asano2009,
abstract = {We introduce theWASABI ([W]ASABI [A]ffect [S]imulation for [A]gents with [B]elievable [I]nteractivity)Affect SimulationArchitecture, in which a virtual human’s cog- nitive reasoning capabilities are combined with simulated embodiment to achieve the sim- ulation of primary and secondary emotions. In modeling primary emotions we follow the idea of “Core Affect” in combination with a continuous progression of bodily feeling in three-dimensional emotion space (PADspace), that is subsequently categorized into discrete emotions. In humans, primary emotions are understood as onto-genetically earlier emotions, which directly influence facial expressions. Secondary emotions, in contrast, afford the abil- ity to reason about current events in the light of experiences and expectations.},
author = {Becker-Asano, Christian and Wachsmuth, Ipke},
doi = {10.1007/s10458-009-9094-9},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Becker-Asano, Wachsmuth - 2009 - Affective computing with primary and secondary emotions in a virtual human(3).pdf:pdf},
issn = {1387-2532},
journal = {Autonomous Agents and Multi-Agent Systems},
keywords = {affect simulation,affective computing,affective gaming,architecture,aware emotions,bdi-based architecture,embodied agent,emotion dynamics,emotion expression,emotion modeling,pad emotion space,primary and secondary emotions,reality,virtual,virtual human},
month = may,
number = {1},
pages = {32--49},
title = {{Affective computing with primary and secondary emotions in a virtual human}},
url = {http://www.becker-asano.de/AffectiveComputingWithPrimaryAndSecondaryEmotionsInAVirtualHuman.pdf},
volume = {20},
year = {2009}
}
@misc{Putten2009,
author = {P\"{u}tten, Astrid M Von Der and Kr\"{a}mer, Nicole C and Gratch, Jonathan},
booktitle = {Design},
file = {::},
keywords = {avatars,behavioral realism,experimental study,virtual agents},
pages = {1--7},
title = {{Who´s there? Can a Virtual Agent Really Elicit Social Presence?}},
year = {2009}
}
@misc{TheMendeleySupportTeam2011,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/The Mendeley Support Team - 2011 - Getting Started with Mendeley(4).pdf:pdf},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@inproceedings{Johnson2004,
abstract = {Embodied conversational agents (ECA) have potential as facilitators for health interventions. However, their utility is limited as long as people must sit down in front of a computer to access them. This paper describes a project that is deploying an ECA on a handheld computer, and using it to assist in a psychosocial intervention aimed at providing training in problem solving skills. The agent is based upon the virtual trainer/counselor in the pedagogical drama Carmen’s Bright IDEAS, adapted for handheld use and for interaction with a human caregiver. The system will go into clinical trails in August of 2004. The paper discusses the design and technical issues involved in the transition from laptop computer to handheld device and from 3rd-person view to first-person interaction, and the plan for evaluation. The clinical trial is designed both to evaluate psychosocial outcomes and to assess user preferences in ECA interaction modalities over the course of multiple sessions of use.},
author = {Johnson, WL and LaBore, C},
booktitle = {AAAI Fall Symposium on Dialogue Systems for Health Communication},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Johnson, LaBore, Chiu - 2004 - A pedagogical agent for psychosocial intervention on a handheld computer(4).pdf:pdf},
pages = {22--24},
title = {{A pedagogical agent for psychosocial intervention on a handheld computer}},
year = {2004}
}
@article{Hogan1969,
author = {Hogan, R},
file = {::},
issn = {0022-006X},
journal = {Journal of consulting and clinical psychology},
keywords = {Emotions,Humans,MMPI,Morals,Personality Assessment,Personality Inventory,Social Behavior,Social Perception,Social Values,Socialization},
month = jun,
number = {3},
pages = {307--16},
pmid = {4389335},
title = {{Development of an empathy scale.}},
volume = {33},
year = {1969}
}
@book{Fussell2002,
author = {Fussell, Susan R.},
editor = {Fussell, Susan R.},
file = {::},
isbn = {9780805836905},
pages = {294},
publisher = {Lawrence Erlbaum Associates},
title = {{The verbal communication of emotions: Interdisciplinary perspectives}},
url = {http://books.google.com/books?id=MHea6DYYfEgC},
year = {2002}
}
@article{Happ2011,
author = {Happ, Christian and Melzer, Andr\'{e}},
file = {::},
journal = {Ifip International Federation For Information Processing},
keywords = {1,1 prosocial and antisocial,aggression,anderson and his colleagues,confirmed that video game,effects of video games,empathy,furthermore,in a recent overview,prosocial behavior,related to indicators of,video games,violence exposure is positively},
pages = {371--374},
title = {{Bringing Empathy into Play: On the Effects of Empathy in Violent and Nonviolent Video Games}},
url = {http://www.springerlink.com/index/P76556V1HN316RK6.pdf},
year = {2011}
}
@article{Feller2003,
abstract = {In this investigation of the construct of empathy, the authors report that the literature reflects strong evidence that empathy is an essential component of the therapeutic alliance across theories and that empathy is necessary in the counseling process. The concept of empathy continues to be a central component of new forms of counseling and therapy.},
author = {Feller, C P and Cottone, R R},
journal = {Journal of Humanistic Counseling Education and Development},
number = {1},
pages = {53--62},
publisher = {American Counseling Association},
title = {{The Importance of Empathy in the Therapeutic Alliance.}},
volume = {42},
year = {2003}
}
@article{CoanJr1984,
abstract = {Rapport is a characteristic of a relationship if there is a high degree of empathy, attention, and shared understanding and expectations. Rapport should be enhanced when the salesperson and the customer are comembers of the same group. Also, rapport should aid persuasion and help increase consumer satisfaction. Both observational and paper-and-pencil techniques can be used to measure rapport.},
author = {{Coan Jr}, G.},
file = {::},
journal = {Advances in Consumer Research},
pages = {333--336},
title = {{RAPPORT: DEFINITION AND DIMENSIONS}},
url = {http://www.acrwebsite.org/volumes/display.asp?id=6269},
volume = {11},
year = {1984}
}
@article{VanSwol2003,
author = {{Van Swol}, Lyn M.},
doi = {10.1177/0093650203253318},
file = {::},
issn = {00000000},
journal = {Communication Research},
month = aug,
number = {4},
pages = {461--480},
title = {{The Effects of Nonverbal Mirroring on Perceived Persuasiveness, Agreement with an Imitator, and Reciprocity in a Group Discussion}},
url = {http://crx.sagepub.com/cgi/doi/10.1177/0093650203253318},
volume = {30},
year = {2003}
}
@article{Heimgartner2011,
author = {Heimg\"{a}rtner, R\"{u}diger and Tiede, L.W. and Windl, Helmut},
file = {::},
journal = {Design, User Experience, and Usability. Theory, Methods, Tools and Practice},
keywords = {1 problems in hci,communication,cultural differences,culture,design caused by cultural,designing the functionality and,differences,empathy,intercultural communication,intercultural hci design,much cultural background has,to be considered when,understanding},
pages = {557--566},
publisher = {Springer},
title = {{Empathy as Key Factor for Successful Intercultural HCI Design}},
url = {http://www.springerlink.com/index/FG03081276H7K042.pdf},
year = {2011}
}
@article{Cowell2005,
author = {Cowell, Andrew J. and Stanney, Kay M.},
doi = {10.1016/j.ijhcs.2004.11.008},
file = {::},
issn = {10715819},
journal = {International Journal of Human-Computer Studies},
month = feb,
number = {2},
pages = {281--306},
title = {{Manipulation of non-verbal interaction style and demographic embodiment to increase anthropomorphic computer character credibility}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1071581904001260},
volume = {62},
year = {2005}
}
@article{Happ2011,
author = {Happ, Christian and Melzer, Andr\'{e}},
file = {::},
journal = {Ifip International Federation For Information Processing},
keywords = {1,1 prosocial and antisocial,aggression,anderson and his colleagues,confirmed that video game,effects of video games,empathy,furthermore,in a recent overview,prosocial behavior,related to indicators of,video games,violence exposure is positively},
pages = {371--374},
title = {{Bringing Empathy into Play: On the Effects of Empathy in Violent and Nonviolent Video Games}},
url = {http://www.springerlink.com/index/P76556V1HN316RK6.pdf},
year = {2011}
}
@book{Miller2002,
abstract = {This bestselling work has introduced hundreds of thousands of professionals and students to motivational interviewing (MI), a proven approach to helping people overcome ambivalence that gets in the way of change. William R. Miller and Stephen Rollnick explain current thinking on the process of behavior change, present the principles of MI, and provide detailed guidelines for putting it into practice. Case examples illustrate key points and demonstrate the benefits of MI in addictions treatment and other clinical contexts. The authors also discuss the process of learning MI. Chapters contributed by other leading experts address such special topics as MI and the stages-of-change model; applications in medical, public health, and criminal justice settings; and using the approach with groups, couples, and adolescents.},
address = {New York},
author = {Miller, William R. and Rollnick, Stephen},
booktitle = {Zeitschrift f\"{u}r Klinische Psychologie und Psychotherapie},
chapter = {428},
doi = {10.1026/1616-3443.34.1.66},
edition = {2nd},
isbn = {1572305630},
issn = {16163443},
number = {1},
pages = {428},
pmid = {12538308},
publisher = {Guilford Press},
title = {{Motivational Interviewing: Preparing People for Change}},
url = {http://books.google.com/books?id=r\_CuyHwdz7EC\&pgis=1},
volume = {2nd},
year = {2002}
}
@incollection{Creed2008,
abstract = {Why do computers need emotional intelligence? Science fiction often portrays emotional computers as dangerous and frightening, and as a serious threat to human life. One of the most famous examples is HAL, the supercomputer onboard the spaceship Discovery, in the movie 2001: A Space Odyssey. HAL could express, recognize and respond to human emotion, and generally had strong emotional skills — the consequences of which were catastrophic. However, since the movie’s release almost 40 years ago, the traditional view of emotions as contributing to irrational and unpredictable behavior has changed. Recent research has suggested that emotions play an essential role in important areas such as learning, memory, motivation, attention, creativity, and decision making. These findings have prompted a large number of research groups around the world to start examining the role of emotions and emotional intelligence in human-computer interaction (HCI). For almost half a century, computer scientists have been attempting to build machines that can interact intelligently with us, and despite initial optimism, they are still struggling to do so. For much of this time, the role of emotion in developing intelligent computers was largely overlooked, and it is only recently that interest in this area has risen dramatically. This increased interest can largely be attributed to the work of [6] and [85] who were amongst the first to bring emotion to the attention of computer scientists. The former highlighted emotion as a fundamental component required in building believable agents, while the latter further raised the awareness of emotion and its potential importance in HCI. Since these publications, the literature on emotions and computing has grown considerably with progress being made on a number of different fronts.},
author = {Creed, Chris and Beale, Russell},
booktitle = {Computational Intelligence: A Compendium},
doi = {10.1007/978-3-540-78293-3},
editor = {Fulcher, John and Jain, L. C.},
file = {::},
isbn = {978-3-540-78292-6},
pages = {185--230},
publisher = {Springer Berlin / Heidelberg},
title = {{Emotional Intelligence: Giving Computers Effective Emotional Skills to Aid Interaction}},
url = {http://www.springerlink.com/index/U2231064587Q8V07.pdf},
volume = {230},
year = {2008}
}
@article{Lee2009,
author = {Lee, Jina and Prendinger, H},
file = {::},
isbn = {9781424447992},
journal = {Affective Computing},
title = {{Learning models of speaker head nods with affective information}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5349543},
year = {2009}
}
@inproceedings{Kumano2011,
author = {Kumano, Shiro and Otsuka, Kazuhiro and Mikami, Dan and Yamato, Junji},
booktitle = {Automatic Face \& Gesture Recognition and Workshops (FG 2011), 2011 IEEE International Conference on},
file = {::},
pages = {43--50},
publisher = {IEEE},
title = {{Analyzing empathetic interactions based on the probabilistic modeling of the co-occurrence patterns of facial expressions in group meetings}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5771440},
year = {2011}
}
@misc{Lundqvist1998,
author = {Lundqvist, D. and Flykt, A. and \"{O}hman, A.},
publisher = {CD ROM from Department of Clinical Neuroscience, Psychology section, Karolinska Institutet, ISBN 91-630-7164-9},
title = {{The Karolinska Directed Emotional Faces - KDEF}},
year = {1998}
}
@article{Gupta2012,
author = {Gupta, Prabodh and Jhala, Darshana and Jhala, Nirag},
doi = {10.1309/AJCPLAE62CRYYXNW},
file = {::},
issn = {1943-7722},
journal = {American journal of clinical pathology},
month = jan,
number = {1},
pages = {160},
pmid = {22180490},
title = {{Book review.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22180490},
volume = {137},
year = {2002}
}
@article{Elliot2001,
author = {Elliot, Andrew J. and McGregor, holly A.},
file = {::},
journal = {Journal of Personality and Social Psychology},
number = {3},
pages = {501--519},
title = {{A 2 x 2 achievement goal framework.pdf}},
volume = {80},
year = {2001}
}
@article{Scherer2007,
abstract = {In earlier work, the authors analyzed emotion portrayals by professional actors separately for facial expression, vocal expression, gestures, and body movements. In a secondary analysis of the combined data set for all these modalities, the authors now examine to what extent actors use prototypical multimodal configurations of expressive actions to portray different emotions, as predicted by basic emotion theories claiming that expressions are produced by fixed neuromotor affect programs. Although several coherent unimodal clusters are identified, the results show only 3 multimodal clusters: agitation, resignation, and joyful surprise, with only the latter being specific to a particular emotion. Finding variable expressions rather than prototypical patterns seems consistent with the notion that emotional expression is differentially driven by the results of sequential appraisal checks, as postulated by componential appraisal theories.},
author = {Scherer, Klaus R and Ellgring, Heiner},
doi = {10.1037/1528-3542.7.1.158},
file = {::},
issn = {1528-3542},
journal = {Emotion (Washington, D.C.)},
keywords = {Adult,Affect,Facial Expression,Female,Gestures,Humans,Judgment,Male,Psychomotor Performance,Speech Acoustics,Voice},
month = feb,
number = {1},
pages = {158--71},
pmid = {17352571},
title = {{Multimodal expression of emotion: affect programs or componential appraisal patterns?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17352571},
volume = {7},
year = {2007}
}
@book{Scherer2001,
address = {New York, NY, US},
author = {Scherer, Klaus R.},
editor = {{Scherer, Klaus R. and Schorr, Angela and Johnstone}, Tom},
isbn = {0-19-513007-3},
keywords = {appraisal,cognitive-motivational-relational theory of emotio,coping,emotions,psychological stress,theory development},
pages = {478},
publisher = {Oxford University Press},
title = {{Appraisal processes in emotion: Theory, methods, research}},
year = {2001}
}
@article{Emmons2001,
abstract = {Motivational interviewing (MI) has been well studied in specialist settings. There has been considerable interest in applying MI to community health care settings. Such settings represent a significant departure from the more traditional, specialist settings in which MI has been developed and tested. The purpose of this paper is to provide a brief overview of MI and to identify and discuss the key issues that are likely to arise when adapting this approach to health care and public health settings. This paper provides an overview of important issues to consider in adapting an effective counseling strategy to new settings, and is intended to begin a dialogue about the use of MI in community health care settings.},
author = {Emmons, K M and Rollnick, S},
file = {::},
issn = {0749-3797},
journal = {American journal of preventive medicine},
keywords = {Adult,Attitude of Health Personnel,Community Health Services,Community Health Services: standards,Community Health Services: trends,Female,Health Care Surveys,Humans,Interviews as Topic,Interviews as Topic: methods,Male,Motivation,Outcome Assessment (Health Care),Preventive Medicine,Preventive Medicine: standards,Preventive Medicine: trends,United States},
month = jan,
number = {1},
pages = {68--74},
pmid = {11137778},
title = {{Motivational interviewing in health care settings. Opportunities and limitations.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11137778},
volume = {20},
year = {2001}
}
@article{Kahn2007,
abstract = {The Linguistic Inquiry and Word Count (LIWC) text analysis program often is used as a measure of emotion expression, yet the construct validity of its use for this purpose has not been examined. Three experimental studies assessed whether the LIWC counts of emotion processes words are sensitive to verbal expression of sadness and amusement. Experiment 1 determined that sad and amusing written autobiographical memories differed in LIWC emotion counts in expected ways. Experiment 2 revealed that reactions to emotionally provocative film clips designed to manipulate the momentary experience of sadness and amusement differed in LIWC counts. Experiment 3 replicated the findings of Experiment 2 and found generally weak relations between LIWC emotion counts and individual differences in emotional reactivity, dispositional expressivity, and personality. The LIWC therefore appears to be a valid method for measuring verbal expression of emotion.},
author = {Kahn, Jeffrey H and Tobin, Ren\'{e}e M and Massey, Audra E and Anderson, Jennifer A},
institution = {Department of Psychology, Illinois State University, Normal, IL 61790-4620, USA. jhkahn@ilstu.edu},
journal = {The American journal of psychology},
number = {2},
pages = {263--286},
pmid = {17650921},
publisher = {JSTOR},
title = {{Measuring emotional expression with the Linguistic Inquiry and Word Count.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17650921},
volume = {120},
year = {2007}
}
@article{Bryant1982,
abstract = {56 1st, 115 4th, and 87 7th graders were administered a newly devised index of empathy partly based on A. Mehrabian and N. Epstein's (see record 1973-23075-001) measure. Item means, item-total correlations, testretest reliabilities, correlations of empathy with aggressiveness and acceptance of individual differences, and correlations with other existing measures of empathy as well as to social desirability response set and reading achievement formed the basis of internal, discriminant, convergent, and general construct validation. The measure demonstrated satisfactory reliability and preliminary construct validity. The study of developmental aspects of empathic arousal toward peers of different sexes is indicated. (38 ref) (PsycINFO Database Record (c) 2010 APA, all rights reserved)},
author = {Bryant, Brenda K},
doi = {10.2307/1128984},
issn = {00093920},
journal = {Child Development},
number = {2},
pages = {413--425},
publisher = {Blackwell Publishing on behalf of the Society for Research in Child Development},
title = {{An Index of Empathy for Children and Adolescents}},
volume = {53},
year = {1982}
}
@inproceedings{Johnson2004,
abstract = {Embodied conversational agents (ECA) have potential as facilitators for health interventions. However, their utility is limited as long as people must sit down in front of a computer to access them. This paper describes a project that is deploying an ECA on a handheld computer, and using it to assist in a psychosocial intervention aimed at providing training in problem solving skills. The agent is based upon the virtual trainer/counselor in the pedagogical drama Carmen’s Bright IDEAS, adapted for handheld use and for interaction with a human caregiver. The system will go into clinical trails in August of 2004. The paper discusses the design and technical issues involved in the transition from laptop computer to handheld device and from 3rd-person view to first-person interaction, and the plan for evaluation. The clinical trial is designed both to evaluate psychosocial outcomes and to assess user preferences in ECA interaction modalities over the course of multiple sessions of use.},
author = {Johnson, WL and LaBore, C},
booktitle = {AAAI Fall Symposium on Dialogue Systems for Health Communication},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Johnson, LaBore, Chiu - 2004 - A pedagogical agent for psychosocial intervention on a handheld computer(4).pdf:pdf},
pages = {22--24},
title = {{A pedagogical agent for psychosocial intervention on a handheld computer}},
year = {2004}
}
@article{Hirsh2010,
abstract = {Research generally indicates that providers demonstrate modest insight into their clinical decision processes. In a previous study utilizing virtual human (VH) technology, we found that patient demographic characteristics and facial expressions of pain were statistically significant predictors of many nurses' pain-related decisions. The current study examined the correspondence between the statistically identified and self-reported influences of contextual information on pain-related decisions. Fifty-four nurses viewed vignettes containing a video of a VH patient and text describing a postsurgical context. VH sex, race, age, and facial expression varied across vignettes. Participants made pain-assessment and treatment decisions on visual analogue scales. Participants subsequently indicated the information they relied on when making decisions. None of the participants reported using VH sex, race, or age in their decision process. Statistical modeling indicated that 28 to 54\% of participants (depending on the decision) used VH demographic cues. 76\% of participants demonstrated concordance between their reported and actual use of the VH facial expression cue. Vital signs, text-based clinical summary, and VH movement were also reported as influential factors. These data suggest that biases may be prominent in practitioner decision-making about pain, but that providers have minimal awareness of and/or a lack of willingness to acknowledge this bias. PERSPECTIVE: The current study highlights the complexity of provider decision-making about pain management. The VH technology could be used in future research and education applications aimed at improving the care of all persons in pain.},
author = {Hirsh, Adam T and Jensen, Mark P and Robinson, Michael E},
doi = {10.1016/j.jpain.2009.09.004},
file = {::},
issn = {1528-8447},
journal = {The journal of pain : official journal of the American Pain Society},
keywords = {Adult,Age Factors,Computer Simulation,Continental Population Groups,Cues,Facial Expression,Female,Humans,Male,Models, Statistical,Movement,Nurses,Nurses: psychology,Pain,Pain Management,Pain Measurement,Pain: diagnosis,Self-Assessment,Sex Factors,User-Computer Interface},
month = may,
number = {5},
pages = {454--61},
pmid = {20015702},
publisher = {Elsevier Ltd},
title = {{Evaluation of nurses' self-insight into their pain assessment and treatment decisions.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2864339\&tool=pmcentrez\&rendertype=abstract},
volume = {11},
year = {2010}
}
@article{CoanJr1984,
author = {{Coan Jr}, G.},
file = {::},
journal = {Advances in Consumer Research},
pages = {333--336},
title = {{RAPPORT: DEFINITION AND DIMENSIONS}},
url = {http://www.acrwebsite.org/volumes/display.asp?id=6269},
volume = {11},
year = {1984}
}
@inproceedings{Hernandez-Trapote2008,
abstract = {In this article we present a research scheme which aims to analyze the use of Embodied Conversational Agent (ECA) technology to improve the robustness and acceptability of speaker enrolment and verification dialogues designed to provide secure access through natural and intuitive speaker recognition. In order to find out the possible effects of the visual information channel provided by the ECA, tests were carried out in which users were divided into two groups, each interacting with a different interface (metaphor): an ECA Metaphor group -with an ECA-, and a VOICE Metaphor group -without an ECA-. Our evaluation methodology is based on the ITU-T P.851 recommendation for spoken dialogue system evaluation, which we have complemented to cover particular aspects with regard to the two major extra elements we have incorporated: secure access and an ECA. Our results suggest that likeability-type factors and system capabilities are perceived more positively by the ECA metaphor users than by the VOICE metaphor users. However, the ECA’s presence seems to intensify users’ privacy concerns.},
address = {New York, New York, USA},
author = {Hern\'{a}ndez-Trapote, \'{A}lvaro and L\'{o}pez-Menc\'{\i}a, Beatriz and D\'{\i}az, David and Fern\'{a}ndez-Pozo, Rub\'{e}n and Caminero, Javier},
booktitle = {Proceedings of the 10th international conference on Multimodal interfaces - IMCI '08},
doi = {10.1145/1452392.1452454},
file = {::},
isbn = {9781605581989},
keywords = {Conversational Agent,Embodied biometrics interfaces,Experimentation,Human Factors,Multimodal evaluation,Security,Standardization,Verification.,voice authentication.},
pages = {305},
publisher = {ACM Press},
title = {{Embodied conversational agents for voice-biometric interfaces}},
url = {http://portal.acm.org/citation.cfm?doid=1452392.1452454},
year = {2008}
}
@inproceedings{Borutta2009,
abstract = {Emotional expressions are considered to be important for robotic and virtual agents to improve nonverbal communication in human-machine-interaction. In this paper we focus on a subset of emotional expressions, namely the smile and it's variations. The proposed concept for generating artificial smile sequences is based on the system-theoretic psychological model of smiling, which is based on the Zurich Model of Social Motivation. The model and seven different types of smiles are introduced and it is presented how to integrate this model in a virtual agent. The evaluation of the generated facial expressions shows that the seven types of smiles are distinguishable from each other and can be classified according to given categories.},
address = {Toyama, Japan},
author = {Borutta, Isabell and Sosnowski, Stefan and Zehetleitner, Michael},
booktitle = {The 18th IEEE International Symposium on Robot and Human Interactive Communication, 2009. RO-MAN 2009.},
doi = {10.1109/ROMAN.2009.5326255},
file = {::},
pages = {245 -- 250},
title = {{Generating artificial smile variations based on a psychological system-theoretic approach}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5326255},
year = {2009}
}
@inproceedings{Nguyen2009,
abstract = {Experiencing emotional distress is the number one reason why people who are undergoing behaviour modification (e.g. quitting smoking, dieting) suffer from relapses. Providing emotional support is an effective way to help them overcome the unpleasant effects of negative affect and adhere to their regimen. Building computers with such ability has grabbed the attention of the HCI community in recent years. This paper presents the results of a 2 (modality: animated vs. no visual) by 3 (intervention: non-empathy vs. empathy vs. empathy and expressivity) between-subjects study that investigates the impact of two important factors and their interaction in the design of such systems: (1) different ways of expressing empathy, and (2) the modality of delivering such content.},
annote = {They investigate: 
1-      Different ways of expressing empathy 
2-      Modality of delivering such content. 
        
They define empathy as the ability to detect what others feel and to experience that emotion ourselves (seems like mimicry).
        
Empirical evidence indicates that expressing accurate empathy can lead to positive psychological, physical and health outcomes.
        
Their results show: 
1. The positive attitude of the users toward active support (active empathy). 
2.  The positive outcome of an empathic system regardless of its representation. 
3.  A system represented by a human-like representation is expected to be empathic.
        
they believe, adding a mechanism to allow the users to freely express themselves does not improve the effectiveness or liking of an empathic system.
      },
author = {Nguyen, H. and Masthoff, Judith},
booktitle = {Proceedings of the 4th International Conference on Persuasive Technology},
file = {::},
isbn = {9781605583761},
keywords = {affective computing,design,experimentation,human factors},
pages = {7},
publisher = {ACM},
title = {{Designing empathic computers: the effect of multimodal empathic feedback using animated agent}},
year = {2009}
}
@article{Borutta2009,
author = {Borutta, Isabell and Sosnowski, Stefan and Zehetleitner, Michael},
file = {::},
journal = {Robot and Human},
title = {{Generating artificial smile variations based on a psychological system-theoretic approach}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5326255},
year = {2009}
}
@book{Fussell2002,
author = {Fussell, S.R.},
file = {::},
isbn = {0805836896},
publisher = {Lawrence Erlbaum},
title = {{The verbal communication of emotions: Interdisciplinary perspectives}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=p3M13y2yfwMC\&amp;oi=fnd\&amp;pg=PP1\&amp;dq=The+Verbal+Communication+of+Emotions\&amp;ots=btc4zGRJN4\&amp;sig=16kr5bEkJhKg\_zO6ond9vkI4uLY},
year = {2002}
}
@inproceedings{Nguyen2009,
abstract = {Experiencing emotional distress is the number one reason why people who are undergoing behaviour modification (e.g. quitting smoking, dieting) suffer from relapses. Providing emotional support is an effective way to help them overcome the unpleasant effects of negative affect and adhere to their regimen. Building computers with such ability has grabbed the attention of the HCI community in recent years. This paper presents the results of a 2 (modality: animated vs. no visual) by 3 (intervention: non-empathy vs. empathy vs. empathy and expressivity) between-subjects study that investigates the impact of two important factors and their interaction in the design of such systems: (1) different ways of expressing empathy, and (2) the modality of delivering such content.},
annote = {They investigate: 
1-      Different ways of expressing empathy 
2-      Modality of delivering such content. 
        
They define empathy as the ability to detect what others feel and to experience that emotion ourselves (seems like mimicry).
        
Empirical evidence indicates that expressing accurate empathy can lead to positive psychological, physical and health outcomes.
        
Their results show: 
1. The positive attitude of the users toward active support (active empathy). 
2.  The positive outcome of an empathic system regardless of its representation. 
3.  A system represented by a human-like representation is expected to be empathic.
        
they believe, adding a mechanism to allow the users to freely express themselves does not improve the effectiveness or liking of an empathic system.
      },
author = {Nguyen, H. and Masthoff, Judith},
booktitle = {Proceedings of the 4th International Conference on Persuasive Technology},
file = {::},
isbn = {9781605583761},
keywords = {affective computing,design,experimentation,human factors},
publisher = {ACM},
title = {{Designing empathic computers: the effect of multimodal empathic feedback using animated agent}},
year = {2009}
}
@article{Caridakis2008,
abstract = {As input they consider the image sequence of the recorded human behavior. Computer vision and image processing techniques are incorporated in order to detect cues needed for expressivity features extraction. Using multimodalities, the virtual agent mimics the human expressions. The multimodality of the approach lies in the fact that both facial and gestural aspects of the user’s behavior are analyzed and processed. The mimicry consists of perception, interpretation, planning and animation of the expressions shown by the human, resulting not in an exact duplicate rather than an expressive model of the user’s original behavior.},
annote = {They use both facial and gestural aspects of the user’s behavior to mimic the user’s expressions. The introductory information and references about the psychological background of the mimicry in the paper are useful. But because most of the work is image processing, other sections would not be useful for our job.
Their system does not work in real time because they use a recorded video or sequence of images (limitation).},
author = {Caridakis, George and Raouzaiou, Amaryllis and Bevacqua, Elisabetta and Mancini, Maurizio and Karpouzis, Kostas and Malatesta, Lori and Pelachaud, Catherine},
doi = {10.1007/s10579-007-9057-1},
file = {::},
issn = {1574-020X},
journal = {International Language Resources and Evaluation Journal: Special issue on Multimodal Corpora For Modelling Human Multimodal Behavior},
keywords = {facial,gesture,mimicry,multimodal,virtual agent},
month = jan,
number = {3-4},
pages = {367--388},
title = {{Virtual agent multimodal mimicry of humans}},
volume = {41},
year = {2008}
}
@article{Hand2008,
author = {Hand, Stacey and Varan, Duane},
file = {::},
journal = {Changing Television Environments},
pages = {11--19},
publisher = {Springer},
title = {{Interactive Narratives: Exploring the Links between Empathy, Interactivity and Structure}},
url = {http://www.springerlink.com/index/15385726247gu863.pdf},
year = {2008}
}
@article{Rogers1957,
author = {Rogers, C R},
editor = {Kirschenbaum, H},
isbn = {9780395483572},
issn = {00958891},
journal = {Journal of Consulting Psychology},
number = {2},
pages = {95--103},
pmid = {13416422},
publisher = {Houghton Mifflin},
title = {{The necessary and sufficient conditions of therapeutic personality change}},
volume = {21},
year = {1957}
}
@article{DiMatteo1980,
abstract = {The relationship between physicians' nonverbal communication skills (their ability to communicate and to understand facial expression, body movement and voice tone cues to emotion) and their patients' satisfaction with medical care was examined in 2 studies. The research involved 71 residents in internal medicine and 462 of their ambulatory and hospitalized patients. Standardized, reliable and valid measures of nonverbal communication skills were administered to the physicians. Their scores on these tests were correlated with ratings they received from a sample of their patients on measures of satisfaction with the technical aspects and the socioemotional aspects (or art) of the medical care they received. While the nonverbal communication skills of the physicians bore little relationship to patients' ratings of the technical quality of care, measures of these skills did predict patient satisfaction with the art of medical care received. Across both samples, physicians who were more sensitive to body movement and posture cues to emotion (the channel suggested by nonverbal researchers as the one in which true affect can be perceived) received higher ratings from their patients on the art of care than did less sensitive physicians. In addition, physicians who were successful at expressing emotion through their nonverbal communications tended to receive higher ratings from patients on the art of care than did physicians who were less effective communicators. The implications of successfully identifying characteristics of physicians with whom patients are satisfied are discussed.},
author = {DiMatteo, M R and Taranta, A and Friedman, H S and Prince, L M},
file = {::},
issn = {0025-7079},
journal = {Medical care},
keywords = {Adult,Consumer Satisfaction,Evaluation Studies as Topic,Female,Humans,Male,Nonverbal Communication,Physician-Patient Relations},
month = apr,
number = {4},
pages = {376--387},
pmid = {7401698},
title = {{Predicting patient satisfaction from physicians' nonverbal communication skills}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/7401698},
volume = {18},
year = {1980}
}
@article{Mehrabian1972,
author = {Mehrabian, Albert and Epstein, N},
file = {::},
journal = {Journal of Personality},
number = {4},
pages = {525--543},
pmid = {4642390},
publisher = {Wiley Online Library},
title = {{A measure of emotional empathy.}},
volume = {40},
year = {1972}
}
@inproceedings{Lopez2007,
abstract = {In this paper we present validation tests that we have carried out on gestures that we have designed for an embodied conver- sational agent (ECAs), to assess their soundness with a view to applying said gestures in a forthcoming experiment to explore the possibilities ECAs can offer to overcome typical robustness problems in spoken language dialogue systems (SLDSs). The paper is divided into two parts: First we carry our a literature review to acquire a sense of the extent to which ECAs can help overcome user frustration during human-machine interaction. Then we associate tentative, yet specific, ECA gestural behaviour with each of the main dialogue stages, with special emphasis on problem situations. In the second part we describe the tests we have carried out to validate our ECA’s gestural repertoire. The results obtained show that users generally understand and naturally accept the ges- tures, to a reasonable degree. This encour- ages us to proceed with the next stage of research: evaluating the gestural strategy in real dialogue situations with the aim of learning about how to favour a more effi- cient and pleasant dialogue flow for the us- ers.},
address = {Prague, Czech Republic},
author = {L\'{o}pez, Beatriz and Hern\'{a}ndez, \'{A}lvaro and D\'{\i}az, David and Fern\'{a}ndez, Rub\'{e}n and Hern\'{a}ndez, Luis and Torre, Doroteo},
booktitle = {Proceedings of the Workshop on Embodied Language Processing},
doi = {10.3115/1610065.1610074},
file = {::},
pages = {67--74},
publisher = {Association for Computational Linguistics},
title = {{Design and validation of ECA gestures to improve dialogue system robustness}},
url = {http://portal.acm.org/citation.cfm?doid=1610065.1610074},
year = {2007}
}
@article{Dias2005a,
author = {Dias, J. and Paiva, Ana},
file = {::},
journal = {Progress in artificial intelligence},
pages = {127--140},
publisher = {Springer},
title = {{Feeling and reasoning: A computational model for emotional characters}},
url = {http://www.springerlink.com/index/YQ18H62602413554.pdf},
year = {2005}
}
@article{Heimendinger2007,
abstract = {The purpose of this article is to report the process outcomes of a coaching methodology used in a study designed to increase fruit and vegetable consumption and physical activity in families. Eighty-eight families with second graders were recruited from a rural, biethnic community in Colorado and randomized to intervention and delayed intervention conditions. This article reports on the 27 families in the delayed intervention group. Families received up to 10 home visits over 10 months from a family advisor and completed activities to improve their dietary and physical activity behaviors. Coaching conversations took place during each home visit. Coaching process outcomes were evaluated by analysis of visit documentation, participant survey, and qualitative interviews. Results indicated that coaching, in conjunction with family activities, engaged families in the process of change and facilitated movement toward the achievement of their weekly nutrition or physical activity goals. Coaching methodology may be particularly useful for participatory research.},
author = {Heimendinger, Jerianne and Uyeki, Terry and Andhara, Aurielle and Marshall, Julie A and Scarbro, Sharon and Belansky, Elaine and Crane, Lori},
institution = {Jerianneb@earthlink.net},
journal = {Health education behavior the official publication of the Society for Public Health Education},
keywords = {colorado,diet,exercise,fruit,health promotion,humans,interviews topic,professional family relations,vegetables},
number = {1},
pages = {71--89},
pmid = {16740515},
title = {{Coaching process outcomes of a family visit nutrition and physical activity intervention.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16740515},
volume = {34},
year = {2007}
}
@incollection{Preston2007,
author = {Preston, SD},
booktitle = {Empathy in mental illness},
chapter = {23},
editor = {Farrow, T. and Woodruff, P.},
file = {::},
isbn = {0521847346},
pages = {428--446},
publisher = {Cambridge University Press},
title = {{A perception-action model for empathy}},
url = {http://www-personal.umich.edu/~prestos/Downloads/Preston2007\_MI.pdf},
year = {2007}
}
@article{Vannini2010,
author = {Vannini, Natalie and Enz, Sibylle and Sapouna, Maria and Wolke, Dieter and Watson, Scott and Woods, Sarah and Dautenhahn, Kerstin and Hall, Lynne and Paiva, Ana and Andr\'{e}, Elizabeth and Aylett, Ruth and Schneider, Wolfgang},
doi = {10.1007/s10212-010-0035-4},
file = {::},
issn = {0256-2928},
journal = {European Journal of Psychology of Education},
month = jun,
number = {1},
pages = {21--44},
title = {{“FearNot!”: a computer-based anti-bullying-programme designed to foster peer intervention}},
url = {http://www.springerlink.com/index/10.1007/s10212-010-0035-4},
volume = {26},
year = {2010}
}
@book{Fussell2002,
author = {Fussell, Susan R.},
file = {::},
isbn = {0805836896},
publisher = {Lawrence Erlbaum},
title = {{The verbal communication of emotions: Interdisciplinary perspectives}},
year = {2002}
}
@inproceedings{Bickmore2009,
abstract = {Ninety million Americans have inadequate health literacy, resulting in a reduced ability to read and follow directions in the healthcare environment. We describe an animated, empathic virtual nurse interface for design rationale, and two Boston University School of Medicine Boston Medical Center brian.jack@bmc.org educating and counseling hospital patients with inadequate health literacy in their hospital beds at the time of discharge. The development methodology, iterations of user testing are described. Results indicate that hospital patients with low health literacy found the system easy to use, reported high levels of satisfaction, and most said they preferred receiving the discharge information from the agent over their doctor or nurse. Patients also expressed appreciation for the time and attention provided by the virtual nurse, and felt that it provided an additional authoritative source for their medical information.},
address = {New York},
author = {Bickmore, Timothy W. and Pfeifer, Laura M and Jack, Brian W},
booktitle = {Proceedings of the 27th international ACM conference on Human factors in computing systems (CHI'09)},
file = {::},
isbn = {9781605582467},
keywords = {Access,Conversational Agent,Embodied,Health Literacy,Hospital Discharge,Patient Education,Patient Safety,Relational Agent,Universal},
pages = {1265--1274},
publisher = {ACM},
title = {{Taking the Time to Care : Empowering Low Health Literacy Hospital Patients with Virtual Nurse Agents}},
year = {2009}
}
@article{Panksepp1982,
abstract = {Emotions seem to arise ultimately from hard-wired neural circuits in the visceral-limbic brain that facilitate diverse and adaptive behavioral and physiological response to major classes of environmental challenges. Presumable these circuits developed early in mammalian brain evolution, and the underlying contro mechanisms remain similar in humans and "lower" mammals. This would suggest that theoretically guided studies of the animal brain can reveal how primitive emotions are organized in the human brain. Conversely, granted these cross-specis heritage, it is arguable that human introspecive access to emotional states may provide direct information concerning operations of emotive circuits and thus be a primary source of hypothese for animal brain research. In this article the possibility that emotions are elaborated by transhypothalamic executive (command) circuits that concurrently activate related behavior patterns is assessed. Current neurobehavioral evidence indicates that there are at least four executive circuits of this type - those which elaborate central states of expectancy, rage, fear, and panic. The manner in which learning and psyuchiatric disorders may arise form activities of such circuits is also discussed.},
author = {Panksepp, J},
issn = {14691825},
journal = {Behavioral and Brain Sciences},
number = {3},
pages = {407--467},
title = {{Toward a general psychobiological theory of emotions}},
url = {http://scholar.google.com.au/scholar?as\_q=Panksepp+J+\&num=10\&btnG=Search+Scholar\&as\_epq=Toward+a+general+psychobiological+theory+of\&as\_oq=\&as\_eq=\&as\_occt=any\&as\_sauthors=\&as\_publication=\&as\_ylo=1982\&as\_yhi=1982\&as\_sdt=1.\&as\_sdtp=on\&as\_sdts=5\&hl=en\#0},
volume = {5},
year = {1982}
}
@article{Napolitano2003,
abstract = {The Internet has the potential for delivering innovative, interactive physical activity (PA) interventions to large numbers of people. This study was designed to test the efficacy of an Internet intervention that consisted of a Web site plus 12 weekly e-mail tip sheets, compared with a waiting list control group. The Internet intervention was theory based and emphasized clear, graphical presentation of PA information. Sixty-five (30 intervention and 35 control) sedentary adult employees of several large hospitals (9 men and 56 women) were randomly assigned to 1 of the 2 study arms. Of the 65 participants, 57 completed the 1-month follow-up, and 52 completed the 3-month follow-up. At both 1 and 3 months, those in the intervention group were significantly more likely to have progressed in stage of motivational readiness for PA than participants in the control group: 1 month, c2(1, N =52) =4.05, p <.05; 3 months, c2(1, N =52) =6.45, p <.01. We hypothesized that at 1 and 3 months, the intervention group would exhibit significant increases relative to the control group on the number of minutes of moderate activity. At the 1-month assessment, the intervention group did exhibit significant increases, relative to the control group in moderate minutes, F(1, 54) =5.79, p <.05; however, at the 3-month assessment this difference was no longer significant. In addition, secondary analyses were conducted to examine total number of minutes of walking reported. At 1 month, the intervention group did exhibit significant increases, relative to the control group, in walking minutes, F(1, 54) =12.1, p <.001. At the 3-month assessment, amount of time spent in walking activity continued to be significantly higher for the intervention group compared with the control group, F(1, 48) =5.2, p <.05. These findings show that a theoretically based PA Web site and weekly e-mail tip sheets can have a short-term impact on PA motivation and behavior both at 1 and 3 months. As Internet access increases, and as bandwidth and other technical attributes of this medium improve, Web site delivered health behavior interventions will become increasingly useful in public health promotion.},
author = {Napolitano, Melissa a and Fotheringham, Michael and Tate, Deborah and Sciamanna, Christopher and Leslie, Eva and Owen, Neville and Bauman, Adrian and Marcus, Bess},
file = {::},
issn = {0883-6612},
journal = {Annals of behavioral medicine : a publication of the Society of Behavioral Medicine},
keywords = {Adult,Computer-Assisted Instruction,Computer-Assisted Instruction: methods,Electronic Mail,Exercise,Female,Health Promotion,Health Promotion: methods,Humans,Internet,Male,Motivation,Motor Activity,Patient Education as Topic,Pilot Projects,Randomized Controlled Trials as Topic,Rhode Island,Treatment Outcome},
month = jan,
number = {2},
pages = {92--9},
pmid = {12704010},
title = {{Evaluation of an internet-based physical activity intervention: a preliminary investigation.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12704010},
volume = {25},
year = {2003}
}
@book{Watson1930,
address = {Chicago},
author = {Watson, J. B.},
publisher = {University of Chicago Press},
title = {{Behaviorism}},
year = {1930}
}
@article{Moreno2006,
abstract = {College students learned about science with a multimedia program. One group (choice or C) chose to learn with or without an animated pedagogical agent (APA) representing a male or female of Wve diVerent ethnicities. Another group (no-choice or NC) was assigned an APA by the system. All participants in C group chose to learn with APAs and students of color chose signiWcantly more same-ethnicity APAs than White American students. A signiWcant interaction between choice and ethnic similarity factors revealed that group C produced lower retention, transfer, and program ratings when learning with same-ethnicity rather than diVerent-ethnicity APAs. Results support an interference hypothesis for students who choose to learn with same-ethnicity APAs.},
author = {Moreno, Roxana and Flowerday, Terri},
doi = {10.1016/j.cedpsych.2005.05.002},
file = {::},
issn = {0361476X},
journal = {Contemporary Educational Psychology},
keywords = {animated pedagogical agents,avect,choice,ethnicity,gender,learning,multimedia,science,similarity-attraction},
month = apr,
number = {2},
pages = {186--207},
title = {{Students’ choice of animated pedagogical agents in science learning: A test of the similarity-attraction hypothesis on gender and ethnicity}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0361476X05000317},
volume = {31},
year = {2006}
}
@article{Pierre-Yves2003,
author = {Pierre-Yves, O},
doi = {10.1016/S1071-5819(02)00141-6},
file = {::},
issn = {10715819},
journal = {International Journal of Human-Computer Studies},
keywords = {emotion production,emotion recognition,emotions,robots,speech},
month = jul,
number = {1-2},
pages = {157--183},
title = {{The production and recognition of emotions in speech: features and algorithms}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1071581902001416},
volume = {59},
year = {2003}
}
@incollection{Preston2007,
author = {Preston, SD},
booktitle = {Empathy in mental illness},
chapter = {23},
editor = {Farrow, T. and Woodruff, P.},
file = {::},
isbn = {0521847346},
pages = {428--446},
publisher = {Cambridge University Press},
title = {{A perception-action model for empathy}},
url = {http://www-personal.umich.edu/~prestos/Downloads/Preston2007\_MI.pdf},
year = {2007}
}
@book{Hojat2007,
author = {Hojat, Mohammadreza},
booktitle = {Patient Care},
file = {::},
isbn = {9780387336077},
publisher = {Springer Verlag},
title = {{Empathy in patient care: antecedents, development, measurement, and outcomes}},
year = {2007}
}
@article{Roesch2010,
abstract = {To investigate the perception of emotional facial expressions, researchers rely on shared sets of photos or videos, most often generated by actor portrayals. The drawback of such standardized material is a lack of flexibility and controllability, as it does not allow the systematic parametric manipulation of specific features of facial expressions on the one hand, and of more general properties of the facial identity (age, ethnicity, gender) on the other. To remedy this problem, we developed FACSGen: a novel tool that allows the creation of realistic synthetic 3D facial stimuli, both static and dynamic, based on the Facial Action Coding System. FACSGen provides researchers with total control over facial action units, and corresponding informational cues in 3D synthetic faces. We present four studies validating both the software and the general methodology of systematically generating controlled facial expression patterns for stimulus presentation.},
author = {Roesch, Etienne B. and Tamarit, Lucas and Reveret, Lionel and Grandjean, Didier and Sander, David and Scherer, Klaus R.},
doi = {10.1007/s10919-010-0095-9},
file = {::},
issn = {0191-5886},
journal = {Journal of Nonverbal Behavior},
keywords = {Emotion,FACS,Facial action coding system,Facial expression,Research material,Software},
month = nov,
number = {1},
pages = {1--16},
title = {{FACSGen: A Tool to Synthesize Emotional Facial Expressions Through Systematic Manipulation of Facial Action Units}},
url = {http://www.springerlink.com/index/10.1007/s10919-010-0095-9},
volume = {35},
year = {2010}
}
@inproceedings{Rodrigues2009,
address = {Porto, Portugal},
author = {Rodrigues, SH and Mascarenhas, SF},
booktitle = {Affective Computing and Intelligent Interaction and Workshops (ACII'2009)},
file = {::},
isbn = {9781424447992},
pages = {1--7},
publisher = {IEEE},
title = {{“ I can feel it too !”: Emergent empathic reactions between synthetic characters}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5349570},
year = {2009}
}
@article{Wasfy2004,
abstract = {An intelligent virtual environment is described for training users in the operation of complex engineering systems. The environment combines an intelligent agent facility, for tutoring, guiding and/or supervising the training; an object-oriented virtual environment engine, for displaying the engineering system; and a simulator, for simulating the system controls. The intelligent agent facility includes: (a) a hierarchical process knowledge base, (b) a rule-based expert system for natural language understanding, and (c) a human-like virtual characters engine. Three types of objects are used for representing the process knowledge, namely, processes, steps, and constraints. An application of the environment to the interactive training for operating a NASA wind tunnel is described. Two agents in the environment can perform several functions, including conducting an interactive virtual tour of the facility; guiding and supervising the training, as well as certifying the trainee.},
author = {Wasfy, Ayman and Wasfy, Tamer and Noor, Ahmed},
doi = {10.1016/j.advengsoft.2004.04.005},
file = {::},
issn = {09659978},
journal = {Advances in Engineering Software},
keywords = {intelligent agents,natural language processing,virtual reality,virtual training environments},
month = jun,
number = {6},
pages = {337--355},
title = {{Intelligent virtual environment for process training}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0965997804000390},
volume = {35},
year = {2004}
}
@article{Carey2009a,
abstract = {In this study, the authors evaluated the efficacy of a brief motivational intervention (BMI) and a computerized program for reducing drinking and related problems among college students sanctioned for alcohol violations. Referred students (N = 198, 46\% women), stratified by gender, were randomly assigned to a BMI or to the Alcohol 101 Plus computer program. Data obtained at baseline, 1, 6, and 12 months were used to evaluate intervention efficacy. Planned analyses revealed 3 primary findings. First, women who received the BMI reduced drinking more than did women who received the computer intervention; in contrast, men's drinking reductions did not differ by condition. Second, readiness to change and hazardous drinking status predicted drinking reductions at 1 month postintervention, regardless of intervention. Third, by 1 year, drinking returned to presanction (baseline) levels, with no differences in recidivism between groups. Exploratory analyses revealed an overall mean reduction in drinking immediately after the sanction event and before taking part in an intervention. Furthermore, after the self-initiated reductions prompted by the sanction were accounted for, participation in the BMI but not the computer intervention was found to produce additional reduction in drinking and related consequences.},
author = {Carey, Kate B. and Henson, James M. and Carey, Michael P. and Maisto, Stephen A.},
title = {{Computer versus in-person intervention for students violating campus alcohol policy.}},
url = {http://psycnet.apa.org/journals/ccp/77/1/74},
year = {2009}
}
@inproceedings{Gama2011,
abstract = {Over the last decade extensive research has been conducted in the area of conversational agents focusing in many different aspects of these agents. In this research, and aiming at building agents that maintain a social connection with users, empathy has been one of those areas, as it plays a leading role in the establishment of social relationships. In this paper we present a relationship model of empathy that takes advantage of Social Penetration Theory's concepts for relationship building. This model has been implemented into an agent that attempts to establish a relationship with the user, expressing empathy both verbally and visually. The visual expression of empathy consists of facial expression and physical proximity representation. The user tests performed showed that while users were able to develop a simple relationship with the agents, they however developed stronger relationships with a version of the agent that is most visually expressive and takes advantage of the proximity element, confirming the significance of our model based on social penetration theory may have and, consequently, the importance of the visual representation of empathic responses.},
address = {Memphis, TN, USA},
author = {Gama, Sandra and Barata, Gabriel and Gon\c{c}alves, D. and Prada, R. and Paiva, Ana},
booktitle = {ACII'11 Proceedings of the 4th international conference on Affective computing and intelligent interaction - Volume Part I},
doi = {10.1007/978-3-642-24600-5\_54},
editor = {{D'Mello, Sidney K. and Graesser, Arthur C. and Schuller, Bj\"{o}rn and Martin}, Jean-Claude},
file = {::},
keywords = {affective computing,conversational agent,empathic agent},
pages = {507--516},
publisher = {Springer Berlin / Heidelberg},
title = {{SARA: social affective relational agent: a study on the role of empathy in artificial social agents}},
url = {http://www.springerlink.com/content/g0433kx744258w62/},
year = {2011}
}
@article{Fuchs1987,
abstract = {The impact of examiner/examinee familiarity and rapport on psychological test performance is reviewed. Drawing upon research involving hundreds of young handicapped and nonhandicapped children, it was found that certain handicapped children obtain higher scores when tested by familiar examiners. Implications for practice, theory, and personnel preparation are discussed.},
author = {Fuchs, Douglas},
journal = {Topics in Early Childhood Special Education},
number = {3},
pages = {90--104},
title = {{Examiner Familiarity Effects on Test Performance: Implications for Training and Practice}},
volume = {7},
year = {1987}
}
@article{Brave2005,
author = {Brave, Scott and Nass, Clifford and Hutchinson, Kevin},
doi = {10.1016/j.ijhcs.2004.11.002},
file = {::},
issn = {10715819},
journal = {International Journal of Human-Computer Studies},
keywords = {affective computing,characters,embodied agents,emotion,empathy,social interfaces},
month = feb,
number = {2},
pages = {161--178},
title = {{Computers that care: investigating the effects of orientation of emotion exhibited by an embodied computer agent}},
volume = {62},
year = {2005}
}
@article{Wu2008,
author = {Wu, Siew-Rong},
doi = {10.1109/DIGITEL.2008.27},
file = {::},
isbn = {978-0-7695-3409-1},
journal = {2008 Second IEEE International Conference on Digital Game and Intelligent Toy Enhanced Learning},
pages = {213--214},
publisher = {Ieee},
title = {{Humor and Empathy: Developing Students' Empathy through Teaching Robots to Tell English Jokes}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4700764},
year = {2008}
}
@inproceedings{Doherty2004,
address = {Madison, WI},
author = {Doherty, William Joseph},
booktitle = {Policy Institute for Family Impact Seminars},
title = {{A family-focused approach to health care [Wisconsin Family Impact seminars]}},
year = {2004}
}
@article{Lafrance1976,
author = {Lafrance, Marianne and Broadbent, M.},
doi = {10.1177/105960117600100307},
file = {::},
isbn = {1059601176},
issn = {1059-6011},
journal = {Group \& Organization Management},
month = sep,
number = {3},
pages = {328--333},
title = {{Group Rapport: Posture Sharing as a Nonverbal Indicator}},
volume = {1},
year = {1976}
}
@article{Jacob2011,
author = {Jacob, Pierre},
doi = {10.1007/s13164-011-0065-0},
file = {::},
issn = {1878-5158},
journal = {Review of Philosophy and Psychology},
month = aug,
number = {August},
pages = {519--540},
title = {{The Direct-Perception Model of Empathy: a Critique}},
url = {http://www.springerlink.com/index/10.1007/s13164-011-0065-0},
year = {2011}
}
@misc{Tsui1985,
abstract = {The extent to which relatively unassimilated Asian clients can utilize traditional psychotherapy is likely to depend upon the ability of therapists to understand cultural differences and to adapt their clinical styles accordingly. Common errors made by non-Asian therapists attempting to engage Asians in psychotherapy are identified and appropriate therapeutic strategies are suggested.},
author = {Tsui, P and Schultz, G L},
booktitle = {The American journal of orthopsychiatry},
number = {4},
pages = {561--569},
pmid = {4073227},
title = {{Failure of rapport: why psychotherapeutic engagement fails in the treatment of Asian clients.}},
volume = {55},
year = {1985}
}
@inproceedings{Denef2009,
abstract = {This thesis investigates the design of human computer interaction techniques for ubiquitous computing solutions in firefighting.},
address = {Uppsala, Sweden},
author = {Denef, Sebastian},
booktitle = {INTERACT '09 Proceedings of the 12th IFIP TC 13 International Conference on Human-Computer Interaction: Part II},
doi = {10.1007/978-3-642-03658-3\_97},
editor = {Gross, Tom and Gulliksen, Jan and Kotz\'{e}, Paula and Oestreicher, Lars and Palanque, Philippe and Prates, Raquel Oliveira and Winckler, Marco},
file = {::},
pages = {864--867},
publisher = {Springer Berlin / Heidelberg},
title = {{Human-Computer Interaction Techniques in Firefighting}},
url = {http://www.springerlink.com/index/n0688783567n3251.pdf http://dl.acm.org/citation.cfm?id=1616339},
year = {2009}
}
@article{Boukricha2007,
abstract = {Addressing user’s emotions in human-computer interaction significantly enhances the believability and lifelikeness of virtual humans. Emotion recognition and interpretation is realized in our approach by integrating empathy as a designated process within the agent’s cognitive architecture. In this paper we describe this empathy process which comprises of two interconnected components: a belief-desire-intention (BDI) based cognitive component and an affective component based on the emotion simulation system of the virtual human Max.},
author = {Boukricha, Hana and Becker, Christian},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Boukricha, Becker-Asano - 2007 - Simulating empathy for the virtual human max(3).pdf:pdf},
journal = {on Emotion and Computing in conj},
title = {{Simulating empathy for the virtual human max}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.133.7516\&amp;rep=rep1\&amp;type=pdf},
year = {2007}
}
@misc{FacebookPlaces,
title = {{Facebook Places}},
url = {http://www.facebook.com/about/location}
}
@inproceedings{Nakano2010,
abstract = {In face-to-face conversations, speakers are continuously checking whether the listener is engaged in the conversation and change the conversational strategy if the listener is not fully engaged in the conversation. With the goal of building a conversational agent that can adaptively control conversations with the user, this study analyzes the user’s gaze behaviors and proposes a method for estimating whether the user is engaged in the conversation based on gaze transition 3-gram patterns. First, we conduct a Wizard- of-Oz experiment to collect Based on the analysis of the gaze data, we propose an engagement estimation method that the user’s gaze behaviors. detects the user’s disengagement gaze patterns. The algorithm is implemented as a real-time engagement-judgment mechanism and is incorporated into a multimodal dialogue manager in a conversational agent. The agent estimates the user’s conversational engagement and generates probing questions when the user is distracted from the conversation. Finally, we conduct an evaluation experiment using the proposed engagement-sensitive agent and demonstrate that engagement the estimation function improves the user’s impression of the agent and the interaction with the agent. In addition, probing performed with proper timing was also found to have a positive effect on user’s verbal/nonverbal behaviors in communication with the conversational agent.},
address = {Hong Kong, China},
author = {Nakano, I and Ishii, Ryo},
booktitle = {IUI '10 Proceedings of the 15th international conference on Intelligent user interfaces},
editor = {ACM},
file = {::},
isbn = {9781605585154},
keywords = {conversational agent,conversational engagement,dialogue management.,eye-gaze},
pages = {139--148},
title = {{Estimating User ’ s Engagement from Eye-gaze Behaviors in Human-Agent Conversations}},
year = {2010}
}
@article{XinLuo2007,
abstract = {The present study investigated the ability of normal-hearing listeners and cochlear implant users to recognize vocal emotions. Sentences were produced by 1 male and 1 female talker according to 5 target emotions: angry, anxious, happy, sad, and neutral. Overall amplitude differences between the stimuli were either preserved or normalized. In experiment 1, vocal emotion recognition was measured in normal-hearing and cochlear implant listeners; cochlear implant subjects were tested using their clinically assigned processors. When overall amplitude cues were preserved, normal-hearing listeners achieved near-perfect performance, whereas listeners with cochlear implant recognized less than half of the target emotions. Removing the overall amplitude cues significantly worsened mean normal-hearing and cochlear implant performance. In experiment 2, vocal emotion recognition was measured in listeners with cochlear implant as a function of the number of channels (from 1 to 8) and envelope filter cutoff frequency (50 vs 400 Hz) in experimental speech processors. In experiment 3, vocal emotion recognition was measured in normal-hearing listeners as a function of the number of channels (from 1 to 16) and envelope filter cutoff frequency (50 vs 500 Hz) in acoustic cochlear implant simulations. Results from experiments 2 and 3 showed that both cochlear implant and normal-hearing performance significantly improved as the number of channels or the envelope filter cutoff frequency was increased. The results suggest that spectral, temporal, and overall amplitude cues each contribute to vocal emotion recognition. The poorer cochlear implant performance is most likely attributable to the lack of salient pitch cues and the limited functional spectral resolution.},
author = {{Xin Luo} and Fu, Qian-Jie and Galvin, John J},
doi = {10.1177/1084713807305301},
file = {::},
issn = {1084-7138},
journal = {Trends in amplification},
keywords = {Aged,Auditory Perception,Cochlear Implants,Cues,Emotions,Female,Hearing Disorders,Hearing Disorders: psychology,Hearing Disorders: surgery,Hearing Impaired Persons,Humans,Male,Middle Aged,Pitch Perception,Rehabilitation of Hearing Impaired,Speech Acoustics,Speech Perception,Time Factors},
month = dec,
number = {4},
pages = {301--15},
pmid = {18003871},
title = {{Vocal emotion recognition by normal-hearing listeners and cochlear implant users.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3210149\&tool=pmcentrez\&rendertype=abstract},
volume = {11},
year = {2007}
}
@article{Biocca2002,
abstract = {This paper outlines the foundation of a definition and measurement for the concept social presence. Justification for such a line of research lies in the ever-increasing use of social presence technologies and expansion of the social interactions across the Internet. A definition of social presence, based upon past literature and theory, describes several levels and dimensions of social presence by which the concept can be operationalized. Specifically, Level 1: co-presence is a necessary but not sufficient requirement for the sense of social presence. Level 2: the Subjective level, attempts to measure the psycho-behavioral accessibility of another interactant. Finally, Level 3: the Intersubjective level, assesses within and cross-interactant symmetry. The purposeful direction of this research and measurement construction is to enable researchers and designers to compare various mediated interactions as well as further theoretical inquiry.},
author = {Biocca, Frank and Harms, Chad},
journal = {Proceedings of PRESENCE},
keywords = {social presence,theory mind},
number = {517},
pages = {1--36},
publisher = {Citeseer},
title = {{Defining and measuring social presence: Contribution to the networked minds theory and measure}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.84.8350\&amp;rep=rep1\&amp;type=pdf},
volume = {2002},
year = {2002}
}
@incollection{Miller1986,
abstract = {The matching hypothesis proposes that clients problem-drinkers who are matched to appropriate treatments will show greater improvement than will those who are unmatched or mismatched undifferentiated treatment: the status quo research strategies predictor studies differential studies problem severity cognitive style neuropsychological status self-esteem social stability client choice (PsycINFO Database Record (c) 2006 APA, all rights reserved)},
author = {Miller, William R. and Hester, Reid K},
booktitle = {Treating addictive behaviors Processes of change},
editor = {Miller, William R and Heather, Nick},
isbn = {0306422484},
pages = {175--203},
publisher = {Plenum Press},
title = {{Matching problem drinkers with optimal treatments.}},
year = {1986}
}
@inproceedings{Stoyanchev2011,
author = {Stoyanchev, Svetlana and Piwek, Paul and Prendinger, Helmut},
booktitle = {Intelligent Virtual Agents},
file = {::},
pages = {377--383},
publisher = {Springer},
title = {{Comparing modes of information presentation: text versus ECA and single versus two ECAs}},
url = {http://www.springerlink.com/index/H72521305G072173.pdf},
year = {2011}
}
@article{Dapretto2006,
abstract = {To examine mirror neuron abnormalities in autism, high-functioning children with autism and matched controls underwent fMRI while imitating and observing emotional expressions. Although both groups performed the tasks equally well, children with autism showed no mirror neuron activity in the inferior frontal gyrus (pars opercularis). Notably, activity in this area was inversely related to symptom severity in the social domain, suggesting that a dysfunctional 'mirror neuron system' may underlie the social deficits observed in autism.},
author = {Dapretto, Mirella and Davies, Mari S and Pfeifer, Jennifer H and Scott, Ashley a and Sigman, Marian and Bookheimer, Susan Y and Iacoboni, Marco},
doi = {10.1038/nn1611},
file = {::},
issn = {1097-6256},
journal = {Nature neuroscience},
keywords = {Autistic Disorder,Autistic Disorder: physiopathology,Autistic Disorder: psychology,Brain Mapping,Child,Emotions,Emotions: physiology,Empathy,Facial Expression,Female,Humans,Magnetic Resonance Imaging,Male,Neurons,Neurons: physiology,Social Perception},
month = jan,
number = {1},
pages = {28--30},
pmid = {16327784},
title = {{Understanding emotions in others: mirror neuron dysfunction in children with autism spectrum disorders.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16327784},
volume = {9},
year = {2006}
}
@incollection{Cooper2000,
abstract = {This paper considers how research into empathy in teaching and learning can inform the research into intelligent systems and intelligent agents embedded in educational applications. It also relates this research to some analysis of classroom practice completed as part of the EU funded NIMIS project. The project is developing three applications, one of which aims to support writing development with young children aged 5-6 years based on a cartoon format. The NIMIS classroom as a whole is designed to enhance and augment existing classroom practices and to foster collaboration by non-intrusive hardware and intuitive hardware and software interfaces. To this end it seeks to enhance both human and electronic communication in the classroom. Empathy is central to ensuring the quality of human communication and personal development. This paper suggests that intelligent systems that can consider more carefully the processes and feelings involved in human interactions in teaching and learning, may promote higher quality support for students in classrooms.},
author = {Cooper, Bridget and Brna, Paul and Martins, Alex},
booktitle = {Affective Interactions Towards a New Generation of Computer Interfaces},
doi = {10.1007/10720296\_3},
editor = {Paiva, Ana},
file = {::},
isbn = {978-3-540-41520-6},
pages = {21--34},
publisher = {Springer Berlin / Heidelberg},
title = {{Effective affective in intelligent systems–building on evidence of empathy in teaching and learning}},
url = {http://www.springerlink.com/index/j8v0l230t3503367.pdf},
volume = {1814/2000},
year = {2000}
}
@article{Maurer1983,
author = {Maurer, R.E. and Tindall, J.H.},
file = {::},
journal = {Journal of Counseling Psychology},
number = {2},
pages = {158},
publisher = {American Psychological Association},
title = {{Effect of postural congruence on client's perception of counselor empathy.}},
volume = {30},
year = {1983}
}
@article{Lazarus1991,
abstract = {The 2 main tasks of this article are 1st, to examine what a theory of emotion must do and basic issues that it must address. These include definitional issues, whether or not physiological activity should be a defining attribute, categorical versus dimensional strategies, the reconciliation of biological universals with sociocultural sources of variability, and a classification of the emotions. The 2nd main task is to apply an analysis of appraisal patterns and the core relational themes that they produce to a number of commonly identified emotions. Anger, anxiety, sadness, and pride (to include 1 positive emotion) are used as illustrations. The purpose is to show the capability of a cognitive-motivational-relational theory to explain and predict the emotions. The role of coping in emotion is also discussed, and the article ends with a response to criticisms of a phenomenological, folk-theory outlook.},
author = {Lazarus, Richard S.},
doi = {10.1037/0003-066X.46.8.819},
file = {::},
issn = {0003-066X},
journal = {The American psychologist},
keywords = {Cognition,Emotions,Humans,Interpersonal Relations,Motivation,Psychological Theory},
month = aug,
number = {8},
pages = {819--834},
pmid = {1928936},
title = {{Progress on a cognitive-motivational-relational theory of emotion}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/1928936},
volume = {46},
year = {1991}
}
@article{Behrend2012,
abstract = {It is increasingly common for people engaging in computer–mediated interactions to be accompanied by a digital avatar that represents them. Little is known, however, about how these avatars influence others’ impressions. We examine this question in the context of employment interviews. It is well known that attractive job candidates are afforded an advantage in traditional face-to-face job interviews. We investigate whether raters evaluating computer–mediated interviews will follow a similar pattern when a digital avatar represents the candidate. To investigate this question, we asked 374 raters to view an interview transcript that was accompanied by either a male or female avatar, applying for either a male or female gender-typed job. We found that candidates with more attractive avatars received more favorable interview ratings, regardless of job gender type. These findings support the notion that the ‘‘what is beautiful is good’’ stereotype influences interview ratings even in computer-mediated interviews; raters automatically apply the same heuristics to digital and non-digital faces.},
author = {Behrend, Tara S. and Toaddy, Steven and Thompson, Lori Foster and Sharek, David J.},
doi = {10.1016/j.chb.2012.06.017},
file = {::},
issn = {07475632},
journal = {Computers in Human Behavior},
keywords = {Computer–mediated interview Attractiveness bias Se,Virtual world},
month = jul,
publisher = {Elsevier Ltd},
title = {{The effects of avatar appearance on interviewer ratings in virtual employment interviews}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0747563212001677},
year = {2012}
}
@article{Larimer2009,
abstract = {It is well established that college students have high rates of alcohol use and misuse and suffer the negative consequences of this behavior. Research evaluating the results of brief interventions with high-risk college students has shown these approaches to be successful in reducing alcohol con- sumption and/or related consequences. Several screening tools have been developed to detect the presence of problematic alcohol use and associated disorders, and some are designed specifically for use in a college student population. College campuses offer several opportunities to implement screening and interventions, including universal or large-scale assessments; health services, counsel- ing centers, or local emergency rooms; or via established judicial or grievance systems set up to deal with students who violate campus alcohol policies. Issues to consider when implementing screening and brief interventions in college populations include who should deliver the interventions—peer or professional counselors—and how students should be encouraged to participate in the interventions. Regardless of how the measures are implemented, the content and process of the brief interventions should be based on the available scientific evidence regarding established efficacious interventions.},
author = {Larimer, Mary E and Cronce, Jessica M and Lee, Christine M and Kilmer, Jason R},
file = {::},
journal = {Alcohol Research \& Health},
keywords = {AODD (alcohol and other drug use disorder),CAGE Questionnaire,Michigan Alcoholism Screening Test (MAST),Young Adult Alcohol Problems Screening Test (YAAPS,alcohol abuse,binge drinking,brief intervention,heavy drinking,identification and screening,interview,literature review,motivational interviewing,peer counseling,professional counseling,undergraduate student},
pages = {94--104},
title = {{Brief Intervention in College Settings}},
url = {?http://pubs.niaaa.nih.gov/publications/arh28 ?2/94?104 .htm},
volume = {28},
year = {2004}
}
@article{Prendinger2006,
abstract = {This paper presents a novel method for evaluating the impact of animated interface agents with affective and empathic behavior. While previous studies relied on question- naires in order to assess the user’s overall experience with the interface agent, we will analyze users’ physiological response (skin conductance and electromyography), which allows us to estimate affect-related user experiences on a moment-by-moment basis with- out interfering with the primary interaction task. As an interaction scenario, a card game has been implemented where the user plays against a virtual opponent. The findings of our study indicate that within a competitive gaming scenario, (i) the absence of the agent’s display of negative emotions is conceived as arousing or stress-inducing, and (ii) the valence of users’ emotional response is congruent with the valence of the emotion expressed by the agent. Our results for skin conductance could also be reproduced by assuming a local rather than a global baseline.},
annote = {they have tested 4 different empathic behaviours in a competitive card game.
1- Non-Emotional2- Self-Centered Emotional
3- Negative Empathic 
4- Positive Empathic 
They found out that:
 - absence of the agent's display of negative emotions is arousing for the user and highers his/her stress.
 - valence of users' emotional response is congruent with the valence of the emotion expressed by the agent.},
author = {Prendinger, Helmut and Becker-Asano, Christian},
file = {::},
journal = {International Journal of Humanoid},
keywords = {affective behavior,empathy,evaluation,life-like characters,physiological user information},
number = {3},
pages = {371--391},
title = {{A Study in User's Physiological Response to an Empathic Interface Agent}},
volume = {3},
year = {2006}
}
@article{Becker-Asano2009,
abstract = {We introduce theWASABI ([W]ASABI [A]ffect [S]imulation for [A]gents with [B]elievable [I]nteractivity)Affect SimulationArchitecture, in which a virtual human’s cog- nitive reasoning capabilities are combined with simulated embodiment to achieve the sim- ulation of primary and secondary emotions. In modeling primary emotions we follow the idea of “Core Affect” in combination with a continuous progression of bodily feeling in three-dimensional emotion space (PADspace), that is subsequently categorized into discrete emotions. In humans, primary emotions are understood as onto-genetically earlier emotions, which directly influence facial expressions. Secondary emotions, in contrast, afford the abil- ity to reason about current events in the light of experiences and expectations.},
author = {Becker-Asano, Christian and Wachsmuth, Ipke},
doi = {10.1007/s10458-009-9094-9},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Becker-Asano, Wachsmuth - 2009 - Affective computing with primary and secondary emotions in a virtual human(3).pdf:pdf},
issn = {1387-2532},
journal = {Autonomous Agents and Multi-Agent Systems},
keywords = {affect simulation,affective computing,affective gaming,architecture,aware emotions,bdi-based architecture,embodied agent,emotion dynamics,emotion expression,emotion modeling,pad emotion space,primary and secondary emotions,reality,virtual,virtual human},
month = may,
number = {1},
pages = {32--49},
title = {{Affective computing with primary and secondary emotions in a virtual human}},
volume = {20},
year = {2009}
}
@article{Baghaei2011,
abstract = {Previous research has shown that providing family engagement and social support play important roles in weight management success, helping to achieve long-term lifestyle changes. Traditionally, the support provided by online health com- munities is primarily targeted at individuals and does not involve their families. SOFA (SOcial FAmilies), a novel approach for engaging, motivating, and persuading families to adopt a healthy lifestyle, is proposed. SOFAis an online social network for families coupled with a repository of health-related educational content. This article reports the results of a live user study aimed at investigating how user profile repre- sentation and system-assigned tasks influence users engagement with the system and change their attitude toward a healthy lifestyle. The results show that representing family members as individuals increases the number of active members per family as well as their retention, contribution to, and engagement with the network. The results also show that family-based social networks positively change the attitude of family members toward a healthy lifestyle.},
author = {Baghaei, Nilufar and Kimani, Stephen and Freyne, Jill and Brindal, Emily and Berkovsky, Shlomo and Smith, Greg},
doi = {10.1080/10447318.2011.555315},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Baghaei et al. - 2011 - Engaging Families in Lifestyle Changes Through Social Networking.pdf:pdf},
issn = {1044-7318},
journal = {International Journal of Human-Computer Interaction},
month = oct,
number = {10},
pages = {971--990},
title = {{Engaging Families in Lifestyle Changes Through Social Networking}},
url = {http://www.tandfonline.com/doi/abs/10.1080/10447318.2011.555315},
volume = {27},
year = {2011}
}
@article{Varni2009,
author = {Varni, Giovanna and Camurri, Antonio and Coletta, Paolo and Volpe, Gualtiero},
doi = {10.1109/CSE.2009.230},
file = {::},
isbn = {978-1-4244-5334-4},
journal = {2009 International Conference on Computational Science and Engineering},
keywords = {Social signals, music, synchronisation},
pages = {843--848},
publisher = {Ieee},
title = {{Toward a Real-Time Automated Measure of Empathy and Dominance}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5283210},
year = {2009}
}
@article{Liu2005,
author = {Liu, Zhen},
file = {::},
journal = {Affective Computing and Intelligent Interaction},
title = {{An emotion model of 3D virtual characters in intelligent virtual environment}},
url = {http://www.springerlink.com/index/p232574rm3036237.pdf},
year = {2005}
}
@article{Ortony1990,
abstract = {A widespread assumption in theories of emotion is that there exists a small set of basic emotions. From a biological perspective, this idea is manifested in the belief that there might be neurophysiological and anatomical substrates corresponding to the basic emotions. From a psychological perspective, basic emotions are often held to be the primitive building blocks of other, nonbasic emotions. The content of such claims is examined, and the results suggest that there is no coherent nontrivial notion of basic emotions as the elementary psychological primitives in terms of which other emotions can be explained. Thus, the view that there exist basic emotions out of which all other emotions are built, and in terms of which they can be explained, is questioned, raising the possibility that this position is an article of faith rather than an empirically or theoretically defensible basis for the conduct of emotion research. This suggests that perhaps the notion of basic emotions will not lead to significant progress in the field. An alternative approach to explaining the phenomena that appear to motivate the postulation of basic emotions is presented.},
author = {Ortony, A and Turner, T J},
institution = {Institute for the Learning Sciences, Northwestern University, Evanston, Illinois 60201.},
journal = {Psychological Review},
number = {3},
pages = {315--331},
pmid = {1669960},
publisher = {Citeseer},
title = {{What's basic about basic emotions?}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0033-295X.97.3.315},
volume = {97},
year = {1990}
}
@article{Happ2011,
author = {Happ, Christian and Melzer, Andr\'{e}},
file = {::},
journal = {Ifip International Federation For Information Processing},
keywords = {1,1 prosocial and antisocial,aggression,anderson and his colleagues,confirmed that video game,effects of video games,empathy,furthermore,in a recent overview,prosocial behavior,related to indicators of,video games,violence exposure is positively},
pages = {371--374},
title = {{Bringing Empathy into Play: On the Effects of Empathy in Violent and Nonviolent Video Games}},
url = {http://www.springerlink.com/index/P76556V1HN316RK6.pdf},
year = {2011}
}
@article{Davidson1986,
author = {Davidson, R and Raistrick, D},
journal = {British journal of addiction},
keywords = {adolescent,adult,age factors,aged,alcoholism,humans,middle aged,questionnaires,self disclosure},
number = {2},
pages = {217--222},
pmid = {3458489},
title = {{The validity of the Short Alcohol Dependence Data (SADD) Questionnaire: a short self-report questionnaire for the assessment of alcohol dependence.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/3458489},
volume = {81},
year = {1986}
}
@article{Graf2002,
abstract = {As we articulate speech, we usually move the head and exhibit various facial expressions. This visual aspect of speech aids understanding and helps communicating additional information, such as the speaker's mood. We analyze quantitatively head and facial movements that accompany speech and investigate how they relate to the text's prosodic structure. We recorded several hours of speech and measured the locations of the speakers' main facial features as well as their head poses. The text was evaluated with a prosody prediction tool, identifying phrase boundaries and pitch accents. Characteristic for most speakers are simple motion patterns that are repeatedly applied in synchrony with the main prosodic events. Direction and strength of head movements vary widely from one speaker to another, yet their timing is typically well synchronized with the spoken text. Understanding quantitatively the correlations between head movements and spoken text is important for synthesizing photo-realistic talking heads. Talking heads appear much more engaging when they exhibit realistic motion patterns.},
author = {Graf, Hans Peter and Cosatto, Eric and Strom, Volker and Huang, Fu Jie},
journal = {Proceedings of Fifth IEEE International Conference on Automatic Face Gesture Recognition},
pages = {396--401},
publisher = {IEEE Computer Society},
title = {{Visual prosody: facial movements accompanying speech}},
url = {http://ieeexplore.ieee.org/servlet/opac?punumber=7862},
year = {2002}
}
@article{Noller1985,
abstract = {This paper reviews the literature on the complex question of the relative importance of the verbal, visual and vocal channels in various types of judgments. It is noted that a wide variety of methodologies are used in such research with studies differing in terms of the type of stimuli used (varying on the dimension of stylised to naturally occurring), the task required of the subjects (particularly varying on the cognitive-affective dimension) and the method used to assess the relative importance of the channels. An attempt is made to assess the important variables which affect the way the various channels are used by decoders, including whether deception is involved or expected, whether the message is discrepant, the particular judgment being made and the dimension on which the stimulus varies, the sex of the encoder and the decoder and the relationship between them, and the age of the decoder. The possibility of other related variables also acting as moderators is discussed.},
author = {Noller, Patricia},
doi = {10.1007/BF00987557},
issn = {01915886},
journal = {Journal of Nonverbal Behavior},
number = {1},
pages = {28--47},
publisher = {Springer Netherlands},
title = {{Video primacy? A further look}},
url = {http://www.springerlink.com/index/10.1007/BF00987557},
volume = {9},
year = {1985}
}
@misc{Putten2009,
author = {P\"{u}tten, Astrid M Von Der and Kr\"{a}mer, Nicole C and Gratch, Jonathan},
booktitle = {Design},
file = {::},
keywords = {avatars,behavioral realism,experimental study,virtual agents},
pages = {1--7},
title = {{Who´s there? Can a Virtual Agent Really Elicit Social Presence?}},
year = {2009}
}
@inproceedings{Boukricha2009,
abstract = {a system for simulating emotional facial expressions for a virtual human has been evolved. This system consists of two parts: (1) a control ar- chitecture for simulating emotional facial expressions with respect to Pleasure, Arousal, and Dominance (PAD) val- ues, (2) an expressive output component for animating the virtual human’s facial muscle actions called Action Units (AUs), modeled following the Facial Action Coding Sys- tem (FACS). A large face repertoire of about 6000 faces arranged in PAD-space with respect to two dominance val- ues (dominant vs. submissive) is obtained as a result of the empirical study. Using the face repertoire an approach to- wards realizing facial mimicry for a virtual human based on backward mapping AUs displaying an emotional facial expression on PAD-values is outlined.},
address = {Amsterdam},
annote = {- For automatic recognition, the mapping of AUs to PAD may be only useful once you can identify the active AUs and their intensity on the face (which you won't be able with image processing teckniques).
- For the expression, if you have an avatar which has control on the AUs, you don’t need to map the AUs to PAD. But, if you have an avatar which expresses based on PAD, then this mapping is useful. 
- Mapping of AUs to PAD is helpful when you want to fuse multiple modalities where other modalities are in PAD values. },
author = {Boukricha, Hana and Wachsmuth, Ipke and Hofstatter, A. and Grammer, Karl},
booktitle = {Interaction and Workshops of 3rd International Conference on Affective Computing and Intelligent ACII2009},
doi = {10.1109/ACII.2009.5349579},
file = {::},
isbn = {9781424447992},
pages = {1--7},
publisher = {IEEE},
title = {{Pleasure-arousal-dominance driven facial expression simulation}},
url = {http://ieeexplore.ieee.org/xpl/freeabs\_all.jsp?arnumber=5349579},
year = {2009}
}
@article{Varni2009,
author = {Varni, Giovanna and Camurri, Antonio and Coletta, Paolo and Volpe, Gualtiero},
doi = {10.1109/CSE.2009.230},
file = {::},
isbn = {978-1-4244-5334-4},
journal = {2009 International Conference on Computational Science and Engineering},
keywords = {Social signals, music, synchronisation},
pages = {843--848},
publisher = {Ieee},
title = {{Toward a Real-Time Automated Measure of Empathy and Dominance}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5283210},
year = {2009}
}
@article{Devoldre2010,
abstract = {Social support researchers and clinicians have repeatedly expressed the need to identify the antecedents of social support provision within close relationships. The aim of the present study is to investigate the extent to which individual differences in cognitive empathy (perspective taking) and affective empathy (empathic concern and personal distress) are predictive of social support provision in couples. Study 1 involved 83 female participants in a relatively young relationship; Study 2 involved 128 married couples. The authors used self-report measures in both studies to assess individual differences in empathy and participants' support provision behaviors. The main findings suggest a significant contribution of the different components of empathy with rather different pictures for each of these components. The authors discuss the present findings in light of existing theory and research on social support in relationships.},
author = {Devoldre, Inge and Davis, Mark H. and Verhofstadt, Lesley L and Buysse, Ann},
doi = {10.1080/00223981003648294},
file = {::},
issn = {0022-3980},
journal = {The Journal of psychology},
keywords = {80 and over,Adolescent,Adult,Affect,Aged,Empathy,Family Characteristics,Female,Humans,Individuality,Male,Middle Aged,Personal Construct Theory,Personality Inventory,Personality Inventory: statistics \& numerical data,Psychometrics,Social Support,Young Adult},
number = {3},
pages = {259--284},
pmid = {20461931},
title = {{Empathy and social support provision in couples: social support and the need to study the underlying processes.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21506454},
volume = {144},
year = {2010}
}
@book{Izard1977,
address = {New York},
author = {Izard, Carroll Ellis},
editor = {Izard, Carroll Ellis},
isbn = {9780306309861},
pages = {495},
publisher = {Plenum Press},
title = {{Human Emotions}},
year = {1977}
}
@article{Woods1970,
abstract = {The use of augmented transition network grammars for the analysis of natural language sentences is described. Struc- ture-building actions associated with the arcs of the gram- mar network allow for the reordering, restructuring, and copy- ing of constituents necessary to produce deep-structure repre- sentations of the type normally obtained from a transforma- tional analysis, and conditions on the arcs allow for a powerful selectivity which can rule out meaningless analyses and take advantage of semantic information to guide the parsing. The advantages of this model for natural language analysis are discussed in detail and illustrated by examples. An imple- mentation of an experimental parsing system for transition network grammars is briefly described.},
author = {Woods, W A},
doi = {10.1145/355598.362773},
editor = {Grosz, Barbara and Jones, Karen and Webber, Bonnie},
file = {::},
issn = {00010782},
journal = {Communications of the ACM},
number = {10},
pages = {591--606},
publisher = {ASSOC COMPUTING MACHINERY},
title = {{Transition Network Grammars for Natural Language Analysis}},
url = {http://portal.acm.org/citation.cfm?doid=355598.362773},
volume = {13},
year = {1970}
}
@article{Ochs2010a,
author = {Ochs, Magalie and Sadek, David and Pelachaud, Catherine},
doi = {10.1007/s10458-010-9156-z},
file = {::},
issn = {1387-2532},
journal = {Autonomous Agents and Multi-Agent Systems},
keywords = {affective computing,dialog,emotions,empathy,rational dialog agent},
month = nov,
number = {3},
pages = {410--440},
title = {{A formal model of emotions for an empathic rational dialog agent}},
url = {http://www.springerlink.com/index/10.1007/s10458-010-9156-z},
volume = {24},
year = {2010}
}
@article{Biocca2002,
abstract = {This paper outlines the foundation of a definition and measurement for the concept social presence. Justification for such a line of research lies in the ever-increasing use of social presence technologies and expansion of the social interactions across the Internet. A definition of social presence, based upon past literature and theory, describes several levels and dimensions of social presence by which the concept can be operationalized. Specifically, Level 1: co-presence is a necessary but not sufficient requirement for the sense of social presence. Level 2: the Subjective level, attempts to measure the psycho-behavioral accessibility of another interactant. Finally, Level 3: the Intersubjective level, assesses within and cross-interactant symmetry. The purposeful direction of this research and measurement construction is to enable researchers and designers to compare various mediated interactions as well as further theoretical inquiry.},
author = {Biocca, Frank and Harms, Chad},
journal = {Proceedings of PRESENCE},
keywords = {social presence,theory mind},
number = {517},
pages = {1--36},
publisher = {Citeseer},
title = {{Defining and measuring social presence: Contribution to the networked minds theory and measure}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.84.8350\&amp;rep=rep1\&amp;type=pdf},
volume = {2002},
year = {2002}
}
@book{Ekman1978,
author = {Ekman, Paul and Freisen, Wallace V.},
booktitle = {Consulting Psychologists Press 1978},
editor = {Press, Consulting Psychologists},
publisher = {Consulting Psychologists Press},
title = {{Facial Action Coding System: A Technique for the Measurement of Facial Movement}},
year = {1978}
}
@article{Larsen1992,
abstract = {TOC The structural bases of emotional behavior James R. Averill - Promises and problems with the circumplex model of emotion Randy J. Larsen and Edward Diener - The complexity of intensity Nico H. Frijda, Andrew Ortony, Joep Sonnemans, and Gerald L. Clore - The behavioral ecology and sociality of human faces Alan J. Firdlund - Appraisal as a cause of emotion Brian Parkinson and A.S.R. Manstead - Affective dynamics Robert Mauro - Cross-cultural similarities and differences in emotion and its representation Phillip R. Shaver, Shelley Wu, and Judith C. Schwartz - The process of emotional experience James D. Laird and Charles Bresler - Inhibitory effects of awareness on affective responding Robert F. Bornstein - A functional analysis of the role of mood in affective systems William N. Morris - Differentiating affect, mood, and emotion C. Daniel Batson, Laura L. Shaw, and Kathryn C. Oleson},
author = {Larsen, Randy J and Diener, Edward},
chapter = {2},
editor = {Clark, Margaret S},
isbn = {0803946139},
journal = {Review of Personality and Social Psychology},
number = {13},
pages = {25--59},
publisher = {Sage},
series = {Review of personality and social psychology; No. 13; 0270-1987},
title = {{Promises and problems with the circumplex model of emotion}},
url = {http://psycnet.apa.org/psycinfo/1992-97396-002},
volume = {13},
year = {1992}
}
@inproceedings{Boukricha2011c,
abstract = {Empathy is believed to play a prominent role in contributing to an efficient and satisfying cooperative social interaction by adjusting one's own behavior to that of others. Thus, endowing virtual humans with the ability to empathize not only enhances their cooperative social skills, but also makes them more likeable, trustworthy, and caring. Supported by psychological models of empathy, we propose an approach to model empathy for EMMA - an Empathic MultiModal Agent - based on three processing steps: First, the Empathy Mechanism consists of an internal simulation of perceived emotional facial expressions and results in an internal emotional feedback that represents the empathic emotion. Second, the Empathy Modulation consists of modulating the empathic emotion through different predefined modulation factors. Third, the Expression of Empathy consists of triggering EMMA's multiple modalities like facial and verbal behaviors. In a conversational agent scenario involving the virtual humans MAX and EMMA, we illustrate our proposed model of empathy and we introduce a planned empirical evaluation of EMMA's empathic behavior.},
address = {Paris, France},
author = {Boukricha, Hana and Wachsmuth, Ipke},
booktitle = {Proceedings of the IEEE SSCI2011 - Symposium Series on Computational Intelligence, Workshop on Affective Computational Intelligence (WACI)},
doi = {10.1109/WACI.2011.5953146},
file = {::},
isbn = {9781612840840},
pages = {30 -- 37},
publisher = {IEEE},
title = {{Mechanism, modulation, and expression of empathy in a virtual human}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5953146},
year = {2011}
}
@article{Devoldre2010,
abstract = {Social support researchers and clinicians have repeatedly expressed the need to identify the antecedents of social support provision within close relationships. The aim of the present study is to investigate the extent to which individual differences in cognitive empathy (perspective taking) and affective empathy (empathic concern and personal distress) are predictive of social support provision in couples. Study 1 involved 83 female participants in a relatively young relationship; Study 2 involved 128 married couples. The authors used self-report measures in both studies to assess individual differences in empathy and participants' support provision behaviors. The main findings suggest a significant contribution of the different components of empathy with rather different pictures for each of these components. The authors discuss the present findings in light of existing theory and research on social support in relationships.},
author = {Devoldre, Inge and Davis, Mark H and Verhofstadt, Lesley L and Buysse, Ann},
doi = {10.1080/00223981003648294},
file = {::},
issn = {0022-3980},
journal = {The Journal of psychology},
keywords = {80 and over,Adolescent,Adult,Affect,Aged,Empathy,Family Characteristics,Female,Humans,Individuality,Male,Middle Aged,Personal Construct Theory,Personality Inventory,Personality Inventory: statistics \& numerical data,Psychometrics,Social Support,Young Adult},
number = {3},
pages = {259--284},
pmid = {20461931},
title = {{Empathy and social support provision in couples: social support and the need to study the underlying processes.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21506454},
volume = {144},
year = {2010}
}
@book{Russell2010,
author = {Russell, S.J. and Norvig, P.},
booktitle = {Artificial Intelligence},
edition = {3},
editor = {Russell, Stuart and Norvig, Peter},
file = {::},
isbn = {9780136042594},
publisher = {Prentice hall},
title = {{Artificial intelligence: a modern approach}},
url = {http://www.just.edu.jo/CoursesAndLabs/ARTIFICAL  INTELLIGENCE\_CS362/Syllabus\_362.doc},
year = {2010}
}
@article{Paiva2000,
author = {Paiva, Ana},
file = {::},
journal = {Affective interactions},
pages = {1--8},
title = {{Affective interactions: toward a new generation of computer interfaces?}},
url = {http://www.springerlink.com/index/826w110p65762167.pdf},
year = {2000}
}
@article{Hess1998,
author = {Hess, Ursula and Philippot, Pierre and Blairy, Sylvie},
doi = {10.1080/026999398379547},
file = {::},
issn = {0269-9931},
journal = {Cognition \& Emotion},
month = jul,
number = {4},
pages = {509--531},
title = {{Facial Reactions to Emotional Facial Expressions: Affect or Cognition?}},
url = {http://www.tandfonline.com/doi/abs/10.1080/026999398379547},
volume = {12},
year = {1998}
}
@article{Roberts1996,
author = {Roberts, William and Strayer, Janet},
doi = {10.2307/1131826},
file = {::},
issn = {00093920},
journal = {Child Development},
month = apr,
number = {2},
pages = {449},
title = {{Empathy, Emotional Expressiveness, and Prosocial Behavior}},
url = {http://www.jstor.org/stable/1131826?origin=crossref},
volume = {67},
year = {1996}
}
@article{Hojat2003,
author = {Hojat, Mohammadreza and Gonnella, J S and Mangione, Salvatore and Nasca, Thomas J and Magee, Mike},
journal = {Seminars in Integrative Medicine},
publisher = {Seminars in Integrative Medicine},
title = {{Pshysician empathy in medical education practice experience with the jefferson scale of physician empathy}},
year = {2003}
}
@article{Mignault2003,
abstract = {Ased on the premise that human head tilt is homologous to animal dominance displays, we hypothesized that when a head is bowed, the face should be perceived as submissive, sad, displaying inferiority emotions (i.e., shame, embarrassment, guilt, humiliation, and respect) and, paradoxically, as contracting the zygomatic major muscle. Conversely, a raised head should be perceived as more dominant and displaying greater superiority emotions (i.e., contempt and pride). We conducted two experiments showing 3-D models of faces to 64 participants. The results confirmed our hypotheses and also showed that a raised head connotes happiness. In addition, we found a significant influence of the actors' sex on participants' perception, such as a bias towards perceiving stronger upward contraction of the mouth in female than male actors when the head is tilted. We discuss these findings within the context of evolution and social behavior.},
author = {Mignault, Alain and Chaudhuri, Avi},
doi = {10.1023/A:1023914509763},
issn = {01915886},
journal = {Journal of Nonverbal Behavior},
number = {2},
pages = {111--132},
publisher = {Springer},
title = {{THE MANY FACES OF A NEUTRAL FACE : HEAD TILT AND PERCEPTION OF DOMINANCE AND EMOTION}},
url = {http://dx.doi.org/10.1023/A:1023914509763},
volume = {27},
year = {2003}
}
@article{Rameson2009,
author = {Rameson, Lian T. and Lieberman, Matthew D.},
doi = {10.1111/j.1751-9004.2008.00154.x},
file = {::},
issn = {17519004},
journal = {Social and Personality Psychology Compass},
month = jan,
number = {1},
pages = {94--110},
title = {{Empathy: A Social Cognitive Neuroscience Approach}},
url = {http://doi.wiley.com/10.1111/j.1751-9004.2008.00154.x},
volume = {3},
year = {2009}
}
@article{Kiesler2008,
author = {Kiesler, Sara and Powers, Aaron and Fussell, Susan R. and Torrey, Cristen},
doi = {10.1521/soco.2008.26.2.169},
file = {::},
issn = {0278-016X},
journal = {Social Cognition},
month = apr,
number = {2},
pages = {169--181},
title = {{Anthropomorphic Interactions with a Robot and Robot–like Agent}},
url = {http://guilfordjournals.com/doi/abs/10.1521/soco.2008.26.2.169},
volume = {26},
year = {2008}
}
@incollection{Bavelas1987,
address = {Cambridge, UK},
author = {Bavelas, Janet Beavin and Black, Alex and Lemery, Charles R. and Mullett, Jennifer},
booktitle = {Motor mimicry as primitive empathy},
editor = {Eisenberg, Nancy and Strayer, Janet},
file = {::},
pages = {317--338},
publisher = {Cambridge University Press},
title = {{Empathy and its developement}},
year = {1987}
}
@article{Bollen2011,
author = {Bollen, Johan and Mao, Huina and Zeng, Xiaojun},
doi = {10.1016/j.jocs.2010.12.007},
file = {::},
issn = {18777503},
journal = {Journal of Computational Science},
month = mar,
number = {1},
pages = {1--8},
publisher = {Elsevier B.V.},
title = {{Twitter mood predicts the stock market}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S187775031100007X},
volume = {2},
year = {2011}
}
@article{Wolf2010,
abstract = {Computer Vision and Biometrics systems have demonstrated considerable improvement in recognizing and verifying faces in digital images. Still, recognizing faces appearing in unconstrained, natural conditions remains a challenging task. In this paper we present a face-image, pair-matching approach primarily developed and tested on the "Labeled Faces in the Wild" (LFW) benchmark that reflect the challenges of face recognition from unconstrained images. The approach we propose makes the following contributions. (a) We present a family of novel face-image descriptors designed to capture statistics of local patch similarities. (b) We demonstrate how semi-labeled background samples may be used to better evaluate image similarities. To this end we describe a number of novel, effective similarity measures. (c) We show how labeled background samples, when available, may further improve classification performance, by employing a unique pair-matching pipeline. We present state-of-the-art results on the LFW pair-matching benchmarks. In addition, we show our system to be well suited for multi-label face classification (recognition) problems. We perform recognition tests on LFW images as well images from the laboratory controlled multiPIE database.},
author = {Wolf, Lior and Hassner, Tal and Taigman, Yaniv},
doi = {10.1109/TPAMI.2010.230},
file = {::},
issn = {1939-3539},
journal = {IEEE transactions on pattern analysis and machine intelligence},
month = dec,
pages = {1--13},
pmid = {21173442},
title = {{Effective Unconstrained Face Recognition by Combining Multiple Descriptors and Learned Background Statistics.}},
volume = {33},
year = {2010}
}
@inproceedings{Broek2005,
address = {Utrecht – The Netherlands},
author = {van den Broek, E. L.},
booktitle = {in Proceedings of AAMAS-05 Agent-Based Systems for Human Learning (ABSHL) workshop},
editor = {Johnson, L. and Richards, D. and Sklar, E. and Wilensky, U.},
pages = {59--67},
title = {{Empathic agent technology}},
year = {2005}
}
@phdthesis{Sze2005,
author = {Sze, Ian},
booktitle = {Ambient Intelligence in Everyday Life},
file = {::},
school = {UNIVERSITY OF NEW SOUTH WALES},
title = {{Empathic computing}},
year = {2005}
}
@inproceedings{Cavazza2010,
abstract = {This paper presents a dialogue system in the form of an ECA that acts as a socia- ble and emotionally intelligent compan- ion for the user. The system dialogue is not task-driven but is social conversation in which the user talks about his/her day at the office. During conversations the system monitors the emotional state of the user and uses that information to in- form its dialogue turns. The system is able to respond to spoken interruptions by the user, for example, the user can in- terrupt to correct the system. The system is already fully implemented and aspects of actual output will be used to illustrate.},
address = {The University of Tokyo},
author = {Cavazza, Marc and Vargas, C Emilio and Gil, Jos\'{e} Rela\~{n}o and Telef\'{o}nica, I D and Crook, Nigel and Field, Debora and Sheffield, S},
booktitle = {Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
file = {::},
pages = {277--280},
publisher = {Association for Computational Linguistics},
title = {{‘ How was your day ?’ An affective companion ECA prototype}},
volume = {1},
year = {2010}
}
@article{Ward2000,
abstract = {Back-channel feedback, responses such as uh-uh from a listener, is a pervasive feature of conversation. It has long been thought that the production of back-channel feedback depends to a large extent on the actions of the other conversation partner, not just on the volition of the one who produces them. In particular, prosodic cues from the speaker have long been thought to play a role, but have so far eluded identification. We have earlier suggested that an important prosodic cue involved, in both English and Japanese, is a region of low pitch late in an utterance (Ward, 1996). This paper discusses issues in the definition of back-channel feedback, presents evidence for our claim, surveys other factors which elicit or inhibit back-channel responses, and mentions a few related phenomena and theoretical issues. (C) 2000 Elsevier Science B.V. All rights reserved.},
author = {Ward, Nigel and Tsukahara, Wataru},
doi = {10.1016/S0378-2166(99)00109-5},
issn = {03782166},
journal = {Journal of Pragmatics},
number = {8},
pages = {1177--1207},
publisher = {Elsevier},
title = {{Prosodic features which cue back-channel responses in English and Japanese}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0378216699001095},
volume = {32},
year = {2000}
}
@article{Szymanski2007,
abstract = {The first step towards creating avatars with human-like artificial minds is to give them human-like memory structures with an access to general knowledge about the world. This type of knowledge is stored in semantic memory. Although many approaches to modeling of semantic memories have been proposed they are not very useful in real life applications because they lack knowledge comparable to the common sense that humans have, and they cannot be implemented in a computationally efficient way. The most drastic simplification of semantic memory leading to the simplest knowledge representation that is sufficient for many applications is based on the Concept Description Vectors (CDVs) that store, for each concept, an information whether a given property is applicable to this concept or not. Unfortunately even such simple information about real objects or concepts is not available. Experiments with automatic creation of concept description vectors from various sources, including ontologies, dictionaries, encyclopedias and unstructured text sources are described. Haptek-based talking head that has an access to this memory has been created as an example of a humanized interface (HIT) that can interact with web pages and exchange information in a natural way. A few examples of applications of an avatar with semantic memory are given, including the twenty questions game and automatic creation of word puzzles.},
author = {Szymanski, Julian and Sarnatowicz, Tomasz and Duch, Wlodzislaw},
file = {::},
journal = {Journal of Ubiquitous Computing and Intelligence},
keywords = {avatars,cyberspace,dialogue systems,natural language processing,semantic memory,word games},
title = {{Towards Avatars with Artificial Minds : Role of Semantic Memory}},
url = {http://cogprints.org/5357/},
year = {2007}
}
@article{Mendelson1999,
author = {Mendelson, M.J. and Aboud, F.E.},
file = {::},
journal = {Canadian Journal of Behavioural Science/Revue canadienne des sciences du comportement},
number = {2},
pages = {130},
publisher = {Canadian Psychological Association},
title = {{Measuring friendship quality in late adolescents and young adults: McGill Friendship Questionnaires.}},
url = {http://psycnet.apa.org/journals/cbs/31/2/130/},
volume = {31},
year = {1999}
}
@article{Turunen2011,
abstract = {Multimodal conversational spoken dialogues using physical and virtual agents provide a potential interface to motivate and support users in the domain of health and fitness. This paper describes how such multimodal conversational Companions can be implemented to support their owners in various pervasive and mobile settings. We present concrete system architectures, virtual, physical and mobile multimodal interfaces, and interaction management techniques for such Companions. In particular how knowledge representation and separation of low-level interaction modelling from high-level reasoning at the domain level makes it possible to implement distributed, but still coherent, interaction with Companions. The distribution is enabled by using a dialogue plan to communicate information from domain level planner to dialogue management and from there to a separate mobile interface. The model enables each part of the system to handle the same information from its own perspective without containing overlapping logic, and makes it possible to separate task-specific and conversational dialogue management from each other. In addition to technical descriptions, results from the first evaluations of the Companions interfaces are presented.},
author = {Turunen, Markku and Hakulinen, Jaakko and St\aa hl, Olov and Gamb\"{a}ck, Bj\"{o}rn and Hansen, Preben and {Rodr\'{\i}guez Gancedo}, Mari C. and de la C\'{a}mara, Ra\'{u}l Santos and Smith, Cameron and Charlton, Daniel and Cavazza, Marc},
doi = {10.1016/j.csl.2010.04.004},
file = {::},
issn = {08852308},
journal = {Computer Speech \& Language},
keywords = {cognitive modelling,companions,conversational spoken dialogue systems,embodied conversational agents,mobile interfaces},
month = apr,
number = {2},
pages = {192--209},
publisher = {Elsevier Ltd},
title = {{Multimodal and mobile conversational Health and Fitness Companions}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0885230810000355},
volume = {25},
year = {2011}
}
@article{Termine1988,
author = {Termine, NT},
file = {::},
journal = {Developmental Psychology},
number = {2},
pages = {223--229},
title = {{Infants' responses to their mothers'; expressions of joy and sadness}},
volume = {24},
year = {1988}
}
@incollection{Gratch2006a,
author = {Gratch, Jonathan and Mao, W and Marsella, Stacy C},
booktitle = {Cognition and Multi-Agent Interaction: From Cognitive Modeling to Social Simulation},
chapter = {9},
doi = {http://dx.doi.org/10.1017/CBO9780511610721.010},
editor = {Sun, Ron},
file = {::;::},
isbn = {9780511610721},
pages = {219--251},
publisher = {Cambridge University Press},
title = {{Modeling social emotions and social attributions}},
year = {2006}
}
@inproceedings{Lisetti2008,
abstract = {In this article, we explore how Embodied Conversational Agents (ECAs) or avatars could be used as social orthotics defined as therapeutic computer- based social companions aimed at promoting healthy behaviors. We review some of the latest related progress and identify specific features of ECAs that are important – if not necessary – to include in the design of social orthotic systems.},
author = {Lisetti, Christine L},
booktitle = {Proceedings of the CHI 2008 Conference Workshop on Technology in Mental Health},
file = {::},
keywords = {acm classification keywords,affective computing,agents,avatars,embodied conversational,psychotherapy,social orthotics},
title = {{Embodied Conversational Agents for Psychotherapy}},
year = {2008}
}
@inproceedings{Mateas2003,
abstract = {In this paper we discuss our research and development towards creating an architecture, and a story design using this architecture, that integrates a broad and shallow approach to natural language processing, a novel character authoring language and a novel drama manager, in order to build an interactive drama about human relationships.},
address = {San Jose, CA, UA},
author = {Mateas, Michael and Stern, Andrew},
booktitle = {Game Developers Conference Game Design track},
file = {::},
publisher = {Citeseer},
title = {{Fa\c{c}ade: An experiment in building a fully-realized interactive drama}},
url = {http://www.mendeley.com/research/faade-an-experiment-in-building-a-fullyrealized-interactive-drama/},
volume = {2},
year = {2003}
}
@article{Calvo2010,
abstract = {This survey describes recent progress in the field of Affective Computing (AC), with a focus on affect detection. Although many AC researchers have traditionally attempted to remain agnostic to the different emotion theories proposed by psychologists, the affective technologies being developed are rife with theoretical assumptions that impact their effectiveness. Hence, an informed and integrated examination of emotion theories from multiple areas will need to become part of computing practice if truly effective real-world systems are to be achieved. This survey discusses theoretical perspectives that view emotions as expressions, embodiments, outcomes of cognitive appraisal, social constructs, products of neural circuitry, and psychological interpretations of basic feelings. It provides meta-analyses on existing reviews of affect detection systems that focus on traditional affect detection modalities like physiology, face, and voice, and also reviews emerging research on more novel channels such as text, body language, and complex multimodal systems. This survey explicitly explores the multidisciplinary foundation that underlies all AC applications by describing how AC researchers have incorporated psychological theories of emotion and how these theories affect research questions, methods, results, and their interpretations. In this way, models and methods can be compared, and emerging insights from various disciplines can be more expertly integrated.},
author = {Calvo, R.A. and D'Mello, S.},
doi = {10.1109/T-AFFC.2010.1},
file = {::},
journal = {IEEE Transactions on Affective Computing},
keywords = {Affective computing,affect sensing and analysis,emotion detection,emotion theory,multimodal recognition},
number = {1},
pages = {18--37},
publisher = {IEEE},
title = {{Affect detection: An interdisciplinary review of models, methods, and their applications}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5520655},
volume = {1},
year = {2010}
}
@article{Carino2004,
abstract = {With the growing prevalence of diabetes worldwide, controlling modifiable risk factors for diabetes is essential to preventing complications and disease progression. Recent research strongly supports targeting at-risk prediabetes clients through therapeutic lifestyle change. Many behavior change techniques and strategies are known to be successful, yet are seldom implemented in today's health care arena. Nurses are in an excellent position to serve as change agents to assist at-risk prediabetes clients in making necessary lifestyle changes. Motivational interviewing has been shown to be effective in counseling clients toward behavior change. The major principles of motivational interviewing will be described and motivational interviewing techniques will be demonstrated using a scenario with a prediabetes client.},
author = {Carino, Judy Lau and Coke, Lola and Gulanick, Meg},
institution = {Rush-Copley Memorial Hospital, 2000 Ogden Avenue-ICA, Aurora, IL 60504, USA.},
journal = {Progress in Cardiovascular Nursing},
number = {4},
pages = {149--154},
title = {{Using motivational interviewing to reduce diabetes risk.}},
volume = {19},
year = {2004}
}
@incollection{Tomkins1984,
address = {Hillsdale, NJ},
author = {Tomkins, S S},
booktitle = {Approaches to emotion},
editor = {Scherer, Klaus R and Ekman, Paul},
isbn = {0898594065},
pages = {163--195},
publisher = {Erlbaum},
title = {{Affect theory}},
volume = {163},
year = {1984}
}
@book{Fogg2003,
abstract = {Can computers change what you think and do? Can they motivate you to stop smoking, persuade you to buy insurance, or convince you to join the Army? "Yes, they can," says Dr. B.J. Fogg, director of the Persuasive Technology Lab at Stanford University. Fogg has coined the phrase "Captology"(an acronym for computers as persuasive technologies) to capture the domain of research, design, and applications of persuasive computers.In this thought-provoking book, based on nine years of research in captology, Dr. Fogg reveals how Web sites, software applications, and mobile devices can be used to change people's attitudes and behavior. Technology designers, marketers, researchers, consumersanyone who wants to leverage or simply understand the persuasive power of interactive technologywill appreciate the compelling insights and illuminating examples found inside. Persuasive technology can be controversialand it should be. Who will wield this power of digital influence? And to what end? Now is the time to survey the issues and explore the principles of persuasive technology, and B.J. Fogg has written this book to be your guide. Filled with key term definitions in persuasive computingProvides frameworks for understanding this domainDescribes real examples of persuasive technologies},
author = {Fogg, B J},
booktitle = {Persuasive Technology Using Computers to Change What We Think and Do},
doi = {10.4017/gt.2006.05.01.009.00},
editor = {Kort, Yvonne and IJsselsteijn, Wijnand and Midden, Cees and Eggen, Berry and Fogg, B J},
file = {::},
isbn = {1558606432},
issn = {15691101},
number = {1},
pages = {283},
publisher = {Morgan Kaufmann},
series = {The Morgan Kaufmann series in interactive technologies},
title = {{Persuasive Technology: Using Computers to Change What We Think and Do}},
url = {http://books.google.com/books?id=r9JIkNjjTfEC\&pgis=1},
volume = {5},
year = {2003}
}
@article{Cassell1999,
author = {Cassell, Justine and Thorisson, K.R.},
file = {::},
journal = {Applied Artificial Intelligence},
number = {4-5},
pages = {519--538},
publisher = {Taylor \& Francis},
title = {{The power of a nod and a glance: Envelope vs. emotional feedback in animated conversational agents}},
url = {http://www.tandfonline.com/doi/abs/10.1080/088395199117360},
volume = {13},
year = {1999}
}
@article{Page2002,
abstract = {In the Ultimatum Game, two players are asked to split a prize. The first player, the proposer, makes an offer of how to split the prize. The second player, the responder, either accepts the offer, in which case the prize is split as agreed, or rejects it, in which case neither player receives anything. The rational strategy suggested by classical game theory is for the proposer to offer the smallest possible positive share and for the responder to accept. Humans do not play this way, however, and instead tend to offer 50\% of the prize and to reject offers below 20\%. Here we study the Ultimatum Game in an evolutionary context and show that empathy can lead to the evolution of fairness. Empathy means that individuals make offers which they themselves would be prepared to accept.},
author = {Page, Karen M and Nowak, Martin a},
doi = {10.1006/bulm.2002.0321},
file = {::},
issn = {0092-8240},
journal = {Bulletin of mathematical biology},
keywords = {Biological Evolution,Choice Behavior,Empathy,Games, Experimental,Humans,Models, Psychological,Social Behavior},
month = nov,
number = {6},
pages = {1101--16},
pmid = {12508533},
title = {{Empathy leads to fairness.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12508533},
volume = {64},
year = {2002}
}
@article{Page2002,
abstract = {In the Ultimatum Game, two players are asked to split a prize. The first player, the proposer, makes an offer of how to split the prize. The second player, the responder, either accepts the offer, in which case the prize is split as agreed, or rejects it, in which case neither player receives anything. The rational strategy suggested by classical game theory is for the proposer to offer the smallest possible positive share and for the responder to accept. Humans do not play this way, however, and instead tend to offer 50\% of the prize and to reject offers below 20\%. Here we study the Ultimatum Game in an evolutionary context and show that empathy can lead to the evolution of fairness. Empathy means that individuals make offers which they themselves would be prepared to accept.},
author = {Page, Karen M and Nowak, Martin a},
doi = {10.1006/bulm.2002.0321},
file = {::},
issn = {0092-8240},
journal = {Bulletin of mathematical biology},
keywords = {Biological Evolution,Choice Behavior,Empathy,Games, Experimental,Humans,Models, Psychological,Social Behavior},
month = nov,
number = {6},
pages = {1101--16},
pmid = {12508533},
title = {{Empathy leads to fairness.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12508533},
volume = {64},
year = {2002}
}
@phdthesis{Becker-Asano2008,
author = {Becker-Asano, Christian},
file = {::},
keywords = {Emotion,Empathy,PhD Thesis,Secondary Emotions,primary Emotions},
mendeley-tags = {PhD Thesis},
pages = {186},
publisher = {IOS Press},
school = {University of Bielefeld},
title = {{WASABI: Affect simulation for agents with believable interactivity}},
type = {PhD Dissertation, IOS Press (DISKI 319)},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=8ABvlwHBCQIC\&amp;oi=fnd\&amp;pg=PA1\&amp;dq=WASABI+:+Affect+Simulation+for+Agents+with+Believable+Interactivity\&amp;ots=m6MhCZ6IzD\&amp;sig=IcDYrCYofbGlJ8E1szs\_wltd18k},
volume = {319},
year = {2008}
}
@inproceedings{Cairco2007,
address = {Newport Beach, California, USA},
author = {Cairco, Lauren and Babu, Sabarish and Ulinski, Amy and Zanbaka, Catherine and Hodges, Larry F.},
booktitle = {Proceedings of the 2007 ACM symposium on Virtual reality software and technology (VRST '07)},
doi = {10.1145/1315184.1315239},
file = {::},
isbn = {9781595938633},
pages = {239--240},
publisher = {ACM Press},
title = {{Shakespearean karaoke}},
url = {http://portal.acm.org/citation.cfm?doid=1315184.1315239},
year = {2007}
}
@article{Caridakis2008,
abstract = {As input they consider the image sequence of the recorded human behavior. Computer vision and image processing techniques are incorporated in order to detect cues needed for expressivity features extraction. Using multimodalities, the virtual agent mimics the human expressions. The multimodality of the approach lies in the fact that both facial and gestural aspects of the user’s behavior are analyzed and processed. The mimicry consists of perception, interpretation, planning and animation of the expressions shown by the human, resulting not in an exact duplicate rather than an expressive model of the user’s original behavior.},
annote = {They use both facial and gestural aspects of the user’s behavior to mimic the user’s expressions. The introductory information and references about the psychological background of the mimicry in the paper are useful. But because most of the work is image processing, other sections would not be useful for our job.
Their system does not work in real time because they use a recorded video or sequence of images (limitation).},
author = {Caridakis, George and Raouzaiou, Amaryllis and Bevacqua, Elisabetta and Mancini, Maurizio and Karpouzis, Kostas and Malatesta, Lori and Pelachaud, Catherine},
doi = {10.1007/s10579-007-9057-1},
file = {::},
issn = {1574-020X},
journal = {Language Resources and Evaluation},
keywords = {facial,gesture,mimicry,multimodal,virtual agent},
month = jan,
number = {3-4},
pages = {367--388},
title = {{Virtual agent multimodal mimicry of humans}},
url = {http://www.springerlink.com/index/10.1007/s10579-007-9057-1},
volume = {41},
year = {2008}
}
@article{Hine2009,
author = {Hine, Michael J. and Murphy, Steven a. and Weber, Michael and Kersten, Gregory},
doi = {10.1007/s10726-008-9151-9},
file = {::},
issn = {0926-2644},
journal = {Group Decision and Negotiation},
keywords = {computer mediated communication,electronic negotiation,emotion,logistic regression},
month = jan,
number = {3},
pages = {193--211},
title = {{The Role of Emotion and Language in Dyadic E-negotiations}},
url = {http://www.springerlink.com/index/10.1007/s10726-008-9151-9},
volume = {18},
year = {2009}
}
@article{Gama2011,
author = {Gama, Sandra and Barata, Gabriel and Gon\c{c}alves, D. and Prada, R. and Paiva, Ana},
file = {::},
journal = {Affective Computing and Intelligent Interaction},
keywords = {affective computing,conversational agent,empathic agent},
pages = {507--516},
publisher = {Springer},
title = {{SARA: social affective relational agent: a study on the role of empathy in artificial social agents}},
url = {http://www.springerlink.com/index/G0433KX744258W62.pdf},
year = {2011}
}
@article{Gratch2006,
author = {Gratch, Jonathan and Okhmatovskaia, Anna and Lamothe, Francois},
file = {::},
journal = {Intelligent Virtual},
title = {{Virtual rapport}},
url = {http://www.springerlink.com/index/k720537752657m81.pdf},
year = {2006}
}
@inproceedings{Schulman2011,
abstract = {We present a conversational agent designed as a virtual counselor for health behavior change. The incorporates techniques drawn from agent Motivational Interviewing to enhance client motivation and confidence to change; these techniques are modeled and implemented based on a domain-specific taxonomy of dialogue acts. We discuss the design and preliminary evaluation of the agent.},
author = {Schulman, Daniel and Bickmore, Timothy W. and Sidner, Candace L},
booktitle = {Association for the Advancement of Artificial Intelligence (AAAI) Spring Symposium Series},
file = {::},
pages = {61--64},
publisher = {Association for the Advancement of Artificial Intelligence (www.aaai.org)},
title = {{An Intelligent Conversational Agent for Promoting Long-Term Health Behavior Change using Motivational Interviewing}},
year = {2011}
}
@article{Ekman1983,
author = {Ekman, Paul and Levenson, Robert W and Freisen, Wallace V.},
file = {::},
journal = {Science},
number = {4616},
pages = {1208--1210},
title = {{Autonomic Nervous System Activity Distinguishes among Emotions}},
volume = {221},
year = {1983}
}
@article{Wasfy2004a,
abstract = {An interrogative visualization environment is described for the interactive display and querying of large datasets. The environment combines a web-based intelligent agent facility with a visualization engine. The intelligent agent facility (IAF) incorporates a rule-based expert system for natural-language understanding, voice and text input facilities, a hierarchical clickable command list, an interface for multimodal devices such as menu-based wireless handheld devices and gesture recognition devices, and human-like avatars acting as virtual assistants. The IAF interacts with, and controls, the visualization engine through a TCP/IP network socket interface. The environment enables multiple users using a variety of interaction modes and devices to effectively browse through large amounts of data, focus on and query interesting features, and more easily comprehend and make use of the data. Application of the environment to the visualization of engineering simulations is described.},
author = {Wasfy, Hatem M. and Wasfy, Tamer M. and Noor, Ahmed K.},
doi = {10.1016/j.advengsoft.2004.06.015},
file = {::},
issn = {09659978},
journal = {Advances in Engineering Software},
keywords = {expert system,intelligent software agent,interface,multimodal,natural language,visualization},
month = dec,
number = {12},
pages = {805--813},
title = {{An interrogative visualization environment for large-scale engineering simulations}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0965997804001310},
volume = {35},
year = {2004}
}
@inproceedings{Boukricha2009,
abstract = {a system for simulating emotional facial expressions for a virtual human has been evolved. This system consists of two parts: (1) a control ar- chitecture for simulating emotional facial expressions with respect to Pleasure, Arousal, and Dominance (PAD) val- ues, (2) an expressive output component for animating the virtual human’s facial muscle actions called Action Units (AUs), modeled following the Facial Action Coding Sys- tem (FACS). A large face repertoire of about 6000 faces arranged in PAD-space with respect to two dominance val- ues (dominant vs. submissive) is obtained as a result of the empirical study. Using the face repertoire an approach to- wards realizing facial mimicry for a virtual human based on backward mapping AUs displaying an emotional facial expression on PAD-values is outlined.},
annote = {- For automatic recognition, the mapping of AUs to PAD may be only useful once you can identify the active AUs and their intensity on the face (which you won't be able with image processing teckniques).
- For the expression, if you have an avatar which has control on the AUs, you don’t need to map the AUs to PAD. But, if you have an avatar which expresses based on PAD, then this mapping is useful. 
- Mapping of AUs to PAD is helpful when you want to fuse multiple modalities where other modalities are in PAD values. },
author = {Boukricha, Hana and Wachsmuth, Ipke and Hofstatter, A. and Grammer, Karl},
booktitle = {Affective Computing and Intelligent Interaction and Workshops, 2009. ACII 2009. 3rd International Conference on},
file = {::},
isbn = {9781424447992},
pages = {1--7},
publisher = {IEEE},
title = {{Pleasure-arousal-dominance driven facial expression simulation}},
year = {2009}
}
@article{Feller2003,
abstract = {In this investigation of the construct of empathy, the authors report that the literature reflects strong evidence that empathy is an essential component of the therapeutic alliance across theories and that empathy is necessary in the counseling process. The concept of empathy continues to be a central component of new forms of counseling and therapy.},
author = {Feller, C P and Cottone, R R},
journal = {Journal of Humanistic Counseling Education and Development},
number = {1},
pages = {53--62},
publisher = {American Counseling Association},
title = {{The Importance of Empathy in the Therapeutic Alliance.}},
volume = {42},
year = {2003}
}
@incollection{Wallbott1995,
author = {Wallbott, H G},
booktitle = {In I Eds pp 8298},
chapter = {Congruence},
editor = {Markova, I and Graumann, C F and Foppa, K},
pages = {82--98},
publisher = {Cambridge University Press},
title = {{Mutualities in dialogue}},
volume = {Cambridge},
year = {1995}
}
@book{Watson1930,
address = {Chicago},
author = {Watson, J. B.},
publisher = {University of Chicago Press},
title = {{Behaviorism}},
year = {1930}
}
@book{Doherty1998,
author = {Doherty, William Joseph and Campbell, Thomas},
pages = {159},
publisher = {Stage Pubications},
title = {{Families and Health}},
year = {1998}
}
@inproceedings{Borutta2009,
abstract = {Emotional expressions are considered to be important for robotic and virtual agents to improve nonverbal communication in human-machine-interaction. In this paper we focus on a subset of emotional expressions, namely the smile and it's variations. The proposed concept for generating artificial smile sequences is based on the system-theoretic psychological model of smiling, which is based on the Zurich Model of Social Motivation. The model and seven different types of smiles are introduced and it is presented how to integrate this model in a virtual agent. The evaluation of the generated facial expressions shows that the seven types of smiles are distinguishable from each other and can be classified according to given categories.},
address = {Toyama, Japan},
author = {Borutta, Isabell and Sosnowski, Stefan and Zehetleitner, Michael},
booktitle = {The 18th IEEE International Symposium on Robot and Human Interactive Communication, 2009. RO-MAN 2009.},
doi = {10.1109/ROMAN.2009.5326255},
file = {::},
pages = {245 -- 250},
title = {{Generating artificial smile variations based on a psychological system-theoretic approach}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5326255},
year = {2009}
}
@inproceedings{Gonsior2011,
address = {Atlanta},
author = {Gonsior, Barbara and Sosnowski, Stefan and Mayer, Christoph and Blume, Jiirgen and Radig, B. and Wollherr, D. and Kuhnlenz, K.},
booktitle = {RO-MAN, 2011 IEEE, 20th IEEE International Symposium on Robot and Human Interactive Communication},
file = {::},
isbn = {9781457715730},
pages = {350--356},
publisher = {IEEE},
title = {{Improving aspects of empathy and subjective performance for HRI through mirroring facial expressions}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6005294},
year = {2011}
}
@article{Schneier2011,
author = {Schneier, B.},
file = {::},
journal = {Security \& Privacy, IEEE},
number = {5},
pages = {88--88},
publisher = {IEEE},
title = {{Empathy and Security}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6029366},
volume = {9},
year = {2011}
}
@book{Babor2001,
abstract = {This manual introduces the AUDIT, the Alcohol Use Disorders Identification Test, and describes how to use it to identify persons with hazardous and harmful patterns of alcohol consumption. The AUDIT was developed by the World Health Organization (WHO) as a simple method of screening for excessive drinking and to assist in brief assessment. It can help in identifying excessive drinking as the cause of the presenting illness. It also provides a framework for intervention to help hazardous and harmful drinkers reduce or cease alcohol consumption and thereby avoid the harmful consequences of their drinking. The first edition of this manual was published in 1989 (Document No. WHO/MNH/DAT/89.4) and was subsequently updated in 1992 (WHO/PSA/92.4). Since that time it has enjoyed widespread use by both health workers and alcohol researchers. With the growing use of alcohol screening and the international popularity of the AUDIT, there was a need to revise the manual to take into account advances in research and clinical experience. This manual is written primarily for health care practitioners, but other professionals who encounter persons with alcohol-related problems may also find it useful. It is designed to be used in conjunction with a companion document that provides complementary information about early intervention procedures, entitled “Brief Intervention for Hazardous and Harmful Drinking: A Manual for Use in Primary Care”. Together these manuals describe a comprehensive approach to screening and brief intervention for alcohol-related problems in primary health care.},
author = {Babor, Thomas F. and Higgins-Biddle, John C. and Saunders, John B. and Monteiro, Maristela G.},
edition = {2},
pages = {39},
publisher = {World Health Organization, Department of Mental Health and Substance Dependence},
title = {{AUDIT: The Alcohol Use Disorders Identification Test. Guidelines for use in primary health care}},
year = {2001}
}
@article{Hunsdahl1967,
author = {Hunsdahl, JB},
doi = {10.1016/0022-1910(58)90015-5},
issn = {00221910},
journal = {Journal of the History of the Behavioral},
number = {4},
pages = {298--312},
title = {{Concerning Einf\"{u}hlung (empathy): A concept analysis of its origin and early development}},
volume = {2},
year = {1967}
}
@article{Sabourin,
author = {Sabourin, Jennifer and Mott, Bradford and Lester, James},
file = {::},
journal = {lorentzcenter.nl},
keywords = {empathetic virtual agents,pedagogical agents,virtual learning},
title = {{Computational Models of Affect and Empathy for Pedagogical Virtual Agents}},
url = {http://www.lorentzcenter.nl/lc/web/2011/464/presentations/Sabourin.pdf}
}
@article{Chavhan2010,
author = {Chavhan, Yashpalsing and Dhore, M. L. and Yesaware, Pallavi},
doi = {10.5120/431-636},
file = {::},
issn = {09758887},
journal = {International Journal of Computer Applications},
keywords = {emotion recognition,mfcc and,speech emotion,svm},
month = feb,
number = {20},
pages = {8--11},
title = {{Speech Emotion Recognition using Support Vector Machine}},
url = {http://www.ijcaonline.org/journal/number20/pxc387636.pdf},
volume = {1},
year = {2010}
}
@article{Riek2008,
abstract = {Expressing empathy is a key component of human social communication. One common way people convey empathy is via facial expression mirroring. It may be helpful for machines intended to interact with people to also convey empathy in this manner. We have thus created Virgil, an expression-mimicking robot. We hypothesize that if people feel like a machine is empathizing with them they will be more likely to rate the interaction positively. We conducted a pilot study to test our hypothesis, and through quantitative and qualitative analysis of our results found some support for it.},
author = {Riek, Laurel D. and Robinson, Peter},
file = {::},
journal = {ACM Workshop on Affective Interaction in Natural Environments AFFINE at the International ACM Conference on Multimodal Interfaces ICMI 08},
pages = {1--5},
publisher = {ACM},
title = {{Real-time empathy: Facial mimicry on a robot}},
year = {2008}
}
@article{Dapretto2006,
abstract = {To examine mirror neuron abnormalities in autism, high-functioning children with autism and matched controls underwent fMRI while imitating and observing emotional expressions. Although both groups performed the tasks equally well, children with autism showed no mirror neuron activity in the inferior frontal gyrus (pars opercularis). Notably, activity in this area was inversely related to symptom severity in the social domain, suggesting that a dysfunctional 'mirror neuron system' may underlie the social deficits observed in autism.},
author = {Dapretto, Mirella and Davies, Mari S and Pfeifer, Jennifer H and Scott, Ashley a and Sigman, Marian and Bookheimer, Susan Y and Iacoboni, Marco},
doi = {10.1038/nn1611},
file = {::},
issn = {1097-6256},
journal = {Nature neuroscience},
keywords = {Autistic Disorder,Autistic Disorder: physiopathology,Autistic Disorder: psychology,Brain Mapping,Child,Emotions,Emotions: physiology,Empathy,Facial Expression,Female,Humans,Magnetic Resonance Imaging,Male,Neurons,Neurons: physiology,Social Perception},
month = jan,
number = {1},
pages = {28--30},
pmid = {16327784},
title = {{Understanding emotions in others: mirror neuron dysfunction in children with autism spectrum disorders.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16327784},
volume = {9},
year = {2006}
}
@article{Albrecht2005,
author = {Albrecht, Irene and Schr\"{o}der, Marc and Haber, J\"{o}rg and Seidel, Hans-Peter},
doi = {10.1007/s10055-005-0153-5},
file = {::},
issn = {1359-4338},
journal = {Virtual Reality},
keywords = {continuous emotions \ae emotional,speech,synthesis \ae facial animation},
month = aug,
number = {4},
pages = {201--212},
title = {{Mixed feelings: expression of non-basic emotions in a muscle-based talking head}},
url = {http://www.springerlink.com/index/10.1007/s10055-005-0153-5},
volume = {8},
year = {2005}
}
@article{Cooper2000,
author = {Cooper, Bridget and Brna, Paul and Martins, Alex},
file = {::},
journal = {Affective interactions},
pages = {21--34},
publisher = {Springer},
title = {{Effective affective in intelligent systems–building on evidence of empathy in teaching and learning}},
url = {http://www.springerlink.com/index/j8v0l230t3503367.pdf},
year = {2000}
}
@article{Vannini2010,
abstract = {Bullying is widespread in European schools, despite multiple intervention strategies having been proposed over the years. The present study investigates the effects of a novel virtual learning strategy (“FearNot!”) to tackle bullying in both UK and German samples. The approach is intended primarily for victims to increase their coping skills and further to heighten empathy and defence of victims by non-involved bystanders. This paper focuses on the defender role. Applying quantitative as well as qualitative methodology, the present study found that “FearNot!” helped non-involved children to become defenders in the German sub-sample while it had no such effect in the UK sub-sample. German “New Defenders” (children who are initially uninvolved but are nominated as defenders by their peers after the intervention period) were found to be significantly more popular at baseline, and to show more cognitive empathy (Theory of Mind) for the virtual victims as compared to permanently non-involved pupils. Moreover, gender interacts with becoming a defender in its effects on affective empathy, with emotional contagion being particularly associated with New Defender status among girls. The findings are discussed in relation to previous research on anti-bullying intervention strategies and cultural differences in bullying prevalence rates and intervention outcomes.},
author = {Vannini, Natalie and Enz, Sibylle and Sapouna, Maria and Wolke, Dieter and Watson, Scott and Woods, Sarah and Dautenhahn, Kerstin and Hall, Lynne and Paiva, Ana and Andr\'{e}, Elizabeth and Aylett, Ruth and Schneider, Wolfgang},
doi = {10.1007/s10212-010-0035-4},
file = {::},
issn = {0256-2928},
journal = {European Journal of Psychology of Education},
month = jun,
number = {1},
pages = {21--44},
title = {{“FearNot!”: a computer-based anti-bullying-programme designed to foster peer intervention}},
url = {http://www.springerlink.com/index/10.1007/s10212-010-0035-4 http://dx.doi.org/10.1007/s10212-010-0035-4},
volume = {26},
year = {2010}
}
@inproceedings{Higashinaka2008,
author = {Higashinaka, R. and Dohsaka, K. and Isozaki, H.},
booktitle = {Spoken Language Technology Workshop, 2008. SLT 2008. IEEE},
file = {::},
isbn = {9781424434725},
pages = {109--112},
publisher = {IEEE},
title = {{Effects of self-disclosure and empathy in human-computer dialogue}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4777852},
year = {2008}
}
@book{Goldstein1985,
author = {Goldstein, Arnold P. and Michaels, Gerald Y.},
edition = {1},
isbn = {089859538X},
pages = {304},
publisher = {Psychology Press},
title = {{Empathy: development, training, and consequences}},
year = {1985}
}
@article{Noller1985,
abstract = {This paper reviews the literature on the complex question of the relative importance of the verbal, visual and vocal channels in various types of judgments. It is noted that a wide variety of methodologies are used in such research with studies differing in terms of the type of stimuli used (varying on the dimension of stylised to naturally occurring), the task required of the subjects (particularly varying on the cognitive-affective dimension) and the method used to assess the relative importance of the channels. An attempt is made to assess the important variables which affect the way the various channels are used by decoders, including whether deception is involved or expected, whether the message is discrepant, the particular judgment being made and the dimension on which the stimulus varies, the sex of the encoder and the decoder and the relationship between them, and the age of the decoder. The possibility of other related variables also acting as moderators is discussed.},
author = {Noller, Patricia},
doi = {10.1007/BF00987557},
issn = {01915886},
journal = {Journal of Nonverbal Behavior},
number = {1},
pages = {28--47},
publisher = {Springer Netherlands},
title = {{Video primacy? A further look}},
url = {http://www.springerlink.com/index/10.1007/BF00987557},
volume = {9},
year = {1985}
}
@article{Varni2009,
author = {Varni, Giovanna and Camurri, Antonio and Coletta, Paolo and Volpe, Gualtiero},
doi = {10.1109/CSE.2009.230},
file = {::},
isbn = {978-1-4244-5334-4},
journal = {2009 International Conference on Computational Science and Engineering},
keywords = {Social signals, music, synchronisation},
pages = {843--848},
publisher = {Ieee},
title = {{Toward a Real-Time Automated Measure of Empathy and Dominance}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5283210},
year = {2009}
}
@article{Gruen1986,
author = {Gruen, Rand J. and Mendelsohn, Gerald},
doi = {10.1037/0022-3514.51.3.609},
file = {::},
issn = {1939-1315},
journal = {Journal of Personality and Social Psychology},
number = {3},
pages = {609--614},
title = {{Emotional responses to affective displays in others: The distinction between empathy and sympathy.}},
volume = {51},
year = {1986}
}
@article{Barrett2007,
abstract = {Experiences of emotion are content-rich events that emerge at the level of psychological description, but must be causally constituted by neurobiological processes. This chapter outlines an emerging scientific agenda for understanding what these experiences feel like and how they arise. We review the available answers to what is felt (i.e., the content that makes up an experience of emotion) and how neurobiological processes instantiate these properties of experience. These answers are then integrated into a broad framework that describes, in psychological terms, how the experience of emotion emerges from more basic processes. We then discuss the role of such experiences in the economy of the mind and behavior.},
author = {Barrett, Lisa Feldman and Mesquita, Batja and Ochsner, Kevin N and Gross, James J},
doi = {10.1146/annurev.psych.58.110405.085709},
editor = {Meyers, Editor-in-Chief Robert A},
institution = {Department of Psychology, Boston College, Chestnut Hill, Massachusetts 02467, USA. barretli$\backslash$@bc.edu},
isbn = {9780122274107},
issn = {00664308},
journal = {Annual Review of Psychology},
keywords = {affect,consciousness,emotion},
number = {1},
pages = {373--403},
pmid = {17002554},
publisher = {Annual Reviews},
title = {{The Experience of Emotion}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17002554},
volume = {58},
year = {2007}
}
@inproceedings{Dinda2007,
abstract = {Experimental computer systems research typically ignores the end-user, modeling him, if at all, in overly simple ways. We argue that this (1) results in inadequate performance evaluation of the systems, and (2) ignores opportunities. We summarize our experiences with (a) directly evaluating user satisfaction and (b) incorporating user feedback in different areas of client/server computing, and use our experiences to motivate principles for that domain. Specifically, we report on user studies to measure user satisfaction with resource borrowing and with different clock frequencies in desktop computing, the development and evaluation of user interfaces to integrate user feedback into scheduling and clock frequency decisions in this context, and results in predicting user action and system response in a remote display system. We also present initial results on extending our work to user control of scheduling and mapping of virtual machines in a virtualization-based distributed computing environment. We then generalize (a) and (b) as recommendations for incorporating the user into experimental computer systems research.},
address = {New York, USA},
author = {Dinda, Peter A and Dick, Robert P and Rossoff, Samuel},
booktitle = {ExpCS '07 Proceedings of the 2007 workshop on Experimental computer science ACM},
doi = {10.1145/1281700.1281710},
file = {::},
isbn = {9781595937513},
keywords = {Autonomic Systems,Design,Experimentation,Human Directed Adaptation,Human Factors,Measurement,Performance,Speculative Remote Display,User Comfort With Resource Borrowing,User-driven Power Management,User-driven Scheduling},
number = {June},
pages = {1--12},
title = {{The User In Experimental Computer Systems Research}},
url = {http://dl.acm.org/citation.cfm?id=1281710},
year = {2007}
}
@article{Shamay-Tsoory2011,
abstract = {Human empathy relies on the ability to share emotions as well as the ability to understand the other's thoughts, desires, and feelings. Recent evidence points to 2 separate systems for empathy: an emotional system that supports our ability to empathize emotionally and a cognitive system that involves cognitive understanding of the other's perspective. A neural network that includes the inferior frontal gyrus and the inferior parietal lobule is necessary for emotion recognition and emotional contagion. Although the emotional and cognitive systems appear to work independently, every empathic response may still evoke both components to some extent, depending on the social context.},
annote = {Difference between cognitive empathy and emotional empathy is explained in this paper. Also they talk about the active brain parts in each empathy type.},
author = {Shamay-Tsoory, Simone G},
doi = {10.1177/1073858410379268},
file = {::},
issn = {1089-4098},
journal = {The Neuroscientist : a review journal bringing neurobiology, neurology and psychiatry},
keywords = {Brain,Brain: physiology,Empathy,Empathy: physiology,Humans,Neural Pathways,Neural Pathways: physiology},
month = feb,
number = {1},
pages = {18--24},
pmid = {21071616},
title = {{The neural bases for empathy.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21071616},
volume = {17},
year = {2011}
}
@inproceedings{Pontier2009,
abstract = {There is a growing belief that the environment plays an important role in the healing process of patients, supported by empirical findings. Previous research showed that psychological stress caused by loneliness can be reduced by artificial companions. As a pilot application for this purpose, this paper presents an affective agent playing tic-tac-toe with the user. Experimenting with a number of agents under different parameter settings shows the agent is able to show human-like emotional behavior, and can make decisions based on rationality as well as on affective influences. After discussing the application with clinical experts and making improvements where needed, the application can be tested in a clinical setting in future research.},
author = {Pontier, Matthijs and Siddiqui, Ghazanfar Farooq},
booktitle = {PRIMA '09 Proceedings of the 12th International Conference on Principles of Practice in Multi-Agent Systems},
editor = {et al. (Eds.):, J.-J. Yang},
file = {::},
keywords = {cognitive modeling,emotion modeling,healing environment},
pages = {33--47},
publisher = {Springer-Verlag Berlin Heidelberg},
title = {{An Affective Agent Playing Tic-Tac-Toe as Part of a}},
year = {2009}
}
@article{Larimer2009,
abstract = {It is well established that college students have high rates of alcohol use and misuse and suffer the negative consequences of this behavior. Research evaluating the results of brief interventions with high-risk college students has shown these approaches to be successful in reducing alcohol con- sumption and/or related consequences. Several screening tools have been developed to detect the presence of problematic alcohol use and associated disorders, and some are designed specifically for use in a college student population. College campuses offer several opportunities to implement screening and interventions, including universal or large-scale assessments; health services, counsel- ing centers, or local emergency rooms; or via established judicial or grievance systems set up to deal with students who violate campus alcohol policies. Issues to consider when implementing screening and brief interventions in college populations include who should deliver the interventions—peer or professional counselors—and how students should be encouraged to participate in the interventions. Regardless of how the measures are implemented, the content and process of the brief interventions should be based on the available scientific evidence regarding established efficacious interventions.},
author = {Larimer, Mary E and Cronce, Jessica M and Lee, Christine M and Kilmer, Jason R},
file = {::},
journal = {Alcohol Research \& Health},
keywords = {AODD (alcohol and other drug use disorder),CAGE Questionnaire,Michigan Alcoholism Screening Test (MAST),Young Adult Alcohol Problems Screening Test (YAAPS,alcohol abuse,binge drinking,brief intervention,heavy drinking,identification and screening,interview,literature review,motivational interviewing,peer counseling,professional counseling,undergraduate student},
pages = {94--104},
title = {{Brief Intervention in College Settings}},
url = {?http://pubs.niaaa.nih.gov/publications/arh28 ?2/94?104 .htm},
volume = {28},
year = {2004}
}
@article{Hine2009,
author = {Hine, Michael J. and Murphy, Steven a. and Weber, Michael and Kersten, Gregory},
doi = {10.1007/s10726-008-9151-9},
file = {::},
issn = {0926-2644},
journal = {Group Decision and Negotiation},
keywords = {computer mediated communication,electronic negotiation,emotion,logistic regression},
month = jan,
number = {3},
pages = {193--211},
title = {{The Role of Emotion and Language in Dyadic E-negotiations}},
url = {http://www.springerlink.com/index/10.1007/s10726-008-9151-9},
volume = {18},
year = {2009}
}
@article{Dapretto2006,
abstract = {To examine mirror neuron abnormalities in autism, high-functioning children with autism and matched controls underwent fMRI while imitating and observing emotional expressions. Although both groups performed the tasks equally well, children with autism showed no mirror neuron activity in the inferior frontal gyrus (pars opercularis). Notably, activity in this area was inversely related to symptom severity in the social domain, suggesting that a dysfunctional 'mirror neuron system' may underlie the social deficits observed in autism.},
author = {Dapretto, Mirella and Davies, Mari S and Pfeifer, Jennifer H and Scott, Ashley a and Sigman, Marian and Bookheimer, Susan Y and Iacoboni, Marco},
doi = {10.1038/nn1611},
file = {::},
issn = {1097-6256},
journal = {Nature neuroscience},
keywords = {Autistic Disorder,Autistic Disorder: physiopathology,Autistic Disorder: psychology,Brain Mapping,Child,Emotions,Emotions: physiology,Empathy,Facial Expression,Female,Humans,Magnetic Resonance Imaging,Male,Neurons,Neurons: physiology,Social Perception},
month = jan,
number = {1},
pages = {28--30},
pmid = {16327784},
title = {{Understanding emotions in others: mirror neuron dysfunction in children with autism spectrum disorders.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16327784},
volume = {9},
year = {2006}
}
@incollection{WeinerBGraham1984,
address = {New York},
author = {{Weiner B Graham}, S},
booktitle = {Emotions, cognition, and behavior},
editor = {Izard, Carroll E and Kagan, J and Zajonc, Robert B},
pages = {167--191},
publisher = {Cambridge University Press},
title = {{An attributional approach to emotional development}},
year = {1984}
}
@article{Mehrabian1996,
author = {Mehrabian, Albert},
file = {::},
journal = {Current Psychology},
number = {4},
pages = {261--292},
title = {{Pleasure-arousal-dominance: A general framework for describing and measuring individual differences in temperament}},
volume = {14},
year = {1996}
}
@article{Walters2007,
abstract = {OBJECTIVE: Alcohol consumption has been a growing concern at U.S. colleges, particularly among first-year students, who are at increased risk for problems. This study tested the efficacy of the "electronic Check-Up to Go" (e-CHUG), a commercially-available internet program, at reducing drinking among a group of at-risk college freshman. METHOD: The design was a randomized controlled trial: 106 freshmen students who reported heavy episodic drinking were randomly assigned to receive feedback or to assessment only. Assessment measures were completed at baseline, 8 weeks, and 16 weeks. RESULTS: At 8 weeks, the feedback group showed a significant decrease in drinks per week and peak BAC over control. By 16 weeks, the control group also declined to a point where there were no differences between groups. Changes in normative drinking estimates mediated the effect of the intervention. An additional 245 abstainers and light drinkers who were also randomized to condition did not show any intervention effect. CONCLUSIONS: This study provides preliminary support for the efficacy of this intervention at reducing short-term drinking among at-risk students.},
author = {Walters, Scott T and Vader, Amanda M and Harris, T Robert},
institution = {University of Texas School of Public Health, Dallas Regional Campus, Dallas, TX 75390-9128, USA. scott.walters@utsouthwestern.edu},
journal = {Prevention science the official journal of the Society for Prevention Research},
keywords = {adult,alcoholism,alcoholism prevention \& control,feedback,female,humans,internet,male,psychological,questionnaires,texas,universities},
number = {1},
pages = {83--88},
pmid = {17136461},
publisher = {University of Texas School of Public Health, Dallas Regional Campus, Dallas, TX 75390-9128, USA. scott.walters@utsouthwestern.edu},
title = {{A controlled trial of web-based feedback for heavy drinking college students.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17136461},
volume = {8},
year = {2007}
}
@inproceedings{Ochs2008,
abstract = {Recent research has shown that virtual agents expressing empathic emotions toward users have the potentiality to en- hance human-machine interaction. To identify under which circumstances a virtual agent should express empathic emo- tions, we have analyzed real human-machine dialog situa- tions that have led users to express emotion. The results of this empirical study have been combined with theoretical descriptions of emotions to construct a model of empathic emotions. Based on this model, a module of emotions has been implemented as a plug-in for JSA agents. It determines the empathic emotions (their types and intensity) of such agents in real time. It has been used to develop a demon- strator where users can interact with an empathic dialog agent to obtain information on their emails. An evaluation of this agent has enabled us to both validate the proposed model of empathic emotions and highlight the positive user’s perception of the virtual agent.},
address = {Estoril, Portugal},
author = {Ochs, Magalie and Pelachaud, Catherine and Sadek, David},
booktitle = {Proceeding of 7th International Conference on Autonomous Agents and Multiagent Systems (AAMAS2008)},
file = {::},
pages = {89--96},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org)},
title = {{An empathic virtual dialog agent to improve human-machine interaction}},
url = {http://jmvidal.cse.sc.edu/library/AAMAS-08/proceedings/pdf/paper/AAMAS08\_0526.pdf},
year = {2008}
}
@article{Borutta2009,
author = {Borutta, Isabell and Sosnowski, Stefan and Zehetleitner, Michael},
file = {::},
journal = {Robot and Human},
title = {{Generating artificial smile variations based on a psychological system-theoretic approach}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5326255},
year = {2009}
}
@article{Cliffordson2002,
abstract = {The purpose of the present study was to examine the structure of empathy using a hierarchical approach, and to compare the dimensions of empathy with measures of social functioning, in order to contribute to the understanding of the nature of empathy. The dimensionality of the Interpersonal Reactivity Index, which comprises four subscales (empathic concern, perspective taking, fantasy and personal distress) was examined using confirmatory factor analysis. Relations with the Social Skills Inventory were also investigated. A sample of 127 applicants for places on nursing and social work undergraduate programs participated in the study. The study findings indicate that empathy is hierarchically organized, with one general dimension at the apex. The general factor is identical to empathic concern and this dimension overlaps to a great extent with perspective taking and fantasy. The findings also indicate that the general dimension constitutes an integrated entirety, with its main emphasis on emotional reactivity by also involving cognitive processes.},
author = {Cliffordson, Christina},
doi = {10.1111/1467-9450.00268},
file = {::},
issn = {0036-5564},
journal = {Scandinavian journal of psychology},
keywords = {Empathy,Factor Analysis,Humans,Social Behavior,Statistical},
month = feb,
number = {1},
pages = {49--59},
pmid = {11885760},
title = {{The hierarchical structure of empathy: dimensional organization and relations to social functioning}},
url = {http://onlinelibrary.wiley.com/doi/10.1111/1467-9450.00268/abstract},
volume = {43},
year = {2002}
}
@article{Gratch2007a,
author = {Gratch, Jonathan and Wang, Ning and Gerten, Jillian and Fast, Edward},
file = {::},
journal = {Intelligent Virtual Agents},
keywords = {evaluation,rapport,virtual agents},
title = {{Creating rapport with virtual agents}},
url = {http://www.springerlink.com/index/X568357400058UM7.pdf},
year = {2007}
}
@article{Wicker2003,
abstract = {What neural mechanism underlies the capacity to understand the emotions of others? Does this mechanism involve brain areas normally involved in experiencing the same emotion? We performed an fMRI study in which participants inhaled odorants producing a strong feeling of disgust. The same participants observed video clips showing the emotional facial expression of disgust. Observing such faces and feeling disgust activated the same sites in the anterior insula and to a lesser extent in the anterior cingulate cortex. Thus, as observing hand actions activates the observer's motor representation of that action, observing an emotion activates the neural representation of that emotion. This finding provides a unifying mechanism for understanding the behaviors of others.},
author = {Wicker, Bruno and Keysers, Christian and Plailly, Jane and Royet, Jean Pierre and Gallese, Vittorio and Rizzolatti, Giacomo},
doi = {10.1016/S0896-6273(03)00679-2},
institution = {Institut de Neurosciences Physiologiques et Cognitives, CNRS, Chemin Joseph Aiguier, 13402 cedex 20, Marseille, France.},
issn = {08966273},
journal = {Neuron},
keywords = {adult,brain mapping,cerebral cortex,cerebral cortex anatomy \& histology,cerebral cortex physiology,chemical,computer assisted,emotions,emotions physiology,facial expression,humans,image processing,magnetic resonance imaging,magnetic resonance imaging methods,male,ocular,ocular physiology,odors,photic stimulation,random allocation,stimulation,vision},
number = {3},
pages = {655--64},
pmid = {14642287},
publisher = {Elsevier},
title = {{Both of us disgusted in My insula: the common neural basis of seeing and feeling disgust.}},
volume = {40},
year = {2003}
}
@article{Prendinger2005,
abstract = {They designed an animated interface agent that accompanies the user in the setting of a virtual job interview. This interface application takes physiological data (skin conductance and electromyography) of a user in realtime, interprets them as emotions, and addresses the user’s affective states in the form of empathic feedback by employing embodied characters.},
annote = {They take physiological data (skin conductance and electromyography) of a user in real-time, interpret them as emotions, and address the user’s affective states by empathic feedback. A decision making agent relates these signals and the user’s answer to arousal and valence to infer the user’s emotional state by applying the model of Lang (1995) (Lang claims that all emotions can be characterized in terms of valence (pleasant or unpleasant) and arousal (calm or aroused)). Then it selects empathetic actions that maximize some utility function. They use text-based empathetic actions in addition to a small full body character.We can use the decision-theoretic agent aspect in our empathy model.
The empathy is mainly expressed in a text-base fashion in their job. The embodied agent that they have is so small and no facial expressions are used. There are some gestural expressions.
As shown in this paper and many other ones, text-base empathy expression can be effective. So we can use that too.
      },
author = {Prendinger, H and Ishizuka, M.},
file = {::;::},
journal = {Applied Artificial Intelligence},
keywords = {electromyography,physiological signals,skin conductance},
number = {3-4},
pages = {267--286},
publisher = {Citeseer},
title = {{The Empathic Companion - A Character-based Interface that Addresses Users’ Affective States}},
volume = {19},
year = {2005}
}
@article{Gray1985,
abstract = {Attempts to show that the experimental psychology of the rat and the neuropsychology of the rat's brain are of relevance to clinical psychology. It is suggested that there is a false dichotomy between the behaviorist and cognitive approaches to psychology and illustrates this by going from a behaviorist analysis of a psychological concept (anxiety) to a cognitive analysis of that concept, basing the argument on brain research: Damage to the septo-hippocampal system mimics the behavioral effects of the antianxiety drugs. The reason for this mimicry is probably that these drugs reduce the noradrenergic input to the septo-hippocampal system. The noradrenergic input is normally activated under conditions of stress and serves to increase the capacity of the septo-hippocampal system to handle information. It seems probable, therefore, that the state of anxiety is, to some degree at least, mediated by activity in the septo-hippocampal system. It is emphasized that there is no dichotomy between cognitive and behaviorist psychology because the brain controls both behavior and cognition.},
author = {Gray, J. A},
journal = {Bulletin of the British Psychological Society},
pages = {99--112},
title = {{The whole and its parts: Behaviour, the brain, cognition and emotion}},
volume = {38},
year = {1985}
}
@article{Turunen2011,
abstract = {Multimodal conversational spoken dialogues using physical and virtual agents provide a potential interface to motivate and support users in the domain of health and fitness. This paper describes how such multimodal conversational Companions can be implemented to support their owners in various pervasive and mobile settings. We present concrete system architectures, virtual, physical and mobile multimodal interfaces, and interaction management techniques for such Companions. In particular how knowledge representation and separation of low-level interaction modelling from high-level reasoning at the domain level makes it possible to implement distributed, but still coherent, interaction with Companions. The distribution is enabled by using a dialogue plan to communicate information from domain level planner to dialogue management and from there to a separate mobile interface. The model enables each part of the system to handle the same information from its own perspective without containing overlapping logic, and makes it possible to separate task-specific and conversational dialogue management from each other. In addition to technical descriptions, results from the first evaluations of the Companions interfaces are presented.},
author = {Turunen, Markku and Hakulinen, Jaakko and St\aa hl, Olov and Gamb\"{a}ck, Bj\"{o}rn and Hansen, Preben and {Rodr\'{\i}guez Gancedo}, Mari C. and de la C\'{a}mara, Ra\'{u}l Santos and Smith, Cameron and Charlton, Daniel and Cavazza, Marc},
doi = {10.1016/j.csl.2010.04.004},
file = {::},
issn = {08852308},
journal = {Computer Speech \& Language},
keywords = {cognitive modelling,companions,conversational spoken dialogue systems,embodied conversational agents,mobile interfaces},
month = apr,
number = {2},
pages = {192--209},
publisher = {Elsevier Ltd},
title = {{Multimodal and mobile conversational Health and Fitness Companions}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0885230810000355},
volume = {25},
year = {2011}
}
@article{Beck1981,
author = {Beck, K H and Lund, A K},
journal = {Journal of Applied Social Psychology},
number = {5},
pages = {401--415},
title = {{The Effects of Health Threat Seriousness and Personal Efficacy upon Intentions and Behavior}},
volume = {11},
year = {1981}
}
@article{Peter2003,
author = {Sonnby-borgstr\"{o}m, Marianne and Jonsson, Peter and Svensson, Owe},
file = {::},
journal = {Journal of Nonverbal},
keywords = {emg,emotional contagion,empathy,facial expressions,facial mim-,icry,mirror neurons},
number = {1},
pages = {3--23},
title = {{Emotional empathy as related to mimicry reactions at different levels of information processing}},
url = {http://www.springerlink.com/index/P81X69QTH751V836.pdf},
volume = {27},
year = {2003}
}
@misc{Ekman1980,
author = {Ekman, Paul and Freisen, Wallace V. and Ancoli, Sonia},
booktitle = {Journal of Personality and Social Psychology},
doi = {10.1037/h0077722},
file = {::},
issn = {0022-3514},
number = {6},
pages = {1125--1134},
title = {{Facial signs of emotional experience.}},
url = {http://content.apa.org/journals/psp/39/6/1125},
volume = {39},
year = {1980}
}
@misc{TheMendeleySupportTeam2011,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/The Mendeley Support Team - 2011 - Getting Started with Mendeley(4).pdf:pdf},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@inproceedings{Ehrlich2000,
abstract = {Designers of video-mediated communication and affective computing applications must make tradeoffs to deal with limited bandwidth. Typically spatial resolution and color are preserved at the expense of temporal resolution and accuracy. Our data suggest that this may not be the appropriate tradeoff for communicating facial affect; preserving motion is critical and may even compensate for major losses in image realism.},
address = {NY},
author = {Ehrlich, Sheryl M and Schiano, Diane J and Sheridan, Kyle},
booktitle = {Proceedings of ACM CHI 2000 Conference on Human Factors in Computing Systems},
file = {::},
keywords = {Facial affect,face,facial expression of emotion,image degradation,nonverbal communication,video conferencing.},
pages = {252--253},
publisher = {ACM},
title = {{Communicating Facial Affect : It's Not the Realism, It's the Motion}},
year = {2000}
}
@article{Calvo2010,
abstract = {This survey describes recent progress in the field of Affective Computing (AC), with a focus on affect detection. Although many AC researchers have traditionally attempted to remain agnostic to the different emotion theories proposed by psychologists, the affective technologies being developed are rife with theoretical assumptions that impact their effectiveness. Hence, an informed and integrated examination of emotion theories from multiple areas will need to become part of computing practice if truly effective real-world systems are to be achieved. This survey discusses theoretical perspectives that view emotions as expressions, embodiments, outcomes of cognitive appraisal, social constructs, products of neural circuitry, and psychological interpretations of basic feelings. It provides meta-analyses on existing reviews of affect detection systems that focus on traditional affect detection modalities like physiology, face, and voice, and also reviews emerging research on more novel channels such as text, body language, and complex multimodal systems. This survey explicitly explores the multidisciplinary foundation that underlies all AC applications by describing how AC researchers have incorporated psychological theories of emotion and how these theories affect research questions, methods, results, and their interpretations. In this way, models and methods can be compared, and emerging insights from various disciplines can be more expertly integrated.},
author = {Calvo, R.A. and D'Mello, S.},
doi = {10.1109/T-AFFC.2010.1},
file = {::},
journal = {IEEE Transactions on Affective Computing},
keywords = {Affective computing,affect sensing and analysis,emotion detection,emotion theory,multimodal recognition},
number = {1},
pages = {18--37},
publisher = {IEEE},
title = {{Affect detection: An interdisciplinary review of models, methods, and their applications}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5520655},
volume = {1},
year = {2010}
}
@book{Mowrer1960,
address = {New York},
author = {Mowrer, Orval Hobart},
pages = {555},
publisher = {Wiley},
title = {{Learning theory and behavior}},
year = {1960}
}
@article{Hodgson2002,
abstract = {Using the Alcohol Use Disorders Identification Test (AUDIT) as the gold standard, the Fast Alcohol Screening Test (FAST) was developed for use in busy medical settings. AUDIT questionnaires were completed by 666 patients in two London accident \& emergency (A\&E) departments. Using a principal components analysis, as well as sensitivity and specificity indices, a two-stage screening test was developed, using four of the AUDIT items. The first stage involved one item that identified >50\% of patients as either hazardous or non-hazardous drinkers. The second stage made use of the other three items to categorize the rest. The performance of this four-item questionnaire was then tested across a range of settings. Opportunistic samples of 100 patients completed AUDIT questionnaires in each of the following National Health Service settings: A\&E department, fracture clinic, primary health centre and a dental hospital. It was concluded that the four-item FAST questionnaire had good sensitivity and specificity, across a range of settings, when the AUDIT score was used as the gold standard. The FAST questionnaire is quick to administer, since >50\% of patients are categorized using just one question.},
author = {Hodgson, Ray and Alwyn, Tina and John, Bev and Thom, Betsy and Smith, Alyson},
institution = {University of Wales College of Medicine, Lansdowne Hospital, Cardiff CF11 8PL, UK.},
journal = {Alcohol and alcoholism Oxford Oxfordshire},
number = {1},
pages = {61--66},
publisher = {Oxford University Press},
title = {{The fast alcohol screening test.}},
url = {http://eprints.mdx.ac.uk/129/},
volume = {37},
year = {2002}
}
@article{Cichosz2007,
author = {Cichosz, Jarosław},
file = {::},
journal = {Doctoral Consortium. ACII},
keywords = {emotion recognition,speech analysis},
pages = {1--8},
title = {{Emotion recognition in speech signal using emotion-extracting binary decision trees}},
url = {http://www.di.uniba.it/intint/DC-ACII07/Chicosz.pdf},
year = {2007}
}
@article{Dinda2007,
author = {Dinda, Peter A and Dick, Robert P and Rossoff, Samuel},
file = {::},
isbn = {9781595937513},
journal = {ACM},
number = {June},
title = {{The User In Experimental Computer Systems Research Categories and Subject Descriptors}},
year = {2007}
}
@article{esposito2011cognitive,
author = {Esposito, A. and Vinciarelli, A. and Haykin, S. and Hussain, A. and Faundez-Zanuy, M.},
journal = {Cognitive Computation},
pages = {1--2},
publisher = {Springer},
title = {{Cognitive Computation Special Issue on Cognitive Behavioural Systems}},
url = {http://www.springerlink.com/index/H4718567520T2H84.pdf},
year = {2011}
}
@inproceedings{Broek2005,
address = {Utrecht – The Netherlands},
author = {van den Broek, E. L.},
booktitle = {in Proceedings of AAMAS-05 Agent-Based Systems for Human Learning (ABSHL) workshop},
editor = {Johnson, L. and Richards, D. and Sklar, E. and Wilensky, U.},
pages = {59--67},
title = {{Empathic agent technology}},
year = {2005}
}
@phdthesis{Li2007,
author = {Li, Xi},
booktitle = {Interface},
file = {::},
school = {Marquette University},
title = {{SPEech Feature Toolbox (SPEFT) Design and Emotional Speech Feature Extraction}},
url = {http://speechlab.eece.mu.edu/johnson/papers/li\_thesis.pdf},
year = {2007}
}
@incollection{Ekman1982,
address = {New York},
author = {Ekman, Paul and Friesen, W V and Ellsworth, P},
booktitle = {Emotion in the human face},
editor = {Ekman, Paul},
pages = {39--55},
publisher = {Cambridge University Press},
title = {{What emotion categories or dimensions can observers judge from facial behavior?}},
year = {1982}
}
@article{Tickle-Degnen1990,
abstract = {The purpose of this article is to offer a conceptualization of rapport that has utility for identifiing the nonverbal correlates associated with rapport. We describe the nature of rapport in terms of a dynamic structure of three interrelating components: mutual attentiveness, positivity, and coor- dination. We propose that the relative weighting of these components in the experience of rapport changes over the course of a developing relationship between individuals. In early interactions, positivity and attentiveness are more heavily weighted than coordination, whereas in later interactions, coordination and attentiveness are the more heavily weighted components. Because of the gestalt nature of the experience of rapport, it is not easy to identifi nonverbal behavioral correlates of the components. We discuss two approaches to nonverbal measurement, molecular and molar, along with recommendations for their appropriate application in the study of rapport at different stages of an interpersonal relationship. We present a meta-analytic study that demon- strates the effect of nonverbal behavior, measured at the molecular level, on the positivity component of rapport, and we conclude with an outline of hypotheses relevant to the investigation of the nonverbal correlates of rapport.},
author = {Tickle-Degnen, L. and Rosenthal, Robert},
file = {::},
journal = {Psychological Inquiry},
number = {4},
pages = {285--293},
publisher = {Taylor \& Francis},
title = {{The nature of rapport and its nonverbal correlates}},
url = {http://www.tandfonline.com/doi/abs/10.1207/s15327965pli0104\_1},
volume = {1},
year = {1990}
}
@article{Niewiadomski2008,
author = {Niewiadomski, Radoslaw and Ochs, Magalie},
file = {::},
journal = {Intelligent Virtual Agents},
keywords = {eca,empathy,facial expressions},
pages = {37--44},
title = {{Expressions of empathy in ECAs}},
url = {http://www.springerlink.com/index/618982507263X720.pdf},
year = {2008}
}
@article{Panksepp1982,
abstract = {Emotions seem to arise ultimately from hard-wired neural circuits in the visceral-limbic brain that facilitate diverse and adaptive behavioral and physiological response to major classes of environmental challenges. Presumable these circuits developed early in mammalian brain evolution, and the underlying contro mechanisms remain similar in humans and "lower" mammals. This would suggest that theoretically guided studies of the animal brain can reveal how primitive emotions are organized in the human brain. Conversely, granted these cross-specis heritage, it is arguable that human introspecive access to emotional states may provide direct information concerning operations of emotive circuits and thus be a primary source of hypothese for animal brain research. In this article the possibility that emotions are elaborated by transhypothalamic executive (command) circuits that concurrently activate related behavior patterns is assessed. Current neurobehavioral evidence indicates that there are at least four executive circuits of this type - those which elaborate central states of expectancy, rage, fear, and panic. The manner in which learning and psyuchiatric disorders may arise form activities of such circuits is also discussed.},
author = {Panksepp, J},
issn = {14691825},
journal = {Behavioral and Brain Sciences},
number = {3},
pages = {407--467},
title = {{Toward a general psychobiological theory of emotions}},
url = {http://scholar.google.com.au/scholar?as\_q=Panksepp+J+\&num=10\&btnG=Search+Scholar\&as\_epq=Toward+a+general+psychobiological+theory+of\&as\_oq=\&as\_eq=\&as\_occt=any\&as\_sauthors=\&as\_publication=\&as\_ylo=1982\&as\_yhi=1982\&as\_sdt=1.\&as\_sdtp=on\&as\_sdts=5\&hl=en\#0},
volume = {5},
year = {1982}
}
@article{Brave2005,
abstract = {Embodied computer agents are becoming an increasingly popular human-computer interaction technique. Often, these agents are programmed with the capacity for emotional expression. This paper investigates the psychological effects of emotion in agents upon users. In particular, two types of emotion were evaluated: self-oriented emotion and other-oriented, empathic emotion. In a 2 (self-oriented emotion: absent vs. present) by 2 (empathic emotion: absent vs. present) by 2 (gender dyad: male vs. female) between-subjects experiment (N = 96), empathic emotion was found to lead to more positive ratings of the agent by users, including greater likeability and trustworthiness, as well as greater perceived caring and felt support. No such effect was found for the presence of self-oriented emotion. Implications for the design of embodied computer agents are discussed and directions for future research suggested.},
author = {Brave, Scott and Nass, Clifford and Hutchinson, Kevin},
doi = {10.1016/j.ijhcs.2004.11.002},
file = {::},
issn = {10715819},
journal = {International Journal of Human-Computer Studies - Special issue: Subtle expressivity for characters and robots},
keywords = {affective computing,characters,embodied agents,emotion,empathy,social interfaces},
month = feb,
number = {2},
pages = {161--178},
title = {{Computers that care: investigating the effects of orientation of emotion exhibited by an embodied computer agent}},
url = {http://www.sciencedirect.com/science/article/pii/S1071581904001284},
volume = {62},
year = {2005}
}
@article{Gratch2004,
author = {Gratch, Jonathan and Marsella, Stacy C},
file = {::;::},
journal = {Cognitive Systems Research},
number = {4},
pages = {269--306},
publisher = {Elsevier},
title = {{A domain-independent framework for modeling emotion}},
volume = {5},
year = {2004}
}
@article{Cohn2004,
abstract = {The diaries of 1,084 U.S. users of an on-line journaling service were downloaded for a period of 4 months spanning the 2 months prior to and after the September 11 attacks. Linguistic analyses of the journal entries revealed pronounced psychological changes in response to the attacks. In the short term, participants expressed more negative emotions, were more cognitively and socially engaged, and wrote with greater psychological distance. After 2 weeks, their moods and social referencing returned to baseline, and their use of cognitive-analytic words dropped below baseline. Over the next 6 weeks, social referencing decreased, and psychological distancing remained elevated relative to baseline. Although the effects were generally stronger for individuals highly preoccupied with September 11, even participants who hardly wrote about the events showed comparable language changes. This study bypasses many of the methodological obstacles of trauma research and provides a fine-grained analysis of the time line of human coping with upheaval.},
author = {Cohn, Michael A and Mehl, Matthias R and Pennebaker, James W},
institution = {University of Michigan, USA.},
journal = {Psychological Science},
keywords = {adaptation,adult,affect,cognition,female,humans,linguistics,male,psychological,terrorism},
number = {10},
pages = {687--693},
pmid = {15447640},
publisher = {SAGE Publications},
title = {{Linguistic markers of psychological change surrounding September 11, 2001.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15447640},
volume = {15},
year = {2004}
}
@inproceedings{Pontier2008,
abstract = {Previous research indicates that self-help therapy is an effective method to prevent and treat unipolar depression. While web-based self-help therapy has many advantages, there are also disadvantages to self-help therapy, such as that it misses the possibility to regard the body language of the user, and the lack of personal feedback on the user responses. This study presents a virtual agent that guides the user through the Beck Depression Inventory (BDI) questionnaire, which is used to measure the severity of depression. The agent responds empathically to the answers given by the user, by changing its facial expression. This resembles face to face therapy more than existing web-based self-help therapies. A pilot experiment indicates that the virtual agent has added value for this application.},
author = {Pontier, Matthijs and Siddiqui, Ghazanfar F},
booktitle = {Proceedings of the 8th international conference on Intelligent Virtual Agents (IVA)},
doi = {10.1007/978-3-540-85483-8\_42},
editor = {{H. Prendinger, J. Lester}, and M. Ishizuka},
file = {::},
keywords = {Emotion modeling,Self-help therapy,Virtual agent},
pages = {417--425},
publisher = {Springer-Verlag Berlin Heidelberg},
title = {{A Virtual Therapist That Responds Empathically to Your Answers}},
year = {2008}
}
@article{Rodrigues2009,
author = {Rodrigues, SH and Mascarenhas, SF},
file = {::},
isbn = {9781424447992},
journal = {and Workshops, 2009},
title = {{“ I can feel it too !”: Emergent empathic reactions between synthetic characters}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5349570},
year = {2009}
}
@article{Cai2006,
abstract = {Empathic computing is an emergent paradigm that enables a system to understand human states and feelings and to share this intimate information. The new paradigm is made possible by the convergence of affordable sensors, embedded processors and wireless ad-hoc networks. The power law for multi-resolution channels and mobile-stationary sensor webs is introduced to resolve the information avalanche problems. As empathic computing is sensor-rich computing, particular models such as semantic differential expressions and inverse physics are discussed. A case study of a wearable sensor network for detection of a falling event is presented. It is found that the location of the wearable sensor is sensitive to the results. From the machine learning algorithm, the accuracy reaches up to 90\% from 21 simulated trials. Empathic computing is not limited to healthcare. It can also be applied to solve other everyday-life problems such as management of emails and stress.},
author = {Cai, Yang},
doi = {10.1007/11825890\_3},
file = {::},
journal = {Ambient Intelligence in Everyday Life, Lecture Notes in Computer Science},
pages = {67--85},
publisher = {Springer},
title = {{Empathic computing}},
url = {http://www.springerlink.com/index/l482m128476w5043.pdf},
volume = {3864/2006},
year = {2006}
}
@inproceedings{Johnson2004,
abstract = {Embodied conversational agents (ECA) have potential as facilitators for health interventions. However, their utility is limited as long as people must sit down in front of a computer to access them. This paper describes a project that is deploying an ECA on a handheld computer, and using it to assist in a psychosocial intervention aimed at providing training in problem solving skills. The agent is based upon the virtual trainer/counselor in the pedagogical drama Carmen’s Bright IDEAS, adapted for handheld use and for interaction with a human caregiver. The system will go into clinical trails in August of 2004. The paper discusses the design and technical issues involved in the transition from laptop computer to handheld device and from 3rd-person view to first-person interaction, and the plan for evaluation. The clinical trial is designed both to evaluate psychosocial outcomes and to assess user preferences in ECA interaction modalities over the course of multiple sessions of use.},
author = {Johnson, WL and LaBore, C},
booktitle = {AAAI Fall Symposium on Dialogue Systems for Health Communication},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Johnson, LaBore, Chiu - 2004 - A pedagogical agent for psychosocial intervention on a handheld computer(4).pdf:pdf},
pages = {22--24},
title = {{A pedagogical agent for psychosocial intervention on a handheld computer}},
year = {2004}
}
@article{Kaliouby2005,
author = {Kaliouby, R. and Robinson, Peter},
file = {::},
journal = {Real-time vision for human-computer interaction},
pages = {181--200},
publisher = {Springer},
title = {{Real-time inference of complex mental states from facial expressions and head gestures}},
url = {http://www.springerlink.com/index/K822871338R66039.pdf},
year = {2005}
}
@inproceedings{Gordon1985,
abstract = {Despite the almost complete lack of research addressing a theoretical understanding of empathy or ways to increase human empathy, empathy is a central component of effective human communication. Seen as a key social science phenomenon, it is viewed, along with power, as an inextricable component of human dynamics, and, in its relationship with altruism, possibly plays a causal role. A problem with research on empathy has been a lack of conceptual clarity. Three ways to improve empathetic listening are to avoid judgment, give the speaker time to speak without interruption, and focus on the speaker. Many of the helping professions have attempted training programs aimed at increasing the empathetic communication skills of practitioners in these fields. However, being told to listen empathetically is not the same as being taught to listen with empathy; and in critique of the empathy skills programs that are conducted within the helping professions, a significantly raised test score does not mean that empathy has been attained. Although empathetic communication is a complex subject matter, skills associated with empathy and active listening have been perceived as being more important than skills associated with critical or deliberative listening.},
address = {Baguio, Philippines},
annote = {Three ways to improve empathetic listening are to 
1.      Avoid judgment: the empathetic communicator must avoid making comparisons or passing moral judgments. 
2.      Give the speaker time to speak without interruption 
3.      Focus on the speaker: the empathetic communicator needs to focus his or her attention on the speaker, and not distract from this focus by verbally calling undue attention to oneself or one’s own situation [14]. },
author = {Gordon, Ronald D.},
booktitle = {International Conference of the World Communication Association},
file = {::},
keywords = {Communication (thought transfer),empathhy,interpersonal communication,listening,listening habits,listening skills,speech communication},
pages = {1--16},
title = {{Empathy: The State of the Art and Science}},
year = {1985}
}
@article{Stockwell1994,
abstract = {The concept of the Alcohol Dependence Syndrome has been influential in the field of alcohol studies in the 1980s. The Severity of Alcohol Dependence Questionnaire (SADQ) is one of a generation of alcohol problem scales developed to measure degree of dependence rather than presence or absence of 'alcoholism'. This paper describes the development of a form of the SADQ for community samples of drinkers (SADQ-C) and its relationship to a brief scale designed to measure impaired control over drinking. In a sample of 52 problem drinkers, SADQ and SADQ-C correlated almost perfectly (r = 0.98). In a larger sample of 197 attenders at a controlled drinking clinic, Principal Components Analysis revealed one major factor accounting for 71.7\% of the total variance. High internal reliability was indicated with a Cronbach's Alpha of 0.98. Application of this instrument in a random survey of Western Australian households is then described. It was necessary to remove items relating to 'reinstatement of dependence' for this sample. A single major factor was identified by principal components analysis, accounting for 69.1\% of the total variance. In both the clinic and the community samples SADQ-C scores correlated highly with Impairment of Control scores. The findings are interpreted as supporting the view that there is a single dimension of alcohol dependence upon which all persons who drink alcohol with any regularity may be located.},
author = {Stockwell, T and Sitharthan, T and McGrath, D and Lang, E},
institution = {National Centre for Research into the Prevention of Drug Abuse, Curtin University of Technology, Perth, Western Australia.},
journal = {Addiction Abingdon England},
keywords = {adolescent,adult,aged,alcohol drinking,alcohol drinking adverse effects,alcohol drinking epidemiology,alcohol drinking psychology,alcoholism,alcoholism classification,alcoholism diagnosis,alcoholism epidemiology,alcoholism psychology,cross sectional studies,female,humans,incidence,internal external control,male,middle aged,psychometrics,reproducibility results,substance withdrawal syndrome,substance withdrawal syndrome classification,substance withdrawal syndrome diagnosis,substance withdrawal syndrome epidemiology,substance withdrawal syndrome psychology,western australia,western australia epidemiology},
number = {2},
pages = {167--174},
pmid = {8173482},
title = {{The measurement of alcohol dependence and impaired control in community samples.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8173482},
volume = {89},
year = {1994}
}
@article{Picard2001,
author = {Picard, Rosalind W and Vyzas, E. and Healey, J.},
doi = {10.1109/34.954607},
file = {::},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {10},
pages = {1175--1191},
title = {{Toward machine emotional intelligence: analysis of affective physiological state}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=954607},
volume = {23},
year = {2001}
}
@book{Fogg2003,
abstract = {Can computers change what you think and do? Can they motivate you to stop smoking, persuade you to buy insurance, or convince you to join the Army? "Yes, they can," says Dr. B.J. Fogg, director of the Persuasive Technology Lab at Stanford University. Fogg has coined the phrase "Captology"(an acronym for computers as persuasive technologies) to capture the domain of research, design, and applications of persuasive computers.In this thought-provoking book, based on nine years of research in captology, Dr. Fogg reveals how Web sites, software applications, and mobile devices can be used to change people's attitudes and behavior. Technology designers, marketers, researchers, consumersanyone who wants to leverage or simply understand the persuasive power of interactive technologywill appreciate the compelling insights and illuminating examples found inside. Persuasive technology can be controversialand it should be. Who will wield this power of digital influence? And to what end? Now is the time to survey the issues and explore the principles of persuasive technology, and B.J. Fogg has written this book to be your guide. Filled with key term definitions in persuasive computingProvides frameworks for understanding this domainDescribes real examples of persuasive technologies},
author = {Fogg, B J},
booktitle = {Persuasive Technology Using Computers to Change What We Think and Do},
doi = {10.4017/gt.2006.05.01.009.00},
editor = {Kort, Yvonne and IJsselsteijn, Wijnand and Midden, Cees and Eggen, Berry and Fogg, B J},
file = {::},
isbn = {1558606432},
issn = {15691101},
number = {1},
pages = {283},
publisher = {Morgan Kaufmann},
series = {The Morgan Kaufmann series in interactive technologies},
title = {{Persuasive Technology: Using Computers to Change What We Think and Do}},
url = {http://books.google.com/books?id=r9JIkNjjTfEC\&pgis=1},
volume = {5},
year = {2003}
}
@misc{ncbde,
title = {{National Certification Board of Diabetes Educators. http://www.ncbde.org}}
}
@article{Wu2008,
author = {Wu, Siew-Rong},
doi = {10.1109/DIGITEL.2008.27},
file = {::},
isbn = {978-0-7695-3409-1},
journal = {2008 Second IEEE International Conference on Digital Game and Intelligent Toy Enhanced Learning},
pages = {213--214},
publisher = {Ieee},
title = {{Humor and Empathy: Developing Students' Empathy through Teaching Robots to Tell English Jokes}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4700764},
year = {2008}
}
@book{Ziegel2000,
address = {Cary, NC, USA},
author = {Ziegel, Eric R. and Stokes, M. and Davis, C. and Koch, G.},
booktitle = {Technometrics},
doi = {10.2307/1271334},
edition = {Second Edi},
file = {::},
isbn = {1580257100},
issn = {00401706},
month = nov,
number = {4},
pages = {413},
publisher = {SAS Institute Inc.},
title = {{Categorical Data Analysis Using the SAS System}},
url = {http://www.jstor.org/stable/1271334?origin=crossref},
volume = {38},
year = {2000}
}
@misc{TheMendeleySupportTeam2011,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/The Mendeley Support Team - 2011 - Getting Started with Mendeley(4).pdf:pdf},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@inproceedings{Paiva2004,
address = {Washington, DC, USA},
author = {Paiva, Ana and Dias, J. and Sobral, Daniel and Aylett, Ruth},
booktitle = {AAMAS '04 Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems},
doi = {10.1109/AAMAS.2004.82},
file = {::},
isbn = {1581138644},
pages = {194--201},
publisher = {IEEE Computer Society},
title = {{Caring for agents and agents that care: Building empathic relations with synthetic agents}},
url = {http://dl.acm.org/citation.cfm?id=1018754 http://dx.doi.org/10.1109/AAMAS.2004.82},
year = {2004}
}
@article{Ochs2010,
author = {Ochs, Magalie and Sadek, David and Pelachaud, Catherine},
doi = {10.1007/s10458-010-9156-z},
file = {::},
issn = {1387-2532},
journal = {Autonomous Agents and Multi-Agent Systems},
keywords = {affective computing,dialog,emotions,empathy,rational dialog agent},
month = nov,
title = {{A formal model of emotions for an empathic rational dialog agent}},
url = {http://www.springerlink.com/index/10.1007/s10458-010-9156-z},
year = {2010}
}
@book{Ekman1978,
author = {Ekman, Paul and Freisen, Wallace V.},
booktitle = {Consulting Psychologists Press 1978},
editor = {Press, Consulting Psychologists},
publisher = {Consulting Psychologists Press},
title = {{Facial Action Coding System: A Technique for the Measurement of Facial Movement}},
year = {1978}
}
@article{Jacob2011,
author = {Jacob, Pierre},
doi = {10.1007/s13164-011-0065-0},
file = {::},
issn = {1878-5158},
journal = {Review of Philosophy and Psychology},
month = aug,
number = {August},
pages = {519--540},
title = {{The Direct-Perception Model of Empathy: a Critique}},
url = {http://www.springerlink.com/index/10.1007/s13164-011-0065-0},
year = {2011}
}
@inproceedings{Bransky2011,
abstract = {To understand the role that memory plays we have collected data from three online experimental sessions in which participants inter- act with our virtual real-estate agent in both a recall and forget mode. We found that partial forgetting and even total loss of recall of an item, whether domain or social-based, was more believable and less frustrating than incorrect recall.},
author = {Bransky, Karla and Richards, Debbie},
booktitle = {Intelligent Virtual Agents 10th International Conference (IVA 2011)},
doi = {10.1007/978-3-642-23974-8\_49},
file = {::},
keywords = {forget-,intelligent virtual agents,memory,remembering},
pages = {433--434},
publisher = {Springer-Verlag Berlin Heidelberg},
title = {{Users ’ s Expectations of IVA Recall and Forgetting}},
year = {2011}
}
@article{Kiene2006,
abstract = {One objective of translational science is to identify elements of human immunodeficiency virus (HIV) risk-reduction interventions that have been shown to be effective and find new ways of delivering these interventions to the community to ensure that they reach the widest possible audience of at-risk individuals. The current study reports the development and evaluation of a computer-delivered, theory-based, individually tailored HIV risk-reduction intervention.},
author = {Kiene, Susan M and Barta, William D},
doi = {10.1016/j.jadohealth.2005.12.029},
file = {:X$\backslash$:/Papers/CBIs/nihms163605.pdf:pdf},
issn = {1879-1972},
journal = {The Journal of adolescent health : official publication of the Society for Adolescent Medicine},
keywords = {Acquired Immunodeficiency Syndrome,Acquired Immunodeficiency Syndrome: prevention \& c,Adolescent,Adult,Analysis of Variance,Computers,Condoms,Condoms: utilization,Female,HIV Infections,HIV Infections: prevention \& control,Health Education,Health Education: methods,Humans,Male,Motivation,Risk Assessment,Risk Reduction Behavior},
month = sep,
number = {3},
pages = {404--10},
pmid = {16919803},
title = {{A brief individualized computer-delivered sexual risk reduction intervention increases HIV/AIDS preventive behavior.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16919803},
volume = {39},
year = {2006}
}
@inproceedings{Hyun2007,
author = {Hyun, KH and Kim, EH},
booktitle = {16th IEEE International Conference on Robot \& Human Interactive Communication},
file = {::},
isbn = {9781424416356},
pages = {802--806},
title = {{Emotional feature extraction based on phoneme information for speech emotion recognition}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4415195},
year = {2007}
}
@book{Fussell2002,
author = {Fussell, S.R.},
file = {::},
isbn = {0805836896},
publisher = {Lawrence Erlbaum},
title = {{The verbal communication of emotions: Interdisciplinary perspectives}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=p3M13y2yfwMC\&amp;oi=fnd\&amp;pg=PP1\&amp;dq=The+Verbal+Communication+of+Emotions\&amp;ots=btc4zGRJN4\&amp;sig=16kr5bEkJhKg\_zO6ond9vkI4uLY},
year = {2002}
}
@article{Riek2009,
author = {Riek, Laurel D. and Paul, Philip C. and Robinson, Peter},
doi = {10.1007/s12193-009-0028-2},
file = {::},
issn = {1783-7677},
journal = {Journal on Multimodal User Interfaces},
keywords = {19,affective computing,emotionally conveying,empathy,expressions,facial,forms of expressive empathy,human-robot interaction,is known as,of the most basic,one,social robotics,understand what others are},
month = nov,
number = {1-2},
pages = {99--108},
title = {{When my robot smiles at me: Enabling human-robot rapport via real-time head gesture mimicry}},
url = {http://www.springerlink.com/index/10.1007/s12193-009-0028-2},
volume = {3},
year = {2009}
}
@article{Paiva2005,
author = {Paiva, Ana and Dias, Jo\~{a}o and Sobral, Daniel and Aylett, Ruth and Woods, Sarah and Hall, Lynne and Zoll, Carsten},
doi = {10.1080/08839510590910165},
file = {::},
issn = {0883-9514},
journal = {Applied Artificial Intelligence},
month = mar,
number = {3-4},
pages = {235--266},
title = {{Learning By Feeling: Evoking Empathy With Synthetic Characters}},
url = {http://www.tandfonline.com/doi/abs/10.1080/08839510590910165},
volume = {19},
year = {2005}
}
@article{Beck1981,
author = {Beck, K H and Lund, A K},
journal = {Journal of Applied Social Psychology},
number = {5},
pages = {401--415},
title = {{The Effects of Health Threat Seriousness and Personal Efficacy upon Intentions and Behavior}},
volume = {11},
year = {1981}
}
@article{Southard1918,
author = {Southard, E E},
journal = {The Journal of Abnormal Psychology},
number = {4},
pages = {199},
publisher = {American Psychological Association},
title = {{The empathic index in the diagnosis of mental diseases.}},
volume = {13},
year = {1918}
}
@inproceedings{Hand2008,
author = {Hand, Stacey and Varan, Duane},
booktitle = {Changing Television Environments},
file = {::},
pages = {11--19},
publisher = {Springer},
title = {{Interactive Narratives: Exploring the Links between Empathy, Interactivity and Structure}},
url = {http://www.springerlink.com/index/15385726247gu863.pdf},
year = {2008}
}
@inproceedings{Nguyen2009,
abstract = {Experiencing emotional distress is the number one reason why people who are undergoing behaviour modification (e.g. quitting smoking, dieting) suffer from relapses. Providing emotional support is an effective way to help them overcome the unpleasant effects of negative affect and adhere to their regimen. Building computers with such ability has grabbed the attention of the HCI community in recent years. This paper presents the results of a 2 (modality: animated vs. no visual) by 3 (intervention: non-empathy vs. empathy vs. empathy and expressivity) between-subjects study that investigates the impact of two important factors and their interaction in the design of such systems: (1) different ways of expressing empathy, and (2) the modality of delivering such content.},
address = {Claremont, California, USA},
annote = {They investigate: 
1-      Different ways of expressing empathy 
2-      Modality of delivering such content. 
        
They define empathy as the ability to detect what others feel and to experience that emotion ourselves (seems like mimicry).
        
Empirical evidence indicates that expressing accurate empathy can lead to positive psychological, physical and health outcomes.
        
Their results show: 
1. The positive attitude of the users toward active support (active empathy). 
2.  The positive outcome of an empathic system regardless of its representation. 
3.  A system represented by a human-like representation is expected to be empathic.
        
they believe, adding a mechanism to allow the users to freely express themselves does not improve the effectiveness or liking of an empathic system.
      },
author = {Nguyen, H. and Masthoff, Judith},
booktitle = {Proceedings of the 4th International Conference on Persuasive Technology (Persuasive’09)},
file = {::},
isbn = {9781605583761},
keywords = {affective computing,design,experimentation,human factors},
publisher = {ACM},
title = {{Designing empathic computers: the effect of multimodal empathic feedback using animated agent}},
year = {2009}
}
@article{Heylen2005,
abstract = {When involved in face-to-face conversations, people move their heads in typical ways. The pattern of head gestures and their function in conversation has been studied in various disciplines. Many factors are involved in determining the exact patterns that occur in conversation. These can be explained by considering some of the basic properties of face-to-face interactions. The fact that conversations are a type of joint activity involving social actions together with a few other properties, such as the need for grounding, can explain the variety in functions that are served by the multitude of movements that people display during conversations.},
author = {Heylen, Dirk},
editor = {Halle, L and Wallis, P and Woods, S and Marsella, S and Pelachaud, C and Heylen, Dirk},
isbn = {1902956492},
journal = {Source},
pages = {45--52},
publisher = {The Society for the Study of Artificial Intelligence and the Simulation of Behaviour},
title = {{Challenges Ahead Head movements and other social acts in conversations}},
url = {http://www.aisb.org.uk/publications/proceedings/aisb05/10\_Virt\_Final.pdf},
year = {2005}
}
@inproceedings{Samsonovich2006,
abstract = {The notion of a human value system can be quantified as a cognitive map, the dimensions of which capture the semantics of concepts and the associated values. This can be done, if one knows (i) how to define the dimensions of the map, and (ii) how to allocate concepts in those dimensions. Regarding the first question, experimental studies with linguistic material using psychometrics have revealed that valence, arousal and dominance are primary dimensions characterizing human values. The same or similar dimensions are used in popular models of emotions and affects. In these studies, the choice of principal dimensions, as well as scoring concepts, was based on subjective reports or psycho-physiological measurements. Can a cognitive map of human values be constructed without testing human subjects? Here we show that the answer is positive, using generally available dictionaries of synonyms and antonyms. By applying a simple statistical-mechanic model to English and French dictionaries, we constructed multidimensional cognitive maps that capture the semantics of words. We calculated the principal dimensions of the resultant maps and found their semantics consistent across two languages as well as with previously known main cognitive dimensions. These results suggest that the linguistically derived cognitive map of the human value system is language-invariant and, being closely related to psychometrically derived maps, is likely to reflect fundamental aspects of the human mind.},
author = {Samsonovich, A V and Ascoli, G A},
booktitle = {Proc AGI Workship Advances in Artificial General Intelligence Concepts Architectures and Algorithms},
pages = {111--124},
title = {{Cognitive map dimensions of the human value system extracted from natural language}},
year = {2006}
}
@article{O'Keefe1988,
abstract = {Offers models of 3 alternative message design logics and describes a general method of message analysis based on these models. The method of analysis is exemplified in a study of messages used in addressing a regulative communication task. 92 undergraduates were asked to provide messages they would address to a subordinate who failed to complete assigned work; these messages were classified in terms of the kind of goal set being pursued and the kind of reasoning reflected in their design. Male and female Ss differed systematically in the message design logic they employed, and there were significant relationships between interpersonal construct differentiation and message design logic and goal structure. ((c) 1997 APA/PsycINFO, all rights reserved)},
author = {O'Keefe, Barbara J},
journal = {Communication Monographs},
number = {1},
pages = {80--103},
title = {{The logic of message design: Individual differences in reasoning about communication}},
volume = {55},
year = {1988}
}
@article{Portnoy2008,
abstract = {The use of computers to promote healthy behavior is increasing. To evaluate the efficacy of these computer-delivered interventions, we conducted a meta-analysis of the published literature.},
author = {Portnoy, David B and Scott-Sheldon, Lori a J and Johnson, Blair T and Carey, Michael P},
doi = {10.1016/j.ypmed.2008.02.014},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Portnoy et al. - 2008 - Computer-delivered interventions for health promotion and behavioral risk reduction a meta-analysis of 75 randomized controlled trials, 1988-2007.pdf:pdf},
issn = {0091-7435},
journal = {Preventive medicine},
keywords = {Computers,Health Behavior,Health Education,Health Promotion,Humans,Randomized Controlled Trials as Topic,Risk Reduction Behavior},
month = jul,
number = {1},
pages = {3--16},
pmid = {18403003},
title = {{Computer-delivered interventions for health promotion and behavioral risk reduction: a meta-analysis of 75 randomized controlled trials, 1988-2007.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2572996\&tool=pmcentrez\&rendertype=abstract},
volume = {47},
year = {2008}
}
@inproceedings{Cairco2009,
abstract = {Avari is a virtual receptionist for the Computer Science department at The University of North Carolina at Charlotte. Her components include background subtraction to detect a person’s presence, speech recognition, audio and visual devices to communicate with passersby. Deployed in a public setting, we investigate the reactions and interactions of passersby with Avari. We describe the design and architecture of the virtual human and discuss the effectiveness of a publicly deployed virtual human.},
address = {Clemson, SC, USA.},
author = {Cairco, Lauren and Hill, Rock and Wilson, Dale-marie and Fowler, Vicky and Leblanc, Morris},
booktitle = {48th ACM Southeast Conference (ACMSE'09)},
file = {::},
isbn = {9781605584218},
keywords = {human-centered,human-computer interaction,virtual humans},
pages = {1--6},
title = {{AVARI : Animated Virtual Agent Retrieving Information}},
year = {2009}
}
@misc{Gordon1985,
annote = {Three ways to improve empathetic listening are to 
1.      Avoid judgment: the empathetic communicator must avoid making comparisons or passing moral judgments. 
2.      Give the speaker time to speak without interruption 
3.      Focus on the speaker: the empathetic communicator needs to focus his or her attention on the speaker, and not distract from this focus by verbally calling undue attention to oneself or one’s own situation [14]. },
author = {Gordon, Ronald D.},
file = {::},
pages = {1--16},
title = {{Empathy- The State of the Art and Science.pdf}},
year = {1985}
}
@article{Chartrand1999,
abstract = {The chameleon effect refers to nonconscious mimicry of the postures, mannerisms, facial expressions, and other behaviors of one's interaction partners, such that one's behavior passively and unintentionally changes to match that of others in one's current social environment. The authors suggest that the mechanism involved is the perception-behavior link, the recently documented finding (e.g., J. A. Bargh, M. Chen, \& L. Burrows, 1996) that the mere perception of another's behavior automatically increases the likelihood of engaging in that behavior oneself. Experiment 1 showed that the motor behavior of participants unintentionally matched that of strangers with whom they worked on a task. Experiment 2 had confederates mimic the posture and movements of participants and showed that mimicry facilitates the smoothness of interactions and increases liking between interaction partners. Experiment 3 showed that dispositionally empathic individuals exhibit the chameleon effect to a greater extent than do other people.},
author = {Chartrand, T. L. and Bargh, J a},
file = {::},
issn = {0022-3514},
journal = {Journal of personality and social psychology},
keywords = {Analysis of Variance,Empathy,Facial Expression,Female,Group Processes,Humans,Imitative Behavior,Interpersonal Relations,Male,Models,Multivariate Analysis,New York City,Posture,Psychological,Social Behavior,Social Perception},
month = jun,
number = {6},
pages = {893--910},
pmid = {10402679},
title = {{The chameleon effect: the perception-behavior link and social interaction.}},
volume = {76},
year = {1999}
}
@book{Fussell2002,
author = {Fussell, Susan R.},
editor = {Fussell, Susan R.},
file = {::},
isbn = {9780805836905},
pages = {294},
publisher = {Lawrence Erlbaum Associates},
title = {{The verbal communication of emotions: Interdisciplinary perspectives}},
url = {http://books.google.com/books?id=MHea6DYYfEgC},
year = {2002}
}
@inproceedings{Kumano2011,
author = {Kumano, Shiro and Otsuka, Kazuhiro and Mikami, Dan and Yamato, Junji},
booktitle = {Automatic Face \& Gesture Recognition and Workshops (FG 2011), 2011 IEEE International Conference on},
file = {::},
pages = {43--50},
publisher = {IEEE},
title = {{Analyzing empathetic interactions based on the probabilistic modeling of the co-occurrence patterns of facial expressions in group meetings}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5771440},
year = {2011}
}
@article{Rameson2009,
author = {Rameson, Lian T. and Lieberman, Matthew D.},
doi = {10.1111/j.1751-9004.2008.00154.x},
file = {::},
issn = {17519004},
journal = {Social and Personality Psychology Compass},
month = jan,
number = {1},
pages = {94--110},
title = {{Empathy: A Social Cognitive Neuroscience Approach}},
url = {http://doi.wiley.com/10.1111/j.1751-9004.2008.00154.x},
volume = {3},
year = {2009}
}
@inproceedings{Johnson2007,
abstract = {Any new tool validated. introduced for education needs to be We developed a virtual human experience called the Virtual Objective Structured Clinical Examination (VOSCE). In the VOSCE, a medical student examines a life-size virtual human who is presenting symptoms of an illness. The student is then graded on interview skills. As part of a medical school class requirement, thirty three second year medical students participated in a user study designed to determine the validity of the VOSCE for testing interview skills. In the study, participant performance in the VOSCE is compared to participant performance in the OSCE, an interview with a trained actor. There was a significant correlation (r(33)=.49, p<.005) between overall score in the VOSCE and overall score in the OSCE. This means that the interaction skills used with a virtual human translate to the interaction skills used with a real human. Comparing the experience of virtual human interaction to real human interaction is the critical validation step towards using virtual humans for interpersonal skills education.},
address = {San Jose, California, USA},
author = {Johnsen, Kyle and Raij, Andrew and Stevens, Amy and Lind, D Scott and Lok, Benjamin},
booktitle = {CHI 2007 Proceedings of Learning \& Education},
file = {::},
isbn = {9781595935939},
keywords = {medicine,multimodal interfaces.,validation,virtual characters,virtual humans,virtual reality},
pages = {1049--1058},
publisher = {ACM},
title = {{The Validity of a Virtual Human Experience for Interpersonal Skills Education}},
year = {2007}
}
@article{Kaliouby2005,
author = {Kaliouby, R. and Robinson, Peter},
file = {::},
journal = {Real-time vision for human-computer interaction},
pages = {181--200},
publisher = {Springer},
title = {{Real-time inference of complex mental states from facial expressions and head gestures}},
url = {http://www.springerlink.com/index/K822871338R66039.pdf},
year = {2005}
}
@article{Albrecht2005,
author = {Albrecht, Irene and Schr\"{o}der, Marc and Haber, J\"{o}rg and Seidel, Hans-Peter},
doi = {10.1007/s10055-005-0153-5},
file = {::},
issn = {1359-4338},
journal = {Virtual Reality},
keywords = {continuous emotions \ae emotional,speech,synthesis \ae facial animation},
month = aug,
number = {4},
pages = {201--212},
title = {{Mixed feelings: expression of non-basic emotions in a muscle-based talking head}},
url = {http://www.springerlink.com/index/10.1007/s10055-005-0153-5},
volume = {8},
year = {2005}
}
@inproceedings{McQuiggan2008,
abstract = {Humans continuously assess one another’s situational context, modify their own affective state, and then respond based on these outcomes through empathetic expression. Virtual agents should be capable of similarly empathizing with users in interactive environments. A key challenge posed by empathetic reasoning in virtual agents is determining whether to respond with parallel or reactive empathy. Parallel empathy refers to mere replication of another’s affective state, whereas reactive empathy exhibits greater cognitive awareness and may lead to incongruent emotional responses (i.e., emotions different from the recipient’s and perhaps intended to alter negative affect). This paper proposes a unified inductive framework for modeling parallel and reactive empathy. Empathy models are used to drive runtime situation-appropriate empathetic behaviors by selecting suitable parallel or reactive empathetic expressions.},
annote = {- No automatic affect detection
- agent demographics are not taken into account.},
author = {McQuiggan, Scott W and Robison, Jennifer and Phillips, Robert},
booktitle = {on Autonomous agents},
file = {::},
number = {Aamas},
pages = {167--174},
title = {{Modeling parallel and reactive empathy in virtual agents: An inductive approach}},
year = {2008}
}
@article{Shimoda2000,
author = {Shimoda, H. and Kunihiro, T. and Yang, D. and Yoshikawa, H.},
doi = {10.1109/IECON.2000.972406},
file = {::},
isbn = {0-7803-6456-2},
journal = {2000 26th Annual Conference of the IEEE Industrial Electronics Society. IECON 2000. 2000 IEEE International Conference on Industrial Electronics, Control and Instrumentation. 21st Century Technologies and Industrial Opportunities (Cat. No.00CH37141)},
pages = {2589--2594},
publisher = {Ieee},
title = {{Design of affective interface for realizing human-machine empathy}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=972406},
volume = {4},
year = {2000}
}
@book{Hojat2007a,
author = {Hojat, M.},
booktitle = {Patient Care},
file = {::},
isbn = {9780387336077},
publisher = {Springer Verlag},
title = {{Empathy in patient care: antecedents, development, measurement, and outcomes}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=OZT1sypBp5EC\&amp;oi=fnd\&amp;pg=PR7\&amp;dq=Empathy+In+Patient+Care:+Antecedents,+Development,+Measurements,+and+Outcomes\&amp;ots=8aQbxTclHN\&amp;sig=HFiEPtCVpFvXI6HU3rprIwvHGXc},
year = {2007}
}
@article{Friesen1983,
author = {Friesen, Wallace V and Ekman, Paul},
journal = {Unpublished manuscript, University of California at San Francisco},
publisher = {University of California},
title = {{EMFACS-7: Emotional Facial Action Coding System}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:EMFACS-7:+Emotional+Facial+Action+Coding+System\#0},
year = {1983}
}
@article{Riper2008,
abstract = {Self-help interventions for adult problem drinkers in the general population have proved effective. The question is whether this also holds for self-help interventions delivered over the internet.},
author = {Riper, Heleen and Kramer, Jeannet and Smit, Filip and Conijn, Barbara and Schippers, Gerard and Cuijpers, Pim},
doi = {10.1111/j.1360-0443.2007.02063.x},
file = {::},
issn = {0965-2140},
journal = {Addiction (Abingdon, England)},
keywords = {Adolescent,Adult,Aged,Alcohol Drinking,Alcohol Drinking: epidemiology,Alcohol Drinking: prevention \& control,Alcohol Drinking: psychology,Cognitive Therapy,Cognitive Therapy: methods,Female,Humans,Internet,Male,Middle Aged,Patient Acceptance of Health Care,Patient Acceptance of Health Care: psychology,Self Care,Self Care: methods,Statistics as Topic,Treatment Outcome},
month = feb,
number = {2},
pages = {218--27},
pmid = {18199300},
title = {{Web-based self-help for problem drinkers: a pragmatic randomized trial.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18199300},
volume = {103},
year = {2008}
}
@article{Liu2008,
author = {Liu, Zhen},
file = {::},
journal = {InTech Education and Publishing},
title = {{Computational Emotion Model for Virtual Characters}},
url = {http://www.intechopen.com/source/pdfs/5186/InTech-Computational\_emotion\_model\_for\_virtual\_characters.pdf},
year = {2008}
}
@article{Bestgen1994,
abstract = {In spite of the growing interest witnessed in the study of the relationship between emotion and language, the determination of the emotional valence of sentences, paragraphs or texts has so far attracted little attention. To bridge this gap, a technique based on the emotional aspect of words is presented. In this preliminary study, we have compared the affective tones of the sentences of four texts as perceived by readers, to the values generated by the words that compose the texts. The results support the psychological reality of the affective tones of linguistic units larger than a word, and the possibility of their evaluation through the lexical information. Such information should be useful for studying the role of emotional interest on text processing and for the analysis of the natural stories produced by people in reaction to stressful events.},
author = {Bestgen, Yves},
doi = {10.1080/02699939408408926},
issn = {02699931},
journal = {Cognition \& Emotion},
number = {1},
pages = {21--36},
title = {{Can emotional valence in stories be determined from words?}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/02699939408408926\&magic=crossref},
volume = {8},
year = {1994}
}
@article{Orozco2010,
author = {Orozco, H. and Thalmann, Daniel and Ramos, F.},
file = {::},
journal = {Proceedings of 11th Computer Graphics International, CGI},
title = {{Making empathetic virtual humans in human–computer interaction scenarios}},
url = {http://cgi2010.miralab.unige.ch/short/SP09/SP09.pdf},
volume = {10},
year = {2010}
}
@article{Tom1991,
abstract = {Reasoning that nodding head movements up and down serve a mnemesic function of positive thoughts and feelings and shaking head movements from side to side serve a mnemesic function of negative thoughts and feelings, this study determined that nodding head movements resulted in the establishment of increased preference for a neutral object, whereas shaking head movements lead to a decline in preference for the neutral object. The findings suggest that overt head movement is instrumental in the formation of preference and focuses attention on the importance of the somatic component of attitude.},
author = {Tom, Gail and Pettersen, Paul and Lau, Teresa and Burton, Trevor and Cook, Jim},
doi = {10.1207/s15324834basp1203\_3},
issn = {01973533},
journal = {Basic and Applied Social Psychology},
number = {3},
pages = {281--289},
publisher = {Psychology Press},
title = {{The Role of Overt Head Movement in the Formation of Affect}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1207/s15324834basp1203\_3\&magic=crossref},
volume = {12},
year = {1991}
}
@inproceedings{Fabri2007,
abstract = {We present our work on emotionally expressive avatars, animated virtual characters that can express emotions via facial expressions. Because these avatars are highly distinctive and easily recognizable, they may be used in a range of applications. In the first part of the paper we present their use in computer mediated communication where two or more people meet in virtual space, each represented by an avatar. Study results suggest that social interaction behavior from the real-world is readily transferred to the virtual world. Empathy is identified as a key component for creating a more enjoyable experience and greater harmony between users. In the second part of the paper we discuss the use of avatars as an assistive, educational and therapeutic technology for people with autism. Based on the results of a preliminary study, we provide pointers regarding how people with autism may overcome some of the limitations that characterize their condition.},
address = {Beijing, China},
author = {Fabri, Marc and Elzouki, SYA},
booktitle = {Human-Computer Interaction, HCI Intelligent Multimodal Interaction Environments 12th International Conference},
doi = {10.1007/978-3-540-73110-8},
editor = {Jacko, Julie A.},
file = {::},
keywords = {Emotion,autism,avatar,education,empathy,facial messaging,therapeutic intervention,virtual reality},
pages = {275--285},
publisher = {Springer Berlin / Heidelberg},
title = {{Emotionally expressive avatars for chatting, learning and therapeutic intervention}},
url = {http://dl.acm.org/citation.cfm?id=1769621 http://www.springerlink.com/content/7gju6n38605hp3h2/},
year = {2007}
}
@book{Prochaska1994,
author = {Prochaska, James O. and DiClemente, Carlo C.},
isbn = {0894648489, 9780894648489},
pages = {193},
publisher = {Krieger Pub.},
title = {{The transtheoretical approach: crossing traditional boundaries of therapy}},
year = {1994}
}
@article{Bavelas1986,
author = {Bavelas, Janet Beavin and Black, Alex and Lemery, Charles R. and {Jennifer Muller}},
file = {::},
journal = {Journal of Personality and Social Psychology},
number = {2},
pages = {322--329},
title = {{"I show how you feel" - Motor mimicry as a communicative act}},
volume = {50},
year = {1986}
}
@inproceedings{Caridakis2006,
author = {Caridakis, George and Malatesta, Lori and Kessous, Loic and Amir, Noam and Raouzaiou, Amaryllis and Karpouzis, Kostas},
booktitle = {Proceedings of the 8th international conference on Multimodal interfaces},
file = {::},
pages = {146--154},
publisher = {ACM},
title = {{Modeling naturalistic affective states via facial and vocal expressions recognition}},
year = {2006}
}
@inproceedings{Hyun2007,
author = {Hyun, KH and Kim, EH},
booktitle = {16th IEEE International Conference on Robot \& Human Interactive Communication},
file = {::},
isbn = {9781424416356},
pages = {802--806},
title = {{Emotional feature extraction based on phoneme information for speech emotion recognition}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4415195},
year = {2007}
}
@article{Wang2009,
annote = {Out of three components of rapport by Tickle-Degnene and Rosenthal (mutual attentiveness, positivity, and coordination), they investigated the relationship between human speakers' facial expression and rapport. Results show that recognizing positive facial expressions alone is insufficient but negative facial displays are more effective in assessing the level of rapport between participants.},
author = {Wang, Ning},
doi = {10.1109/ACII.2009.5349514},
file = {::},
isbn = {978-1-4244-4800-5},
journal = {and Workshops, 2009. ACII 2009. 3rd},
month = sep,
pages = {1--6},
publisher = {Ieee},
title = {{Rapport and facial expression}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5349514 http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5349514},
year = {2009}
}
@article{Grahe1999,
author = {Grahe, JE},
file = {::},
journal = {Journal of Nonverbal behavior},
number = {4},
pages = {253--269},
title = {{The importance of nonverbal cues in judging rapport}},
url = {http://www.springerlink.com/index/V8U30855W38M4673.pdf},
volume = {23},
year = {1999}
}
@article{Gupta2012,
author = {Gupta, Prabodh and Jhala, Darshana and Jhala, Nirag},
doi = {10.1309/AJCPLAE62CRYYXNW},
file = {::},
issn = {1943-7722},
journal = {American journal of clinical pathology},
month = jan,
number = {1},
pages = {160},
pmid = {22180490},
title = {{Book review.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22180490},
volume = {137},
year = {2002}
}
@article{Robison2010,
abstract = {affective interventions can both positively and negatively influence learning experiences. In this paper we investigate the role of student personality, including goal orienta- tion and empathetic tendencies, in estimating confidence in the benefits of an affective intervention strategy. The results indicate that student personality profiles can serve as a powerful tool for informing affective feedback models.},
annote = {We can use the same way of menu base self-report affective state recognition (in addition to automatic) and text-base empathic feedback. Then after each feedback we can evaluate the feedback with another user self-report.},
author = {Robison, Jennifer and McQuiggan, Scott W and Lester, James and Carolina, North},
keywords = {affect,affective computing,pedagogical agents},
pages = {285--295},
title = {{Developing Empirically Based Student Personality Profiles for Affective Feedback Models}},
year = {2010}
}
@book{Thayer1996,
author = {Thayer, Robert E.},
isbn = {9780195118056},
pages = {288},
publisher = {Oxford University Press},
title = {{The Origin of Everyday Moods: Managing Energy, Tension, and Stress}},
year = {1996}
}
@article{Eisenberg1983,
abstract = {Reviews the literature on sex differences in empathy (defined as vicarious affective responding to the emotional state of another) and related capacities (affective role taking and decoding of nonverbal cues). The literature is discussed according to method used to assess empathy and affective role taking. Where appropriate, meta-analyses were also computed. In general, sex differences in empathy were found to be a function of the methods used to assess empathy. There was a large sex difference favoring women when the measure of empathy was self-report scales; moderate differences (favoring females) were found for reflexive crying and self-report measures in laboratory situations; and no sex differences were evident when the measure of empathy was either physiological or unobtrusive observations of nonverbal reactions to another's emotional state. Moreover, few sex differences were found for children's affective role taking and decoding abilities. (156 ref) (PsycINFO Database Record (c) 2006 APA, all rights reserved), (C) 1983 by the American Psychological Association},
author = {Eisenberg, Nancy and Lennon, Randy},
issn = {19391455},
journal = {Psychological Bulletin},
number = {1},
pages = {100--131},
title = {{Sex Differences in Empathy and Related Capacities}},
volume = {94},
year = {1983}
}
@article{Mehrabian1972,
author = {Mehrabian, Albert and Epstein, N},
file = {::},
journal = {Journal of Personality},
number = {4},
pages = {525--543},
pmid = {4642390},
publisher = {Wiley Online Library},
title = {{A measure of emotional empathy.}},
volume = {40},
year = {1972}
}
@article{Grynberg2010,
abstract = {Alexithymia and empathy have been related but very little is known on shared variance between their respective affective and cognitive dimensions. We examined this question with correlations, as well as both exploratory and confirmatory analyses, and controlled for anxiety and depression. The responses of 645 young adults to self-report questionnaires of alexithymia (TAS-20), empathy (IRI), anxiety (STAI-T) and depression (BDI-13) were examined. We observed associations between the proposed cog- nitive components of alexithymia (externally-oriented thinking) and that of empathy (perspective taking, fantasy) as well as empathic concern, which were insensitive to anxiety or depression. In contrast, asso- ciations between the proposed affective components of alexithymia (difficulty identifying feelings, diffi- culty describing feelings) and empathy (personal distress) were largely due to shared covariance with anxiety. A model encompassing an affective and a cognitive (including empathic concern) latent factors emerged, even after controlling for dysphoric affects. These findings suggest specific associations between cognitive and affective components of both constructs that were dissimilarly affected by anxiety and depression. The allocation of empathic concern to the cognitive factor is also discussed.},
author = {Grynberg, Delphine and Luminet, Olivier and Corneille, Olivier and Gr\`{e}zes, Julie and Berthoz, Sylvie},
doi = {10.1016/j.paid.2010.07.013},
file = {::},
issn = {01918869},
journal = {Personality and Individual Differences},
keywords = {Alexithymia,Anxiety,Depression,Empathy,IRI,TAS-20},
mendeley-tags = {Alexithymia,Anxiety,Depression,Empathy,IRI,TAS-20},
month = dec,
number = {8},
pages = {845--850},
publisher = {Elsevier Ltd},
title = {{Alexithymia in the interpersonal domain: A general deficit of empathy?}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S019188691000365X},
volume = {49},
year = {2010}
}
@article{LaBrie2007,
abstract = {The present study examines the relationships among reasons for drinking, alcohol consumption, and alcohol-related consequences in two college-aged samples. Personal motivators such as mood enhancement and coping (tension reduction) have consistently been shown to predict problematic alcohol use, but because of the salient nature of social drinking in college, we hypothesized that social reasons for drinking would be most frequently endorsed and, in turn, predict negative consequences.},
author = {LaBrie, Joseph W and Hummer, Justin F and Pedersen, Eric R},
file = {::},
issn = {1937-1888},
journal = {Journal of studies on alcohol and drugs},
keywords = {Adaptation, Psychological,Adolescent,Adult,Affect,Alcohol Drinking,Alcohol Drinking: legislation \& jurisprudence,Alcohol Drinking: prevention \& control,Alcohol Drinking: psychology,Alcoholic Intoxication,Alcoholic Intoxication: psychology,Female,Friends,Humans,Male,Motivation,Sex Factors,Social Behavior,Social Control, Formal,Social Environment,Social Facilitation,Stress, Psychological,Stress, Psychological: complications,Students,Students: psychology,United States},
month = may,
number = {3},
pages = {393--8},
pmid = {17446979},
title = {{Reasons for drinking in the college student context: the differential role and risk of the social motivator.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17446979},
volume = {68},
year = {2007}
}
@inproceedings{Charniak2000,
abstract = {We present a new parser for parsing down to Penn tree-bank style parse trees that achieves 90.1\% average precision/recall for sentences of length 40 and less, and 89.5\% for sentences of length 100 and less when trMned and tested on the previously established [5,9,10,15,17] "stan- dard" sections of the Wall Street Journal tree- bank. This represents a 13\% decrease in er- ror rate over the best single-parser results on this corpus [9]. The major technical innova- tion is tire use of a "ma\~{}ximum-entropy-inspired" model for conditioning and smoothing that let us successfully to test and combine many differ- ent conditioning events. We also present some partial results showing the effects of different conditioning information, including a surpris- ing 2\% improvement due to guessing the lexical head's pre-terminal before guessing the lexical head.},
author = {Charniak, Eugene},
booktitle = {1st North American chapter of the Association for Computational Linguistics conference (NAACL' 2000)},
file = {::},
number = {c},
pages = {132--139},
publisher = {Association for Computational Linguistics Stroudsburg, PA, USA},
title = {{A Maximum-Entropy-Inspired Parser}},
year = {2000}
}
@article{Hojat2003,
author = {Hojat, Mohammadreza and Gonnella, J S and Mangione, Salvatore and Nasca, Thomas J and Magee, Mike},
journal = {Seminars in Integrative Medicine},
publisher = {Seminars in Integrative Medicine},
title = {{Pshysician empathy in medical education practice experience with the jefferson scale of physician empathy}},
year = {2003}
}
@article{Lien1998,
author = {Lien, James J and Cohn, Jeffrey F and Kanade, Takeo and Li, Ching-Chung},
file = {::},
journal = {IEEE Proceedings of FG'98},
title = {{Automated Facial Expression Recognition Based on FACS Action Units University of Pittsburgh Takeo Kanade Vision and Autonomous Systems Center Ching-Chung Li}},
year = {1998}
}
@article{Gratch2006,
author = {Gratch, Jonathan and Okhmatovskaia, Anna and Lamothe, Francois},
file = {::},
journal = {Intelligent Virtual},
title = {{Virtual rapport}},
url = {http://www.springerlink.com/index/k720537752657m81.pdf},
year = {2006}
}
@article{Lakin2003b,
author = {Lakin, J. L. and Chartrand, T. L.},
doi = {10.1111/1467-9280.14481},
file = {::},
issn = {0956-7976},
journal = {Psychological Science},
month = jul,
number = {4},
pages = {334--339},
title = {{Using Nonconscious Behavioral Mimicry to Create Affiliation and Rapport}},
url = {http://pss.sagepub.com/lookup/doi/10.1111/1467-9280.14481},
volume = {14},
year = {2003}
}
@incollection{Burke2002,
address = {New-York,NY},
author = {Burke, B. L. and Arkowitz, H. and Dunn, C.},
booktitle = {Motivational Interviewing: Preparing People for Change},
edition = {2nd},
pages = {217--250},
publisher = {Guilford Press},
title = {{The Efficacy of Motivational Interviewing and Its Adaptation}},
year = {2002}
}
@article{Lakin2003b,
author = {Lakin, J. L. and Chartrand, T. L.},
doi = {10.1111/1467-9280.14481},
file = {::},
issn = {0956-7976},
journal = {Psychological Science},
month = jul,
number = {4},
pages = {334--339},
title = {{Using Nonconscious Behavioral Mimicry to Create Affiliation and Rapport}},
url = {http://pss.sagepub.com/lookup/doi/10.1111/1467-9280.14481},
volume = {14},
year = {2003}
}
@article{Klein2002,
abstract = {Use of technology often has unpleasant side effects, which may include strong, negative emotional states that arise during interaction with computers. Frustration, confusion, anger, anxiety and similar emotional states can affect not only the interaction itself, but also productivity, learning, social relationships, and overall well-being. This paper suggests a new solution to this problem: designing human–computer interaction systems to actively support users in their ability to manage and recover from negative emotional states. An interactive affect–support agent was designed and built to test the proposed solution in a situation where users were feeling frustration. The agent, which used only text and buttons in a graphical user interface for its interaction, demonstrated components of active listening, empathy, and sympathy in an effort to support users in their ability to recover from frustration. The agent's effectiveness was evaluated against two control conditions, which were also text-based interactions: (1) users’ emotions were ignored, and (2) users were able to report problems and ‘vent’ their feelings and concerns to the computer. Behavioral results showed that users chose to continue to interact with the system that had caused their frustration significantly longer after interacting with the affect–support agent, in comparison with the two controls. These results support the prediction that the computer can undo some of the negative feelings it causes by helping a user manage his or her emotional state.},
author = {Klein, J and Moon, Y and {Rosalind W. Picard}},
doi = {http://dx.doi.org/10.1016/S0953-5438(01)00053-4},
file = {::},
journal = {Interacting with computers},
keywords = {affect,affective computing,empathetic interface,frustration,human-centred design,social interface,user emotion},
number = {2},
pages = {119--140},
publisher = {Elsevier Science Ltd},
title = {{This computer responds to user frustration: Theory, design, and results}},
url = {http://www.sciencedirect.com/science/article/pii/S0953543801000534},
volume = {14},
year = {2002}
}
@inproceedings{Nguyen2007,
abstract = {Using theories of behaviour change, argumentation theory, and findings in social psychology, our research explores new methods to raise the persuasiveness of adaptive dialog-based systems using tailored arguments and onscreen characters to enhance the system’s credibility and trustworthiness. Initial results revealed the existence of individual preferences for arguments, types of communication, and appearance of onscreen characters. In the future, we will explore methods to learn these preferences through interactions with the user, and to utilize them to maximize the persuasion effect of the system. The final outcome of the research will be a persuasion model that is capable of modelling the user’s cognitive and affective state and generating tailored arguments to move the user in the desired direction.},
author = {Nguyen, Hien},
booktitle = {LNAI 4511},
editor = {Conati, C. and McCoy, K. and Paliouras, G.},
file = {::},
pages = {475--479},
publisher = {Springer-Verlag Berlin Heidelberg},
title = {{Designing Persuasive Health Behaviour Change Dialogs}},
year = {2007}
}
@article{Saunier2010,
author = {Saunier, Julien and Jones, Hazael and Lourdeaux, Domitile},
doi = {10.1109/WI-IAT.2010.255},
file = {::},
isbn = {978-1-4244-8482-9},
journal = {2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology},
keywords = {emotions,empathy,multi-agent architecture,personality,placebo},
month = aug,
pages = {277--282},
publisher = {Ieee},
title = {{Empathy and Placebo for Autonomous Agents}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5616059},
year = {2010}
}
@inproceedings{Dias2005,
abstract = {Interactive virtual environments (IVEs) are now seen as an engaging new way by which children learn experimental sciences and other disciplines. These environments are populated by synthetic characters that guide and stimulate the children activities. In order to build such environments, one needs to address the problem of how achieve believable and empathic characters that act autonomously. Inspired by the work of traditional character animators, this paper proposes an architectural model to build autonomous characters where the agent’s reasoning and behaviour is influenced by its emotional state and personality. We performed a small case evaluation in order to determine if the characters evoked empathic reactions in the users with positive results.},
address = {Covilh\~{a}, Portugal},
author = {Dias, J. and Paiva, Ana},
booktitle = {EPIA 2005, 12th Portuguese Conference on Artificial Intelligence},
doi = {10.1007/11595014\_13},
editor = {Bento, Carlos and Cardoso, Am\'{\i}lcar and Dias, Ga\"{e}l},
file = {::},
pages = {127--140},
publisher = {Springer Berlin / Heidelberg},
title = {{Feeling and reasoning: A computational model for emotional characters}},
url = {http://www.springerlink.com/index/YQ18H62602413554.pdf},
year = {2005}
}
@article{Walters2007,
abstract = {OBJECTIVE: Alcohol consumption has been a growing concern at U.S. colleges, particularly among first-year students, who are at increased risk for problems. This study tested the efficacy of the "electronic Check-Up to Go" (e-CHUG), a commercially-available internet program, at reducing drinking among a group of at-risk college freshman. METHOD: The design was a randomized controlled trial: 106 freshmen students who reported heavy episodic drinking were randomly assigned to receive feedback or to assessment only. Assessment measures were completed at baseline, 8 weeks, and 16 weeks. RESULTS: At 8 weeks, the feedback group showed a significant decrease in drinks per week and peak BAC over control. By 16 weeks, the control group also declined to a point where there were no differences between groups. Changes in normative drinking estimates mediated the effect of the intervention. An additional 245 abstainers and light drinkers who were also randomized to condition did not show any intervention effect. CONCLUSIONS: This study provides preliminary support for the efficacy of this intervention at reducing short-term drinking among at-risk students.},
author = {Walters, Scott T and Vader, Amanda M and Harris, T Robert},
institution = {University of Texas School of Public Health, Dallas Regional Campus, Dallas, TX 75390-9128, USA. scott.walters@utsouthwestern.edu},
journal = {Prevention science the official journal of the Society for Prevention Research},
keywords = {adult,alcoholism,alcoholism prevention \& control,feedback,female,humans,internet,male,psychological,questionnaires,texas,universities},
number = {1},
pages = {83--88},
pmid = {17136461},
publisher = {University of Texas School of Public Health, Dallas Regional Campus, Dallas, TX 75390-9128, USA. scott.walters@utsouthwestern.edu},
title = {{A controlled trial of web-based feedback for heavy drinking college students.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17136461},
volume = {8},
year = {2007}
}
@misc{TheMendeleySupportTeam2011,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/The Mendeley Support Team - 2011 - Getting Started with Mendeley(4).pdf:pdf},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@article{Breazeal2005,
author = {Breazeal, Cynthia and Buchsbaum, Daphna and Gray, Jesse and Gatenby, David and Blumberg, Bruce},
file = {::},
journal = {Artificial Life},
number = {1-2},
pages = {31--62},
publisher = {MIT Press},
title = {{Learning from and about others: Towards using imitation to bootstrap the social understanding of others by robots}},
volume = {11},
year = {2005}
}
@article{Bellet1991,
abstract = {IN HIS RESEARCH on the physician-patient relationship, Cousins1 found that 85\% of people had changed physicians or were thinking of changing in the past 5 years. Many of those who changed did so because of their physician's poor communication skills. One of the qualities of effective communication is the use of empathy. Because some physicians have not learned to use empathy in their training as medical students and residents, they may be ineffective in the care of patients.2 In this article, we discuss the importance of empathy in medical practice and illustrate its use with two examples.},
author = {Bellet, P S and Maloney, M J},
doi = {10.1001/jama.1991.03470130111039},
file = {::},
issn = {0098-7484},
journal = {JAMA : the journal of the American Medical Association},
keywords = {Communication,Cost-Benefit Analysis,Empathy,Humans,Physician's Practice Patterns,Physician's Practice Patterns: economics,Physician-Patient Relations},
month = oct,
number = {13},
pages = {1831--2},
pmid = {1909761},
title = {{The importance of empathy as an interviewing skill in medicine}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/1909761},
volume = {266},
year = {1991}
}
@article{Hester2005,
abstract = {Sixty-one problem drinkers were randomly assigned to either immediate treatment or a 4-week wait-list control group. Treatment consisted of a computer-based brief motivational intervention, the Drinker's Check-up (DCU). Outcomes strongly support the experimental hypotheses and long-term effectiveness of the treatment. Overall, participants reduced the quantity and frequency of drinking by 50\%, and had similar reductions in alcohol-related problems that were sustained through 12-month follow-up. The DCU seems to be effective in enhancing problem drinkers' motivation for change.},
author = {Hester, Reid K and Squires, Daniel D and Delaney, Harold D},
journal = {Journal of Substance Abuse Treatment},
keywords = {adult,alcohol drinking,alcoholism,blood,computer assisted,epidemiology,ethanol,female,follow up studies,humans,male,middle aged,motivation,outcome assessment (health care),patient compliance,patient dropouts,personality assessment,psychometrics,px [psychology],rh [rehabilitation],sn [statistics \&,sn [statistics \& numer,sn [statistics \& numerical,sn [statistics \& numerical data,sn [statistics \& numerical data],software,therapy,united states,waiting lists},
number = {2},
pages = {159--169},
pmid = {15780546},
publisher = {Research Division, Behavior Therapy Associates, LLP, Albuquerque, NM 87112, USA. reidhester@behaviortherapy.com},
title = {{The Drinker's Check-up: 12-month outcomes of a controlled clinical trial of a stand-alone software program for problem drinkers}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15780546},
volume = {28},
year = {2005}
}
@article{Gupta2012,
author = {Gupta, Prabodh and Jhala, Darshana and Jhala, Nirag},
doi = {10.1309/AJCPLAE62CRYYXNW},
file = {::},
issn = {1943-7722},
journal = {American journal of clinical pathology},
month = jan,
number = {1},
pages = {160},
pmid = {22180490},
title = {{Book review.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22180490},
volume = {137},
year = {2002}
}
@book{Bull1987,
abstract = {The purpose of this book is to present the results of a series of studies carried out by the author over a number of years, sharing a common focus on the role of posture and gesture in interpersonal communication. The first section of the book is intended to set these studies in the general context of non-verbal communication research; in addition, previous research on posture and gesture is reviewed in order to highlight the particular issues which were chosen as the focus of research to be reported here. Techniques of measurement are also discussed, and two scoring procedures are presented which were devised by the author for the purpose of categorizing posture and gesture. In the second and third parts of the volume are presented the results of eleven original studies of posture and gesture carried out by the author. The six experiments reported in Part II were concerned with the extent of which posture communicates information about listener emotions and attitudes, the seven studies reported in Part III were concerned with the relationship between posture, gesture and speech. The final section of the book (Part IV) is intended to summarize the main findings from the studies presented in this volume, to discuss their theoretical and practical significance, and to consider their implications for the way in which research on non-verbal communication is carried out.},
author = {Bull, Peter},
booktitle = {Encoding of Disagreement and Agreement},
pages = {1--6},
publisher = {Pergamon Books},
series = {International Series in Experimental Social Psychology},
title = {{Posture and Gesture}},
url = {http://eprints.whiterose.ac.uk/74117/},
volume = {16},
year = {1987}
}
@inproceedings{Steunebrink2009,
author = {Steunebrink, B.R. and Dastani, Mehdi and Meyer, J.J.C.},
booktitle = {Proceedings of the 4th Workshop on Emotion and Computing},
file = {::},
title = {{The OCC model revisited}},
url = {http://www.idsia.ch/~steunebrink/Publications/KI09\_OCC\_revisited.pdf},
year = {2009}
}
@article{Mehrabian1967,
author = {Mehrabian, Albert and Ferris, S R},
journal = {Journal of Consulting Psychology},
keywords = {attitude,communication,facial expression,female,humans,verbal behavior},
number = {3},
pages = {248--252},
pmid = {6046577},
title = {{Inference of attitudes from nonverbal communication in two channels.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/6046577},
volume = {31},
year = {1967}
}
@incollection{Gratch2006a,
author = {Gratch, Jonathan and Mao, W and Marsella, Stacy},
booktitle = {Cognition and Multi-Agent Interaction: From Cognitive Modeling to Social Simulation},
chapter = {9},
doi = {http://dx.doi.org/10.1017/CBO9780511610721.010},
editor = {Sun, Ron},
file = {::;::},
isbn = {9780511610721},
pages = {219--251},
publisher = {Cambridge University Press},
title = {{Modeling social emotions and social attributions}},
year = {2006}
}
@article{Kendon1967,
abstract = {Films of two-person conversations were transcribed and analyzed from the point of view of how gaze direction is related to utterance and silence. It was found that patterns of looking were systematically related to features of talk and could be accounted for in terms of the monitoring functions of gaze. At the same time, evidence was presented that suggested that gaze direction may also play a role in the regulation of turn-taking in conversation.},
author = {Kendon, Adam},
doi = {10.1016/0001-6918(67)90005-},
issn = {00016918},
journal = {Acta Psychologica},
number = {1},
pages = {22--63},
publisher = {Elsevier BV, Radarweg 29, Amsterdam, 1043 NX, Netherlands,},
title = {{Some functions of gaze-direction in social interaction.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/6043092},
volume = {26},
year = {1967}
}
@inproceedings{Bosse2010,
abstract = {In order to enhance user involvement in financial services, this paper proposes to combine the idea of adaptive personalisation with intelligent virtual agents. To this end, a computational model for human decision making in financial context is incorporated within an intelligent virtual agent. To test whether the agent enhances user involvement, a web application has been developed, in which users have to make a number of investment decisions. This application has been evaluated in an experiment for a number of participants interacting with the system and afterwards providing their judgement by means of a questionnaire. The preliminary results indicate that the virtual agent can show appropriate emotional expressions related to states like happiness, greed and fear, and has high potential to enhance user involvement.},
author = {Bosse, Tibor and Siddiqui, Ghazanfar F and Treur, Jan},
booktitle = {IVA'10 Proceedings of the 10th international conference on Intelligent virtual agents},
file = {::},
keywords = {adaptive personalisation.,finance,greed and risk,user involvement},
pages = {378--384},
publisher = {Springer-Verlag Berlin, Heidelberg},
title = {{An Intelligent Virtual Agent to Increase Involvement in Financial Services}},
year = {2010}
}
@phdthesis{Sidorova2007,
author = {Sidorova, Julia},
booktitle = {Speech communication},
file = {::},
school = {Universitat Pompeu Fabra},
title = {{Speech emotion recognition using hidden Markov models}},
year = {2007}
}
@book{Thayer1996,
author = {Thayer, Robert E.},
isbn = {9780195118056},
pages = {288},
publisher = {Oxford University Press},
title = {{The Origin of Everyday Moods: Managing Energy, Tension, and Stress}},
year = {1996}
}
@techreport{Bradley1999,
author = {Bradley, Margaret M and Lang, PJ},
file = {::},
institution = {Technical Report C-1, The Center for Research in Psychophysiology, University of Florida},
title = {{Affective norms for English words (ANEW): Instruction manual and affective ratings}},
url = {http://www.uvm.edu/~pdodds/research/papers/others/1999/bradley1999a.pdf},
year = {1999}
}
@article{D&39;Mello2006,
author = {Mello, Sidney D' and Graesser, Art},
file = {::},
journal = {Intelligent Virtual Agents},
pages = {54--67},
title = {{Affect detection from human-computer dialogue with an intelligent tutoring system}},
url = {http://www.springerlink.com/index/b574kpu6nl719408.pdf},
year = {2006}
}
@article{Ward2000,
abstract = {Back-channel feedback, responses such as uh-uh from a listener, is a pervasive feature of conversation. It has long been thought that the production of back-channel feedback depends to a large extent on the actions of the other conversation partner, not just on the volition of the one who produces them. In particular, prosodic cues from the speaker have long been thought to play a role, but have so far eluded identification. We have earlier suggested that an important prosodic cue involved, in both English and Japanese, is a region of low pitch late in an utterance (Ward, 1996). This paper discusses issues in the definition of back-channel feedback, presents evidence for our claim, surveys other factors which elicit or inhibit back-channel responses, and mentions a few related phenomena and theoretical issues. (C) 2000 Elsevier Science B.V. All rights reserved.},
author = {Ward, Nigel and Tsukahara, Wataru},
doi = {10.1016/S0378-2166(99)00109-5},
issn = {03782166},
journal = {Journal of Pragmatics},
number = {8},
pages = {1177--1207},
publisher = {Elsevier},
title = {{Prosodic features which cue back-channel responses in English and Japanese}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0378216699001095},
volume = {32},
year = {2000}
}
@article{DeVignemont2006,
abstract = {Recent imaging results suggest that individuals automatically share the emotions of others when exposed to their emotions. We question the assumption of the automaticity and propose a contextual approach, suggesting several modulatory factors that might influence empathic brain responses. Contextual appraisal could occur early in emotional cue evaluation, which then might or might not lead to an empathic brain response, or not until after an empathic brain response is automatically elicited. We propose two major roles for empathy; its epistemological role is to provide information about the future actions of other people, and important environmental properties. Its social role is to serve as the origin of the motivation for cooperative and prosocial behavior, as well as help for effective social communication.},
author = {de Vignemont, Frederique and Singer, Tania},
doi = {10.1016/j.tics.2006.08.008},
file = {::},
issn = {1364-6613},
journal = {Trends in cognitive sciences},
keywords = {Automatism,Automatism: psychology,Brain,Brain Mapping,Brain: physiology,Cerebral,Cerebral Cortex,Cerebral Cortex: physiology,Cerebral: physiology,Communication,Cooperative Behavior,Cues,Dominance,Emotions,Emotions: physiology,Empathy,Female,Gyrus Cinguli,Gyrus Cinguli: physiology,Humans,Interpersonal Relations,Magnetic Resonance Imaging,Male,Motivation,Nerve Net,Nerve Net: physiology,Neurons,Neurons: physiology,Social Behavior,Social Environment},
month = oct,
number = {10},
pages = {435--41},
pmid = {16949331},
title = {{The empathic brain: how, when and why?}},
volume = {10},
year = {2006}
}
@book{Ziegel2000,
address = {Cary, NC, USA},
author = {Ziegel, Eric R. and Stokes, M. and Davis, C. and Koch, G.},
booktitle = {Technometrics},
doi = {10.2307/1271334},
edition = {Second Edi},
file = {::},
isbn = {1580257100},
issn = {00401706},
month = nov,
number = {4},
pages = {413},
publisher = {SAS Institute Inc.},
title = {{Categorical Data Analysis Using the SAS System}},
url = {http://www.jstor.org/stable/1271334?origin=crossref},
volume = {38},
year = {2000}
}
@article{Boucouvalas2003,
abstract = {In this work we focus on demonstrating a real time communication interface which enhances text communication by detecting from real time typed text, the extracted emotions, and displaying on the screen appropriate facial expression images in real time. The displayed expressions are represented in terms of expressive images or sketches of the communicating persons. This interface makes use of a developed real time emotion extraction engine from text. The emotion extraction engine and extraction rules are discussed together with a description of the interface, its limits and future direction of such interface. The extracted emotions are mapped into displayed facial expressions. Such interface can be used as a platform for a number of future CMC experiments. The developed online communication interface brings together remotely located collaborating parties in a shared electronic spacefor their communication. In its current state the interface allows the participant to see at a glance all other online participants and all those who are engaged in communications. An important aspect of the interface is that for two users engaged in communication, the interface locally extracts emotional states from the content of typed textual sentences automatically. Subsequently it displays discrete expressions mapped from extracted emotions to the remote screen of the other person. It also analyses/extracts the intensity/duration of the emotional state. At the same time the users can also control their expression, if they wish, manually. The interface also uses text to speech synthesis, which allows the user to glance on other tasks while at the same time listening to the communication. A shared whiteboard also allows the users to engage in collaborative work. Finally it is also possible to view your own expression (feedback) which is displayed and viewed by the other user, an add on feature not possible with face to face communication between two people.},
author = {Boucouvalas, Anthony C},
chapter = {21},
editor = {Riva, G and Davide, F and Jsselsteijn, W A I},
journal = {Emotion},
pages = {305--318},
publisher = {Ios Press},
title = {{Real Time Text-to-Emotion Engine for Expressive Internet Communications}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:Real+Time+Text-to-Emotion+Engine+for+Expressive+Internet+Communications\#1},
volume = {5},
year = {2003}
}
@article{Carey2009,
abstract = {This meta-analysis evaluates the efficacy of computer-delivered interventions (CDIs) to reduce alcohol use among college students.},
author = {Carey, Kate B and Scott-Sheldon, Lori A J and Elliott, Jennifer C and Bolles, Jamie R and Carey, Michael P},
doi = {10.1111/j.1360-0443.2009.02691.x},
issn = {1360-0443},
journal = {Addiction (Abingdon, England)},
keywords = {Adolescent,Alcohol Drinking,Alcohol Drinking: prevention \& control,Alcohol Drinking: trends,Alcohol-Related Disorders,Alcohol-Related Disorders: prevention \& control,Ethanol,Ethanol: poisoning,Female,Health Education,Health Education: methods,Health Knowledge, Attitudes, Practice,Humans,Internet,Male,Program Evaluation,Program Evaluation: statistics \& numerical data,Randomized Controlled Trials as Topic,Students,Therapy, Computer-Assisted,Therapy, Computer-Assisted: methods,Time Factors,Treatment Outcome,Universities,Young Adult},
month = nov,
number = {11},
pages = {1807--19},
pmid = {19744139},
title = {{Computer-delivered interventions to reduce college student drinking: a meta-analysis.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2763045\&tool=pmcentrez\&rendertype=abstract},
volume = {104},
year = {2009}
}
@inproceedings{Takashima2008,
abstract = {Blinking is one of the most important cues for forming person impressions. We focus on the eye blinking rate of avatars and investigate its effect on viewer subjective impressions. Two experiments are conducted. The stimulus avatars included humans with generic reality (male and female), cartoon-style humans (male and female), animals, and unidentified life forms that were presented as a 20-second animation with various blink rates: 9, 12, 18, 24 and 36 blinks/min. Subjects rated their impressions of the presented stimulus avatars on a seven-point semantic differential scale. The results showed a significant effect of the avatars blinking on viewer impressions and it was larger with the human- style avatars than the others. The results also lead to several implications and guidelines for the design of avatar representation. Blink animation of 18 blinks/min with a human-style avatar produces the friendliest impression. The higher blink rates, i.e., 36 blinks/min, give inactive impressions while the lower blink rates, i.e., 9 blinks/min, give intelligent impressions. Through these results, guidelines are derived for managing attractiveness of avatar by changing the avatars blinking rate.},
author = {Takashima, Kazuki and Omori, Yasuko and Yoshimoto, Yoshiharu and Itoh, Yuich and Kitamura, Yoshifumi and Kishino, Fumio},
booktitle = {Intelligence},
pages = {169--176},
publisher = {Canadian Information Processing Society},
title = {{Effects of avatar's blinking animation on person impressions}},
url = {http://portal.acm.org/citation.cfm?id=1375744},
year = {2008}
}
@book{Russell2010,
author = {Russell, S.J. and Norvig, P.},
booktitle = {Artificial Intelligence},
edition = {3},
editor = {Russell, Stuart and Norvig, Peter},
file = {::},
isbn = {9780136042594},
publisher = {Prentice hall},
title = {{Artificial intelligence: a modern approach}},
url = {http://www.just.edu.jo/CoursesAndLabs/ARTIFICAL  INTELLIGENCE\_CS362/Syllabus\_362.doc},
year = {2010}
}
@incollection{Stueber2008,
author = {Stueber, Karsten},
booktitle = {The Stanford Encyclopedia of Philosophy},
edition = {Fall 2008},
editor = {Zalta, Edward N.},
title = {{Empathy}},
url = {http://plato.stanford.edu/archives/fall2008/entries/empathy/},
year = {2008}
}
@article{Robison2010,
abstract = {affective interventions can both positively and negatively influence learning experiences. In this paper we investigate the role of student personality, including goal orienta- tion and empathetic tendencies, in estimating confidence in the benefits of an affective intervention strategy. The results indicate that student personality profiles can serve as a powerful tool for informing affective feedback models.},
annote = {We can use the same way of menu base self-report affective state recognition (in addition to automatic) and text-base empathic feedback. Then after each feedback we can evaluate the feedback with another user self-report.},
author = {Robison, Jennifer and McQuiggan, Scott W and Lester, James and Carolina, North},
keywords = {affect,affective computing,pedagogical agents},
pages = {285--295},
title = {{Developing Empirically Based Student Personality Profiles for Affective Feedback Models}},
year = {2010}
}
@article{Ortony1990,
abstract = {A widespread assumption in theories of emotion is that there exists a small set of basic emotions. From a biological perspective, this idea is manifested in the belief that there might be neurophysiological and anatomical substrates corresponding to the basic emotions. From a psychological perspective, basic emotions are often held to be the primitive building blocks of other, nonbasic emotions. The content of such claims is examined, and the results suggest that there is no coherent nontrivial notion of basic emotions as the elementary psychological primitives in terms of which other emotions can be explained. Thus, the view that there exist basic emotions out of which all other emotions are built, and in terms of which they can be explained, is questioned, raising the possibility that this position is an article of faith rather than an empirically or theoretically defensible basis for the conduct of emotion research. This suggests that perhaps the notion of basic emotions will not lead to significant progress in the field. An alternative approach to explaining the phenomena that appear to motivate the postulation of basic emotions is presented.},
author = {Ortony, A and Turner, T J},
institution = {Institute for the Learning Sciences, Northwestern University, Evanston, Illinois 60201.},
journal = {Psychological Review},
number = {3},
pages = {315--331},
pmid = {1669960},
publisher = {Citeseer},
title = {{What's basic about basic emotions?}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0033-295X.97.3.315},
volume = {97},
year = {1990}
}
@article{ArthurJ.Clark2010,
abstract = {Expanding on a framework introduced by Carl Rogers, an integral model of empathy in counseling uses empathic understanding through 3 ways of knowing: Subjective empathy enables a counselor to momentarily experience what it is like to be a client, interpersonal empathy relates to understanding a client's phenomenological experiencing, and objective empathy uses reputable knowledge sources outside of a client's frame of reference. Across the counseling process, empathy is integral to treatment strategies and interventions.},
author = {{Arthur J. Clark}},
file = {::},
journal = {Journal of Counseling \& Development},
keywords = {Counseling,Counseling Techniques,Counselor Client Relationship,Empathy,Models},
number = {3},
pages = {348 -- 356},
title = {{Empathy: An integral model in the counseling process}},
url = {http://aca.metapress.com/link.asp?id=075658qt56l20466 },
volume = {88},
year = {2010}
}
@article{Shamay-Tsoory2011a,
abstract = {Human empathy relies on the ability to share emotions as well as the ability to understand the other's thoughts, desires, and feelings. Recent evidence points to 2 separate systems for empathy: an emotional system that supports our ability to empathize emotionally and a cognitive system that involves cognitive understanding of the other's perspective. A neural network that includes the inferior frontal gyrus and the inferior parietal lobule is necessary for emotion recognition and emotional contagion. Although the emotional and cognitive systems appear to work independently, every empathic response may still evoke both components to some extent, depending on the social context.},
annote = {Difference between cognitive empathy and emotional empathy is explained in this paper. Also they talk about the active brain parts in each empathy type.},
author = {Shamay-Tsoory, Simone G},
doi = {10.1177/1073858410379268},
file = {::},
issn = {1089-4098},
journal = {The Neuroscientist : a review journal bringing neurobiology, neurology and psychiatry},
keywords = {Brain,Brain: physiology,Empathy,Empathy: physiology,Humans,Neural Pathways,Neural Pathways: physiology},
month = feb,
number = {1},
pages = {18--24},
pmid = {21071616},
title = {{The neural bases for empathy.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21071616},
volume = {17},
year = {2011}
}
@article{Southard1918,
author = {Southard, E E},
journal = {The Journal of Abnormal Psychology},
number = {4},
pages = {199},
publisher = {American Psychological Association},
title = {{The empathic index in the diagnosis of mental diseases.}},
volume = {13},
year = {1918}
}
@article{Rameson2009,
author = {Rameson, Lian T. and Lieberman, Matthew D.},
doi = {10.1111/j.1751-9004.2008.00154.x},
file = {::},
issn = {17519004},
journal = {Social and Personality Psychology Compass},
month = jan,
number = {1},
pages = {94--110},
title = {{Empathy: A Social Cognitive Neuroscience Approach}},
url = {http://doi.wiley.com/10.1111/j.1751-9004.2008.00154.x},
volume = {3},
year = {2009}
}
@book{McDougall1926,
address = {Boston},
author = {McDougall, William},
publisher = {Luce},
title = {{An introduction to social psychology}},
year = {1926}
}
@article{Devoldre2010,
abstract = {Social support researchers and clinicians have repeatedly expressed the need to identify the antecedents of social support provision within close relationships. The aim of the present study is to investigate the extent to which individual differences in cognitive empathy (perspective taking) and affective empathy (empathic concern and personal distress) are predictive of social support provision in couples. Study 1 involved 83 female participants in a relatively young relationship; Study 2 involved 128 married couples. The authors used self-report measures in both studies to assess individual differences in empathy and participants' support provision behaviors. The main findings suggest a significant contribution of the different components of empathy with rather different pictures for each of these components. The authors discuss the present findings in light of existing theory and research on social support in relationships.},
author = {Devoldre, Inge and Davis, Mark H. and Verhofstadt, Lesley L and Buysse, Ann},
doi = {10.1080/00223981003648294},
file = {::},
issn = {0022-3980},
journal = {The Journal of psychology},
keywords = {80 and over,Adolescent,Adult,Affect,Aged,Empathy,Family Characteristics,Female,Humans,Individuality,Male,Middle Aged,Personal Construct Theory,Personality Inventory,Personality Inventory: statistics \& numerical data,Psychometrics,Social Support,Young Adult},
number = {3},
pages = {259--284},
pmid = {20461931},
title = {{Empathy and social support provision in couples: social support and the need to study the underlying processes.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21506454},
volume = {144},
year = {2010}
}
@article{Becker-Asano2009,
abstract = {We introduce theWASABI ([W]ASABI [A]ffect [S]imulation for [A]gents with [B]elievable [I]nteractivity)Affect SimulationArchitecture, in which a virtual human’s cog- nitive reasoning capabilities are combined with simulated embodiment to achieve the sim- ulation of primary and secondary emotions. In modeling primary emotions we follow the idea of “Core Affect” in combination with a continuous progression of bodily feeling in three-dimensional emotion space (PADspace), that is subsequently categorized into discrete emotions. In humans, primary emotions are understood as onto-genetically earlier emotions, which directly influence facial expressions. Secondary emotions, in contrast, afford the abil- ity to reason about current events in the light of experiences and expectations.},
author = {Becker-Asano, Christian and Wachsmuth, Ipke},
doi = {10.1007/s10458-009-9094-9},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Becker-Asano, Wachsmuth - 2009 - Affective computing with primary and secondary emotions in a virtual human(3).pdf:pdf},
issn = {1387-2532},
journal = {Autonomous Agents and Multi-Agent Systems},
keywords = {affect simulation,affective computing,affective gaming,architecture,aware emotions,bdi-based architecture,embodied agent,emotion dynamics,emotion expression,emotion modeling,pad emotion space,primary and secondary emotions,reality,virtual,virtual human},
month = may,
number = {1},
pages = {32--49},
title = {{Affective computing with primary and secondary emotions in a virtual human}},
url = {http://www.springerlink.com/index/10.1007/s10458-009-9094-9},
volume = {20},
year = {2009}
}
@article{Russell1980,
abstract = {Factor-analytic evidence has led most psychologists to describe affect as a set of dimensions, such as displeasure, distress, depression, excitement, and so on, with each dimension varying independently of the others. However, there is other evidence that rather than being independent, these affective dimensions are interrelated in a highly systematic fashion. The evidence suggests that these interrelationships can be represented by a spatial model in which affective concepts fall in a circle in the following order: pleasure (0), excitement (45), arousal (90), distress (135), displeasure (180), depression (225), sleepiness (270), and relaxation (315). This model was offered both as a way psychologists can represent the structure of affective experience, as assessed through self-report, and as a representation of the cognitive structure that laymen utilize in conceptualizing affect. Supportive evidence was obtained by scaling 28 emotion-denoting adjectives in 4 different ways: R. T. Ross's (1938) technique for a circular ordering of variables, a multidimensional scaling procedure based on perceived similarity among the terms, a unidimensional scaling on hypothesized pleasure–displeasure and degree-of-arousal dimensions, and a principal-components analysis of 343 Ss' self-reports of their current affective states. (70 ref) (PsycINFO Database Record (c) 2010 APA, all rights reserved)},
author = {Russell, James A},
doi = {10.1037/h0077714},
journal = {Journal of Personality and Social Psychology},
number = {6},
pages = {1161--1178},
title = {{A circumplex model of affect}},
url = {http://psycnet.apa.org/psycinfo/1981-25062-001},
volume = {39},
year = {1980}
}
@article{Hand2008,
author = {Hand, Stacey and Varan, Duane},
file = {::},
journal = {Changing Television Environments},
pages = {11--19},
publisher = {Springer},
title = {{Interactive Narratives: Exploring the Links between Empathy, Interactivity and Structure}},
url = {http://www.springerlink.com/index/15385726247gu863.pdf},
year = {2008}
}
@article{Caridakis2008,
abstract = {As input they consider the image sequence of the recorded human behavior. Computer vision and image processing techniques are incorporated in order to detect cues needed for expressivity features extraction. Using multimodalities, the virtual agent mimics the human expressions. The multimodality of the approach lies in the fact that both facial and gestural aspects of the user’s behavior are analyzed and processed. The mimicry consists of perception, interpretation, planning and animation of the expressions shown by the human, resulting not in an exact duplicate rather than an expressive model of the user’s original behavior.},
annote = {They use both facial and gestural aspects of the user’s behavior to mimic the user’s expressions. The introductory information and references about the psychological background of the mimicry in the paper are useful. But because most of the work is image processing, other sections would not be useful for our job.
Their system does not work in real time because they use a recorded video or sequence of images (limitation).},
author = {Caridakis, George and Raouzaiou, Amaryllis and Bevacqua, Elisabetta and Mancini, Maurizio and Karpouzis, Kostas and Malatesta, Lori and Pelachaud, Catherine},
doi = {10.1007/s10579-007-9057-1},
file = {::},
issn = {1574-020X},
journal = {Language Resources and Evaluation},
keywords = {facial,gesture,mimicry,multimodal,virtual agent},
month = jan,
number = {3-4},
pages = {367--388},
title = {{Virtual agent multimodal mimicry of humans}},
volume = {41},
year = {2008}
}
@article{VanSwol2003,
author = {{Van Swol}, Lyn M.},
doi = {10.1177/0093650203253318},
file = {::},
issn = {00000000},
journal = {Communication Research},
month = aug,
number = {4},
pages = {461--480},
title = {{The Effects of Nonverbal Mirroring on Perceived Persuasiveness, Agreement with an Imitator, and Reciprocity in a Group Discussion}},
volume = {30},
year = {2003}
}
@inproceedings{Krauss1996,
address = {San Diego, CA, US},
author = {Krauss, Robert M. and Chen, Yihsiu and Chawla, Purnima},
booktitle = {Advances in experimental social psychology},
doi = {10.1016/S0065-2601(08)60241-5},
editor = {Zanna, Mark P.},
file = {::},
pages = {389--450},
publisher = {Academic Press},
title = {{Nonverbal behavior and nonverbal communication: What do conversational hand gestures tell us?}},
url = {http://www.sciencedirect.com/science/article/pii/S0065260108602415},
volume = {28},
year = {1996}
}
@inproceedings{Magerko2011,
abstract = {This article presents our work on building a virtual coach agent, called Dr. Vicky, and training environment (called the Virtual BNI Trainer, or VBT) for learning how to correctly talk with medical patients who have substance abuse issues. This work focuses on how to effectively design menu-based dialogue interactions for conversing with a virtual patient within the context of learning how to properly engage in such conversations according to the brief negotiated interview techniques we desire to train. Dr. Vicky also employs a model of student knowledge to influence the mediation strategies used in personalizing the training experience and guidance offered. The VBT is a prototype training application that will be used by medical students and practitioners within the Yale medical community in the future.},
author = {Magerko, Brian and Dean, James and Idnani, Avinash and Pantalon, Michael and Onofrio, Gail D},
booktitle = {Association for the Advancement of Artificial Intelligence (AAAI) Spring Symposium},
file = {::},
keywords = {AAAI Technical Report SS-11-01},
pages = {25--32},
publisher = {Association for the Advancement of Artificial Intelligence (www.aaai.org)},
title = {{Dr. Vicky : A Virtual Coach for Learning Brief Negotiated Interview Techniques for Treating Emergency Room Patients}},
year = {2011}
}
@article{Hand2008,
author = {Hand, Stacey and Varan, Duane},
file = {::},
journal = {Changing Television Environments},
pages = {11--19},
publisher = {Springer},
title = {{Interactive Narratives: Exploring the Links between Empathy, Interactivity and Structure}},
url = {http://www.springerlink.com/index/15385726247gu863.pdf},
year = {2008}
}
@article{Shamay-Tsoory2011,
abstract = {Human empathy relies on the ability to share emotions as well as the ability to understand the other's thoughts, desires, and feelings. Recent evidence points to 2 separate systems for empathy: an emotional system that supports our ability to empathize emotionally and a cognitive system that involves cognitive understanding of the other's perspective. A neural network that includes the inferior frontal gyrus and the inferior parietal lobule is necessary for emotion recognition and emotional contagion. Although the emotional and cognitive systems appear to work independently, every empathic response may still evoke both components to some extent, depending on the social context.},
annote = {Difference between cognitive empathy and emotional empathy is explained in this paper. Also they talk about the active brain parts in each empathy type.},
author = {Shamay-Tsoory, Simone G},
doi = {10.1177/1073858410379268},
file = {::},
issn = {1089-4098},
journal = {The Neuroscientist : a review journal bringing neurobiology, neurology and psychiatry},
keywords = {Brain,Brain: physiology,Empathy,Empathy: physiology,Humans,Neural Pathways,Neural Pathways: physiology},
month = feb,
number = {1},
pages = {18--24},
pmid = {21071616},
title = {{The neural bases for empathy.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21071616},
volume = {17},
year = {2011}
}
@inproceedings{Gratch2007,
abstract = {Emotional bonds don’t arise from a simple exchange of facial displays, but often emerge through the dynamic give and take of face-to-face interactions. This article explores the phenome- non of rapport, a feeling of connectedness that seems to arise from rapid and contingent positive feedback between partners and is often associated with socio-emotional processes. Rapport has been argued to lead to communicative efficiency, better learning outcomes, improved acceptance of medical advice and successful negotiations. We provide experimental evidence that a simple vir- tual character that provides positive listening feedback can induce stronger rapport-like effects than face-to-face communication between human partners. Specifically, this interaction can be more en- gaging to storytellers than speaking to a human audience, as measured by the length and content of their stories.},
address = {Chamonix, France},
annote = {They explore the rapport, a feeling of connectedness that arises from rapid and contingent positive feedback between partners and is often associated with socio-emotional processes. Rapport can lead to communicative efficiency, better learning outcomes, improved acceptance of medical advice and successful negotiations.
They experimentally proved that a simple virtual character with positive listening feedback can induce stronger rapport-like effects than face-to-face communication between human partners.},
author = {Gratch, Jonathan and Wang, Ning and Okhmatovskaia, Anna},
booktitle = {Proceedings of the 12th international conference on Human-computer interaction: intelligent multimodal interaction environments, HCI'07},
file = {::},
publisher = {Springer-Verlag Berlin, Heidelber},
title = {{Can virtual humans be more engaging than real ones?}},
url = {http://dl.acm.org/citation.cfm?id=1769622},
year = {2007}
}
@article{DiMatteo1980,
abstract = {The relationship between physicians' nonverbal communication skills (their ability to communicate and to understand facial expression, body movement and voice tone cues to emotion) and their patients' satisfaction with medical care was examined in 2 studies. The research involved 71 residents in internal medicine and 462 of their ambulatory and hospitalized patients. Standardized, reliable and valid measures of nonverbal communication skills were administered to the physicians. Their scores on these tests were correlated with ratings they received from a sample of their patients on measures of satisfaction with the technical aspects and the socioemotional aspects (or art) of the medical care they received. While the nonverbal communication skills of the physicians bore little relationship to patients' ratings of the technical quality of care, measures of these skills did predict patient satisfaction with the art of medical care received. Across both samples, physicians who were more sensitive to body movement and posture cues to emotion (the channel suggested by nonverbal researchers as the one in which true affect can be perceived) received higher ratings from their patients on the art of care than did less sensitive physicians. In addition, physicians who were successful at expressing emotion through their nonverbal communications tended to receive higher ratings from patients on the art of care than did physicians who were less effective communicators. The implications of successfully identifying characteristics of physicians with whom patients are satisfied are discussed.},
author = {DiMatteo, M R and Taranta, A and Friedman, H S and Prince, L M},
file = {::},
issn = {0025-7079},
journal = {Medical care},
keywords = {Adult,Consumer Satisfaction,Evaluation Studies as Topic,Female,Humans,Male,Nonverbal Communication,Physician-Patient Relations},
month = apr,
number = {4},
pages = {376--387},
pmid = {7401698},
title = {{Predicting patient satisfaction from physicians' nonverbal communication skills}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/7401698},
volume = {18},
year = {1980}
}
@article{Baldassarri2008,
abstract = {This paper presents a powerful animation engine for developing applications with embodied animated agents called Maxine. The engine, based on open source tools, allows management of scenes and virtual characters, and pays special attention to multimodal and emotional interaction with the user. Virtual actors are endowed with facial expressions, lip-synch, emotional voice, and they can vary their answers depending on their own emotional state and the relationship with the user during conversation. Maxine virtual agents have been used in several applications: a virtual presenter was employed in MaxinePPT, a specific application developed to allow non-programmers to create 3D presentations easily using classical PowerPoint presentations; a virtual character was also used as an interactive interface to communicate with and control a domotic environment; finally, an interactive pedagogical agent was used to simplify and improve the teaching and practice of Computer Graphics subjects.},
annote = {SummarizationThe system consists of a virtual character that can interact with the user via natural language for purposes such as teaching, presenting, and acting as an intermediate to a computer interface. The system gains supplemental information about the user via a camera, microphones, and a tracking system to determine their emotional state and level of engagement. The system can recognize user questions using natural language processing, and uses scripted AI markup language to answer them. The system maintains an internal emotional state, which is expressed through it's facial animations and voice quality.What is the same as what we have3D characterEmotional facial expressions
Hand gestures
TTS and lip syncAbility to recognize user's emotion from cameraWhat we have that they don'tSpecific focus on mirroring/empathyA well defined purposeA supplemental GUI for user inputWhat they have that we don'tAwareness of the user's position via a physical tracking systemAwareness of background noise (level of attention) in the room
Character's voice changes dynamically based on it's emotion
Their self built engine is more flexible in terms of ability
Speech recognition
Natural language processing + answer engine + pseudo AI
User gesture recognition (pointing, nods, etc)Reactive and deliberative behavior modulesFuture improvementDevelop a better human like avatarSettle on a specific purpose for the systemConduct a user study!WeaknessesThey never specifically say what kind of dialogs are possible with the system nor give examplesThis is not true AI, but rather a pre-scripted response system
They claim the character is "lifelike", but it is a robot; also, this is less empathetic than a human character
They bill the system as an "animation engine", which does not make much sense as really animation is only one of the many components involved
They tout the fact that users can interact via a scripting console, but this creates a source of alienation to a general (non-technical) user baseThey never give any sort of measure of how accurate the system is at anything (i.e. detecting emotion)},
author = {Baldassarri, Sandra and Cerezo, Eva and Seron, Francisco J.},
doi = {10.1016/j.cag.2008.04.006},
issn = {00978493},
journal = {Computers \& Graphics},
keywords = {animated characters,multimodal interfaces,natural interaction,virtual worlds},
month = aug,
number = {4},
pages = {430--437},
title = {{Maxine: A platform for embodied animated agents}},
url = {http://dx.doi.org/10.1016/j.cag.2008.04.006},
volume = {32},
year = {2008}
}
@article{Bavelas1986,
abstract = {Elementary motor mimicry (e.g., wincing when another is injured) has been previously considered in social psychology as the overt manifestation of some intrapersonal process such as vicarious emotion. A 2-part experiment with 50 university students tested the hypothesis that motor mimicry is instead an interpersonal event, a nonverbal communication intended to be seen by the other. Part 1 examined the effect of a receiver on the observer's motor mimicry. The victim of an apparently painful injury was either increasingly or decreasingly available for eye contact with the observer. Microanalysis showed that the pattern and timing of the observer's motor mimicry were significantly affected by the visual availability of the victim. In Part 2, naive decoders viewed and rated the reactions of these observers. Their ratings confirmed that motor mimicry was consistently decoded as "knowing" and "caring" and that these interpretations were significantly related to the experimental condition under which the reactions were elicited. Results cannot be explained by any alternative intrapersonal theory, so a parallel process model is proposed in which the eliciting stimulus may set off both internal reactions and communicative responses, and it is the communicative situation that determines the visable behavior. (37 ref) (PsycINFO Database Record (c) 2010 APA, all rights reserved)},
author = {Bavelas, Janet Beavin and Black, Alex and Lemery, Charles R. and Mullett, Jennifer},
doi = {10.1037/0022-3514.50.2.322},
file = {::},
journal = {Journal of Personality and Social Psychology},
number = {2},
pages = {322--329},
title = {{"I show how you feel" - Motor mimicry as a communicative act}},
url = {http://psycnet.apa.org/journals/psp/50/2/322/},
volume = {50},
year = {1986}
}
@article{Pereira2011,
author = {Pereira, A. and Leite, Iolanda and Mascarenhas, Samuel and Martinho, Carlos and Paiva, Ana},
file = {::},
journal = {Human-Robot Personal Relationships},
keywords = {companionship,empathy,human-robot interaction},
pages = {130--138},
publisher = {Springer},
title = {{Using empathy to improve human-robot relationships}},
url = {http://www.springerlink.com/index/R468X62581620V62.pdf},
volume = {59},
year = {2011}
}
@article{Silverman2001,
abstract = {The goal of this research is to determine whether a computer based training game (HEART-SENSE) can improve recognition of heart attack symptoms and shift behavioral issues so as to reduce pre-hospitalization delay in seeking treatment. Since treatment delay correlates with adverse outcomes, this research could reduce myocardial infarction mortality and morbidity. In Phase I we created and evaluated a prototype virtual village in which users encounter and help convince synthetic personas to deal appropriately with a variety of heart attack scenarios and delay issues. Innovations made here are: (1) a design for a generic simulator package for promoting health behavior shifts, and (2) algorithms for animated pedagogical agents to reason about how their emotional state ties to patient condition and user progress. Initial results show that users of the game exhibit a significant shift in intention to call 9-1-1 and avoid delay, that multi-media versions of the game foster vividness and memory retention as well as a better understanding of both symptoms and of the need to manage time during a heart attack event. Also, results provide insight into areas where emotive pedagogical agents help and hinder user performance. Finally, we conclude with next steps that will help improve the game and the field of pedagogical agents and tools for simulated worlds for healthcare education and promotion.},
author = {Silverman, B G and Holmes, John and Kimmel, Stephan and Branas, Charles and Ivins, Doug and Weaver, Ransom and Chen, Yi},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Silverman et al. - 2001 - Modeling emotion and behavior in animated personas to facilitate human behavior change the case of the HEART-SENSE game(4).pdf:pdf},
issn = {1386-9620},
journal = {Health care management science},
keywords = {Algorithms,Behavior Therapy,Computer Simulation,Computer-Assisted Instruction,Emotions,Experimental,Games,Humans,Models,Myocardial Infarction,Myocardial Infarction: diagnosis,Myocardial Infarction: physiopathology,Myocardial Infarction: psychology,Patient Acceptance of Health Care,Patient Acceptance of Health Care: psychology,Psychological,Software,United States},
month = sep,
number = {3},
pages = {213--28},
pmid = {11519847},
title = {{Modeling emotion and behavior in animated personas to facilitate human behavior change: the case of the HEART-SENSE game.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11519847},
volume = {4},
year = {2001}
}
@article{Zeng2009a,
abstract = {Automated analysis of human affective behavior has attracted increasing attention from researchers in psychology, computer science, linguistics, neuroscience, and related disciplines. However, the existing methods typically handle only deliberately displayed and exaggerated expressions of prototypical emotions despite the fact that deliberate behaviour differs in visual appearance, audio profile, and timing from spontaneously occurring behaviour. To address this problem, efforts to develop algorithms that can process naturally occurring human affective behaviour have recently emerged. Moreover, an increasing number of efforts are reported toward multimodal fusion for human affect analysis including audiovisual fusion, linguistic and paralinguistic fusion, and multi-cue visual fusion based on facial expressions, head movements, and body gestures. This paper introduces and surveys these recent advances. We first discuss human emotion perception from a psychological perspective. Next we examine available approaches to solving the problem of machine understanding of human affective behavior, and discuss important issues like the collection and availability of training and test data. We finally outline some of the scientific and engineering challenges to advancing human affect sensing technology.},
author = {Zeng, Zhihong and Pantic, Maja and Roisman, Glenn I and Huang, Thomas S.},
doi = {10.1109/TPAMI.2008.52},
file = {::},
isbn = {9781595938176},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Affect,Affect: physiology,Algorithms,Artificial Intelligence,Automated,Automated: methods,Emotions,Emotions: physiology,Facial Expression,Monitoring,Pattern Recognition,Physiologic,Physiologic: methods,Sound Spectrography,Sound Spectrography: methods},
month = jan,
number = {1},
pages = {39--58},
pmid = {19029545},
title = {{A survey of affect recognition methods: audio, visual, and spontaneous expressions.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19029545},
volume = {31},
year = {2009}
}
@inproceedings{Kang2008,
author = {Kang, Sin-hwa and Gratch, Jonathan and Wang, Ning and Watt, J.H.},
booktitle = {Proceedings of the 7th international joint conference on Autonomous agents and multiagent systems-Volume 1},
file = {::},
keywords = {agents,contingency of nonverbal feedback,evaluation,rapport,social anxiety,virtual humans},
number = {Aamas},
pages = {120--127},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
title = {{Does the contingency of agents' nonverbal feedback affect users' social anxiety?}},
url = {http://dl.acm.org/citation.cfm?id=1402405},
year = {2008}
}
@inproceedings{Wang2010,
address = {Atlanta, GA, USA},
author = {Wang, Ning and Gratch, Jonathan},
booktitle = {CHI},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - p1241-wang.pdf(6).pdf:pdf},
pages = {1241--1249},
title = {{Don't just stare at me.pdf}},
year = {2010}
}
@article{Wicker2003,
abstract = {What neural mechanism underlies the capacity to understand the emotions of others? Does this mechanism involve brain areas normally involved in experiencing the same emotion? We performed an fMRI study in which participants inhaled odorants producing a strong feeling of disgust. The same participants observed video clips showing the emotional facial expression of disgust. Observing such faces and feeling disgust activated the same sites in the anterior insula and to a lesser extent in the anterior cingulate cortex. Thus, as observing hand actions activates the observer's motor representation of that action, observing an emotion activates the neural representation of that emotion. This finding provides a unifying mechanism for understanding the behaviors of others.},
author = {Wicker, Bruno and Keysers, Christian and Plailly, Jane and Royet, Jean Pierre and Gallese, Vittorio and Rizzolatti, Giacomo},
doi = {10.1016/S0896-6273(03)00679-2},
institution = {Institut de Neurosciences Physiologiques et Cognitives, CNRS, Chemin Joseph Aiguier, 13402 cedex 20, Marseille, France.},
issn = {08966273},
journal = {Neuron},
keywords = {adult,brain mapping,cerebral cortex,cerebral cortex anatomy \& histology,cerebral cortex physiology,chemical,computer assisted,emotions,emotions physiology,facial expression,humans,image processing,magnetic resonance imaging,magnetic resonance imaging methods,male,ocular,ocular physiology,odors,photic stimulation,random allocation,stimulation,vision},
number = {3},
pages = {655--64},
pmid = {14642287},
publisher = {Elsevier},
title = {{Both of us disgusted in My insula: the common neural basis of seeing and feeling disgust.}},
volume = {40},
year = {2003}
}
@article{Busso2004,
author = {Busso, Carlos and Deng, Zhigang and Yildirim, Serdar and Bulut, Murtaza},
file = {::},
isbn = {1581138903},
journal = {ICMI'04},
pages = {1--7},
title = {{Analysis of emotion recognition using facial expressions, speech and multimodal information}},
url = {http://dl.acm.org/citation.cfm?id=1027968},
year = {2004}
}
@article{Huang2010,
author = {Huang, Lixing and Morency, Louis-Philippe and Gratch, Jonathan},
file = {::},
journal = {of the 9th International Conference on},
number = {Aamas},
pages = {10--14},
title = {{Parasocial consensus sampling: combining multiple perspectives to learn virtual human behavior}},
url = {http://dl.acm.org/citation.cfm?id=1838371},
year = {2010}
}
@article{Cowell2005,
abstract = {For years, people have sought more natural means of communicating with their computers. Many have suggested that interaction with a computer should be as easy as interacting with other people, taking advantage of the multimodal nature of human communication. While users should, in theory, gravitate to such anthropomorphic embodiments, quite the contrary has been experienced; users generally have been dissatisfied and abandoned their use. This suggests a disconnect between factors that make human-human communication engaging and those used by designers to support human-agent interaction. This paper discusses a set of empirical studies that attempted to replicate human-human non-verbal behavior. The focus revolved around behaviors that portray a credible fa\c{c}ade, thereby helping embodied conversational agents (ECAs) to form a successful cooperative dyad with users. Based on a review of the non-verbal literature, a framework was created that identified trustworthy and credible non-verbal behaviors across five areas and formed design guidelines for character interaction. The design suggestions for those areas emanating from the facial region were experimentally supported but there was no concordant increase in perceived trust when bodily regions (posture, gesture) were added. In addition, in examining the importance of demographic elements in embodiment, it was found that users prefer to interact with characters that match their ethnicity and are young looking. There was no significant preference for gender. The implications of these results, as well as other interesting consequences are discussed.},
author = {Cowell, Andrew J. and Stanney, Kay M.},
doi = {10.1016/j.ijhcs.2004.11.008},
file = {::},
issn = {10715819},
journal = {International Journal of Human-Computer Studies - Special issue: Subtle expressivity for characters and robots},
keywords = {Anthropomorphic interfaces,Interface agents,Non-verbal behavior},
month = feb,
number = {2},
pages = {281--306},
title = {{Manipulation of non-verbal interaction style and demographic embodiment to increase anthropomorphic computer character credibility}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1071581904001260 http://ocw.tudelft.nl/fileadmin/ocw/opener/Manipulation\_of\_non-verbal\_interaction\_style\_and\_demographic\_embodiment\_to\_increase\_anthropomorphic\_computer\_character\_credibility.pdf},
volume = {62},
year = {2005}
}
@incollection{Chartrand2005,
author = {Chartrand, T. L. and Maddux, W W and Lakin, J. L.},
booktitle = {The new unconscious},
file = {::},
pages = {334--361},
publisher = {Oxford University Press New York},
title = {{Beyond the perception-behavior link: The ubiquitous utility and motivational moderators of nonconscious mimicry}},
year = {2005}
}
@article{Peter2003,
author = {Sonnby-borgstr\"{o}m, Marianne and Jonsson, Peter and Svensson, Owe},
file = {::},
journal = {Journal of Nonverbal},
keywords = {emg,emotional contagion,empathy,facial expressions,facial mim-,icry,mirror neurons},
number = {1},
pages = {3--23},
title = {{Emotional empathy as related to mimicry reactions at different levels of information processing}},
url = {http://www.springerlink.com/index/P81X69QTH751V836.pdf},
volume = {27},
year = {2003}
}
@article{Bavelas1986,
abstract = {Elementary motor mimicry (e.g., wincing when another is injured) has been previously considered in social psychology as the overt manifestation of some intrapersonal process such as vicarious emotion. A 2-part experiment with 50 university students tested the hypothesis that motor mimicry is instead an interpersonal event, a nonverbal communication intended to be seen by the other. Part 1 examined the effect of a receiver on the observer's motor mimicry. The victim of an apparently painful injury was either increasingly or decreasingly available for eye contact with the observer. Microanalysis showed that the pattern and timing of the observer's motor mimicry were significantly affected by the visual availability of the victim. In Part 2, naive decoders viewed and rated the reactions of these observers. Their ratings confirmed that motor mimicry was consistently decoded as "knowing" and "caring" and that these interpretations were significantly related to the experimental condition under which the reactions were elicited. Results cannot be explained by any alternative intrapersonal theory, so a parallel process model is proposed in which the eliciting stimulus may set off both internal reactions and communicative responses, and it is the communicative situation that determines the visable behavior. (37 ref) (PsycINFO Database Record (c) 2010 APA, all rights reserved)},
author = {Bavelas, Janet Beavin and Black, Alex and Lemery, Charles R. and Mullett, Jennifer},
doi = {10.1037/0022-3514.50.2.322},
file = {::},
journal = {Journal of Personality and Social Psychology},
number = {2},
pages = {322--329},
title = {{"I show how you feel" - Motor mimicry as a communicative act}},
url = {http://psycnet.apa.org/journals/psp/50/2/322/},
volume = {50},
year = {1986}
}
@inproceedings{Heerink2009,
author = {Heerink, Marcel and Krose, B. and Evers, Vanessa and Wielinga, Bob},
booktitle = {Robot and Human Interactive Communication, 2009. RO-MAN 2009. The 18th IEEE International Symposium on},
file = {::},
pages = {528--533},
publisher = {Ieee},
title = {{Measuring acceptance of an assistive social robot: a suggested toolkit}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5326320},
year = {2009}
}
@article{Becker-Asano2009,
abstract = {We introduce theWASABI ([W]ASABI [A]ffect [S]imulation for [A]gents with [B]elievable [I]nteractivity)Affect SimulationArchitecture, in which a virtual human’s cog- nitive reasoning capabilities are combined with simulated embodiment to achieve the sim- ulation of primary and secondary emotions. In modeling primary emotions we follow the idea of “Core Affect” in combination with a continuous progression of bodily feeling in three-dimensional emotion space (PADspace), that is subsequently categorized into discrete emotions. In humans, primary emotions are understood as onto-genetically earlier emotions, which directly influence facial expressions. Secondary emotions, in contrast, afford the abil- ity to reason about current events in the light of experiences and expectations.},
author = {Becker-Asano, Christian and Wachsmuth, Ipke},
doi = {10.1007/s10458-009-9094-9},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Becker-Asano, Wachsmuth - 2009 - Affective computing with primary and secondary emotions in a virtual human(3).pdf:pdf},
issn = {1387-2532},
journal = {Autonomous Agents and Multi-Agent Systems},
keywords = {affect simulation,affective computing,affective gaming,architecture,aware emotions,bdi-based architecture,embodied agent,emotion dynamics,emotion expression,emotion modeling,pad emotion space,primary and secondary emotions,reality,virtual,virtual human},
month = may,
number = {1},
pages = {32--49},
title = {{Affective computing with primary and secondary emotions in a virtual human}},
url = {http://www.becker-asano.de/AffectiveComputingWithPrimaryAndSecondaryEmotionsInAVirtualHuman.pdf},
volume = {20},
year = {2009}
}
@article{Wu2008,
author = {Wu, Siew-Rong},
doi = {10.1109/DIGITEL.2008.27},
file = {::},
isbn = {978-0-7695-3409-1},
journal = {2008 Second IEEE International Conference on Digital Game and Intelligent Toy Enhanced Learning},
pages = {213--214},
publisher = {Ieee},
title = {{Humor and Empathy: Developing Students' Empathy through Teaching Robots to Tell English Jokes}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4700764},
year = {2008}
}
@article{Cliffordson2002,
abstract = {The purpose of the present study was to examine the structure of empathy using a hierarchical approach, and to compare the dimensions of empathy with measures of social functioning, in order to contribute to the understanding of the nature of empathy. The dimensionality of the Interpersonal Reactivity Index, which comprises four subscales (empathic concern, perspective taking, fantasy and personal distress) was examined using confirmatory factor analysis. Relations with the Social Skills Inventory were also investigated. A sample of 127 applicants for places on nursing and social work undergraduate programs participated in the study. The study findings indicate that empathy is hierarchically organized, with one general dimension at the apex. The general factor is identical to empathic concern and this dimension overlaps to a great extent with perspective taking and fantasy. The findings also indicate that the general dimension constitutes an integrated entirety, with its main emphasis on emotional reactivity by also involving cognitive processes.},
author = {Cliffordson, Christina},
doi = {10.1111/1467-9450.00268},
file = {::},
issn = {0036-5564},
journal = {Scandinavian journal of psychology},
keywords = {Empathy,Factor Analysis,Humans,Social Behavior,Statistical},
month = feb,
number = {1},
pages = {49--59},
pmid = {11885760},
title = {{The hierarchical structure of empathy: dimensional organization and relations to social functioning}},
url = {http://onlinelibrary.wiley.com/doi/10.1111/1467-9450.00268/abstract},
volume = {43},
year = {2002}
}
@inproceedings{Kang2008,
author = {Kang, Sin-hwa and Gratch, Jonathan and Wang, Ning and Watt, J.H.},
booktitle = {Proceedings of the 7th international joint conference on Autonomous agents and multiagent systems-Volume 1},
file = {::},
keywords = {agents,contingency of nonverbal feedback,evaluation,rapport,social anxiety,virtual humans},
number = {Aamas},
pages = {120--127},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
title = {{Does the contingency of agents' nonverbal feedback affect users' social anxiety?}},
url = {http://dl.acm.org/citation.cfm?id=1402405},
year = {2008}
}
@article{Ververidis2006,
author = {Ververidis, Dimitrios},
file = {::},
journal = {Speech communication},
keywords = {acoustic features,emotional speech classification,emotional speech data collections,emotions,interfaces,stress},
number = {April},
title = {{Emotional speech recognition: Resources, features, and methods}},
url = {http://www.sciencedirect.com/science/article/pii/S0167639306000422},
year = {2006}
}
@book{Andreassi2009,
author = {Andreassi, John L.},
edition = {5},
isbn = {978-0805828337},
pages = {488},
publisher = {Taylor \& Francis},
title = {{Psychophysiology: Human Behavior and Physiological Response}},
year = {2009}
}
@article{Boukricha2011b,
author = {Boukricha, Hana and Nguyen, H.},
file = {::},
journal = {Intelligent Virtual Agents},
pages = {350--362},
title = {{Sharing Emotions and Space – Empathy as a Basis for}},
url = {http://www.springerlink.com/index/Q22784632U008337.pdf},
year = {2011}
}
@article{Pennebaker2003,
abstract = {The words people use in their daily lives can reveal important aspects of their social and psychological worlds. With advances in computer technology, text analysis allows researchers to reliably and quickly assess features of what people say as well as subtleties in their linguistic styles. Following a brief review of several text analysis programs, we summarize some of the evidence that links natural word use to personality, social and situational fluctuations, and psychological interventions. Of particular interest are findings that point to the psychological value of studying particles-parts of speech that include pronouns, articles, prepositions, conjunctives, and auxiliary verbs. Particles, which serve as the glue that holds nouns and regular verbs together, can serve as markers of emotional state, social identity, and cognitive styles.},
author = {Pennebaker, James W and Mehl, Matthias R and Niederhoffer, Kate G},
doi = {10.1146/annurev.psych.54.101601.145041},
editor = {Guo, Li},
isbn = {0973403942},
issn = {00664308},
journal = {Annual Review of Psychology},
keywords = {artificial intelligence,emotions,health status,humans,individuality,interpersonal relations,mental health,natural language processing,personality,psycholinguistics,semantics,social environment,verbal behavior},
number = {1},
pages = {547--77},
pmid = {12185209},
publisher = {Annual Reviews},
title = {{Psychological aspects of natural language. use: our words, our selves.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12185209},
volume = {54},
year = {2003}
}
@article{Liu2010,
abstract = {Emotions accompany everyone in the daily life, playing a key role in non-verbal communication, and they are essential to the understanding of human behavior. Emotion recognition could be done from the text, speech, facial expression or gesture. In this paper, we concentrate on recognition of “inner” emotions from electroencephalogram (EEG) signals as humans could control their facial expressions or vocal intonation. The need and importance of the automatic emotion recognition from EEG signals has grown with increasing role of brain computer interface applications and development of new forms of human-centric and humandriven interaction with digital media. We propose fractal dimension based algorithm of quantification of basic emotions and describe its implementation as a feedback in 3D virtual environments. The user emotions are recognized and visualized in real time on his/her avatar adding one more so-called “emotion dimension” to human computer interfaces.},
author = {Liu, Yisi and Sourina, Olga and Nguyen, Minh Khoa},
doi = {10.1109/CW.2010.37},
file = {::},
isbn = {978-1-4244-8301-3},
journal = {2010 International Conference on Cyberworlds},
keywords = {BCI,EEG,HCI,emotion recognition,emotion visualization,fractal dimension},
month = oct,
pages = {262--269},
publisher = {Ieee},
title = {{Real-Time EEG-Based Human Emotion Recognition and Visualization}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5656346},
year = {2010}
}
@article{Vanbaaren2004,
author = {Van baaren, Rick B. and Holland, Rob W. and Kawakami, Kerry and Knippenberg, Ad Van},
doi = {10.1111/j.0963-7214.2004.01501012.x},
file = {::},
issn = {0956-7976},
journal = {Psychological Science},
month = jan,
number = {1},
pages = {71--74},
title = {{Mimicry and Prosocial Behavior}},
url = {http://pss.sagepub.com/lookup/doi/10.1111/j.0963-7214.2004.01501012.x},
volume = {15},
year = {2004}
}
@article{Bickmore2005,
abstract = {This research investigates the meaning of “human-computer relationship” and presents techniques for constructing, maintaining, and evaluating such relationships, based on research in social psychology, sociolinguistics, communication and other social sciences. Contexts in which relationships are particularly important are described, together with specific benefits (like trust) and task outcomes (like improved learning) known to be associated with relationship quality. We especially consider the problem of designing for long-term interaction, and define relational agents as computational artifacts designed to establish and maintain long-term social-emotional relationships with their users. We construct the first such agent, and evaluate it in a controlled experiment with 101 users who were asked to interact daily with an exercise adoption system for a month. Compared to an equivalent task-oriented agent without any deliberate social-emotional or relationship-building skills, the relational agent was respected more, liked more, and trusted more, even after four weeks of interaction. Additionally, users expressed a significantly greater desire to continue working with the relational agent after the termination of the study. We conclude by discussing future directions for this research together with ethical and other ramifications of this work for HCI designers.},
author = {Bickmore, Timothy W. and {Rosalind W. Picard}},
doi = {10.1145/1067860.1067867},
file = {::},
journal = {ACM Transactions on Computer-Human Interaction (TOCHI)},
keywords = {Human-computer interaction,embodied conversational agent,relational agent,social interface},
number = {2},
pages = {617--638},
title = {{Establishing and maintaining long-term human-computer relationships}},
url = {http://dl.acm.org/citation.cfm?id=1067860.1067867},
volume = {12},
year = {2005}
}
@article{Boukricha2011,
author = {Boukricha, Hana and Wachsmuth, Ipke},
doi = {10.1007/s13218-011-0109-8},
file = {::},
issn = {0933-1875},
journal = {KI - K\"{u}nstliche Intelligenz},
keywords = {agent-agent interaction,empathic virtual humans,human-agent,internal simulation},
month = may,
number = {3},
pages = {195--204},
title = {{Empathy-Based Emotional Alignment for a Virtual Human: A Three-Step Approach}},
url = {http://www.springerlink.com/index/10.1007/s13218-011-0109-8},
volume = {25},
year = {2011}
}
@article{Munhall2004,
abstract = {People naturally move their heads when they speak, and our study shows that this rhythmic head motion conveys linguistic information. Three-dimensional head and face motion and the acoustics of a talker producing Japanese sentences were recorded and analyzed. The head movement correlated strongly with the pitch (fundamental frequency) and amplitude of the talker's voice. In a perception study, Japanese subjects viewed realistic talking-head animations based on these movement recordings in a speech-in-noise task. The animations allowed the head motion to be manipulated without changing other characteristics of the visual or acoustic speech. Subjects correctly identified more syllables when natural head motion was present in the animation than when it was eliminated or distorted. These results suggest that nonverbal gestures such as head movements play a more direct role in the perception of speech than previously known.},
author = {Munhall, K G and Jones, Jeffery A and Callan, Daniel E and Kuratate, Takaaki and Vatikiotis-Bateson, Eric},
institution = {Department of Psychology, Queen's University, Kingston, Ontario, Canada. munhallk@psyc.queensu.ca},
journal = {Psychological Science},
keywords = {adult,biomechanics,facial expression,female,gestures,head movements,humans,imaging,male,perceptual distortion,phonetics,semantics,sound localization,sound spectrography,speech acoustics,speech intelligibility,speech perception,three dimensional,user computer interface},
number = {2},
pages = {133--137},
pmid = {14738521},
publisher = {SAGE Publications},
title = {{Visual prosody and speech intelligibility: head movement improves auditory speech perception.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/14738521},
volume = {15},
year = {2004}
}
@article{Friesen1983,
author = {Friesen, Wallace V and Ekman, Paul},
journal = {Unpublished manuscript, University of California at San Francisco},
publisher = {University of California},
title = {{EMFACS-7: Emotional Facial Action Coding System}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:EMFACS-7:+Emotional+Facial+Action+Coding+System\#0},
year = {1983}
}
@article{Ververidis2006,
author = {Ververidis, Dimitrios},
file = {::},
journal = {Speech communication},
keywords = {acoustic features,emotional speech classification,emotional speech data collections,emotions,interfaces,stress},
number = {April},
title = {{Emotional speech recognition: Resources, features, and methods}},
url = {http://www.sciencedirect.com/science/article/pii/S0167639306000422},
year = {2006}
}
@article{Pelachaud2009,
abstract = {Over the past few years we have been developing an expressive embodied conversational agent system. In particular, we have developed a model of multimodal behaviours that includes dynamism and complex facial expressions. The first feature refers to the qualitative execution of behaviours. Our model is based on perceptual studies and encompasses several parameters that modulate multimodal behaviours. The second feature, the model of complex expressions, follows a componential approach where a new expression is obtained by combining facial areas of other expressions. Lately we have been working on adding temporal dynamism to expressions. So far they have been designed statically, typically at their apex. Only full-blown expressions could be modelled. To overcome this limitation, we have defined a representation scheme that describes the temporal evolution of the expression of an emotion. It is no longer represented by a static definition but by a temporally ordered sequence of multimodal signals.},
author = {Pelachaud, Catherine},
doi = {10.1098/rstb.2009.0186},
file = {::},
issn = {1471-2970},
journal = {Philosophical transactions of the Royal Society of London. Series B, Biological sciences},
keywords = {Computer Simulation,Emotions,Emotions: physiology,Facial Expression,Humans,Models, Psychological,Social Behavior},
month = dec,
number = {1535},
pages = {3539--48},
pmid = {19884148},
title = {{Modelling multimodal expression of emotion in a virtual agent.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2781894\&tool=pmcentrez\&rendertype=abstract},
volume = {364},
year = {2009}
}
@article{Busso2004,
author = {Busso, Carlos and Deng, Zhigang and Yildirim, Serdar and Bulut, Murtaza},
file = {::},
isbn = {1581138903},
journal = {ICMI'04},
pages = {1--7},
title = {{Analysis of emotion recognition using facial expressions, speech and multimodal information}},
url = {http://dl.acm.org/citation.cfm?id=1027968},
year = {2004}
}
@inproceedings{DeCarlo2002,
abstract = {People highlight the intended interpretation of their utterances within a larger discourse by a diverse set of nonverbal signals. These signals represent a key chal- lenge for animated conversational agents because they are pervasive, variable, and need to be coordinated ju- diciously in an effective contribution to conversation. In this paper, we describe a freely-available cross-platform real-time facial animation system, RUTH, that animates such high-level signals in synchrony with speech and lip movements. RUTH adopts an open, layered archi- tecture in which fine-grained features of the animation can be derived by rule from inferred linguistic structure, allowing us to use RUTH, in conjunction with annota- tion of observed discourse, to investigate the meaningful high-level elements of conversational facial movement for American English speakers.},
author = {DeCarlo, D. and Revilla, C. and Stone, Matthew and Venditti, J.J.},
booktitle = {Proceedings of Computer Animation 2002 (CA 2002)},
doi = {10.1109/CA.2002.1017501},
file = {::},
isbn = {0-7695-1594-0},
number = {Ca},
pages = {11--16},
publisher = {IEEE Comput. Soc},
title = {{Making discourse visible: coding and animating conversational facial displays}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1017501},
volume = {2002},
year = {2002}
}
@article{Page2002,
abstract = {In the Ultimatum Game, two players are asked to split a prize. The first player, the proposer, makes an offer of how to split the prize. The second player, the responder, either accepts the offer, in which case the prize is split as agreed, or rejects it, in which case neither player receives anything. The rational strategy suggested by classical game theory is for the proposer to offer the smallest possible positive share and for the responder to accept. Humans do not play this way, however, and instead tend to offer 50\% of the prize and to reject offers below 20\%. Here we study the Ultimatum Game in an evolutionary context and show that empathy can lead to the evolution of fairness. Empathy means that individuals make offers which they themselves would be prepared to accept.},
author = {Page, Karen M and Nowak, Martin a},
doi = {10.1006/bulm.2002.0321},
file = {::},
issn = {0092-8240},
journal = {Bulletin of mathematical biology},
keywords = {Biological Evolution,Choice Behavior,Empathy,Games, Experimental,Humans,Models, Psychological,Social Behavior},
month = nov,
number = {6},
pages = {1101--16},
pmid = {12508533},
title = {{Empathy leads to fairness.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/12508533},
volume = {64},
year = {2002}
}
@incollection{Wispe1987,
author = {Wisp\'{e}, L},
booktitle = {Empathy and its development},
chapter = {2},
editor = {Einsenberg, Nancy and Strayer, Janet},
isbn = {0521326095},
issn = {05213260},
pages = {17--37},
publisher = {Cambridge University Press},
title = {{History of the concept of empathy}},
year = {1987}
}
@book{Goldstein1985,
author = {Goldstein, Arnold P. and Michaels, Gerald Y.},
edition = {1},
isbn = {089859538X},
pages = {304},
publisher = {Hillsdale, N.J. : L. Erlbaum Associates},
title = {{Empathy: development, training, and consequences}},
year = {1985}
}
@article{Lafrance1979,
author = {Lafrance, Marianne},
file = {::},
journal = {Social Psychology},
number = {1},
pages = {66--70},
title = {{Nonverbal Synchrony Panel Technique: Analysis by the Cross-Lag and Rapport}},
volume = {42},
year = {1979}
}
@article{Ochs2010,
author = {Ochs, Magalie and Sadek, David and Pelachaud, Catherine},
doi = {10.1007/s10458-010-9156-z},
file = {::},
issn = {1387-2532},
journal = {Autonomous Agents and Multi-Agent Systems},
keywords = {affective computing,dialog,emotions,empathy,rational dialog agent},
month = nov,
title = {{A formal model of emotions for an empathic rational dialog agent}},
url = {http://www.springerlink.com/index/10.1007/s10458-010-9156-z},
year = {2010}
}
@article{Lien1998,
author = {Lien, James J and Cohn, Jeffrey F and Kanade, Takeo and Li, Ching-Chung},
file = {::},
journal = {IEEE Proceedings of FG'98},
title = {{Automated Facial Expression Recognition Based on FACS Action Units University of Pittsburgh Takeo Kanade Vision and Autonomous Systems Center Ching-Chung Li}},
year = {1998}
}
@inproceedings{Gama2011,
abstract = {Over the last decade extensive research has been conducted in the area of conversational agents focusing in many different aspects of these agents. In this research, and aiming at building agents that maintain a social connection with users, empathy has been one of those areas, as it plays a leading role in the establishment of social relationships. In this paper we present a relationship model of empathy that takes advantage of Social Penetration Theory's concepts for relationship building. This model has been implemented into an agent that attempts to establish a relationship with the user, expressing empathy both verbally and visually. The visual expression of empathy consists of facial expression and physical proximity representation. The user tests performed showed that while users were able to develop a simple relationship with the agents, they however developed stronger relationships with a version of the agent that is most visually expressive and takes advantage of the proximity element, confirming the significance of our model based on social penetration theory may have and, consequently, the importance of the visual representation of empathic responses.},
address = {Memphis, TN, USA},
author = {Gama, Sandra and Barata, Gabriel and Gon\c{c}alves, D. and Prada, R. and Paiva, Ana},
booktitle = {ACII'11 Proceedings of the 4th international conference on Affective computing and intelligent interaction - Volume Part I},
doi = {10.1007/978-3-642-24600-5\_54},
editor = {{D'Mello, Sidney K. and Graesser, Arthur C. and Schuller, Bj\"{o}rn and Martin}, Jean-Claude},
file = {::},
keywords = {affective computing,conversational agent,empathic agent},
pages = {507--516},
publisher = {Springer Berlin / Heidelberg},
title = {{SARA: social affective relational agent: a study on the role of empathy in artificial social agents}},
url = {http://www.springerlink.com/content/g0433kx744258w62/},
year = {2011}
}
@inproceedings{Gratch2007,
abstract = {Emotional bonds don’t arise from a simple exchange of facial displays, but often emerge through the dynamic give and take of face-to-face interactions. This article explores the phenome- non of rapport, a feeling of connectedness that seems to arise from rapid and contingent positive feedback between partners and is often associated with socio-emotional processes. Rapport has been argued to lead to communicative efficiency, better learning outcomes, improved acceptance of medical advice and successful negotiations. We provide experimental evidence that a simple vir- tual character that provides positive listening feedback can induce stronger rapport-like effects than face-to-face communication between human partners. Specifically, this interaction can be more en- gaging to storytellers than speaking to a human audience, as measured by the length and content of their stories.},
address = {Chamonix, France},
annote = {They explore the rapport, a feeling of connectedness that arises from rapid and contingent positive feedback between partners and is often associated with socio-emotional processes. Rapport can lead to communicative efficiency, better learning outcomes, improved acceptance of medical advice and successful negotiations.
They experimentally proved that a simple virtual character with positive listening feedback can induce stronger rapport-like effects than face-to-face communication between human partners.},
author = {Gratch, Jonathan and Wang, Ning and Okhmatovskaia, Anna},
booktitle = {Proceedings of the 12th international conference on Human-computer interaction: intelligent multimodal interaction environments, HCI'07},
file = {::},
publisher = {Springer-Verlag Berlin, Heidelber},
title = {{Can virtual humans be more engaging than real ones?}},
url = {http://dl.acm.org/citation.cfm?id=1769622},
year = {2007}
}
@article{Wang2009,
annote = {Out of three components of rapport by Tickle-Degnene and Rosenthal (mutual attentiveness, positivity, and coordination), they investigated the relationship between human speakers' facial expression and rapport. Results show that recognizing positive facial expressions alone is insufficient but negative facial displays are more effective in assessing the level of rapport between participants.},
author = {Wang, Ning},
doi = {10.1109/ACII.2009.5349514},
file = {::},
isbn = {978-1-4244-4800-5},
journal = {and Workshops, 2009. ACII 2009. 3rd},
month = sep,
pages = {1--6},
publisher = {Ieee},
title = {{Rapport and facial expression}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5349514 http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5349514},
year = {2009}
}
@book{Hojat2007,
author = {Hojat, Mohammadreza},
booktitle = {Patient Care},
file = {::},
isbn = {9780387336077},
publisher = {Springer Verlag},
title = {{Empathy in patient care: antecedents, development, measurement, and outcomes}},
year = {2007}
}
@inproceedings{Cavazza2010,
abstract = {This paper presents a dialogue system in the form of an ECA that acts as a socia- ble and emotionally intelligent compan- ion for the user. The system dialogue is not task-driven but is social conversation in which the user talks about his/her day at the office. During conversations the system monitors the emotional state of the user and uses that information to in- form its dialogue turns. The system is able to respond to spoken interruptions by the user, for example, the user can in- terrupt to correct the system. The system is already fully implemented and aspects of actual output will be used to illustrate.},
address = {The University of Tokyo},
author = {Cavazza, Marc and Vargas, C Emilio and Gil, Jos\'{e} Rela\~{n}o and Telef\'{o}nica, I D and Crook, Nigel and Field, Debora and Sheffield, S},
booktitle = {Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
file = {::},
pages = {277--280},
publisher = {Association for Computational Linguistics},
title = {{‘ How was your day ?’ An affective companion ECA prototype}},
volume = {1},
year = {2010}
}
@article{Boukricha2011,
author = {Boukricha, Hana and Wachsmuth, Ipke},
doi = {10.1007/s13218-011-0109-8},
file = {::},
issn = {0933-1875},
journal = {KI - K\"{u}nstliche Intelligenz},
keywords = {agent-agent interaction,empathic virtual humans,human-agent,internal simulation},
month = may,
number = {3},
pages = {195--204},
title = {{Empathy-Based Emotional Alignment for a Virtual Human: A Three-Step Approach}},
volume = {25},
year = {2011}
}
@article{Lakin2003,
abstract = {The “chameleon effect” refers to the tendency to adopt the postures, gestures, and mannerisms of interaction partners (Chartrand \& Bargh, 1999). This type of mimicry occurs outside of conscious awareness, and without any intent to mimic or imitate. Empirical evidence suggests a bi-directional relationship between nonconscious mimicry on the one hand, and liking, rapport, and affiliation on the other. That is, nonconscious mimicry creates affiliation, and affiliation can be expressed through nonconscious mimicry. We argue that mimicry played an important role in human evolution. Initially, mimicry may have had survival value by helping humans communicate. We propose that the purpose of mimicry has now evolved to serve a social function. Nonconscious behavioral mimicry increases affiliation, which serves to foster relationships with others.},
annote = {nonconscious mimicry creates affiliation, and affiliation can be expressed through nonconscious mimicry.
Initially, mimicry may have had survival value by helping humans communicate. The purpose of mimicry has now evolved to serve a social function. Nonconscious behavioral mimicry increases affiliation, which serves to foster relationships with others.
Empathic individuals mimic people more that people low in empathy.},
author = {Lakin, J. L. and Jefferis, VE and Cheng, CM},
file = {::},
journal = {Journal of nonverbal},
keywords = {1994,1999,2000,2001a,affiliation,and sometimes from,animals,aronson,caporael,chameleon effect,dusk to dawn,ehrlich,from dawn to dusk,human beings are social,human evolution,mimicry,our lives are filled,we talk to signif-,with social interactions,wright},
number = {3},
pages = {145--162},
title = {{The chameleon effect as social glue: Evidence for the evolutionary significance of nonconscious mimicry}},
volume = {27},
year = {2003}
}
@article{Shields2005,
abstract = {OBJECTIVES: To develop a reliable and valid computer coded measure to assess emotional expression from transcripts of physician-patient interactions. METHODS: Physician encounters with two standardized patients (SPs) were audiotaped. Fifty patients from each physician (n = 100 primary care physicians) completed surveys that assessed patients' perceptions of their relationships with physicians. Audio-recordings of 193 patient-physician encounters were transcribed and computer-coded to derive a percent emotion words, and research assistants completed the Measure of Patient-Centered Communication (MPCC). RESULTS: After adjustment for potential confounders, regression analyses revealed physicians' use of emotion words and the MPCC contribute independently to patients' and SPs' perceptions of their relationship with physicians. CONCLUSIONS: The computerized coding of emotion words shows promise as a reliable, valid, and simple method to code transcript data of physician-patient interactions. This method may be expanded to examine other aspects of physician language and does not require coder training.},
author = {Shields, Cleveland G and Epstein, Ronald M and Franks, Peter and Fiscella, Kevin and Duberstein, Paul and McDaniel, Susan H and Meldrum, Sean},
institution = {Department of Family Medicine, University of Rochester Medical Center, Rochester Center to Improve Communication in Health Care, 1381 South Avenue, Rochester, NY 14620-2830, USA. Cleveland\_Shields@URMC.Rochester.edu},
journal = {Patient Education and Counseling},
number = {2},
pages = {232--238},
pmid = {15911198},
publisher = {Elsevier},
title = {{Emotion language in primary care encounters: reliability and validity of an emotion word count coding system.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15911198},
volume = {57},
year = {2005}
}
@article{Robison2010,
abstract = {affective interventions can both positively and negatively influence learning experiences. In this paper we investigate the role of student personality, including goal orienta- tion and empathetic tendencies, in estimating confidence in the benefits of an affective intervention strategy. The results indicate that student personality profiles can serve as a powerful tool for informing affective feedback models.},
annote = {We can use the same way of menu base self-report affective state recognition (in addition to automatic) and text-base empathic feedback. Then after each feedback we can evaluate the feedback with another user self-report.},
author = {Robison, Jennifer and McQuiggan, Scott W and Lester, James and Carolina, North},
keywords = {affect,affective computing,pedagogical agents},
pages = {285--295},
title = {{Developing Empirically Based Student Personality Profiles for Affective Feedback Models}},
year = {2010}
}
@incollection{Pereira2008,
abstract = {Emotional-BDI agents are BDI agents whose behaviour is guided not only by beliefs, desires and intentions, but also by the role of emotions in reasoning and decision-making. The EBDI logic is a formal sys- tem for expressing the concepts of the Emotional-BDI model of agency. In this paper we present an improved version of the EBDI logic and show how it can be used to model the role of three emotions in Emotional-BDI agents: fear, anxiety and self-confidence. We also focus in the computa- tional properties of EBDI which can lead to its use in automated proof systems.},
author = {Pereira, David},
booktitle = {Computational Logic in Multi-Agent Systems},
doi = {10.1007/978-3-540-88833-8\_4},
editor = {Sadri, Fariba and Satoh, Ken},
file = {::},
isbn = {978-3-540-88832-1},
pages = {62--81},
publisher = {Springer-Verlag},
title = {{Formal Modelling of Emotions in BDI Agents}},
year = {2008}
}
@article{Campbell1994,
abstract = {OBJECTIVES. To achieve the Healthy People 2000 objectives, public health professionals must develop effective dietary interventions that address psychosocial and behavioral components of change. This study tested the effect of individually computer-tailored messages designed to decrease fat intake and increase fruit and vegetable intake. METHODS. Adult patients from four North Carolina family practices were surveyed at baseline and then randomly assigned to one of two interventions or to a control group. The first intervention consisted of individually computer-tailored nutrition messages; the second consisted of nontailored nutrition information based on the 1990 Dietary Guidelines for Americans. Patients were resurveyed 4 months postintervention. RESULTS. The tailored intervention produced significant decreases in total fat and saturated fat scores compared with those of the control group (P < .05). Total fat was decreased in the tailored group by 23\%, in the nontailored group by 9\%, and in the control group by 3\%. Fruit and vegetable consumption did not increase in any study group. Seventy-three percent of the tailored intervention group recalled receiving a message, compared with 33\% of the nontailored intervention group. CONCLUSIONS. Tailored nutrition messages are effective in promoting dietary fat reduction for disease prevention.},
author = {Campbell, M K and DeVellis, B M and Strecher, V J and Ammerman, A S and DeVellis, R F and Sandler, R S},
institution = {Department of Health Behavior, Department of Nutrition, School of Public Health, University of North Carolina, Chapel Hill 27599-7400.},
journal = {American Journal of Public Health},
number = {5},
pages = {783--787},
title = {{Improving dietary behavior: the effectiveness of tailored messages in primary care settings.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1615043\&tool=pmcentrez\&rendertype=abstract},
volume = {84},
year = {1994}
}
@article{Miller1996,
abstract = {The Stages of Change Readiness and Treatment Eagerness Scale (SOCRATES) is an instrument designed to assess motivation for change in problem drinkers. Data from a multisite clinical sample ( N = 1,672) and a test-retest study ( N = 82) provided support for the reliability of SOCRATES scales. Factor analyses yielded 3 relatively unrelated factors that were stable across rotations: Recognition, Ambivalence, and Taking Steps. Recognition scores at baseline were found to be mildly related to intensity of alcohol consumption and problems. Comparable scale scores resulted from short (19-item) and longer (39-item) forms of the instrument. Normative data are provided for the short form.},
author = {Miller, W. R. and Tonigan, J. S.},
journal = {Psychology of Addictive Behaviors},
number = {2},
pages = {81--89},
title = {{Assessing drinkers' motivation for change: The Stages of Change Readiness and Treatment Eagerness Scale (SOCRATES)}},
volume = {10},
year = {1996}
}
@article{Lang1995,
abstract = {Emotions are action dispositions--states of vigilant readiness that vary widely in reported affect, physiology, and behavior. They are driven, however, by only 2 opponent motivational systems, appetitive and aversive--subcortical circuits that mediate reactions to primary reinforcers. Using a large emotional picture library, reliable affective psychophysiologies are shown, defined by the judged valence (appetitive/pleasant or aversive/unpleasant) and arousal of picture percepts. Picture-evoked affects also modulate responses to independently presented startle probe stimuli. In other words, they potentiate startle reflexes during unpleasant pictures and inhibit them during pleasant pictures, and both effects are augmented by high picture arousal. Implications are elucidated for research in basic emotions, psychopathology, and theories of orienting and defense. Conclusions highlight both the approach's constraints and promising paths for future study.},
author = {Lang, P J},
file = {::},
issn = {0003-066X},
journal = {The American psychologist},
keywords = {Affect,Arousal,Attention,Blinking,Humans,Mental Disorders,Mental Disorders: psychology,Motivation,Startle Reaction},
month = may,
number = {5},
pages = {372--85},
pmid = {7762889},
title = {{The emotion probe. Studies of motivation and attention.}},
volume = {50},
year = {1995}
}
@article{DeRosis2006a,
abstract = {We propose a theory of a-rational persuasion in which we integrate emotional and non emotional strategies by arguing that they both imply reasoning and planning abilities in the two participants. We show some examples of texts from a corpus of persuasion messages in the healthy eating domain and propose a formalism to represent this knowledge. The final goal of our research is to simulate user-adapted persuasion dialogs about healthy eating.},
author = {{De Rosis}, Fiorella and Mazzotta, Irene and Miceli, Maria and Poggi, Isabella},
doi = {10.1007/11755494\_12},
journal = {Persuasive Technology},
pages = {84--95},
publisher = {Springer},
title = {{Persuasion Artifices to Promote Wellbeing}},
url = {http://www.springerlink.com/index/u78430771uh35637.pdf},
year = {2006}
}
@article{CoanJr1984,
author = {{Coan Jr}, G.},
file = {::},
journal = {Advances in Consumer Research},
pages = {333--336},
title = {{RAPPORT: DEFINITION AND DIMENSIONS}},
url = {http://www.acrwebsite.org/volumes/display.asp?id=6269},
volume = {11},
year = {1984}
}
@book{McNeill1992,
abstract = {What is the relation between gestures and speech? In terms of symbolic forms, of course, the spontaneous and unwitting gestures we make while talking differ sharply from spoken language itself. Whereas spoken language is linear, segmented, standardized, and arbitrary, gestures are global, synthetic, idiosyncratic, and imagistic. In Hand and Mind, David McNeill presents a bold theory of the essential unity of speech and the gestures that accompany it. This long-awaited, provocative study argues that the unity of gestures and language far exceeds the surface level of speech noted by previous researchers and in fact also includes the semantic and pragmatic levels of language. In effect, the whole concept of language must be altered to take into account the nonsegmented, instantaneous, and holistic images conveyed by gestures. McNeill and his colleagues carefully devised a standard methodology for examining the speech and gesture behavior of individuals engaged in narrative discourse. A research subject is shown a cartoon like the 1950 Canary Row-a classic Sylvester and Tweedy Bird caper that features Sylvester climbing up a downspout, swallowing a bowling ball and slamming into a brick wall. After watching the cartoon, the subject is videotaped recounting the story from memory to a listener who has not seen the cartoon. Painstaking analysis of the videotapes revealed that although the research subjects-children as well as adults, some neurologically impaired-represented a wide variety of linguistic groupings, the gestures of people speaking English and a half dozen other languages manifest the same principles. Relying on data from more than ten years of research, McNeill shows thatgestures do not simply form a part of what is said and meant but have an impact on thought itself. He persuasively argues that because gestures directly transfer mental images to visible forms, conveying ideas that language cannot always express, we must examine language and gesture together to unveil the operations of the mind.},
author = {McNeill, David},
booktitle = {Library},
isbn = {0226561348},
pages = {423},
publisher = {University of Chicago Press},
series = {Psychology/cognitive science},
title = {{Hand and Mind: What Gestures Reveal about Thought}},
url = {http://uwashington.worldcat.org.offcampus.lib.washington.edu/title/hand-and-mind-what-gestures-reveal-about-thought/oclc/24379126\&referer=brief\_results},
year = {1992}
}
@article{Paiva2004,
author = {Paiva, Ana and Dias, J. and Sobral, Daniel and Aylett, Ruth},
file = {::},
isbn = {1581138644},
journal = {on Autonomous Agents},
title = {{Caring for agents and agents that care: Building empathic relations with synthetic agents}},
url = {http://dl.acm.org/citation.cfm?id=1018754},
year = {2004}
}
@article{Straalen2009,
author = {Straalen, Bart Van and Heylen, Dirk and Theune, Mari\"{e}t},
file = {::},
journal = {Agents for Games and},
keywords = {bad news con-,embodied conversational agents,empathy,social agents,tutoring,versations},
pages = {95--106},
title = {{Enhancing Embodied Conversational Agents with Social and Emotional Capabilities}},
url = {http://www.springerlink.com/index/3612181747K5L570.pdf},
year = {2009}
}
@incollection{Burke2002,
address = {New-York,NY},
author = {Burke, B. L. and Arkowitz, H. and Dunn, C.},
booktitle = {Motivational Interviewing: Preparing People for Change},
edition = {2nd},
pages = {217--250},
publisher = {Guilford Press},
title = {{The Efficacy of Motivational Interviewing and Its Adaptation}},
year = {2002}
}
@article{ArthurJ.Clark2010,
abstract = {Expanding on a framework introduced by Carl Rogers, an integral model of empathy in counseling uses empathic understanding through 3 ways of knowing: Subjective empathy enables a counselor to momentarily experience what it is like to be a client, interpersonal empathy relates to understanding a client's phenomenological experiencing, and objective empathy uses reputable knowledge sources outside of a client's frame of reference. Across the counseling process, empathy is integral to treatment strategies and interventions.},
author = {{Arthur J. Clark}},
file = {::},
journal = {Journal of Counseling \& Development},
keywords = {Counseling,Counseling Techniques,Counselor Client Relationship,Empathy,Models},
number = {3},
pages = {348 -- 356},
title = {{Empathy: An integral model in the counseling process}},
url = {http://aca.metapress.com/link.asp?id=075658qt56l20466 },
volume = {88},
year = {2010}
}
@article{Shamay-Tsoory2011,
abstract = {Human empathy relies on the ability to share emotions as well as the ability to understand the other's thoughts, desires, and feelings. Recent evidence points to 2 separate systems for empathy: an emotional system that supports our ability to empathize emotionally and a cognitive system that involves cognitive understanding of the other's perspective. A neural network that includes the inferior frontal gyrus and the inferior parietal lobule is necessary for emotion recognition and emotional contagion. Although the emotional and cognitive systems appear to work independently, every empathic response may still evoke both components to some extent, depending on the social context.},
annote = {Difference between cognitive empathy and emotional empathy is explained in this paper. Also they talk about the active brain parts in each empathy type.},
author = {Shamay-Tsoory, Simone G},
doi = {10.1177/1073858410379268},
file = {::},
issn = {1089-4098},
journal = {The Neuroscientist : a review journal bringing neurobiology, neurology and psychiatry},
keywords = {Brain,Brain: physiology,Empathy,Empathy: physiology,Humans,Neural Pathways,Neural Pathways: physiology},
month = feb,
number = {1},
pages = {18--24},
pmid = {21071616},
title = {{The neural bases for empathy.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21071616},
volume = {17},
year = {2011}
}
@article{Litvack-Miller1997,
abstract = {This study was an investigation of the structure and development of dispositional empathy during middle childhood and its relationship to altruism. A sample of 478 students from 2nd, 4th, and 6th grades completed an altruism questionnaire and a social desirability scale, both created for this study, and the Interpersonal Reactivity Index (Davis, 1980), adapted for this study. Teachers also rated the students on prosocial behaviors, such as sharing. In addition, as an experimental part of the study, the children could make monetary donations and volunteer time to raise funds. Results of a confirmatory factor analysis on the Interpersonal Reactivity Index supported Davis's (1980) findings that empathy comprises four components: perspective taking, fantasy, empathic concern, and personal distress. Factor intercorrelations, however, were not the same as those reported by Davis. MANOVAs were used to examine gender and age effects on empathy. Girls were more empathic in general than boys, and older children showed more empathic concern than younger children. Only empathic concern and perspective taking were significant predictors of prosocial behavior.},
author = {Litvack-Miller, W and McDougall, D and Romney, D M},
doi = {10.1037/0022-3514.45.6.1299},
file = {::},
issn = {8756-7547},
journal = {Genetic, social, and general psychology monographs},
keywords = {Adolescent,Altruism,Child,Empathy,Female,Humans,Interpersonal Relations,Male,Questionnaires,Social Behavior,Social Desirability},
month = aug,
number = {3},
pages = {303--24},
pmid = {9259121},
title = {{The structure of empathy during middle childhood and its relationship to prosocial behavior.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21981037},
volume = {123},
year = {1997}
}
@article{Segal2011,
author = {Segal, Elizabeth},
doi = {10.1080/01488376.2011.564040},
file = {::},
issn = {0148-8376},
journal = {Journal of Social Service Research},
keywords = {a dedication to justice,a nation that proclaims,and social well-being and,civic involvement,empathy,scapegoating,social empathy,social responsibility,the united states is},
month = may,
number = {3},
pages = {266--277},
title = {{Social Empathy: A Model Built on Empathy, Contextual Understanding, and Social Responsibility That Promotes Social Justice}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10.1080/01488376.2011.564040\&magic=crossref||D404A21C5BB053405B1A640AFFD44AE3},
volume = {37},
year = {2011}
}
@article{Cooper2000,
author = {Cooper, Bridget and Brna, Paul and Martins, Alex},
file = {::},
journal = {Affective interactions},
pages = {21--34},
publisher = {Springer},
title = {{Effective affective in intelligent systems–building on evidence of empathy in teaching and learning}},
url = {http://www.springerlink.com/index/j8v0l230t3503367.pdf},
year = {2000}
}
@article{Picard2001,
author = {Picard, Rosalind W and Vyzas, E. and Healey, J.},
doi = {10.1109/34.954607},
file = {::},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {10},
pages = {1175--1191},
title = {{Toward machine emotional intelligence: analysis of affective physiological state}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=954607},
volume = {23},
year = {2001}
}
@article{Larimer2007,
abstract = {The current study was designed to evaluate the efficacy of a mailed feedback and tips intervention as a universal prevention strategy for college drinking. Participants (N = 1,488) were randomly assigned to feedback or assessment-only control conditions. Results indicated that the mailed feedback intervention had a preventive effect on drinking rates overall, with participants in the feedback condition consuming less alcohol at follow-up in comparison with controls. In addition, abstainers in the feedback condition were twice as likely to remain abstinent from alcohol at follow-up in comparison with control participants (odds ratio = 2.02), and feedback participants were significantly more likely to refrain from heavy episodic drinking (odds ratio = 1.43). Neither gender nor severity of baseline drinking moderated the efficacy of the intervention in these analyses, but more conservative analyses utilizing last-observation carryforward suggested women and abstainers benefited more from this prevention approach. Protective behaviors mediated intervention efficacy, with participants who received the intervention being more likely to use strategies such as setting limits and alternating alcohol with nonalcoholic beverages. Implications of these findings for universal prevention of college drinking are discussed.},
author = {Larimer, Mary E and Lee, Christine M and Kilmer, Jason R and Fabiano, Patricia M and Stark, Christopher B and Geisner, Irene M and Mallett, Kimberly A and Lostutter, Ty W and Cronce, Jessica M and Feeney, Maggie and Neighbors, Clayton},
institution = {Department of Psychiatry and Behavioral Sciences, University of Washington, Seattle, WA 98105, USA. larimer@u.washington.edu},
journal = {Journal of Consulting and Clinical Psychology},
keywords = {adult,alcohol drinking,alcohol drinking epidemiology,alcohol drinking prevention \& control,communication,feedback,female,humans,male,motivation,postal service,students,students statistics \& numerical data,universities},
number = {2},
pages = {285--293},
pmid = {17469886},
publisher = {American Psychological Association. Journals Department, 750 First Street NE, Washington, DC 20002-4242. Tel: 800-374-2721; Tel: 202-336-5510; Fax: 202-336-5502; e-mail: order@apa.org; Web site: http://www.apa.org/publications},
title = {{Personalized mailed feedback for college drinking prevention: a randomized clinical trial.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17469886},
volume = {75},
year = {2007}
}
@article{Barkham2001,
abstract = {To complement the evidence-based practice paradigm, the authors argued for a core outcome measure to provide practice-based evidence for the psychological therapies. Utility requires instruments that are acceptable scientifically, as well as to service users, and a coordinated implementation of the measure at a national level. The development of the Clinical Outcomes in Routine Evaluation-Outcome Measure (CORE-OM) is summarized. Data are presented across 39 secondary-care services (n = 2,710) and within an intensively evaluated single service (n = 1,455). Results suggest that the CORE-OM is a valid and reliable measure for multiple settings and is acceptable to users and clinicians as well as policy makers. Baseline data levels of patient presenting problem severity, including risk, are reported in addition to outcome benchmarks that use the concept of reliable and clinically significant change. Basic quality improvement in outcomes for a single service is considered.},
author = {Barkham, M and Margison, F and Leach, C and Lucock, M and Mellor-Clark, J and Evans, C and Benson, L and Connell, J and Audin, K and McGrath, G},
issn = {0022006X},
journal = {Journal of Consulting and Clinical Psychology},
number = {2},
pages = {184--96},
title = {{Service profiling and outcomes benchmarking using the CORE-OM: toward practice-based evidence in the psychological therapies. Clinical Outcomes in Routine Evaluation-Outcome Measures}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11393596?ordinalpos=17\&itool=EntrezSystem2.PEntrez.Pubmed.Pubmed\_ResultsPanel.Pubmed\_RVDocSum},
volume = {69},
year = {2001}
}
@article{Woodruff2008,
abstract = {The purpose of the study was to explore whether sociodemographic characteristics and baseline psychosocial factors were related to short-term smoking cessation and reduction, after controlling for the effects of participating in a virtual world, Internet chat room intervention. Results indicate that smoking-related psychosocial factors are important predictors of adolescent smoking cessation and reduction, independent of the effects of participating in the intervention. Self-efficacy for quitting, social support, and perceived benefits of quitting was related to positive short-term changes in smoking behavior.},
author = {Woodruff, Susan I and Conway, Terry L and Edwards, Christine C},
doi = {10.1016/j.addbeh.2007.09.012},
file = {:X$\backslash$:/Papers/CBIs/1-s2.0-S0306460307002596-main.pdf:pdf},
issn = {0306-4603},
journal = {Addictive behaviors},
keywords = {Adolescent,Adolescent Behavior,Adolescent Behavior: psychology,Adult,Attitude to Health,Female,Health Behavior,Humans,Internet,Male,Self Efficacy,Smoking,Smoking Cessation,Smoking Cessation: psychology,Smoking: prevention \& control,Smoking: psychology,Social Support,Therapy, Computer-Assisted},
month = feb,
number = {2},
pages = {354--8},
pmid = {17900818},
title = {{Sociodemographic and smoking-related psychosocial predictors of smoking behavior change among high school smokers.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17900818},
volume = {33},
year = {2008}
}
@article{Zahn-waxler1992,
author = {Zahn-Waxler, Carolyn and Robinson, JoAnn L. and Emde, Robert N.},
doi = {10.1037//0012-1649.28.6.1038},
file = {::},
issn = {0012-1649},
journal = {Developmental Psychology},
number = {6},
pages = {1038--1047},
title = {{The development of empathy in twins.}},
volume = {28},
year = {1992}
}
@article{Jackson1992,
abstract = {OBJECTIVE: The purpose of this paper is the assessment of the healer's listening as an aspect of the history of caring and curing, with particular attention to its place in psychological healing. METHOD: An extensive range of philosophical, religious, and medical sources from antiquity to the present were studied. RESULTS: Over the centuries, listening has been a crucial aspect of the various endeavors undertaken by healers in the interest of acquiring information from, achieving understanding of, and bringing about healing effects for sufferers. Yet it has been vision rather than hearing that has been emphasized in knowing and understanding, and looking rather than listening that has been emphasized in healing endeavors. Only around the turn of the twentieth century did there emerge the focused study of care in listening, of listening beyond the words themselves, and of the significance of the interested listener as a soothing, empathic force. CONCLUSIONS: The place of listening in depth and with empathy is a crucial element in healing. While the emphasis on looking remains significant in the gathering and appraisal of data, at times it threatens to overwhelm the need for an attentive and concerned listener. There appears to be a natural tension between the two modes that has, in modern times, been translated into a tension between the two modes that has, in modern times, been translated into a tension between a scientific mode of gaining information and a humanistic mode of knowing sufferers. A healer neglects either one at his or her peril-and at the peril of his or her patients.},
author = {Jackson, S W},
institution = {Department of Psychiatry, Yale University School of Medicine, New Haven, CT 06510.},
journal = {The American Journal of Psychiatry},
number = {12},
pages = {1623--1632},
pmid = {1443239},
title = {{The listening healer in the history of psychological healing.}},
volume = {149},
year = {1992}
}
@article{Paiva2000,
author = {Paiva, Ana},
file = {::},
journal = {Affective interactions},
pages = {1--8},
title = {{Affective interactions: toward a new generation of computer interfaces?}},
url = {http://www.springerlink.com/index/826w110p65762167.pdf},
year = {2000}
}
@book{Greene2003,
abstract = {Providing a thorough review and synthesis of work on communication skills and skill enhancement, this "Handbook" serves as a comprehensive and contemporary survey of theory and research on social interaction skills. Editors John O. Greene and Brant R. Burleson have brought together preeminent researchers and writers to contribute to this volume, establishing a foundation on which future study and research will build. The handbook chapters are organized into five major units: general theoretical and methodological issues (models of skill acquisition, methods of skill assessment); fundamental interaction skills (both transfunctional and transcontextual); function-focused skills (informing, persuading, supporting); skills used in management of diverse personal relationships (friendships, romances, marriages); and skills used in varied venues of public and professional life (managing leading, teaching). Distinctive features of this handbook include: broad, comprehensive treatment of work on social interaction skills and skill acquisition; up-to-date reviews of research in each area; and emphasis on empirically supported strategies for developing and enhancing specific skills. Researchers in communication studies, psychology, family studies, business management, and related areas will find this volume a comprehensive, authoritative source on communications skills and their enhancement, and it will be essential reading for scholars and students across the spectrum of disciplines studying social interaction.},
author = {Greene, John O and Burleson, Brant Raney},
booktitle = {Communication},
editor = {Greene, John O and Burleson, Brant R},
isbn = {0805834176},
pages = {1051},
publisher = {Lawrence Erlbaum Associates, Inc., Publishers},
title = {{Handbook of Communication and Social Interaction Skills}},
year = {2003}
}
@article{Gunes2008,
author = {Gunes, Hatice and Piccardi, Massimo},
file = {::},
journal = {Emotion},
title = {{From the lab to the real world: Affect recognition using multiple cues and modalities}},
year = {2008}
}
@misc{FourSquare,
title = {{Four Square}},
url = {https://foursquare.com}
}
@article{Boukricha2011,
author = {Boukricha, Hana and Wachsmuth, Ipke},
doi = {10.1007/s13218-011-0109-8},
file = {::},
issn = {0933-1875},
journal = {KI - K\"{u}nstliche Intelligenz},
keywords = {agent-agent interaction,empathic virtual humans,human-agent,internal simulation},
month = may,
number = {3},
pages = {195--204},
title = {{Empathy-Based Emotional Alignment for a Virtual Human: A Three-Step Approach}},
volume = {25},
year = {2011}
}
@misc{Tsui1985,
abstract = {The extent to which relatively unassimilated Asian clients can utilize traditional psychotherapy is likely to depend upon the ability of therapists to understand cultural differences and to adapt their clinical styles accordingly. Common errors made by non-Asian therapists attempting to engage Asians in psychotherapy are identified and appropriate therapeutic strategies are suggested.},
author = {Tsui, P and Schultz, G L},
booktitle = {The American journal of orthopsychiatry},
number = {4},
pages = {561--569},
pmid = {4073227},
title = {{Failure of rapport: why psychotherapeutic engagement fails in the treatment of Asian clients.}},
volume = {55},
year = {1985}
}
@phdthesis{Sze2005,
author = {Sze, Ian},
booktitle = {Ambient Intelligence in Everyday Life},
file = {::},
school = {UNIVERSITY OF NEW SOUTH WALES},
title = {{Empathic computing}},
year = {2005}
}
@article{Heimendinger2007,
abstract = {The purpose of this article is to report the process outcomes of a coaching methodology used in a study designed to increase fruit and vegetable consumption and physical activity in families. Eighty-eight families with second graders were recruited from a rural, biethnic community in Colorado and randomized to intervention and delayed intervention conditions. This article reports on the 27 families in the delayed intervention group. Families received up to 10 home visits over 10 months from a family advisor and completed activities to improve their dietary and physical activity behaviors. Coaching conversations took place during each home visit. Coaching process outcomes were evaluated by analysis of visit documentation, participant survey, and qualitative interviews. Results indicated that coaching, in conjunction with family activities, engaged families in the process of change and facilitated movement toward the achievement of their weekly nutrition or physical activity goals. Coaching methodology may be particularly useful for participatory research.},
author = {Heimendinger, Jerianne and Uyeki, Terry and Andhara, Aurielle and Marshall, Julie A and Scarbro, Sharon and Belansky, Elaine and Crane, Lori},
institution = {Jerianneb@earthlink.net},
journal = {Health education behavior the official publication of the Society for Public Health Education},
keywords = {colorado,diet,exercise,fruit,health promotion,humans,interviews topic,professional family relations,vegetables},
number = {1},
pages = {71--89},
pmid = {16740515},
title = {{Coaching process outcomes of a family visit nutrition and physical activity intervention.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16740515},
volume = {34},
year = {2007}
}
@article{Cappella1990,
author = {Cappella, Joseph N.},
doi = {10.1207/s15327965pli0104\_5},
file = {::},
issn = {1047-840X},
journal = {Psychological Inquiry},
month = oct,
number = {4},
pages = {303--305},
title = {{On Defining Conversational Coordination and Rapport}},
url = {http://www.tandfonline.com/doi/abs/10.1207/s15327965pli0104\_5},
volume = {1},
year = {1990}
}
@article{Gunes2010,
author = {Gunes, Hatice and Pantic, Maja},
doi = {10.4018/jse.2010101605},
file = {::},
issn = {1947-9093},
journal = {International Journal of Synthetic Emotions},
keywords = {bodily expression,continuous emotion recognition,dimensional emotion modelling,emotional acoustic and bio-signals,facial expression,multimodal fusion},
month = jan,
number = {1},
pages = {68--99},
title = {{Automatic, Dimensional and Continuous Emotion Recognition}},
volume = {1},
year = {2010}
}
@inproceedings{Gonsior2011,
abstract = {In this paper, the impact of facial expressions on HRI is explored. To determine their influence on empathy of a human towards a robot and perceived subjective performance, an experimental setup is created, in which participants engage in a dialog with the robot head EDDIE. The web-based gaming application “Akinator” serves as a backbone for the dialog structure. In this game, the robot tries to guess a thought-of person chosen by the human by asking various questions about the person. In our experimental evaluation, the robot reacts in various ways to the human's facial expressions, either ignoring them, mirroring them, or displaying its own facial expression based on a psychological model for social awareness. In which way this robot behavior influences human perception of the interaction is investigated by a questionnaire. Our results support the hypothesis that the robot behavior during interaction heavily influences the extent of empathy by a human towards a robot and perceived subjective task-performance, with the adaptive modes clearly leading compared to the non-adaptive mode.},
address = {Atlanta, GA, USA},
author = {Gonsior, Barbara and Sosnowski, Stefan and Mayer, Christoph and Blume, Jiirgen and Radig, B. and Wollherr, D. and Kuhnlenz, K.},
booktitle = {RO-MAN, 20th IEEE International Symposium on Robot and Human Interactive Communication},
doi = {10.1109/ROMAN.2011.6005294},
file = {::},
isbn = {9781457715730},
pages = {350--356},
publisher = {IEEE},
title = {{Improving aspects of empathy and subjective performance for HRI through mirroring facial expressions}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6005294},
year = {2011}
}
@article{Suchman1997,
abstract = {To formulate an empirically derived model of empathic communication in medical interviews by describing the specific behaviors and patterns of interaction associated with verbal expressions of emotion.},
author = {Suchman, a L and Markakis, K and Beckman, H B and Frankel, R},
file = {::},
issn = {0098-7484},
journal = {JAMA : the journal of the American Medical Association},
keywords = {Communication,Empathy,Humans,Interviews as Topic,Models,Physician-Patient Relations,Psychological},
month = feb,
number = {8},
pages = {678--82},
pmid = {9039890},
title = {{A model of empathic communication in the medical interview.}},
volume = {277},
year = {1997}
}
@techreport{Pereira2006,
abstract = {In this report we present the Emotional-BDI architecture, an extension to the BDI architecture supporting Artificial Emotions and including internal representations for agent’s Capabilities and Resources. The architecture we present here, is conceptual, defining which components should exist so that Emotional- BDI agents can use Effective Capabilities as well as Effective Resources in order to better cope with highly dynamic environments.},
address = {Porto, Portugal},
author = {Pereira, David and Oliveira, Eugenio and Moreira, Nelma},
file = {::},
institution = {Universidade do Porto},
keywords = {Artificial Emotions,BDI Agents},
title = {{Towards an Architecture for Emotional BDI Agents}},
year = {2006}
}
@inproceedings{Wang2009,
abstract = {How to build virtual agents that establish rapport with human? According to Tickle-Degnen and Rosenthal, the three essential components of rapport are mutual attentiveness, positivity and coordination. In our previous work, we designed an embodied virtual agent to establish rapport with a human speaker by providing rapid and contingent nonverbal feedback. How do we know that a human speaker is feeling a sense of rapport? In this paper, we focus on the positivity component of rapport by investigating the relationship of human speakers' facial expressions on the establishment of rapport. We used an automatic facial expression coding tool called CERT to analyze the human dyad interactions and human-virtual human interactions. Results show that recognizing positive facial displays alone may be insufficient and that recognized negative facial displays was more diagnostic in assessing the level of rapport between participants.},
address = {Amsterdam},
annote = {Out of three components of rapport by Tickle-Degnene and Rosenthal (mutual attentiveness, positivity, and coordination), they investigated the relationship between human speakers' facial expression and rapport. Results show that recognizing positive facial expressions alone is insufficient but negative facial displays are more effective in assessing the level of rapport between participants.},
author = {Wang, Ning and Gratch, Jonathan},
booktitle = {3rd International Conference on Affective Computing and Intelligent Interaction and Workshops, 2009. ACII 2009},
doi = {10.1109/ACII.2009.5349514},
file = {::},
isbn = {978-1-4244-4800-5},
month = sep,
pages = {1--6},
publisher = {IEEE},
title = {{Rapport and facial expression}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5349514},
year = {2009}
}
@inproceedings{Nor2010,
author = {Nor, R.M. and Muhlberger, Ralf},
booktitle = {User Science and Engineering (i-USEr), 2010 International Conference on},
file = {::},
isbn = {9781424490493},
keywords = {-component,community,empathy,emphatic communication,user experience},
pages = {7--10},
publisher = {IEEE},
title = {{Designing to support empathy: Understanding user experience by using a model of interaction in meeting human needs}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5716713},
year = {2010}
}
@book{McDougall1926,
address = {Boston},
author = {McDougall, William},
publisher = {Luce},
title = {{An introduction to social psychology}},
year = {1926}
}
@article{Kiesler2008,
author = {Kiesler, Sara and Powers, Aaron and Fussell, Susan R. and Torrey, Cristen},
doi = {10.1521/soco.2008.26.2.169},
file = {::},
issn = {0278-016X},
journal = {Social Cognition},
month = apr,
number = {2},
pages = {169--181},
title = {{Anthropomorphic Interactions with a Robot and Robot–like Agent}},
url = {http://guilfordjournals.com/doi/abs/10.1521/soco.2008.26.2.169},
volume = {26},
year = {2008}
}
@misc{Pantic2003,
abstract = {The ability to recognize affective states of a person we are communicating with is the core of emotional intelligence. Emotional intelligence is a facet of human intelligence that has been argued to be indispensable and perhaps the most important for successful interpersonal social interaction. This paper argues that next-generation human-computer interaction (HCI) designs need to include the essence of emotional intelligence - the ability to recognize a user's affective states-in order to become more human-like, more effective, and more efficient. Affective arousal modulates all nonverbal communicative cues (facial expressions, body movements, and vocal and physiological reactions). In a face-to-face interaction, humans detect and interpret those interactive signals of their communicator with little or no effort. Yet design and development of an automated system that accomplishes these tasks is rather difficult. This paper surveys the past work in solving these problems by a computer and provides a set of recommendations for developing the first part of an intelligent multimodal HCI-an automatic personalized analyzer of a user's nonverbal affective feedback.},
author = {Pantic, Maja and Rothkrantz, L J M},
booktitle = {Proceedings of the IEEE},
doi = {10.1109/JPROC.2003.817122},
issn = {00189219},
number = {9},
pages = {1370--1390},
publisher = {IEEE},
title = {{Toward an affect-sensitive multimodal human-computer interaction}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1230215},
volume = {91},
year = {2003}
}
@article{Brave2005,
abstract = {Embodied computer agents are becoming an increasingly popular human-computer interaction technique. Often, these agents are programmed with the capacity for emotional expression. This paper investigates the psychological effects of emotion in agents upon users. In particular, two types of emotion were evaluated: self-oriented emotion and other-oriented, empathic emotion. In a 2 (self-oriented emotion: absent vs. present) by 2 (empathic emotion: absent vs. present) by 2 (gender dyad: male vs. female) between-subjects experiment (N = 96), empathic emotion was found to lead to more positive ratings of the agent by users, including greater likeability and trustworthiness, as well as greater perceived caring and felt support. No such effect was found for the presence of self-oriented emotion. Implications for the design of embodied computer agents are discussed and directions for future research suggested.},
author = {Brave, Scott and Nass, Clifford and Hutchinson, Kevin},
doi = {10.1016/j.ijhcs.2004.11.002},
file = {::},
issn = {10715819},
journal = {International Journal of Human-Computer Studies - Special issue: Subtle expressivity for characters and robots},
keywords = {affective computing,characters,embodied agents,emotion,empathy,social interfaces},
month = feb,
number = {2},
pages = {161--178},
title = {{Computers that care: investigating the effects of orientation of emotion exhibited by an embodied computer agent}},
url = {http://www.sciencedirect.com/science/article/pii/S1071581904001284},
volume = {62},
year = {2005}
}
@article{Roberts1996,
author = {Roberts, William and Strayer, Janet},
doi = {10.2307/1131826},
file = {::},
issn = {00093920},
journal = {Child Development},
month = apr,
number = {2},
pages = {449},
title = {{Empathy, Emotional Expressiveness, and Prosocial Behavior}},
url = {http://www.jstor.org/stable/1131826?origin=crossref},
volume = {67},
year = {1996}
}
@incollection{Wallbott1995,
author = {Wallbott, H G},
booktitle = {In I Eds pp 8298},
chapter = {Congruence},
editor = {Markova, I and Graumann, C F and Foppa, K},
pages = {82--98},
publisher = {Cambridge University Press},
title = {{Mutualities in dialogue}},
volume = {Cambridge},
year = {1995}
}
@incollection{Plutchik1980,
address = {New York},
author = {Plutchik, R},
booktitle = {Emotion: Theory, research, and experience},
chapter = {Theories o},
editor = {Plutchik, R and Kellerman, H},
number = {3},
pages = {3--33},
publisher = {Academic Press},
series = {Emotion: Theory, research, and experience: Vol. 1. Theories of emotion},
title = {{A general psychoevolutionary theory of emotion}},
url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:A+general+psychoevolutionary+theory+of+emotion\#0},
volume = {1},
year = {1980}
}
@article{Lazarus1991,
abstract = {The 2 main tasks of this article are 1st, to examine what a theory of emotion must do and basic issues that it must address. These include definitional issues, whether or not physiological activity should be a defining attribute, categorical versus dimensional strategies, the reconciliation of biological universals with sociocultural sources of variability, and a classification of the emotions. The 2nd main task is to apply an analysis of appraisal patterns and the core relational themes that they produce to a number of commonly identified emotions. Anger, anxiety, sadness, and pride (to include 1 positive emotion) are used as illustrations. The purpose is to show the capability of a cognitive-motivational-relational theory to explain and predict the emotions. The role of coping in emotion is also discussed, and the article ends with a response to criticisms of a phenomenological, folk-theory outlook.},
author = {Lazarus, Richard S.},
doi = {10.1037/0003-066X.46.8.819},
file = {::},
issn = {0003-066X},
journal = {The American psychologist},
keywords = {Cognition,Emotions,Humans,Interpersonal Relations,Motivation,Psychological Theory},
month = aug,
number = {8},
pages = {819--834},
pmid = {1928936},
title = {{Progress on a cognitive-motivational-relational theory of emotion}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/1928936},
volume = {46},
year = {1991}
}
@article{Bartneck2004,
abstract = {The ability of artificial characters to express emotions is essential for the natural interaction with humans. Their absence could be interpreted as coldness towards the user. Artificial characters can have different embodiments. Screen characters and robotic characters are currently among the most widely used. This study investigates the influence of the characters embodiment on how users perceive the characters emotional expressions. The results show that there is no significant difference in the perceived intensity and recognition accuracy between a robotic character and a screen character.},
author = {Bartneck, Christoph and Reichenbach, Juliane and Breemen, Albert Van},
institution = {Citeseer},
journal = {Emotion},
pages = {32--51},
publisher = {Citeseer},
title = {{In Your Face , Robot ! The Influence of a Character ’ s Embodiment on How Users Perceive Its Emotional Expressions}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.67.9090\&amp;rep=rep1\&amp;type=pdf},
year = {2004}
}
@article{Southard1918,
author = {Southard, E E},
journal = {The Journal of Abnormal Psychology},
number = {4},
pages = {199},
publisher = {American Psychological Association},
title = {{The empathic index in the diagnosis of mental diseases.}},
volume = {13},
year = {1918}
}
@inproceedings{Boukricha2007,
abstract = {Addressing user’s emotions in human-computer interaction significantly enhances the believability and lifelikeness of virtual humans. Emotion recognition and interpretation is realized in our approach by integrating empathy as a designated process within the agent’s cognitive architecture. In this paper we describe this empathy process which comprises of two interconnected components: a belief-desire-intention (BDI) based cognitive component and an affective component based on the emotion simulation system of the virtual human Max.},
address = {Osnabr\"{u}ck, Germany},
author = {Boukricha, Hana and Becker-Asano, Christian},
booktitle = {Proceedings of the 2nd Workshop at KI2007 on Emotion and Computing – Current Research and Future Impact},
editor = {{Dirk Reichardt} and Levi, Paul},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Boukricha, Becker-Asano - 2007 - Simulating empathy for the virtual human max(3).pdf:pdf},
pages = {23--28},
title = {{Simulating empathy for the virtual human max}},
url = {http://wwwlehre.dhbw-stuttgart.de/~reichard/itemotion/2007/},
year = {2007}
}
@article{Riek2008,
abstract = {Expressing empathy is a key component of human social communication. One common way people convey empathy is via facial expression mirroring. It may be helpful for machines intended to interact with people to also convey empathy in this manner. We have thus created Virgil, an expression-mimicking robot. We hypothesize that if people feel like a machine is empathizing with them they will be more likely to rate the interaction positively. We conducted a pilot study to test our hypothesis, and through quantitative and qualitative analysis of our results found some support for it.},
author = {Riek, Laurel D. and Robinson, Peter},
file = {::},
journal = {ACM Workshop on Affective Interaction in Natural Environments AFFINE at the International ACM Conference on Multimodal Interfaces ICMI 08},
pages = {1--5},
publisher = {ACM},
title = {{Real-time empathy: Facial mimicry on a robot}},
year = {2008}
}
@book{Scherer2001,
address = {New York, NY, US},
author = {Scherer, Klaus R.},
editor = {{Scherer, Klaus R. and Schorr, Angela and Johnstone}, Tom},
isbn = {0-19-513007-3},
keywords = {appraisal,cognitive-motivational-relational theory of emotio,coping,emotions,psychological stress,theory development},
pages = {478},
publisher = {Oxford University Press},
title = {{Appraisal processes in emotion: Theory, methods, research}},
year = {2001}
}
@article{Breemen2005,
abstract = {We developed a robotic research platform called "iCat" for studying social human-robot interaction. The platform consists of the robotic character "iCat", which is a desktop user-interface robot with mechanically rendered facial expressions. Recently, Philips Research made this platform available for universities and research laboratories to stimulate the momentum in Human-Robot Interaction research [5].},
author = {van Breemen, A and Yan, X},
doi = {10.1145/1082473.1082823},
file = {::},
journal = {AAMAS '05 Proceedings of the fourth international joint conference on Autonomous agents and multiagent systems},
pages = {143--144},
title = {{iCat: an animated user-interface robot with personality}},
url = {http://dl.acm.org/citation.cfm?id=1082823},
year = {2005}
}
@article{Picard2001,
author = {Picard, Rosalind W and Vyzas, E. and Healey, J.},
doi = {10.1109/34.954607},
file = {::},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {10},
pages = {1175--1191},
title = {{Toward machine emotional intelligence: analysis of affective physiological state}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=954607},
volume = {23},
year = {2001}
}
@inproceedings{Kang2008a,
author = {Kang, Sin-hwa and Gratch, Jonathan and Wang, Ning and Watt, J.},
booktitle = {Intelligent Virtual Agents},
file = {::},
keywords = {evaluation,nonverbal feedback,personality,rapport,virtual agents},
pages = {253--261},
publisher = {Springer},
title = {{Agreeable people like agreeable virtual humans}},
url = {http://www.springerlink.com/index/DT61V8556710VW13.pdf},
year = {2008}
}
@inproceedings{McQuiggan2008,
abstract = {Humans continuously assess one another’s situational context, modify their own affective state, and then respond based on these outcomes through empathetic expression. Virtual agents should be capable of similarly empathizing with users in interactive environments. A key challenge posed by empathetic reasoning in virtual agents is determining whether to respond with parallel or reactive empathy. Parallel empathy refers to mere replication of another’s affective state, whereas reactive empathy exhibits greater cognitive awareness and may lead to incongruent emotional responses (i.e., emotions different from the recipient’s and perhaps intended to alter negative affect). This paper proposes a unified inductive framework for modeling parallel and reactive empathy. Empathy models are used to drive runtime situation-appropriate empathetic behaviors by selecting suitable parallel or reactive empathetic expressions.},
address = {Estoril, Portugal},
annote = {- No automatic affect detection
- agent demographics are not taken into account.},
author = {McQuiggan, Scott W and Robison, Jennifer and Phillips, Robert},
booktitle = {Proceedings of 7th Int. Conf. on Autonomous Agents and Multiagent Systems (AAMAS 2008)},
editor = {{Padgham, Parkes}, M\"{u}ller and Parsons},
file = {::},
keywords = {Affective Reasoning,Empathy,Human-Computer Interaction,Intelligent Virtual Agents,Machine Learning},
number = {Aamas},
pages = {167--174},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems (www.ifaamas.org)},
title = {{Modeling parallel and reactive empathy in virtual agents: An inductive approach}},
year = {2008}
}
@article{Gunes2010,
author = {Gunes, Hatice and Pantic, Maja},
doi = {10.4018/jse.2010101605},
file = {::},
issn = {1947-9093},
journal = {International Journal of Synthetic Emotions},
keywords = {bodily expression,continuous emotion recognition,dimensional emotion modelling,emotional acoustic and bio-signals,facial expression,multimodal fusion},
month = jan,
number = {1},
pages = {68--99},
title = {{Automatic, Dimensional and Continuous Emotion Recognition}},
volume = {1},
year = {2010}
}
@article{Sabourin,
author = {Sabourin, Jennifer and Mott, Bradford and Lester, James},
file = {::},
journal = {lorentzcenter.nl},
keywords = {empathetic virtual agents,pedagogical agents,virtual learning},
title = {{Computational Models of Affect and Empathy for Pedagogical Virtual Agents}},
url = {http://www.lorentzcenter.nl/lc/web/2011/464/presentations/Sabourin.pdf}
}
@article{Prendinger2005,
abstract = {In this paper, we report on our efforts in developing affective character-based interfaces, i.e., interfaces that recognize and measure affective information of the user and address user affect by employing embodied characters. In particular, we describe the Empathic Companion, an ani- mated interface agent that accompanies the user in the setting of a virtual job interview. This inter- face application takes physiological data (skin conductance and electromyography) of a user in realtime, interprets them as emotions, and addresses the user’s affective states in the form of empathic feedback. The Empathic Companion is conceived as an educational agent that supports job seekers preparing for a job interview. We also present results from an exploratory study that aims to evaluate the impact of the Empathic Companion by measuring users’ skin conductance and heart rate. While an overall positive effect of the Empathic Companion could not be shown, the outcome of the experiment suggests that empathic feedback has a positive effect on the interviewee’s stress level while hearing the interviewer question.},
annote = {They take physiological data (skin conductance and electromyography) of a user in real-time, interpret them as emotions, and address the user’s affective states by empathic feedback. A decision making agent relates these signals and the user’s answer to arousal and valence to infer the user’s emotional state by applying the model of Lang (1995) (Lang claims that all emotions can be characterized in terms of valence (pleasant or unpleasant) and arousal (calm or aroused)). Then it selects empathetic actions that maximize some utility function. They use text-based empathetic actions in addition to a small full body character.We can use the decision-theoretic agent aspect in our empathy model.
The empathy is mainly expressed in a text-base fashion in their job. The embodied agent that they have is so small and no facial expressions are used. There are some gestural expressions.
As shown in this paper and many other ones, text-base empathy expression can be effective. So we can use that too.
      },
author = {Prendinger, Helmut and Ishizuka, M.},
doi = {10.1080/08839510590910174},
file = {::;::},
journal = {Applied Artificial Intelligence},
keywords = {electromyography,physiological signals,skin conductance},
number = {3-4},
pages = {267--286},
publisher = {Citeseer},
title = {{The Empathic Companion - A Character-based Interface that Addresses Users’ Affective States}},
volume = {19},
year = {2005}
}
@book{Dimeff1999,
abstract = {(from the cover) This manual presents a pragmatic and clinically proven approach to the prevention and treatment of undergraduate alcohol abuse. The Brief Alcohol Screening and Intervention for College Students (BASICS) model is a nonconfrontational, harm reduction approach that helps students reduce their alcohol consumption and decrease the behavioral and health risks associated with heavy drinking. Including reproducible handouts and assessment forms, the book takes readers step-by-step through conducting BASICS assessment and feedback sessions. Special topics covered include the use of Diagnostic and Statistical Manual of Mental Disorders-IV (DSM-IV) criteria to evaluate alcohol abuse, ways to counter defensiveness about drinking and how to help students who continue to drink in a hazardous fashion. (PsycINFO Database Record (c) 2010 APA, all rights reserved) (cover)},
author = {Dimeff, Linda A and Baer, John S and Kivlahan, Daniel R and Marlatt, G Alan},
booktitle = {The Journal of Psychiatry Law},
isbn = {1572303921},
pages = {1929--1945},
publisher = {Guilford Press},
title = {{Brief alcohol screening and intervention for college students (BASICS): A harm reduction approach}},
url = {http://search.ebscohost.com/login.aspx?direct=true\&db=psyh\&AN=1999-02125-000\&lang=fr\&site=ehost-live},
volume = {30},
year = {1999}
}
@article{Borutta2009,
author = {Borutta, Isabell and Sosnowski, Stefan and Zehetleitner, Michael},
file = {::},
journal = {Robot and Human},
title = {{Generating artificial smile variations based on a psychological system-theoretic approach}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5326255},
year = {2009}
}
@article{Stockwell1994,
abstract = {The concept of the Alcohol Dependence Syndrome has been influential in the field of alcohol studies in the 1980s. The Severity of Alcohol Dependence Questionnaire (SADQ) is one of a generation of alcohol problem scales developed to measure degree of dependence rather than presence or absence of 'alcoholism'. This paper describes the development of a form of the SADQ for community samples of drinkers (SADQ-C) and its relationship to a brief scale designed to measure impaired control over drinking. In a sample of 52 problem drinkers, SADQ and SADQ-C correlated almost perfectly (r = 0.98). In a larger sample of 197 attenders at a controlled drinking clinic, Principal Components Analysis revealed one major factor accounting for 71.7\% of the total variance. High internal reliability was indicated with a Cronbach's Alpha of 0.98. Application of this instrument in a random survey of Western Australian households is then described. It was necessary to remove items relating to 'reinstatement of dependence' for this sample. A single major factor was identified by principal components analysis, accounting for 69.1\% of the total variance. In both the clinic and the community samples SADQ-C scores correlated highly with Impairment of Control scores. The findings are interpreted as supporting the view that there is a single dimension of alcohol dependence upon which all persons who drink alcohol with any regularity may be located.},
author = {Stockwell, T and Sitharthan, T and McGrath, D and Lang, E},
institution = {National Centre for Research into the Prevention of Drug Abuse, Curtin University of Technology, Perth, Western Australia.},
journal = {Addiction Abingdon England},
keywords = {adolescent,adult,aged,alcohol drinking,alcohol drinking adverse effects,alcohol drinking epidemiology,alcohol drinking psychology,alcoholism,alcoholism classification,alcoholism diagnosis,alcoholism epidemiology,alcoholism psychology,cross sectional studies,female,humans,incidence,internal external control,male,middle aged,psychometrics,reproducibility results,substance withdrawal syndrome,substance withdrawal syndrome classification,substance withdrawal syndrome diagnosis,substance withdrawal syndrome epidemiology,substance withdrawal syndrome psychology,western australia,western australia epidemiology},
number = {2},
pages = {167--174},
pmid = {8173482},
title = {{The measurement of alcohol dependence and impaired control in community samples.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8173482},
volume = {89},
year = {1994}
}
@article{Varni2009,
author = {Varni, Giovanna and Camurri, Antonio and Coletta, Paolo and Volpe, Gualtiero},
doi = {10.1109/CSE.2009.230},
file = {::},
isbn = {978-1-4244-5334-4},
journal = {2009 International Conference on Computational Science and Engineering},
keywords = {Social signals, music, synchronisation},
pages = {843--848},
publisher = {Ieee},
title = {{Toward a Real-Time Automated Measure of Empathy and Dominance}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5283210},
year = {2009}
}
@inproceedings{Magerko2011,
abstract = {This article presents our work on building a virtual coach agent, called Dr. Vicky, and training environment (called the Virtual BNI Trainer, or VBT) for learning how to correctly talk with medical patients who have substance abuse issues. This work focuses on how to effectively design menu-based dialogue interactions for conversing with a virtual patient within the context of learning how to properly engage in such conversations according to the brief negotiated interview techniques we desire to train. Dr. Vicky also employs a model of student knowledge to influence the mediation strategies used in personalizing the training experience and guidance offered. The VBT is a prototype training application that will be used by medical students and practitioners within the Yale medical community in the future.},
author = {Magerko, Brian and Dean, James and Idnani, Avinash and Pantalon, Michael and Onofrio, Gail D},
booktitle = {Association for the Advancement of Artificial Intelligence (AAAI) Spring Symposium},
file = {::},
keywords = {AAAI Technical Report SS-11-01},
pages = {25--32},
publisher = {Association for the Advancement of Artificial Intelligence (www.aaai.org)},
title = {{Dr. Vicky : A Virtual Coach for Learning Brief Negotiated Interview Techniques for Treating Emergency Room Patients}},
year = {2011}
}
@article{Bellet1991,
abstract = {IN HIS RESEARCH on the physician-patient relationship, Cousins1 found that 85\% of people had changed physicians or were thinking of changing in the past 5 years. Many of those who changed did so because of their physician's poor communication skills. One of the qualities of effective communication is the use of empathy. Because some physicians have not learned to use empathy in their training as medical students and residents, they may be ineffective in the care of patients.2 In this article, we discuss the importance of empathy in medical practice and illustrate its use with two examples.},
author = {Bellet, P S and Maloney, M J},
doi = {10.1001/jama.1991.03470130111039},
file = {::},
issn = {0098-7484},
journal = {JAMA : the journal of the American Medical Association},
keywords = {Communication,Cost-Benefit Analysis,Empathy,Humans,Physician's Practice Patterns,Physician's Practice Patterns: economics,Physician-Patient Relations},
month = oct,
number = {13},
pages = {1831--2},
pmid = {1909761},
title = {{The importance of empathy as an interviewing skill in medicine}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/1909761},
volume = {266},
year = {1991}
}
@article{Bradley2008,
abstract = {Pupil diameter was monitored during picture viewing to assess effects of hedonic valence and emotional arousal on pupillary responses. Autonomic activity (heart rate and skin conductance) was concurrently measured to determine whether pupillary changes are mediated by parasympathetic or sympathetic activation. Following an initial light reflex, pupillary changes were larger when viewing emotionally arousing pictures, regardless of whether these were pleasant or unpleasant. Pupillary changes during picture viewing covaried with skin conductance change, supporting the interpretation that sympathetic nervous system activity modulates these changes in the context of affective picture viewing. Taken together, the data provide strong support for the hypothesis that the pupil's response during affective picture viewing reflects emotional arousal associated with increased sympathetic activity.},
author = {Bradley, Margaret M and Miccoli, Laura and Escrig, Miguel A and Lang, Peter J},
institution = {Center for the Study of Emotion and Attention, Box 112766, University of Florida, Gainesville, FL 32611, USA. bradley@ufl.edu},
journal = {Psychophysiology},
keywords = {adolescent,adult,arousal,arousal physiology,autonomic nervous system,autonomic nervous system physiology,emotions,emotions physiology,female,galvanic skin response,galvanic skin response physiology,heart rate,heart rate physiology,humans,light,male,photic stimulation,pupil,pupil physiology},
number = {4},
pages = {602--607},
pmid = {18282202},
publisher = {Wiley Online Library},
title = {{The pupil as a measure of emotional arousal and autonomic activation.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18282202},
volume = {45},
year = {2008}
}
@article{Woods1970,
abstract = {The use of augmented transition network grammars for the analysis of natural language sentences is described. Struc- ture-building actions associated with the arcs of the gram- mar network allow for the reordering, restructuring, and copy- ing of constituents necessary to produce deep-structure repre- sentations of the type normally obtained from a transforma- tional analysis, and conditions on the arcs allow for a powerful selectivity which can rule out meaningless analyses and take advantage of semantic information to guide the parsing. The advantages of this model for natural language analysis are discussed in detail and illustrated by examples. An imple- mentation of an experimental parsing system for transition network grammars is briefly described.},
author = {Woods, W A},
doi = {10.1145/355598.362773},
editor = {Grosz, Barbara and Jones, Karen and Webber, Bonnie},
file = {::},
issn = {00010782},
journal = {Communications of the ACM},
number = {10},
pages = {591--606},
publisher = {ASSOC COMPUTING MACHINERY},
title = {{Transition Network Grammars for Natural Language Analysis}},
url = {http://portal.acm.org/citation.cfm?doid=355598.362773},
volume = {13},
year = {1970}
}
@book{Thayer1996,
author = {Thayer, Robert E.},
isbn = {9780195118056},
pages = {288},
publisher = {Oxford University Press},
title = {{The Origin of Everyday Moods: Managing Energy, Tension, and Stress}},
year = {1996}
}
@inproceedings{Massimi2010,
author = {Massimi, M. and Baecker, R.M.},
booktitle = {Proceedings of the 28th international conference on Human factors in computing systems},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - p1821-massimi.pdf.pdf:pdf},
pages = {1821--1830},
publisher = {ACM},
title = {{A death in the family: opportunities for designing technologies for the bereaved}},
url = {http://dl.acm.org/citation.cfm?id=1753600},
year = {2010}
}
@article{Warner1987,
author = {Warner, Rebecca M. and Malloy, Daniel and Schneider, Kathy and Knoth, Russell and Wilder, Bruce},
doi = {10.1007/BF00990958},
file = {::},
issn = {0191-5886},
journal = {Journal of Nonverbal Behavior},
number = {2},
pages = {57--74},
title = {{Rhythmic organization of social interaction and observer ratings of positive affect and involvement}},
url = {http://www.springerlink.com/index/10.1007/BF00990958},
volume = {11},
year = {1987}
}
@article{Dada2006,
abstract = {Images: p1372-a:},
author = {Dada, Michael},
journal = {Journal of the National Medical Association},
number = {8},
pages = {1372},
publisher = {Motivate Healthy Habits},
title = {{Motivational Practice: Promoting Healthy Habits and Self-Care of Chronic Diseases}},
volume = {98},
year = {2006}
}
@article{Fehr1984,
author = {Fehr, B. and Russell, S.J.},
journal = {Journal of experimental psychology. General},
pages = {464 -- 486},
title = {{Concept of emotion viewed from a prototype perspective}},
volume = {113},
year = {1984}
}
@article{Hirsh2010,
abstract = {Research generally indicates that providers demonstrate modest insight into their clinical decision processes. In a previous study utilizing virtual human (VH) technology, we found that patient demographic characteristics and facial expressions of pain were statistically significant predictors of many nurses' pain-related decisions. The current study examined the correspondence between the statistically identified and self-reported influences of contextual information on pain-related decisions. Fifty-four nurses viewed vignettes containing a video of a VH patient and text describing a postsurgical context. VH sex, race, age, and facial expression varied across vignettes. Participants made pain-assessment and treatment decisions on visual analogue scales. Participants subsequently indicated the information they relied on when making decisions. None of the participants reported using VH sex, race, or age in their decision process. Statistical modeling indicated that 28 to 54\% of participants (depending on the decision) used VH demographic cues. 76\% of participants demonstrated concordance between their reported and actual use of the VH facial expression cue. Vital signs, text-based clinical summary, and VH movement were also reported as influential factors. These data suggest that biases may be prominent in practitioner decision-making about pain, but that providers have minimal awareness of and/or a lack of willingness to acknowledge this bias. PERSPECTIVE: The current study highlights the complexity of provider decision-making about pain management. The VH technology could be used in future research and education applications aimed at improving the care of all persons in pain.},
author = {Hirsh, Adam T and Jensen, Mark P and Robinson, Michael E},
doi = {10.1016/j.jpain.2009.09.004},
file = {::},
issn = {1528-8447},
journal = {The journal of pain : official journal of the American Pain Society},
keywords = {Adult,Age Factors,Computer Simulation,Continental Population Groups,Cues,Facial Expression,Female,Humans,Male,Models, Statistical,Movement,Nurses,Nurses: psychology,Pain,Pain Management,Pain Measurement,Pain: diagnosis,Self-Assessment,Sex Factors,User-Computer Interface},
month = may,
number = {5},
pages = {454--61},
pmid = {20015702},
publisher = {Elsevier Ltd},
title = {{Evaluation of nurses' self-insight into their pain assessment and treatment decisions.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2864339\&tool=pmcentrez\&rendertype=abstract},
volume = {11},
year = {2010}
}
@inproceedings{Ludwig2011,
abstract = {This paper describes a recommender system designed to help the user make enhanced life choices and prevent ill health. The system utilises sensors and user interactions, including physiological data, activity monitoring and dietary information. Based on these data the system estab- lishes user needs and provides lifestyle and nutritional advice to the user. To cement behavioural change the system utilises a feedback loop and al- lows the user to track his progress over time. The system is now in an early prototyping phase and has two main goals: 1) to improve the quality of life for users and 2) to prevent future health problems.},
address = {Dublin},
author = {Ludwig, Bernd and Mandl, Stefan and Elsweiler, David},
booktitle = {5th International Conference on Pervasive Computing Technologies for Healthcare (PervasiveHealth) and Workshops},
doi = {10.4108/icst.pervasivehealth.2011.246053},
file = {::},
isbn = {9781936968152},
keywords = {Health,Lifestyle,Prevention,Recommender Systems},
pages = {206--207},
title = {{REFRESH : REcommendations and Feedback for Realising and Stabilising Health}},
year = {2011}
}
@article{Meng2009,
author = {Meng, Qinggang and Lee, Mark},
doi = {10.1109/CASE.2009.156},
file = {::},
isbn = {978-0-7695-3728-3},
journal = {2009 IITA International Conference on Control, Automation and Systems Engineering (case 2009)},
keywords = {-home service robots,human-robot interaction},
month = jul,
pages = {220--224},
publisher = {Ieee},
title = {{Empathy between Human and Home Service Robots}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5194430},
year = {2009}
}
@inproceedings{Nguyen2009c,
author = {Nguyen, H. and Masthoff, Judith},
booktitle = {Proceedings of the 4th International Conference on Persuasive Technology},
file = {::},
isbn = {9781605583761},
keywords = {affective computing,design,experimentation,human factors},
pages = {7},
publisher = {ACM},
title = {{Designing empathic computers: the effect of multimodal empathic feedback using animated agent}},
url = {http://dl.acm.org/citation.cfm?id=1541958},
year = {2009}
}
@inproceedings{Cairco2009,
abstract = {Avari is a virtual receptionist for the Computer Science department at The University of North Carolina at Charlotte. Her components include background subtraction to detect a person’s presence, speech recognition, audio and visual devices to communicate with passersby. Deployed in a public setting, we investigate the reactions and interactions of passersby with Avari. We describe the design and architecture of the virtual human and discuss the effectiveness of a publicly deployed virtual human.},
address = {Clemson, SC, USA.},
author = {Cairco, Lauren and Hill, Rock and Wilson, Dale-marie and Fowler, Vicky and Leblanc, Morris},
booktitle = {48th ACM Southeast Conference (ACMSE'09)},
file = {::},
isbn = {9781605584218},
keywords = {human-centered,human-computer interaction,virtual humans},
pages = {1--6},
title = {{AVARI : Animated Virtual Agent Retrieving Information}},
year = {2009}
}
@article{Warner1987,
author = {Warner, Rebecca M. and Malloy, Daniel and Schneider, Kathy and Knoth, Russell and Wilder, Bruce},
doi = {10.1007/BF00990958},
file = {::},
issn = {0191-5886},
journal = {Journal of Nonverbal Behavior},
number = {2},
pages = {57--74},
title = {{Rhythmic organization of social interaction and observer ratings of positive affect and involvement}},
url = {http://www.springerlink.com/index/10.1007/BF00990958},
volume = {11},
year = {1987}
}
@article{Zahn-waxler1992,
author = {Zahn-Waxler, Carolyn and Robinson, JoAnn L. and Emde, Robert N.},
doi = {10.1037//0012-1649.28.6.1038},
file = {::},
issn = {0012-1649},
journal = {Developmental Psychology},
number = {6},
pages = {1038--1047},
title = {{The development of empathy in twins.}},
volume = {28},
year = {1992}
}
@article{Kaliouby2005,
author = {Kaliouby, R. and Robinson, Peter},
file = {::},
journal = {Real-time vision for human-computer interaction},
pages = {181--200},
publisher = {Springer},
title = {{Real-time inference of complex mental states from facial expressions and head gestures}},
url = {http://www.springerlink.com/index/K822871338R66039.pdf},
year = {2005}
}
@inproceedings{Hegel2006,
author = {Hegel, Frank and Spexard, Torsten and Wrede, Britta and Horstmann, G. and Vogt, T.},
booktitle = {Humanoid Robots, 2006 6th IEEE-RAS International Conference on},
file = {::},
isbn = {142440200X},
pages = {56--61},
publisher = {IEEE},
title = {{Playing a different imitation game: Interaction with an Empathic Android Robot}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4115580},
year = {2006}
}
@inproceedings{Nor2010,
author = {Nor, R.M. and Muhlberger, Ralf},
booktitle = {User Science and Engineering (i-USEr), 2010 International Conference on},
file = {::},
isbn = {9781424490493},
keywords = {-component,community,empathy,emphatic communication,user experience},
pages = {7--10},
publisher = {IEEE},
title = {{Designing to support empathy: Understanding user experience by using a model of interaction in meeting human needs}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5716713},
year = {2010}
}
@inproceedings{Vargas2010,
abstract = {Multimodal conversational dialogue sys- tems consisting of numerous software components create challenges for the un- derlying software architecture and devel- opment practices. Typically, such sys- tems are built on separate, often pre- existing components developed by dif- ferent organizations and integrated in a highly iterative way. The traditional dia- logue system pipeline is not flexible enough to address the needs of highly in- teractive systems, which include parallel processing of multimodal input and out- put. We present an architectural solution for a multimodal conversational social dialogue system.},
address = {The University of Tokyo},
author = {Vargas, C Emilio and Field, Debora},
booktitle = {Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
file = {::},
pages = {47--50},
publisher = {Association for Computational Linguistics},
title = {{‘ How was your day ?’ An architecture for multimodal ECA systems}},
year = {2010}
}

@inproceedings{singh1999reinforcement,
  title={Reinforcement learning for spoken dialogue systems},
  author={Singh, Satinder and Kearns, Michael and Litman, Diane and Walker, Marilyn},
  booktitle={Proc. NIPS99},
  year={1999}
}

@article{young2013pomdp,
  title={POMDP-Based Statistical Spoken Dialog Systems: A Review},
  author={Young, Steve and Ga{\v{s}}i{\'c}, M and Thomson, Blaise and Williams, JD},
  year={2013},
  publisher={IEEE}
}

@article{young2010POMDP,
  title={The hidden information state model: A practical framework for POMDP-based spoken dialogue management},
  author={Young, Steve and Ga{\v{s}}i{\'c}, Milica and Keizer, Simon and Mairesse, Fran{\c{c}}ois and Schatzmann, Jost and Thomson, Blaise and Yu, Kai},
  journal={Computer Speech \& Language},
  volume={24},
  number={2},
  pages={150--174},
  year={2010},
  publisher={Elsevier}
}

@inproceedings{Janarthanam2010,
 author = {Janarthanam, Srinivasan and Lemon, Oliver},
 title = {Adaptive referring expression generation in spoken dialogue systems: evaluation with real users},
 booktitle = {Proceedings of the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 series = {SIGDIAL '10},
 year = {2010},
 isbn = {978-1-932432-85-5},
 location = {Tokyo, Japan},
 pages = {124--131},
 numpages = {8},
 url = {http://dl.acm.org/citation.cfm?id=1944506.1944530},
 acmid = {1944530},
 publisher = {Association for Computational Linguistics},
 address = {Stroudsburg, PA, USA},
} 

@article{Shamay-Tsoory2011,
abstract = {Human empathy relies on the ability to share emotions as well as the ability to understand the other's thoughts, desires, and feelings. Recent evidence points to 2 separate systems for empathy: an emotional system that supports our ability to empathize emotionally and a cognitive system that involves cognitive understanding of the other's perspective. A neural network that includes the inferior frontal gyrus and the inferior parietal lobule is necessary for emotion recognition and emotional contagion. Although the emotional and cognitive systems appear to work independently, every empathic response may still evoke both components to some extent, depending on the social context.},
annote = {Difference between cognitive empathy and emotional empathy is explained in this paper. Also they talk about the active brain parts in each empathy type.},
author = {Shamay-Tsoory, Simone G},
doi = {10.1177/1073858410379268},
file = {::},
issn = {1089-4098},
journal = {The Neuroscientist : a review journal bringing neurobiology, neurology and psychiatry},
keywords = {Brain,Brain: physiology,Empathy,Empathy: physiology,Humans,Neural Pathways,Neural Pathways: physiology},
month = feb,
number = {1},
pages = {18--24},
pmid = {21071616},
title = {{The neural bases for empathy.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21071616},
volume = {17},
year = {2011}
}
@book{Doherty1998,
author = {Doherty, William Joseph and Campbell, Thomas},
pages = {159},
publisher = {Stage Pubications},
title = {{Families and Health}},
year = {1998}
}
@article{Prendinger2006,
annote = {they have tested 4 different empathic behaviours in a competitive card game.
1- Non-Emotional2- Self-Centered Emotional
3- Negative Empathic 
4- Positive Empathic 
They found out that:
 - absence of the agent's display of negative emotions is arousing for the user and highers his/her stress.
 - valence of users' emotional response is congruent with the valence of the emotion expressed by the agent.},
author = {Prendinger, H and Becker-Asano, Christian},
file = {::},
journal = {International Journal of Humanoid},
keywords = {affective behavior,empathy,evaluation,life-like characters,physiological user information},
number = {3},
pages = {371--391},
title = {{A STUDY IN USERS'S;PHYSIOLOGICAL RESPONSE TO AN EMPATHIC INTERFACE AGENT}},
volume = {3},
year = {2006}
}
@book{Miller1995a,
author = {Miller, WR and Tonigan, JS and Longabaugh, R},
booktitle = {Psychology},
editor = {Mattson, Margaret E},
pages = {98},
publisher = {National Institute on Alcohol Abuse and Alcoholism},
series = {Project MATCH Monograph Series},
title = {{The Drinker Inventory of Consequences (DrInC): An Instrument for Assessing Adverse Consequences of Alcohol Abuse}},
url = {http://scholar.google.com/scholar?q=The+Drinker+Inventory+of+Consequences+(DrInC).+An+Instrument+for+Assessing+Adverse+Consequences+of+Alcohol+Abuse\&hl=en\&btnG=Search\&as\_sdt=2001\&as\_sdtp=on\#1},
volume = {4},
year = {1995}
}
@inproceedings{Smith2010,
abstract = {The development of Embodied Conversational Agents (ECA) as Companions brings several challenges for both affective and conversational dialogue. These include challenges in generating appropriate affective responses, selecting the overall shape of the dialogue, providing prompt system response times and handling interruptions. We present an implementation of such a Companion showing the development of individual modules that attempt to address these challenges. Further, to resolve resulting conflicts, we present encompassing interaction strategies that attempt to balance the competing requirements. Finally, we present dialogues from our working prototype to illustrate these interaction strategies in operation.},
author = {Smith, Cameron and Crook, Nigel and Boye, Johan and Charlton, Daniel and Dobnik, Simon and Pizzi, David and Cavazza, Marc and Pulman, Stephen},
booktitle = {IVA'10 Proceedings of the 10th international conference on Intelligent virtual agents},
file = {::},
keywords = {affective dialogue,companion,conversational dialogue,embodied conversational agents,interaction strategies,interruptions},
pages = {301--314},
publisher = {Springer-Verlag Berlin, Heidelberg},
title = {{Interaction Strategies for an Affective Conversational Agent}},
year = {2010}
}
@article{Chung,
author = {Chung, Donghun and DeBuys, B. and Nam, C.},
file = {::},
journal = {Human-Computer Interaction. Interaction Design and Usability},
keywords = {attitude,avatar,empathy,para-social interaction,presence,wii},
pages = {711--720},
publisher = {Springer},
title = {{Influence of avatar creation on attitude, empathy, presence, and para-social interaction}},
url = {http://www.springerlink.com/index/9518116J51670433.pdf},
year = {2007}
}
@misc{TheMendeleySupportTeam2011,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/The Mendeley Support Team - 2011 - Getting Started with Mendeley(4).pdf:pdf},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@article{Zhang2009,
abstract = {This paper presents a new anthropometrics-based method for generating realistic, controllable face models. Our method establishes an intuitive and efficient interface to facilitate procedures for interactive 3D face modeling and editing. It takes 3D face scans as examples in order to exploit the variations presented in the real faces of individuals. The system automatically learns a model prior from the data-sets of example meshes of facial features using principal component analysis (PCA) and uses it to regulate the naturalness of synthesized faces. For each facial feature, we compute a set of anthropometric measurements to parameterize the example meshes into a measurement space. Using PCA coefficients as a compact shape representation, we formulate the face modeling problem in a scattered data interpolation framework which takes the user-specified anthropometric parameters as input. Solving the interpolation problem in a reduced subspace allows us to generate a natural face shape that satisfies the user-specified constraints. At runtime, the new face shape can be generated at an interactive rate.We demonstrate the utility of our method by presenting several applications, including analysis of facial features of subjects in different race groups, facial feature transfer, and adapting face models to a particular population group.},
author = {Zhang, Yu and Prakash, Edmond C.},
doi = {10.1155/2009/573924},
file = {::},
issn = {1687-7047},
journal = {International Journal of Computer Games Technology},
pages = {1--15},
title = {{Face to Face: Anthropometry-Based Interactive Face Shape Modeling Using Model Priors}},
url = {http://www.hindawi.com/journals/ijcgt/2009/573924/},
volume = {2009},
year = {2009}
}
@article{LaFrance1982,
abstract = {The relationship between client-perceived rapport (as measured from a standardized client) and physical mirroring and the standard counsellor posture was investigated with interviews performed by 59 post-graduate students (47 females and 12 males, aged 21-60 yrs) in counselling psychology. Videotaped recordings were used to code counsellor posture in the categories of: total postural mirroring, mirroring of the hands and arms, mirroring of the legs, mirroring of the torso, and the frequency of the standard counsellor posture across each minute of the interviews. These minutes were classified as 'high' in rapport or 'low' in rapport as measured by the standardized client. Results indicated that there was significantly more postural mirroring of the torso during high versus low minutes, but that the counsellor standard posture occurred significantly more frequently during low rapport minutes than in high rapport minutes. However, when examined over the entire length of the interviews, these data were able to be understood in terms of counsellor 'flexibility' of response rather than simply whether these postural behaviors were present or not. Implications for counsellor training are discussed. (PsycINFO Database Record (c) 2009 APA},
author = {Lafrance, Marianne},
doi = {10.1080/09515070110088843},
issn = {09515070},
journal = {Counselling Psychology Quarterly},
number = {4},
pages = {267--280},
publisher = {Human Sciences Press},
title = {{Posture mirroring and rapport}},
volume = {14},
year = {1982}
}
@book{Hojat2007b,
author = {Hojat, M.},
booktitle = {Patient Care},
file = {::},
isbn = {9780387336077},
publisher = {Springer Verlag},
title = {{Empathy in patient care: antecedents, development, measurement, and outcomes}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=OZT1sypBp5EC\&amp;oi=fnd\&amp;pg=PR7\&amp;dq=Empathy+In+Patient+Care:+Antecedents,+Development,+Measurements,+and+Outcomes\&amp;ots=8aQbxTclHN\&amp;sig=HFiEPtCVpFvXI6HU3rprIwvHGXc},
year = {2007}
}
@article{Schneier2011,
author = {Schneier, B.},
file = {::},
journal = {Security \& Privacy, IEEE},
number = {5},
pages = {88--88},
publisher = {IEEE},
title = {{Empathy and Security}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6029366},
volume = {9},
year = {2011}
}
@article{Chuang2004,
author = {Chuang, ZJ},
file = {::},
journal = {International Journal of Computational},
number = {2},
pages = {45--62},
title = {{Multi-modal emotion recognition from speech and text}},
url = {http://www.mendeley.com/research/multimodal-emotion-recognition-from-speech-and-text/},
volume = {9},
year = {2004}
}
@article{Allwood2002,
author = {Allwood, Jens},
file = {::},
journal = {Multimodality in language and speech systems},
number = {26},
pages = {1--15},
publisher = {Kluwer Academic Publishers},
title = {{Bodily communication dimensions of expression and content}},
url = {http://books.google.com/books?hl=en\&lr=\&id=EhvKccHyp-YC\&oi=fnd\&pg=PA7\&dq=BODILY+COMMUNICATION+DIMENSIONS+OF+EXPRESSION+AND+CONTENT\&ots=VJi0CsBpSv\&sig=hKcLiJG5dnvRXrrCAzlwTC3Le8M},
volume = {7},
year = {2002}
}
@article{Bartlett2006,
author = {Bartlett, Marian Stewart and Littlewort, Gwen C and Frank, Mark G and Lainscsek, Claudia and Fasel, Ian R and Movellan, Javier R},
doi = {10.4304/jmm.1.6.22-35},
file = {::},
institution = {UCSD},
issn = {17962048},
journal = {Journal of Multimedia},
number = {6},
pages = {22--35},
publisher = {Citeseer},
title = {{Automatic Recognition of Facial Actions in Spontaneous Expressions}},
volume = {1},
year = {2006}
}
@inproceedings{Bartneck2008,
abstract = {This study emphasizes the need for standardized measurement tools for human robot interaction (HRI). If we are to make progress in this field then we must be able to compare the results from different studies. A literature review has been performed on the measurements of five key concepts in HRI: anthropomorphism, animacy, likeability, perceived intelligence, and perceived safety. The results have been distilled into five consistent questionnaires using semantic differential scales. We report reliability and validity indicators based on several empirical studies that used these questionnaires. It is our hope that these questionnaires can be used by robot developers to monitor their progress. Psychologists are invited to further develop the questionnaires by adding new concepts, and to conduct further validations where it appears necessary.},
address = {Amsterdam},
author = {Bartneck, Christoph and Kulic, Dana and Croft, Elizabeth},
booktitle = {Proceedings of the Metrics for Human-Robot Interaction Workshop in affiliation with the 3rd ACM/IEEE International Conference on Human-Robot Interaction (HRI 2008), Technical Report 471},
file = {::},
keywords = {Human factors,measurement,perception,robot},
pages = {37--44},
publisher = {University of Hertfordshire},
title = {{Measuring the anthropomorphism, animacy, likeability, perceived intelligence and perceived safety of robots}},
url = {http://ece.uwaterloo.ca/~dkulic/pubs/bartneckKulicCroft.pdf},
volume = {471},
year = {2008}
}
@article{Saunier2010,
author = {Saunier, Julien and Jones, Hazael and Lourdeaux, Domitile},
doi = {10.1109/WI-IAT.2010.255},
file = {::},
isbn = {978-1-4244-8482-9},
journal = {2010 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology},
keywords = {emotions,empathy,multi-agent architecture,personality,placebo},
month = aug,
pages = {277--282},
publisher = {Ieee},
title = {{Empathy and Placebo for Autonomous Agents}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5616059},
year = {2010}
}
@article{Feshbach1968,
author = {Feshbach, N D and Roe, K},
journal = {Child Development},
number = {1},
pages = {133--145},
pmid = {5645790},
title = {{Empathy in six- and seven-year-olds.}},
volume = {39},
year = {1968}
}
@article{Lakin2003b,
author = {Lakin, J. L. and Chartrand, T. L.},
doi = {10.1111/1467-9280.14481},
file = {::},
issn = {0956-7976},
journal = {Psychological Science},
month = jul,
number = {4},
pages = {334--339},
title = {{Using Nonconscious Behavioral Mimicry to Create Affiliation and Rapport}},
url = {http://pss.sagepub.com/lookup/doi/10.1111/1467-9280.14481},
volume = {14},
year = {2003}
}
@article{Albrecht2005,
author = {Albrecht, Irene and Schr\"{o}der, Marc and Haber, J\"{o}rg and Seidel, Hans-Peter},
doi = {10.1007/s10055-005-0153-5},
file = {::},
issn = {1359-4338},
journal = {Virtual Reality},
keywords = {continuous emotions \ae emotional,speech,synthesis \ae facial animation},
month = aug,
number = {4},
pages = {201--212},
title = {{Mixed feelings: expression of non-basic emotions in a muscle-based talking head}},
url = {http://www.springerlink.com/index/10.1007/s10055-005-0153-5},
volume = {8},
year = {2005}
}
@article{Johnstone2000,
abstract = {This chapter provides a comprehensive overview of the current state of the literature on the vocal communication of emotion. It highlights some of the many evolutionary, physiological, cognitive, social, and cultural factors which shape the way humans express and perceive emotions in speech. With such a large and seemingly disparate number of determinants, it might seem as if the topic were too messy to expect any invariance in empirical findings. Perhaps surprisingly however, the summary of research into the production and perception of emotional speech has revealed considerable consistency. On the production side, the evidence is starting to accumulate that humans consistently modify their speech in specific ways to express different emotions. The major acoustic parameters are described and the relevant literature reviewed. Results of perception studies indicate that emotions expressed in speech are to a large extent successfully detected by a variety of populations, on the basis of an experimentally identifiable set of acoustic parameters. The differences in recognition accuracy between different emotions are discussed. The consistency in the results is no doubt partly because most research to date has been limited to settings in which many of the factors described above have been eliminated or controlled for. In addition to further refinement of analysis techniques and a focus on real, as well as acted, emotional speech, there is clearly a need for studies that better quantify the relative contribution of culture, language and social strategy to the vocal comunication of emotion. To address these issues in a manner that allows results from different studies to be integrated and compared, a coordinated, interdisciplinary approach to research on the vocal communication of emotion will be required.},
author = {Johnstone, Tom and Scherer, Klaus R.},
chapter = {14},
editor = {Lewis, M and Haviland-Jones, J M},
journal = {Handbook of emotions},
number = {1-2},
pages = {220--235},
publisher = {The Guilford Press},
title = {{Vocal communication of emotion}},
url = {http://centaur.reading.ac.uk/4362/},
volume = {2},
year = {2000}
}
@inproceedings{Steunebrink2009,
author = {Steunebrink, B.R. and Dastani, Mehdi and Meyer, J.J.C.},
booktitle = {Proceedings of the 4th Workshop on Emotion and Computing},
file = {::},
title = {{The OCC model revisited}},
url = {http://www.idsia.ch/~steunebrink/Publications/KI09\_OCC\_revisited.pdf},
year = {2009}
}
@article{McQuiggan2008,
abstract = {Humans continuously assess one another’s situational context, modify their own affective state, and then respond based on these outcomes through empathetic expression. Virtual agents should be capable of similarly empathizing with users in interactive environments. A key challenge posed by empathetic reasoning in virtual agents is determining whether to respond with parallel or reactive empathy. Parallel empathy refers to mere replication of another’s affective state, whereas reactive empathy exhibits greater cognitive awareness and may lead to incongruent emotional responses (i.e., emotions different from the recipient’s and perhaps intended to alter negative affect). This paper proposes a unified inductive framework for modeling parallel and reactive empathy. Empathy models are used to drive runtime situation-appropriate empathetic behaviors by selecting suitable parallel or reactive empathetic expressions.},
annote = {- No automatic affect detection
- agent demographics are not taken into account.},
author = {McQuiggan, SW and Robison, JL and Phillips, Robert},
file = {::},
journal = {on Autonomous agents},
number = {Aamas},
pages = {167--174},
title = {{Modeling parallel and reactive empathy in virtual agents: An inductive approach}},
url = {http://portal.acm.org/citation.cfm?id=1402411},
year = {2008}
}
@article{Cogger1982,
author = {Cogger, J W},
journal = {The Personnel journal},
number = {11},
pages = {840--843},
pmid = {10258019},
title = {{Are you a skilled interviewer?}},
volume = {61},
year = {1982}
}
@article{Kuntsche2006,
abstract = {The aim was to review the empirical research carried out over the last 15 years on the characteristics of young people (10- to 25-year olds) who have specific motives for drinking. In a computer-assisted search of relevant literature, 82 studies were identified. Concerning demographic factors, a developmental trend was found - from general, undifferentiated drinking motives in late childhood and early adolescence to more gender-specific drinking motives in subsequent years. With regard to personality factors, two specific patterns can be distinguished: extraversion and sensation-seeking correlate with enhancement motives, while neuroticism and anxiety correlate most strongly with coping motives. For contextual factors, drinking motives were found to vary across countries but not among different ethnic groups in the same culture. Based on these results, preventive strategies should take into account general, undifferentiated drinking motivation in late childhood, and social and enhancement motives in adolescence, particularly among boys. Findings on personality indicate that it would be useful to focus on extraverted, sensation-seeking boys who drink for enhancement motives and neurotic, anxious girls who drink for coping motives.},
author = {Kuntsche, Emmanuel and Knibbe, Ronald and Gmel, Gerhard and Engels, Rutger},
doi = {10.1016/j.addbeh.2005.12.028},
file = {::},
issn = {0306-4603},
journal = {Addictive behaviors},
keywords = {Adaptation, Psychological,Adolescent,Adult,Age Factors,Alcohol Drinking,Alcohol Drinking: psychology,Anxiety,Anxiety: etiology,Child,Culture,Humans,Motivation,Personality,Sex Factors},
month = oct,
number = {10},
pages = {1844--57},
pmid = {16460883},
title = {{Who drinks and why? A review of socio-demographic, personality, and contextual issues behind the drinking motives in young people.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16460883},
volume = {31},
year = {2006}
}
@article{Hatfield2009,
author = {Hatfield, Elaine and Rapson, Richard L. and Le, Yen-Chi L.},
file = {::},
journal = {The social neuroscience of empathy},
pages = {1--20},
title = {{Emotional Contagion and Empathy}},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=KLvJKTN\_nDoC\&amp;oi=fnd\&amp;pg=PA19\&amp;dq=Emotional+Contagion+and+Empathy\&amp;ots=gC929Xij3X\&amp;sig=IFpRxpx1igOlZl86Jr837oVgfhY},
year = {2009}
}
@article{Zeng2009,
abstract = {Automated analysis of human affective behavior has attracted increasing attention from researchers in psychology, computer science, linguistics, neuroscience, and related disciplines. However, the existing methods typically handle only deliberately displayed and exaggerated expressions of prototypical emotions despite the fact that deliberate behaviour differs in visual appearance, audio profile, and timing from spontaneously occurring behaviour. To address this problem, efforts to develop algorithms that can process naturally occurring human affective behaviour have recently emerged. Moreover, an increasing number of efforts are reported toward multimodal fusion for human affect analysis including audiovisual fusion, linguistic and paralinguistic fusion, and multi-cue visual fusion based on facial expressions, head movements, and body gestures. This paper introduces and surveys these recent advances. We first discuss human emotion perception from a psychological perspective. Next we examine available approaches to solving the problem of machine understanding of human affective behavior, and discuss important issues like the collection and availability of training and test data. We finally outline some of the scientific and engineering challenges to advancing human affect sensing technology.},
author = {Zeng, Zhihong and Pantic, Maja and Roisman, Glenn I and Huang, Thomas S.},
doi = {10.1109/TPAMI.2008.52},
file = {::},
isbn = {9781595938176},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Affect,Affect: physiology,Algorithms,Artificial Intelligence,Automated,Automated: methods,Emotions,Emotions: physiology,Facial Expression,Monitoring,Pattern Recognition,Physiologic,Physiologic: methods,Sound Spectrography,Sound Spectrography: methods},
month = jan,
number = {1},
pages = {39--58},
pmid = {19029545},
title = {{A survey of affect recognition methods: audio, visual, and spontaneous expressions.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19029545},
volume = {31},
year = {2009}
}
@inproceedings{Wright2008,
author = {Wright, Peter and McCarthy, J.},
booktitle = {Proceeding of the twenty-sixth annual SIGCHI conference on Human factors in computing systems},
file = {::},
isbn = {9781605580111},
pages = {637--646},
publisher = {ACM},
title = {{Empathy and experience in HCI}},
url = {http://dl.acm.org/citation.cfm?id=1357156},
year = {2008}
}
@article{Segal2011,
author = {Segal, Elizabeth},
doi = {10.1080/01488376.2011.564040},
file = {::},
issn = {0148-8376},
journal = {Journal of Social Service Research},
keywords = {a dedication to justice,a nation that proclaims,and social well-being and,civic involvement,empathy,scapegoating,social empathy,social responsibility,the united states is},
month = may,
number = {3},
pages = {266--277},
title = {{Social Empathy: A Model Built on Empathy, Contextual Understanding, and Social Responsibility That Promotes Social Justice}},
url = {http://www.informaworld.com/openurl?genre=article\&doi=10\%2e1080\%2f01488376\%2e2011\%2e564040\&magic=crossref\%7c\%7cD404A21C5BB053405B1A640AFFD44AE3},
volume = {37},
year = {2011}
}
@article{Liu2008,
author = {Liu, Zhen},
file = {::},
journal = {InTech Education and Publishing},
title = {{Computational Emotion Model for Virtual Characters}},
url = {http://www.intechopen.com/source/pdfs/5186/InTech-Computational\_emotion\_model\_for\_virtual\_characters.pdf},
year = {2008}
}
@incollection{Dautenhahn2002,
author = {Dautenhahn, Kerstin and Bond, Alan and Ca\~{n}amero, Lola and Edmonds, Bruce},
booktitle = {Socially Intelligent Agents: Creating Relationships with Computers and Robots},
chapter = {1},
editor = {Dautenhahn, Kerstin and Bond, Alan and Ca\~{n}amero, Lola and Edmonds, Bruce},
file = {::},
isbn = {978-1-4020-7057-0},
pages = {1--20},
publisher = {Springer},
title = {{Creating Relationships with Computers and Robots}},
url = {http://www.springerlink.com/index/V38H434X220766G8.pdf},
year = {2002}
}
@inproceedings{Heerink2009,
author = {Heerink, Marcel and Krose, B. and Evers, Vanessa and Wielinga, Bob},
booktitle = {Robot and Human Interactive Communication, 2009. RO-MAN 2009. The 18th IEEE International Symposium on},
file = {::},
pages = {528--533},
publisher = {Ieee},
title = {{Measuring acceptance of an assistive social robot: a suggested toolkit}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5326320},
year = {2009}
}
@article{Breemen2005,
abstract = {We developed a robotic research platform called "iCat" for studying social human-robot interaction. The platform consists of the robotic character "iCat", which is a desktop user-interface robot with mechanically rendered facial expressions. Recently, Philips Research made this platform available for universities and research laboratories to stimulate the momentum in Human-Robot Interaction research [5].},
author = {van Breemen, A and Yan, X},
doi = {10.1145/1082473.1082823},
file = {::},
journal = {AAMAS '05 Proceedings of the fourth international joint conference on Autonomous agents and multiagent systems},
pages = {143--144},
title = {{iCat: an animated user-interface robot with personality}},
url = {http://dl.acm.org/citation.cfm?id=1082823},
year = {2005}
}
@inproceedings{Wright2008,
author = {Wright, Peter and McCarthy, J.},
booktitle = {Proceeding of the twenty-sixth annual SIGCHI conference on Human factors in computing systems},
file = {::},
isbn = {9781605580111},
pages = {637--646},
publisher = {ACM},
title = {{Empathy and experience in HCI}},
url = {http://dl.acm.org/citation.cfm?id=1357156},
year = {2008}
}
@incollection{Pereira2008,
abstract = {Emotional-BDI agents are BDI agents whose behaviour is guided not only by beliefs, desires and intentions, but also by the role of emotions in reasoning and decision-making. The EBDI logic is a formal sys- tem for expressing the concepts of the Emotional-BDI model of agency. In this paper we present an improved version of the EBDI logic and show how it can be used to model the role of three emotions in Emotional-BDI agents: fear, anxiety and self-confidence. We also focus in the computa- tional properties of EBDI which can lead to its use in automated proof systems.},
author = {Pereira, David},
booktitle = {Computational Logic in Multi-Agent Systems},
doi = {10.1007/978-3-540-88833-8\_4},
editor = {Sadri, Fariba and Satoh, Ken},
file = {::},
isbn = {978-3-540-88832-1},
pages = {62--81},
publisher = {Springer-Verlag},
title = {{Formal Modelling of Emotions in BDI Agents}},
year = {2008}
}
@article{Riek2008,
abstract = {Expressing empathy is a key component of human social communication. One common way people convey empathy is via facial expression mirroring. It may be helpful for machines intended to interact with people to also convey empathy in this manner. We have thus created Virgil, an expression-mimicking robot. We hypothesize that if people feel like a machine is empathizing with them they will be more likely to rate the interaction positively. We conducted a pilot study to test our hypothesis, and through quantitative and qualitative analysis of our results found some support for it.},
author = {Riek, Laurel D. and Robinson, Peter},
file = {::},
journal = {ACM Workshop on Affective Interaction in Natural Environments AFFINE at the International ACM Conference on Multimodal Interfaces ICMI 08},
pages = {1--5},
publisher = {ACM},
title = {{Real-time empathy: Facial mimicry on a robot}},
year = {2008}
}
@article{Rameson2009,
author = {Rameson, Lian T. and Lieberman, Matthew D.},
doi = {10.1111/j.1751-9004.2008.00154.x},
file = {::},
issn = {17519004},
journal = {Social and Personality Psychology Compass},
month = jan,
number = {1},
pages = {94--110},
title = {{Empathy: A Social Cognitive Neuroscience Approach}},
url = {http://doi.wiley.com/10.1111/j.1751-9004.2008.00154.x},
volume = {3},
year = {2009}
}
@incollection{Rogers1959,
address = {New York},
author = {Rogers, C R},
booktitle = {Psychology: the Study of a Science},
chapter = {3},
editor = {Koch, S},
pages = {184--256},
publisher = {McGraw-Hill},
title = {{A theory of therapy, personality and interpersonal relationships as developed in the client-centered framework}},
volume = {3},
year = {1959}
}
@book{Davis1994,
author = {Davis, Mark H.},
isbn = {0697168948},
publisher = {Westview Press},
title = {{Empathy: A social psychological approach}},
year = {1994}
}
@article{Bartlett2006,
author = {Bartlett, Marian Stewart and Littlewort, Gwen C and Frank, Mark G and Lainscsek, Claudia and Fasel, Ian R and Movellan, Javier R},
doi = {10.4304/jmm.1.6.22-35},
file = {::},
institution = {UCSD},
issn = {17962048},
journal = {Journal of Multimedia},
number = {6},
pages = {22--35},
publisher = {Citeseer},
title = {{Automatic Recognition of Facial Actions in Spontaneous Expressions}},
volume = {1},
year = {2006}
}
@article{Gruen1986,
author = {Gruen, Rand J. and Mendelsohn, Gerald},
doi = {10.1037/0022-3514.51.3.609},
file = {::},
issn = {1939-1315},
journal = {Journal of Personality and Social Psychology},
number = {3},
pages = {609--614},
title = {{Emotional responses to affective displays in others: The distinction between empathy and sympathy.}},
volume = {51},
year = {1986}
}
@article{Hess2001,
author = {Hess, Ursula and Blairy, Sylvie},
file = {::},
journal = {International Journal of Psychophysiology},
keywords = {emotion recognition,emotional contagion,facial mimicry},
pages = {129--141},
title = {{Facial mimicry and emotional contagion to dynamic emotional facial expressions and their influence on decoding accuracy}},
volume = {40},
year = {2001}
}
@article{Baldassarri2008,
abstract = {This paper presents a powerful animation engine for developing applications with embodied animated agents called Maxine. The engine, based on open source tools, allowsmanagement of scenes and virtual characters, and pays special attention to multimodal and emotional interaction with the user. Virtual actors are endowed with facial expressions, lip-synch, emotional voice, and they can vary their answers depending on their own emotional state and the relationship with the user during conversation. Maxine virtual agents have been used in several applications: a virtual presenterwas employed in MaxinePPT, a specific application developed to allow non-programmers to create 3D presentations easily using classical PowerPoint presentations; a virtual character was also used as an interactive interface to communicate with and control a domotic environment; finally, an interactive pedagogical agent was used to simplify and improve the teaching and practice of Computer Graphics subjects.},
annote = {Summery: 
        
Their system is an animating engine which allows management of scenes and virtual characters. It provides multimodal emotional interaction with the user. The virtual characters have different emotional facial expressions, lip-synch, and emotional voice. The expressions are selected based on the character's emotional state and the relationship with the user during conversation.
        
In this research they focus on the interactive virtual agents that support multimodal and emotional interaction in order to establish more effective communication with the user. So, the character captures the user’s emotional facial expressions through a camera, and responds with appropriate emotional facial expressions and voices.
        
They use Ekman’s emotional facial classification for recognition and expression: happiness, sadness, anger, fear, surprise, disgust, and neutral.
        
Positive points:
        
 - Good references for us: 
        
"most research on social interfaces is related to the design of embodied conversational agents (ECAs) [1]".
        
"Virtual characters equipped with these new features can be used in a wide range of contexts [2,3], including education and learning [4–8], sign language interpretation [9], therapy [10], persuasion [11,12],entertainment [13,14], among others".
        
"In order to achieve a more natural and realistic interaction,
virtual agents must be capable of appropriately responding to users with affective feedback [15]".
        
 - another application that we can add to the future grants:
we can use our system to interact with with disabled clients (for example, the hearing-impaired or paraplegics) if we add appropriate voice recognition, NLP, and body languages to the system.
        
 - they use a voice recognition engine built on the commercial Loquendo ASR software [22] which we can use too. 
        
- They use the same model as our system for the character's feedbacks. There are 2 kinds of character feedbacks in their system: 1- Purely reactive: For example, if the user keys something in, the virtual character will interrupt the presentation; or if the user changes his or her position, the character’s look/ orientation will change; if a lot of background noise is detected, it will request silence, etc. 
        
2- Deliberative: The choice of the virtual character’s reaction needs more complex analysis.
 - They use emotional voice as another modality by modifying the tone, frequency scale, volume and speed. We can do the same to add the another modality to the emotion expression of our system. 
        
        
Negative points:
        
 - It is not clear what avatar system they use. It looks like Haptek, but because of the way they talk about animating the character it might be another system.
        
 - They don't present their model of feedback in details. So we don't know how their system decides what to express based on the inputs (mouse, keyboard, user emotions, character emotions, user position).
        
      },
author = {Baldassarri, Sandra and Cerezo, Eva and Seron, Francisco J.},
doi = {10.1016/j.cag.2008.04.006},
file = {::},
issn = {00978493},
journal = {Computers \& Graphics},
keywords = {Animated characters,Multimodal interfaces,Natural interaction,Virtual worlds},
month = aug,
number = {4},
pages = {430--437},
title = {{Maxine: A platform for embodied animated agents}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0097849308000472},
volume = {32},
year = {2008}
}
@article{Scherer2007,
abstract = {In earlier work, the authors analyzed emotion portrayals by professional actors separately for facial expression, vocal expression, gestures, and body movements. In a secondary analysis of the combined data set for all these modalities, the authors now examine to what extent actors use prototypical multimodal configurations of expressive actions to portray different emotions, as predicted by basic emotion theories claiming that expressions are produced by fixed neuromotor affect programs. Although several coherent unimodal clusters are identified, the results show only 3 multimodal clusters: agitation, resignation, and joyful surprise, with only the latter being specific to a particular emotion. Finding variable expressions rather than prototypical patterns seems consistent with the notion that emotional expression is differentially driven by the results of sequential appraisal checks, as postulated by componential appraisal theories.},
author = {Scherer, Klaus R. and Ellgring, Heiner},
doi = {10.1037/1528-3542.7.1.158},
file = {::},
issn = {1528-3542},
journal = {Emotion (Washington, D.C.)},
keywords = {Adult,Affect,Facial Expression,Female,Gestures,Humans,Judgment,Male,Psychomotor Performance,Speech Acoustics,Voice},
month = feb,
number = {1},
pages = {158--71},
pmid = {17352571},
title = {{Multimodal expression of emotion: affect programs or componential appraisal patterns?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17352571},
volume = {7},
year = {2007}
}
@inproceedings{Sullins2009,
abstract = {In this paper we explored the relationship between learning gains and affective displays of an animated pedagogical agent. Students read information on the topic of computer literacy while receiving either positive or negative affective responses from an on-screen animated agent. Analyses revealed that only students with low prior knowledge were influenced by the emotion displayed by the animated agent. We discuss the generalizability of our findings to other domains and the implications of these results on intelligent tutoring systems that are emotionally intelligent.},
author = {Sullins, Jeremiah and Craig, Scotty D and Graesser, Arthur C},
booktitle = {Proceedings of the 2009 conference on Artificial Intelligence in Education: Building Learning Systems that Care: From Knowledge Representation to Affective Modelling},
file = {::},
keywords = {affect,animated agents,emotion,prior knowledge},
pages = {677--679},
publisher = {IOS Press Amsterdam, The Netherlands},
title = {{Tough Love : The Influence of an Agent ’ s Negative Affect on Students ’ Learning}},
year = {2009}
}
@article{Tickle-Degnen1990,
abstract = {The purpose of this article is to offer a conceptualization of rapport that has utility for identifiing the nonverbal correlates associated with rapport. We describe the nature of rapport in terms of a dynamic structure of three interrelating components: mutual attentiveness, positivity, and coor- dination. We propose that the relative weighting of these components in the experience of rapport changes over the course of a developing relationship between individuals. In early interactions, positivity and attentiveness are more heavily weighted than coordination, whereas in later interactions, coordination and attentiveness are the more heavily weighted components. Because of the gestalt nature of the experience of rapport, it is not easy to identifi nonverbal behavioral correlates of the components. We discuss two approaches to nonverbal measurement, molecular and molar, along with recommendations for their appropriate application in the study of rapport at different stages of an interpersonal relationship. We present a meta-analytic study that demon- strates the effect of nonverbal behavior, measured at the molecular level, on the positivity component of rapport, and we conclude with an outline of hypotheses relevant to the investigation of the nonverbal correlates of rapport.},
author = {Tickle-Degnen, L. and Rosenthal, Robert},
file = {::},
journal = {Psychological Inquiry},
number = {4},
pages = {285--293},
publisher = {Taylor \& Francis},
title = {{The nature of rapport and its nonverbal correlates}},
url = {http://www.tandfonline.com/doi/abs/10.1207/s15327965pli0104\_1},
volume = {1},
year = {1990}
}
@article{Berry1997,
author = {Berry, D S and Pennebaker, James W and Mueller, J S and Hiller, W S},
doi = {10.1177/0146167297235008},
issn = {01461672},
journal = {Personality and Social Psychology Bulletin},
number = {5},
pages = {526--537},
title = {{Linguistic Bases of Social Perception}},
url = {http://psp.sagepub.com/cgi/doi/10.1177/0146167297235008},
volume = {23},
year = {1997}
}
@article{Steunebrink2011,
abstract = {[1] B. R. Steunebrink, M. Dastani, and J.-J. C. Meyer, “A formal model of emotion triggers: an approach for BDI agents,” Synthese, vol. 185, no. S1, pp. 83–129, Sep. 2011.},
author = {Steunebrink, Bas R. and Dastani, Mehdi and Meyer, John-Jules Ch.},
doi = {10.1007/s11229-011-0004-8},
file = {::},
isbn = {1122901100},
issn = {0039-7857},
journal = {Synthese},
keywords = {cognitive modeling,intelligent agents,logic of emotions},
month = sep,
number = {S1},
pages = {83--129},
title = {{A formal model of emotion triggers: an approach for BDI agents}},
url = {http://www.springerlink.com/index/10.1007/s11229-011-0004-8},
volume = {185},
year = {2011}
}
@article{Ekman1974,
author = {Ekman, Paul and Freisen, Wallace V.},
file = {::},
journal = {Journal of Personality and Social Psychology},
number = {3},
pages = {288--298},
title = {{Detecting Deception From The Body Or Face.pdf}},
volume = {29},
year = {1974}
}
@article{Blairy1999,
abstract = {Lipps (1907) presented a model of empathy which had an important influence on later formulations. According to Lipps, individuals tend to mimic an interaction partner's behavior, and this nonverbal mimicry induces—via a feedback process—the corresponding affective state in the observer. The resulting shared affect is believed to foster the understanding of the observed person's self. The present study tested this model in the context of judgments of emotional facial expressions. The results confirm that individuals mimic emotional facial expressions, and that the decoding of facial expressions is accompanied by shared affect. However, no evidence that emotion recognition accuracy or shared affect are mediated by mimicry was found. Yet, voluntary mimicry was found to have some limited influence on observer' s assessment of the observed person's personality. The implications of these results with regard to Lipps' original hypothesis are discussed.},
author = {Blairy, Sylvie and Herrera, Pedro and Hess, Ursula},
doi = {10.1023/A:1021370825283},
file = {::},
journal = {Journal of Nonverbal Behavior},
number = {1},
pages = {5--41},
title = {{Mimicry and the Judgment of Emotional Facial Expressions}},
url = {http://www.springerlink.com/content/unx02r46695w7651/ http://dx.doi.org/10.1023/A:1021370825283},
volume = {23},
year = {1999}
}
@inproceedings{Yasavur2012,
abstract = {In this paper, we have proposed a user model for com- puter based drinking behavior change intervention and rec- ommender systems. We discuss speci c requirements of user modeling in health promotion and speci cally alco- hol interventions. We believe that making behavior change systems available pervasively may lead to better and sus- tainable results. Therefore, our proposed user model takes advantage of the target-behavior related features such as contextual features (e.g., social interactions, location, and time). The proposed user model uses well-validated ques- tionnaires to capture target-behavior speci c aspects. We also introduced approaches for enhancing users' experience in the model creation stage by using Embodied Conversa- tional Agents(ECAs) and users' a ective states.},
address = {Dublin, Ireland},
author = {Yasavur, Ugan and Amini, Reza and Lisetti, Christine L},
booktitle = {First International Workshop on Recommendation Technologies for Lifestyle Change 2012 (LIFESTYLE 2012)},
file = {::},
keywords = {User modeling,alcohol intervention,behavior change,lifestyle change recommender systems (LSCRS).,tailoring},
pages = {29--34},
title = {{User Modeling for Pervasive Alcohol Intervention Systems}},
url = {http://ceur-ws.org/Vol-891/LIFESTYLE\_INTERFACERS\_2012\_proceedings.pdf\#page=29},
year = {2012}
}
@article{Cai2006,
author = {Cai, Yang},
file = {::},
journal = {Ambient Intelligence in Everyday Life},
pages = {67--85},
publisher = {Springer},
title = {{Empathic computing}},
url = {http://www.springerlink.com/index/l482m128476w5043.pdf},
year = {2006}
}
@article{Miller2010,
abstract = {The widely-disseminated clinical method of motivational interviewing (MI) arose through a convergence of science and practice. Beyond a large base of clinical trials, advances have been made toward “looking under the hood” of MI to understand the underlying mechanisms by which it affects behavior change. Such specification of outcome-relevant aspects of practice is vital to theory development, and can inform both treatment delivery and clinical training. An emergent theory of MI is proposed, emphasizing two specific active components: a relational component focused on empathy and the interpersonal spirit of MI, and a technical component involving the differential evocation and reinforcement of client change talk A resulting causal chain model links therapist training, therapist and client responses during treatment sessions, and post-treatment outcomes.},
author = {Miller, William R. and Rose, Gary S.},
doi = {10.1037/a0016830},
file = {::},
journal = {American Psychologist},
keywords = {Behavior change,Causal chain,Client-centered,Motivational interviewing,Psychotherapy,Theory,Therapeutic process},
number = {6},
pages = {527--537},
title = {{Toward a Theory of Motivational Interviewing}},
volume = {64},
year = {2010}
}
@article{Hingson2005,
author = {Hingson, Ralph and Heeren, Timothy and Winter, Michael and Wechsler, Henry},
journal = {Journal of Studies on Alcohol and Drugs},
pages = {12--20},
title = {{MAGNITUDE OF ALCOHOL-RELATED MORTALITY AND MORBIDITY AMONG U.S. COLLEGE STUDENTS AGES 18–24: Changes from 1999 to 2005}},
url = {http://www.jsad.com/},
volume = {16},
year = {2009}
}
@inproceedings{Jaques2004,
abstract = {In this paper we describe the use of mental states, more specifically the BDI approach, to implement the process of affective diagnosis in an educational environment. We use the OCC model, which is based on the cognitive theory of emotions and is possible to be implemented computationally, in order to infer the learner’s emotions from his actions in the system interface. The BDI approach is very adequate since the emotions have a dynamic nature. Besides, in our work we profit from the reasoning capacity of the BDI approach in order to infer the student’s appraisal, which allow us to deduce student’s emotions.},
address = {Puebla},
author = {Jaques, Patricia Augustin and Viccari, Rosa M},
booktitle = {IBERO-AMERICAN CONFERENCE ON ARTIFICIAL INTELLIGENCE (IBERAMIA)},
file = {::},
pages = {901--911},
publisher = {Springer-Verlag},
title = {{A BDI Approach to Infer Student's Emotions}},
year = {2004}
}
@article{Moridis2012a,
abstract = {Empathetic behavior has been suggested to be one effective way for Embodied Conversational Agents (ECAs) to provide feedback to learners’ emotions. An issue that has been raised is the effective integration of parallel and reactive empathy. The aim of this study is to examine the impact of ECAs’ emotional facial and tone of voice expressions combined with empathetic verbal behavior when displayed as feedback to students’ fear, sad, and happy emotions in the context of a self-assessment test. Three identical female agents were used for this experiment: 1) an ECA performing parallel empathy combined with neutral emotional expressions, 2) an ECA performing parallel empathy displaying emotional expressions that were relevant to the emotional state of the student, and 3) an ECA performing parallel empathy by displaying relevant emotional expressions followed by emotional expressions of reactive empathy with the goal of altering the student’s emotional state. Results indicate that an agent performing parallel empathy displaying emotional expressions relevant to the emotional state of the student may cause this emotion to persist. Moreover, the agent performing parallel and then reactive empathy appeared to be effective in altering an emotional state of fear to a neutral one.},
author = {Moridis, Christos N and Economides, Anastasios A and Member, Senior},
file = {::},
journal = {IEEE Transactions on Affective Computing},
keywords = {empathy,intelligent agents,user interfaces,—Computers and education},
number = {3},
pages = {260--272},
title = {{Affective Learning : Empathetic Agents with Emotional Facial and Tone of Voice Expressions}},
volume = {3},
year = {2012}
}
@inproceedings{Bartneck2008,
author = {Bartneck, Christoph and Kulic, Dana and Croft, Elizabeth},
booktitle = {Metrics for HRI Workshop, Technical Report},
file = {::},
pages = {37--44},
title = {{Measuring the anthropomorphism, animacy, likeability, perceived intelligence and perceived safety of robots}},
url = {http://ece.uwaterloo.ca/~dkulic/pubs/bartneckKulicCroft.pdf},
volume = {471},
year = {2008}
}
@article{Panksepp1982,
abstract = {Emotions seem to arise ultimately from hard-wired neural circuits in the visceral-limbic brain that facilitate diverse and adaptive behavioral and physiological response to major classes of environmental challenges. Presumable these circuits developed early in mammalian brain evolution, and the underlying contro mechanisms remain similar in humans and "lower" mammals. This would suggest that theoretically guided studies of the animal brain can reveal how primitive emotions are organized in the human brain. Conversely, granted these cross-specis heritage, it is arguable that human introspecive access to emotional states may provide direct information concerning operations of emotive circuits and thus be a primary source of hypothese for animal brain research. In this article the possibility that emotions are elaborated by transhypothalamic executive (command) circuits that concurrently activate related behavior patterns is assessed. Current neurobehavioral evidence indicates that there are at least four executive circuits of this type - those which elaborate central states of expectancy, rage, fear, and panic. The manner in which learning and psyuchiatric disorders may arise form activities of such circuits is also discussed.},
author = {Panksepp, J},
issn = {14691825},
journal = {Behavioral and Brain Sciences},
number = {3},
pages = {407--467},
title = {{Toward a general psychobiological theory of emotions}},
url = {http://scholar.google.com.au/scholar?as\_q=Panksepp+J+\&num=10\&btnG=Search+Scholar\&as\_epq=Toward+a+general+psychobiological+theory+of\&as\_oq=\&as\_eq=\&as\_occt=any\&as\_sauthors=\&as\_publication=\&as\_ylo=1982\&as\_yhi=1982\&as\_sdt=1.\&as\_sdtp=on\&as\_sdts=5\&hl=en\#0},
volume = {5},
year = {1982}
}
@article{Denef2009,
author = {Denef, Sebastian},
file = {::},
journal = {Human-Computer Interaction–INTERACT 2009},
pages = {864--867},
publisher = {Springer},
title = {{Human-Computer Interaction Techniques in Firefighting}},
url = {http://www.springerlink.com/index/n0688783567n3251.pdf},
year = {2009}
}
@article{Hess1998,
author = {Hess, Ursula and Philippot, Pierre and Blairy, Sylvie},
doi = {10.1080/026999398379547},
file = {::},
issn = {0269-9931},
journal = {Cognition \& Emotion},
month = jul,
number = {4},
pages = {509--531},
title = {{Facial Reactions to Emotional Facial Expressions: Affect or Cognition?}},
url = {http://www.tandfonline.com/doi/abs/10.1080/026999398379547},
volume = {12},
year = {1998}
}
@book{Ortony1988,
abstract = {What causes us to experience emotions? What makes emotions vary in intensity? How are different emotions related to one another and to the language used to talk about them? What are the information processing mechanisms and structures that underlie the elicitation and intensification of emotions? Despite an abundance of psychological research on emotions, many fundamental questions like these have yet to be answered. The Cognitive Structure of Emotions addresses such questions by presenting a systematic and detailed account of the cognitive antecedents of emotions. The authors propose three aspects of the world to which people can react emotionally. People can react to events of concern to them, to the actions of those they consider responsible for such events, and to objects. It is argued that these three classes of reactions lead to three classes of emotions, each based on evaluations in terms of different kinds of knowledge representations. The authors characterize a wide range of emotions, offering concrete proposals about the factors that influence the intensity of each. In doing so, they forge a clear separation between emotions themselves and the language of emotion, and offer the first systematic, comprehensive, and computationally tractable account of the cognitions that underlie distinct types of human emotions.},
address = {Cambridge, UK},
author = {Ortony, A and Clore, G L and Collins, A},
booktitle = {Contemporary Sociology},
doi = {10.1016/0004-3702(92)90091-B},
isbn = {0521353645},
number = {6},
pages = {957},
publisher = {Cambridge University Press},
title = {{The Cognitive Structure of Emotions}},
volume = {18},
year = {1988}
}
@book{national2007helping,
  title={Helping Patients Who Drink Too Much, A Clinician's Guide},
  author={NIAAA},
  year={2007}
}

@article{gerbert2003using,
  title={Using innovative video doctor technology in primary care to deliver brief smoking and alcohol intervention},
  author={Gerbert, Barbara and Berg-Smith, Steven and Mancuso, Michelle and Caspers, Nona and McPhee, Stephen and Null, Daniel and Wofsy, Judith},
  journal={Health promotion practice},
  volume={4},
  number={3},
  pages={249--261},
  year={2003},
  publisher={SAGE Publications}
}

@article{Portnoy2008,
abstract = {The use of computers to promote healthy behavior is increasing. To evaluate the efficacy of these computer-delivered interventions, we conducted a meta-analysis of the published literature.},
author = {Portnoy, David B and Scott-Sheldon, Lori a J and Johnson, Blair T and Carey, Michael P},
doi = {10.1016/j.ypmed.2008.02.014},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Portnoy et al. - 2008 - Computer-delivered interventions for health promotion and behavioral risk reduction a meta-analysis of 75 randomized controlled trials, 1988-2007.pdf:pdf},
issn = {0091-7435},
journal = {Preventive medicine},
keywords = {Computers,Health Behavior,Health Education,Health Promotion,Humans,Randomized Controlled Trials as Topic,Risk Reduction Behavior},
month = jul,
number = {1},
pages = {3--16},
pmid = {18403003},
title = {{Computer-delivered interventions for health promotion and behavioral risk reduction: a meta-analysis of 75 randomized controlled trials, 1988-2007}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2572996\&tool=pmcentrez\&rendertype=abstract},
volume = {47},
year = {2008}
}
@article{Colineau2010,
author = {Colineau, Nathalie and Paris, C\'{e}cile},
doi = {10.1007/s11257-010-9089-x},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Colineau, Paris - 2010 - Motivating reflection about health within the family the use of goal setting and tailored feedback.pdf:pdf},
issn = {0924-1868},
journal = {User Modeling and User-Adapted Interaction},
keywords = {evaluation,family support,goal setting theory,health behaviour,lifestyle and wellbeing,motivation strategies},
month = dec,
pages = {341--376},
title = {{Motivating reflection about health within the family: the use of goal setting and tailored feedback}},
url = {http://www.springerlink.com/index/10.1007/s11257-010-9089-x},
year = {2010}
}
@article{Meng2009,
author = {Meng, Qinggang and Lee, Mark},
doi = {10.1109/CASE.2009.156},
file = {::},
isbn = {978-0-7695-3728-3},
journal = {2009 IITA International Conference on Control, Automation and Systems Engineering (case 2009)},
keywords = {-home service robots,human-robot interaction},
month = jul,
pages = {220--224},
publisher = {Ieee},
title = {{Empathy between Human and Home Service Robots}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5194430},
year = {2009}
}
@article{Biocca2002,
abstract = {This paper outlines the foundation of a definition and measurement for the concept social presence. Justification for such a line of research lies in the ever-increasing use of social presence technologies and expansion of the social interactions across the Internet. A definition of social presence, based upon past literature and theory, describes several levels and dimensions of social presence by which the concept can be operationalized. Specifically, Level 1: co-presence is a necessary but not sufficient requirement for the sense of social presence. Level 2: the Subjective level, attempts to measure the psycho-behavioral accessibility of another interactant. Finally, Level 3: the Intersubjective level, assesses within and cross-interactant symmetry. The purposeful direction of this research and measurement construction is to enable researchers and designers to compare various mediated interactions as well as further theoretical inquiry.},
author = {Biocca, Frank and Harms, Chad},
journal = {Proceedings of PRESENCE},
keywords = {social presence,theory mind},
number = {517},
pages = {1--36},
publisher = {Citeseer},
title = {{Defining and measuring social presence: Contribution to the networked minds theory and measure}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.84.8350\&amp;rep=rep1\&amp;type=pdf},
volume = {2002},
year = {2002}
}
@article{Chavhan2010,
author = {Chavhan, Yashpalsing and Dhore, M. L. and Yesaware, Pallavi},
doi = {10.5120/431-636},
file = {::},
issn = {09758887},
journal = {International Journal of Computer Applications},
keywords = {emotion recognition,mfcc and,speech emotion,svm},
month = feb,
number = {20},
pages = {8--11},
title = {{Speech Emotion Recognition using Support Vector Machine}},
url = {http://www.ijcaonline.org/journal/number20/pxc387636.pdf},
volume = {1},
year = {2010}
}
@book{Arnold1960,
address = {New York},
author = {Arnold, M. B},
publisher = {Columbia University Press},
title = {{Emotion and personality}},
year = {1960}
}
@book{Hojat2007,
author = {Hojat, Mohammadreza},
booktitle = {Patient Care},
file = {::},
isbn = {9780387336077},
publisher = {New York, NY: Springer},
title = {{Empathy in patient care: antecedents, development, measurement, and outcomes}},
year = {2007}
}
@inproceedings{Kumano2011,
author = {Kumano, Shiro and Otsuka, Kazuhiro and Mikami, Dan and Yamato, Junji},
booktitle = {Automatic Face \& Gesture Recognition and Workshops (FG 2011), 2011 IEEE International Conference on},
file = {::},
pages = {43--50},
publisher = {IEEE},
title = {{Analyzing empathetic interactions based on the probabilistic modeling of the co-occurrence patterns of facial expressions in group meetings}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5771440},
year = {2011}
}
@misc{TheMendeleySupportTeam2011,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
file = {:C$\backslash$:/Users/ugan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/The Mendeley Support Team - 2011 - Getting Started with Mendeley(4).pdf:pdf},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@inproceedings{Yasavur2012,
abstract = {In this paper, we have proposed a user model for com- puter based drinking behavior change intervention and rec- ommender systems. We discuss speci c requirements of user modeling in health promotion and speci cally alco- hol interventions. We believe that making behavior change systems available pervasively may lead to better and sus- tainable results. Therefore, our proposed user model takes advantage of the target-behavior related features such as contextual features (e.g., social interactions, location, and time). The proposed user model uses well-validated ques- tionnaires to capture target-behavior speci c aspects. We also introduced approaches for enhancing users' experience in the model creation stage by using Embodied Conversa- tional Agents(ECAs) and users' a ective states.},
address = {Dublin, Ireland},
author = {Yasavur, Ugan and Amini, Reza and Lisetti, Christine L},
booktitle = {First International Workshop on Recommendation Technologies for Lifestyle Change 2012 (LIFESTYLE 2012)},
file = {::},
keywords = {User modeling,alcohol intervention,behavior change,lifestyle change recommender systems (LSCRS).,tailoring},
pages = {29--34},
title = {{User Modeling for Pervasive Alcohol Intervention Systems}},
url = {http://ceur-ws.org/Vol-891/LIFESTYLE\_INTERFACERS\_2012\_proceedings.pdf\#page=29},
year = {2012}
}
@incollection{Wispe1987,
author = {Wisp\'{e}, L},
booktitle = {Empathy and its development},
chapter = {2},
editor = {Einsenberg, Nancy and Strayer, Janet},
isbn = {0521326095},
issn = {05213260},
pages = {17--37},
publisher = {Cambridge University Press},
title = {{History of the concept of empathy}},
year = {1987}
}
@article{Sabourin,
author = {Sabourin, Jennifer and Mott, Bradford and Lester, James},
file = {::},
journal = {lorentzcenter.nl},
keywords = {empathetic virtual agents,pedagogical agents,virtual learning},
title = {{Computational Models of Affect and Empathy for Pedagogical Virtual Agents}},
url = {http://www.lorentzcenter.nl/lc/web/2011/464/presentations/Sabourin.pdf}
}
@article{Litvack-Miller1997a,
abstract = {This study was an investigation of the structure and development of dispositional empathy during middle childhood and its relationship to altruism. A sample of 478 students from 2nd, 4th, and 6th grades completed an altruism questionnaire and a social desirability scale, both created for this study, and the Interpersonal Reactivity Index (Davis, 1980), adapted for this study. Teachers also rated the students on prosocial behaviors, such as sharing. In addition, as an experimental part of the study, the children could make monetary donations and volunteer time to raise funds. Results of a confirmatory factor analysis on the Interpersonal Reactivity Index supported Davis's (1980) findings that empathy comprises four components: perspective taking, fantasy, empathic concern, and personal distress. Factor intercorrelations, however, were not the same as those reported by Davis. MANOVAs were used to examine gender and age effects on empathy. Girls were more empathic in general than boys, and older children showed more empathic concern than younger children. Only empathic concern and perspective taking were significant predictors of prosocial behavior.},
author = {Litvack-Miller, W and McDougall, D and Romney, D M},
file = {::},
issn = {8756-7547},
journal = {Genetic, social, and general psychology monographs},
keywords = {Adolescent,Altruism,Child,Empathy,Female,Humans,Interpersonal Relations,Male,Questionnaires,Social Behavior,Social Desirability},
month = aug,
number = {3},
pages = {303--24},
pmid = {9259121},
title = {{The structure of empathy during middle childhood and its relationship to prosocial behavior.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21981037},
volume = {123},
year = {1997}
}
@article{Scherer2007,
abstract = {In earlier work, the authors analyzed emotion portrayals by professional actors separately for facial expression, vocal expression, gestures, and body movements. In a secondary analysis of the combined data set for all these modalities, the authors now examine to what extent actors use prototypical multimodal configurations of expressive actions to portray different emotions, as predicted by basic emotion theories claiming that expressions are produced by fixed neuromotor affect programs. Although several coherent unimodal clusters are identified, the results show only 3 multimodal clusters: agitation, resignation, and joyful surprise, with only the latter being specific to a particular emotion. Finding variable expressions rather than prototypical patterns seems consistent with the notion that emotional expression is differentially driven by the results of sequential appraisal checks, as postulated by componential appraisal theories.},
author = {Scherer, Klaus R. and Ellgring, Heiner},
doi = {10.1037/1528-3542.7.1.158},
file = {::},
issn = {1528-3542},
journal = {Emotion (Washington, D.C.)},
keywords = {Adult,Affect,Facial Expression,Female,Gestures,Humans,Judgment,Male,Psychomotor Performance,Speech Acoustics,Voice},
month = feb,
number = {1},
pages = {158--71},
pmid = {17352571},
title = {{Multimodal expression of emotion: affect programs or componential appraisal patterns?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17352571},
volume = {7},
year = {2007}
}
@article{DavilaRoss2008,
abstract = {Emotional contagion enables individuals to experience emotions of others. This important empathic phenomenon is closely linked to facial mimicry, where facial displays evoke the same facial expressions in social partners. In humans, facial mimicry can be voluntary or involuntary, whereby its latter mode can be processed as rapid as within or at 1s. Thus far, studies have not provided evidence of rapid involuntary facial mimicry in animals. This study assessed whether rapid involuntary facial mimicry is present in orangutans (Pongo pygmaeus; N=25) for their open-mouth faces (OMFs) during everyday dyadic play. Results clearly indicated that orangutans rapidly mimicked OMFs of their playmates within or at 1s. Our study revealed the first evidence on rapid involuntary facial mimicry in non-human mammals. This finding suggests that fundamental building blocks of positive emotional contagion and empathy that link to rapid involuntary facial mimicry in humans have homologues in non-human primates.},
author = {{Davila Ross}, Marina and Menzler, Susanne and Zimmermann, Elke},
institution = {Centre for the study of Emotion, Department of Psychology, University of Portsmouth, Portsmouth, Hampshire PO1 2DY, UK. marina.davila-ross@port.ac.uk},
journal = {Biology Letters},
keywords = {animal,animal physiology,animals,behavior,face,face physiology,pongo pygmaeus,pongo pygmaeus physiology,social behavior,time factors,videotape recording},
number = {1},
pages = {27--30},
publisher = {The Royal Society},
title = {{Rapid facial mimicry in orangutan play}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18077238},
volume = {4},
year = {2008}
}
@book{Prendinger2004,
author = {Prendinger, Helmut and Ishizuka, M.},
editor = {Prendinger, Helmut and Ishizuka, M.},
isbn = {9783642056550},
publisher = {Springer-Verlag Berlin and Heidelberg GmbH \& Co. K},
title = {{Life-Like Characters. Cognitive Technologies}},
year = {2004}
}
@inproceedings{Jaques2004,
abstract = {In this paper we describe the use of mental states, more specifically the BDI approach, to implement the process of affective diagnosis in an educational environment. We use the OCC model, which is based on the cognitive theory of emotions and is possible to be implemented computationally, in order to infer the learner’s emotions from his actions in the system interface. The BDI approach is very adequate since the emotions have a dynamic nature. Besides, in our work we profit from the reasoning capacity of the BDI approach in order to infer the student’s appraisal, which allow us to deduce student’s emotions.},
address = {Puebla},
author = {Jaques, Patricia Augustin and Viccari, Rosa M},
booktitle = {IBERO-AMERICAN CONFERENCE ON ARTIFICIAL INTELLIGENCE (IBERAMIA)},
file = {::},
pages = {901--911},
publisher = {Springer-Verlag},
title = {{A BDI Approach to Infer Student's Emotions}},
year = {2004}
}
@article{Clark1998,
abstract = {Speakers often repeat the first word of major constituents, as in, "I uh I wouldn't be surprised at that." Repeats like this divide into four stages: an initial commitment to the constituent (with "I"); the suspension of speech; a hiatus in speaking (filled with "uh"); and a restart of the constituent ("I wouldn't."). An analysis of all repeated articles and pronouns in two large corpora of spontaneous speech shows that the four stages reflect different principles. Speakers are more likely to make a premature commitment, immediately suspending their speech, as both the local constituent and the constituent containing it become more complex. They plan some of these suspensions from the start as preliminary commitments to what they are about to say. And they are more likely to restart a constituent the more their stopping has disrupted its delivery. We argue that the principles governing these stages are general and not specific to repeats.},
author = {Clark, H H and Wasow, T},
doi = {10.1006/cogp.1998.0693},
file = {::},
issn = {0010-0285},
journal = {Cognitive psychology},
keywords = {Humans,Language,Verbal Behavior},
month = dec,
number = {3},
pages = {201--42},
pmid = {9892548},
title = {{Repeating words in spontaneous speech.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/9892548},
volume = {37},
year = {1998}
}
@article{Straalen2009,
author = {Straalen, Bart Van and Heylen, Dirk and Theune, Mari\"{e}t},
file = {::},
journal = {Agents for Games and},
keywords = {bad news con-,embodied conversational agents,empathy,social agents,tutoring,versations},
pages = {95--106},
title = {{Enhancing Embodied Conversational Agents with Social and Emotional Capabilities}},
url = {http://www.springerlink.com/index/3612181747K5L570.pdf},
year = {2009}
}
@inproceedings{Polajnar2011,
author = {Polajnar, Jernej and Dalvandi, B. and Polajnar, D.},
booktitle = {Cognitive Informatics \& Cognitive Computing (ICCI'CC'11), 2011 10th IEEE International Conference on},
file = {::},
isbn = {9781457716973},
pages = {96--102},
publisher = {IEEE},
title = {{Does empathy between artificial agents improve agent teamwork?}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=6016126},
year = {2011}
}
@article{Kaliouby2005,
author = {Kaliouby, R. and Robinson, Peter},
file = {::},
journal = {Real-time vision for human-computer interaction},
pages = {181--200},
publisher = {Springer},
title = {{Real-time inference of complex mental states from facial expressions and head gestures}},
url = {http://www.springerlink.com/index/K822871338R66039.pdf},
year = {2005}
}
@article{Gratch2007,
annote = {They explore the rapport, a feeling of connectedness that arises from rapid and contingent positive feedback between partners and is often associated with socio-emotional processes. Rapport can lead to communicative efficiency, better learning outcomes, improved acceptance of medical advice and successful negotiations.
They experimentally proved that a simple virtual character with positive listening feedback can induce stronger rapport-like effects than face-to-face communication between human partners.},
author = {Gratch, Jonathan and Wang, Ning and Okhmatovskaia, Anna},
file = {::},
journal = {conference on Human-},
title = {{Can virtual humans be more engaging than real ones?}},
url = {http://dl.acm.org/citation.cfm?id=1769622},
year = {2007}
}
@incollection{Gratch2006a,
author = {Gratch, Jonathan and Mao, W and Marsella, Stacy},
booktitle = {Cognition and Multi-Agent Interaction: From Cognitive Modeling to Social Simulation},
chapter = {9},
doi = {http://dx.doi.org/10.1017/CBO9780511610721.010},
editor = {Sun, Ron},
file = {::;::},
isbn = {9780511610721},
pages = {219--251},
publisher = {Cambridge University Press},
title = {{Modeling social emotions and social attributions}},
year = {2006}
}
@article{Banziger2009,
abstract = {Emotion recognition ability has been identified as a central component of emotional competence. We describe the development of an instrument that objectively measures this ability on the basis of actor portrayals of dynamic expressions of 10 emotions (2 variants each for 5 emotion families), operationalized as recognition accuracy in 4 presentation modes combining the visual and auditory sense modalities (audio/video, audio only, video only, still picture). Data from a large validation study, including construct validation using related tests (Profile of Nonverbal Sensitivity; Rosenthal, Hall, DiMatteo, Rogers, \& Archer, 1979; Japanese and Caucasian Facial Expressions of Emotion; Biehl et al., 1997; Diagnostic Analysis of Nonverbal Accuracy; Nowicki \& Duke, 1994; Emotion Recognition Index; Scherer \& Scherer, 2008), are reported. The results show the utility of a test designed to measure both coarse and fine-grained emotion differentiation and modality-specific skills. Factor analysis of the data suggests 2 separate abilities, visual and auditory recognition, which seem to be largely independent of personality dispositions.},
author = {B\"{a}nziger, Tanja and Grandjean, Didier and Scherer, Klaus R.},
doi = {10.1037/a0017088},
file = {::},
issn = {1931-1516},
journal = {Emotion (Washington, D.C.)},
keywords = {Adolescent,Adult,Discrimination (Psychology),Emotional Intelligence,Emotions,Facial Expression,Female,Humans,Male,Nonverbal Communication,Pattern Recognition,Personality Inventory,Personality Inventory: statistics \& numerical data,Psychometrics,Psychometrics: statistics \& numerical data,Recognition (Psychology),Reproducibility of Results,Social Adjustment,Visual,Voice Quality,Young Adult},
month = oct,
number = {5},
pages = {691--704},
pmid = {19803591},
title = {{Emotion recognition from expressions in face, voice, and body: the Multimodal Emotion Recognition Test (MERT).}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19803591},
volume = {9},
year = {2009}
}
@inproceedings{Dias2005,
abstract = {Interactive virtual environments (IVEs) are now seen as an engaging new way by which children learn experimental sciences and other disciplines. These environments are populated by synthetic characters that guide and stimulate the children activities. In order to build such environments, one needs to address the problem of how achieve believable and empathic characters that act autonomously. Inspired by the work of traditional character animators, this paper proposes an architectural model to build autonomous characters where the agent’s reasoning and behaviour is influenced by its emotional state and personality. We performed a small case evaluation in order to determine if the characters evoked empathic reactions in the users with positive results.},
address = {Covilh\~{a}, Portugal},
author = {Dias, J. and Paiva, Ana},
booktitle = {EPIA 2005, 12th Portuguese Conference on Artificial Intelligence},
doi = {10.1007/11595014\_13},
editor = {Bento, Carlos and Cardoso, Am\'{\i}lcar and Dias, Ga\"{e}l},
file = {::},
pages = {127--140},
publisher = {Springer Berlin / Heidelberg},
title = {{Feeling and reasoning: A computational model for emotional characters}},
url = {http://www.springerlink.com/index/YQ18H62602413554.pdf},
year = {2005}
}
@inproceedings{Nguyen2009b,
abstract = {Experiencing emotional distress is the number one reason why people who are undergoing behaviour modification (e.g. quitting smoking, dieting) suffer from relapses. Providing emotional support is an effective way to help them overcome the unpleasant effects of negative affect and adhere to their regimen. Building computers with such ability has grabbed the attention of the HCI community in recent years. This paper presents the results of a 2 (modality: animated vs. no visual) by 3 (intervention: non-empathy vs. empathy vs. empathy and expressivity) between-subjects study that investigates the impact of two important factors and their interaction in the design of such systems: (1) different ways of expressing empathy, and (2) the modality of delivering such content.},
author = {Nguyen, H. and Masthoff, Judith},
booktitle = {Proceedings of the 4th International Conference on Persuasive Technology},
file = {::},
isbn = {9781605583761},
keywords = {affective computing,design,experimentation,human factors},
pages = {7},
publisher = {ACM},
title = {{Designing empathic computers: the effect of multimodal empathic feedback using animated agent}},
url = {http://portal.acm.org/citation.cfm?id=1541958},
year = {2009}
}
@article{Rogers1957,
author = {Rogers, C R},
editor = {Kirschenbaum, H},
isbn = {9780395483572},
issn = {00958891},
journal = {Journal of Consulting Psychology},
number = {2},
pages = {95--103},
pmid = {13416422},
publisher = {Houghton Mifflin},
title = {{The necessary and sufficient conditions of therapeutic personality change}},
volume = {21},
year = {1957}
}
@article{Breemen2005,
abstract = {We developed a robotic research platform called "iCat" for studying social human-robot interaction. The platform consists of the robotic character "iCat", which is a desktop user-interface robot with mechanically rendered facial expressions. Recently, Philips Research made this platform available for universities and research laboratories to stimulate the momentum in Human-Robot Interaction research [5].},
author = {van Breemen, A and Yan, X},
doi = {10.1145/1082473.1082823},
file = {::},
journal = {AAMAS '05 Proceedings of the fourth international joint conference on Autonomous agents and multiagent systems},
pages = {143--144},
title = {{iCat: an animated user-interface robot with personality}},
url = {http://dl.acm.org/citation.cfm?id=1082823},
year = {2005}
}
@inproceedings{Schrammel2007,
abstract = {This paper describes the results of three studies investigating an embodied agent that supports its interaction with the user by gazing at corresponding objects within its close environment. Three experiments were conducted in order to research whether users can detect an agent’s line of sight, whether the agent’s gaze direction can help to guide the users' attention towards designated locations and whether such a setup can be used to improve realistic interaction situations. The results show that a) users can detect the agent’s gaze direction quickly (within 200 ms) but not very exactly, b) the use of the agent’s gaze direction can speed up but also slow down the detection of objects in dependence on their location and c) that the agent’s gaze towards corresponding objects during the interaction can have counterproductive effects in realistic settings.},
address = {San Jose, California, USA.},
author = {Schrammel, Johann and Sefelin, Reinhard and Tscheligi, Manfred},
booktitle = {CHI 2007 Proceedings of People, Looking at People April},
file = {::},
isbn = {9781595935939},
keywords = {Computer Vision,Embodied Agent,Gaze Direction},
pages = {1187--1190},
publisher = {ACM},
title = {{“ Look !” – Using the Gaze Direction of Embodied Agents}},
year = {2007}
}
@article{Cogger1982,
author = {Cogger, J W},
journal = {The Personnel journal},
number = {11},
pages = {840--843},
pmid = {10258019},
title = {{Are you a skilled interviewer?}},
volume = {61},
year = {1982}
}
@article{Vannini2010,
author = {Vannini, Natalie and Enz, Sibylle and Sapouna, Maria and Wolke, Dieter and Watson, Scott and Woods, Sarah and Dautenhahn, Kerstin and Hall, Lynne and Paiva, Ana and Andr\'{e}, Elizabeth and Aylett, Ruth and Schneider, Wolfgang},
doi = {10.1007/s10212-010-0035-4},
file = {::},
issn = {0256-2928},
journal = {European Journal of Psychology of Education},
month = jun,
number = {1},
pages = {21--44},
title = {{“FearNot!”: a computer-based anti-bullying-programme designed to foster peer intervention}},
url = {http://www.springerlink.com/index/10.1007/s10212-010-0035-4},
volume = {26},
year = {2010}
}
@inproceedings{Hegel2006,
author = {Hegel, Frank and Spexard, Torsten and Wrede, Britta and Horstmann, G. and Vogt, T.},
booktitle = {Humanoid Robots, 2006 6th IEEE-RAS International Conference on},
file = {::},
isbn = {142440200X},
pages = {56--61},
publisher = {IEEE},
title = {{Playing a different imitation game: Interaction with an Empathic Android Robot}},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4115580},
year = {2006}
}
@article{Mandryk2007,
author = {Mandryk, R L and Atkins, M S},
journal = {International Journal of Human-Computer Studies},
number = {4},
pages = {329--347},
title = {{A fuzzy physiological approach for continuously modeling emotion during interaction with play technologies}},
volume = {65},
year = {2007}
}
@article{Hazlett2007,
author = {Hazlett, R and Benedek, J},
issn = {10715819},
journal = {International Journal of Human-Computer Studies},
keywords = {affecting computing,desirability,emotion,physiologic measures,software testing methods,user experience},
number = {4},
pages = {306--314},
publisher = {Academic Press, Inc.},
title = {{Measuring emotional valence to understand the user's experience of software}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1071581906001868},
volume = {65},
year = {2007}
}
@inproceedings{Hirshfield2009,
abstract = {A well designed user interface (UI) should be transparent, allowing users to focus their mental workload on the task at hand. We hypothesize that the overall mental workload required to perform a task using a computer system is composed of a portion attributable to the difficulty of the underlying task plus a portion attributable to the complexity of operating the user interface. In this regard, we follow Shneiderman's theory of syntactic and semantic components of a UI. We present an experiment protocol that can be used to measure the workload experienced by users in their various cognitive resources while working with a computer. We then describe an experiment where we used the protocol to quantify the syntactic workload of two user interfaces. We use functional near infrared spectroscopy, a new brain imaging technology that is beginning to be used in HCI. We also discuss extensions of our techniques to adaptive interfaces.},
address = {Boston, MA, USA},
author = {Hirshfield, Leanne M and Solovey, Erin Treacy and Girouard, Audrey and Kebinger, James and Jacob, Robert J K and Sassaroli, Angelo and Fantini, Sergio},
booktitle = {Proceedings of the 27th international conference on Human factors in computing systems (CHI)},
doi = {10.1145/1518701.1519035},
isbn = {978-1-60558-246-7},
keywords = {Hirshfield2009,brain,evaluation,syntactic,workload},
mendeley-tags = {Hirshfield2009},
pages = {2185--2194},
publisher = {ACM},
title = {{Brain measurement for usability testing and adaptive interfaces: an example of uncovering syntactic workload with functional near infrared spectroscopy}},
url = {http://portal.acm.org/citation.cfm?id=1518701.1519035\&coll=GUIDE\&dl=GUIDE\&CFID=51145589\&CFTOKEN=45123851},
year = {2009}
}
@inproceedings{GSMTNJ_CHI2010,
abstract = {The human brain and body are prolific signal generators. Recent technologies and computing techniques allow us to measure, process and interpret these signals. We can now infer such things as cognitive and emotional states to create adaptive interactive systems and to gain an understanding of user experience. This workshop brings together researchers from the formerly separated communities of physiological computing (PC), and brain-computer interfaces (BCI) to discuss psychophysiological computing. We set out to identify key research challenges, potential global synergies, and emerging technological contributions.},
address = {Atlanta, GA},
author = {Girouard, Audrey and Solovey, Erin Treacy and Mandryk, Regan and Tan, Desney and Nacke, Lennart and Jacob, Robert J.K.},
booktitle = {Conference on Human Factors in Computing Systems},
doi = {10.1145/1753846.1754167},
file = {::},
isbn = {978-1-60558-930-5},
keywords = {affective computing,body,brain,brain-computer interfaces,bytes,hci,interaction,physiological computing,psychophysiological signals,ui},
mendeley-tags = {affective computing,body,brain,bytes,hci,interaction,physiological computing,ui},
pages = {4433--4436},
publisher = {ACM},
title = {{Brain, body and bytes: psychophysiological user interaction}},
type = {Conference proceedings (article)},
url = {http://portal.acm.org/citation.cfm?id=1753846.1754167},
year = {2010}
}
@article{Gilleade2005,
author = {Gilleade, K and Dix, A and Allanson, J},
file = {::},
journal = {Proceedings of DIGRA'2005},
pages = {16--20},
title = {{Affective videogames and modes of affective gaming: assist me, challenge me, emote me}},
year = {2005}
}
@article{Bradley2008a,
abstract = {Emotional reactions are organized by underlying motivational states--defensive and appetitive--that have evolved to promote the survival of individuals and species. Affective responses were measured while participants viewed pictures with varied emotional and neutral content. Consistent with the motivational hypothesis, reports of the strongest emotional arousal, largest skin conductance responses, most pronounced cardiac deceleration, and greatest modulation of the startle reflex occurred when participants viewed pictures depicting threat, violent death, and erotica. Moreover, reflex modulation and conductance change varied with arousal, whereas facial patterns were content specific. The findings suggest that affective responses serve different functions-mobilization for action, attention, and social communication-and reflect the motivational system that is engaged, its intensity of activation, and the specific emotional context.},
author = {Bradley, M M and Codispoti, M and Cuthbert, B N and Lang, P J},
file = {::},
issn = {1528-3542},
journal = {Emotion},
keywords = {affect,eda,emg,emotion,face,gsr,motivation,picture,psychophysiology},
mendeley-tags = {affect,eda,emg,emotion,face,gsr,motivation,picture,psychophysiology},
month = sep,
number = {3},
pages = {276--298},
pmid = {12934687},
title = {{Emotion and motivation I: defensive and appetitive reactions in picture processing.}},
type = {Journal article},
volume = {1},
year = {2001}
}
@article{Yannakakis2008,
author = {Yannakakis, G N and Hallam, J},
journal = {International Journal of Human-Computer Studies},
number = {10},
pages = {741--755},
title = {{Entertainment modeling through physiology in physical play}},
volume = {66},
year = {2008}
}
@inproceedings{Kivikangas2010,
author = {Kivikangas, J Matias and Ekman, Inger and Chanel, Guillaume and J\"{a}rvel\"{a}, Simo and Cowley, Ben and Salminen, M and Henttonen, Pentti},
booktitle = {Proceedings of Nordic DiGRA},
file = {::},
keywords = {affective,after,conveniently,details most pertinent,digra,method,practical use,previous research section,psychophysiology,recent work,review,theory behind psychophysiological},
mendeley-tags = {affective,digra,psychophysiology,review},
title = {{Review on psychophysiological methods in game research}},
url = {http://www.nordic-digra.org/nordicdigra2010\_submission\_22.pdf},
year = {2010}
}
@inproceedings{Nacke2010,
address = {New York, New York, USA},
author = {Nacke, Lennart E.},
booktitle = {Proceedings of the International Academic Conference on the Future of Game Design and Technology - Futureplay '10},
keywords = {affective computing,digital games,eeg,electroencephalography (EEG),entertainment,games,hci,interaction,psychophysiology,user experience (UX)},
mendeley-tags = {affective computing,eeg,games,hci,interaction},
month = may,
pages = {159--166},
publisher = {ACM Press},
title = {{Wiimote vs. controller}},
url = {http://portal.acm.org/citation.cfm?id=1920778.1920801},
year = {2010}
}
@article{Hazlett2006,
abstract = {This paper describes the use of facial electromyography (EMG) as a measure of positive and negative emotional valence during interactive experience. Thirteen boys played a car racing video game on an Xbox platform while facial EMG data were collected. Through video review positive and negative events during play were identified. The zygomaticus muscle EMG, which controls smiling, was found to be significantly greater during positive events as compared to negative. The corrugator muscle EMG, which controls frowning, was found to be significantly greater during negative events. The results of this study demonstrate that positive valence can be measured during interactive experiences with physiologic measures. This study also found that the corrugator EMG can still measure negative valence during high intensity interactive play in spite of the confounding factor of mental effort. These methods appear useful for associating the player's emotion with game events, and could be applied to HCI in general.},
author = {Hazlett, Richard L},
journal = {Proceedings of the SIGCHI conference on Human Factors in computing systems CHI 06},
pages = {1023},
publisher = {ACM Press},
title = {{Measuring emotional valence during interactive experiences}},
url = {http://portal.acm.org/citation.cfm?doid=1124772.1124925},
year = {2006}
}
@inproceedings{Nacke2011,
abstract = {Prior work on physiological game interaction has focused on dynamically adapting games using physiological sensors. In this paper, we propose a classification of direct and indirect physiological sensor input to augment traditional game control. To find out which sensors work best for which game mechanics, we conducted a mixed-methods study using different sensor mappings. Our results show participants have a preference for direct physiological control in games. This has two major design implications for physiologically controlled games: (1) Direct physiological sensors should be mapped intuitively to reflect an action in the virtual world; (2) Indirect physiological input is best used as a dramatic device in games to influence features altering the game world.},
address = {Vancouver, BC, Canada},
author = {Nacke, Lennart E. and Kalyn, Michael and Lough, Calvin and Mandryk, Regan L},
booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems},
doi = {10.1145/1978942.1978958},
file = {::},
keywords = {affective computing,affective gaming,biofeedback,entertainment,games,physiological input,psychophysiology},
mendeley-tags = {affective computing,affective gaming,biofeedback,entertainment,games,physiological input,psychophysiology},
pages = {103--112},
publisher = {ACM},
title = {{Biofeedback game design: using direct and indirect physiological control to enhance game interaction}},
url = {http://doi.acm.org/10.1145/1978942.1978958},
year = {2011}
}

@article{paek2008automating,
  title={Automating spoken dialogue management design using machine learning: An industry perspective},
  author={Paek, Tim and Pieraccini, Roberto},
  journal={Speech communication},
  volume={50},
  number={8},
  pages={716--729},
  year={2008},
  publisher={Elsevier}
}

@misc{NIAAA2007colleges,
  title={What colleges need to know now: An update on college drinking research},
  author={NIAAA},
  year={2007},
  publisher={Department of Health and Human Services, National Institutes of Health Bethesda, MD}
}

@book{american2000diagnostic,
  title={Diagnostic and statistical manual of mental disorders: DSM-IV-TR{\textregistered}},
  author={American Psychiatric Association},
  year={2000},
  publisher={American Psychiatric Pub}
}

@article{walters2005demon,
  title={Demon Rum: High-Tech Solutions to an Age-Old Problem},
  author={Walters, Scott T and Hester, Reid K and Chiauzzi, Emil and Miller, Elizabeth},
  journal={Alcoholism: Clinical and Experimental Research},
  volume={29},
  number={2},
  pages={270--277},
  year={2005},
  publisher={Wiley Online Library}
}

@article{walters2005feedback,
  title={Feedback interventions for college alcohol misuse: What, why and for whom?},
  author={Walters, Scott T and Neighbors, Clayton},
  journal={Addictive behaviors},
  volume={30},
  number={6},
  pages={1168--1182},
  year={2005},
  publisher={Elsevier}
}

@article{saitz2007screening,
  title={Screening and brief intervention online for college students: the ihealth study},
  author={Saitz, Richard and Palfai, Tibor P and Freedner, Naomi and Winter, Michael R and Macdonald, Alexandra and Lu, John and Ozonoff, AL and Rosenbloom, David L and Dejong, William},
  journal={Alcohol and Alcoholism},
  volume={42},
  number={1},
  pages={28--36},
  year={2007},
  publisher={Med Council on Alcohol}
}

@inproceedings{swartout2010ada,
  title={Ada and Grace: Toward realistic and engaging virtual museum guides},
  author={Swartout, William and Traum, David and Artstein, Ron and Noren, Dan and Debevec, Paul and Bronnenkant, Kerry and Williams, Josh and Leuski, Anton and Narayanan, Shrikanth and Piepol, Diane and others},
  booktitle={Intelligent Virtual Agents},
  pages={286--300},
  year={2010},
  organization={Springer}
}

@article{jurvcivcek2012reinforcement,
  title={Reinforcement learning for parameter estimation in statistical spoken dialogue systems},
  author={Jur{\v{c}}{\'\i}{\v{c}}ek, Filip and Thomson, Blaise and Young, Steve},
  journal={Computer Speech \& Language},
  volume={26},
  number={3},
  pages={168--192},
  year={2012},
  publisher={Elsevier}
}

@inproceedings{Georgila2010,
 author = {Georgila, Kallirroi and Wolters, Maria K. and Moore, Johanna D.},
 title = {Learning Dialogue Strategies from Older and Younger Simulated Users},
 booktitle = {Proceedings of the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 series = {SIGDIAL '10},
 year = {2010},
 isbn = {978-1-932432-85-5},
 location = {Tokyo, Japan},
 pages = {103--106},
 numpages = {4},
 url = {http://dl.acm.org/citation.cfm?id=1944506.1944527},
 acmid = {1944527},
 publisher = {Association for Computational Linguistics},
 address = {Stroudsburg, PA, USA},
} 

@inproceedings{Chandramohan2010,
 author = {Chandramohan, Senthilkumar and Geist, Matthieu and Pietquin, Olivier},
 title = {Sparse Approximate Dynamic Programming for Dialog Management},
 booktitle = {Proceedings of the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
 series = {SIGDIAL '10},
 year = {2010},
 isbn = {978-1-932432-85-5},
 location = {Tokyo, Japan},
 pages = {107--115},
 numpages = {9},
 url = {http://dl.acm.org/citation.cfm?id=1944506.1944528},
 acmid = {1944528},
 publisher = {Association for Computational Linguistics},
 address = {Stroudsburg, PA, USA},
} 

@article{henderson2008hybrid,
  title={Hybrid reinforcement/supervised learning of dialogue policies from fixed data sets},
  author={Henderson, James and Lemon, Oliver and Georgila, Kallirroi},
  journal={Computational Linguistics},
  volume={34},
  number={4},
  pages={487--511},
  year={2008},
  publisher={MIT Press}
}

@inproceedings{misu2012reinforcement,
  title={Reinforcement learning of question-answering dialogue policies for virtual museum guides},
  author={Misu, Teruhisa and Georgila, Kallirroi and Leuski, Anton and Traum, David},
  booktitle={Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
  pages={84--93},
  year={2012},
  organization={Association for Computational Linguistics}
}

@inproceedings{chi2010micro,
  title={Do micro-level tutorial decisions matter: Applying reinforcement learning to induce pedagogical tutorial tactics},
  author={Chi, Min and VanLehn, Kurt and Litman, Diane},
  booktitle={Intelligent Tutoring Systems},
  pages={224--234},
  year={2010},
  organization={Springer}
}

@Inproceedings{liAssistivePomdp2013,
  author    = {Li, William  and  Glass, Jim  and  Roy, Nicholas  and  Teller, Seth},
  title     = {Probabilistic Dialogue Modeling for Speech-Enabled Assistive Technology},
  booktitle = {Proceedings of the Fourth Workshop on Speech and Language Processing for Assistive Technologies},
  month     = {August},
  year      = {2013},
  address   = {Grenoble, France},
  publisher = {Association for Computational Linguistics},
  pages     = {67--72},
  url       = {http://www.aclweb.org/anthology/W13-3912}
}


@INPROCEEDINGS{georgila2006user,
    author = {Kallirroi Georgila and James Henderson and Oliver Lemon},
    title = {User simulation for spoken dialogue systems: Learning and evaluation},
    booktitle = {in Interspeech/ICSLP},
    year = {2006}
}


@article{williams2007partially,
  title={Partially observable Markov decision processes for spoken dialog systems},
  author={Williams, Jason D and Young, Steve},
  journal={Computer Speech \& Language},
  volume={21},
  number={2},
  pages={393--422},
  year={2007},
  publisher={Elsevier}
}

@article{young2010hidden,
  title={The hidden information state model: A practical framework for POMDP-based spoken dialogue management},
  author={Young, Steve and Ga{\v{s}}i{\'c}, Milica and Keizer, Simon and Mairesse, Fran{\c{c}}ois and Schatzmann, Jost and Thomson, Blaise and Yu, Kai},
  journal={Computer Speech \& Language},
  volume={24},
  number={2},
  pages={150--174},
  year={2010},
  publisher={Elsevier}
}

@inproceedings{schatzmann2005quantitative,
  title={Quantitative evaluation of user simulation techniques for spoken dialogue systems},
  author={Schatzmann, Jost and Georgila, Kallirroi and Young, Steve},
  booktitle={6th SIGdial Workshop on DISCOURSE and DIALOGUE},
  year={2005}
}

@article{allen2006chester,
  title={Chester: towards a personal medication advisor},
  author={Allen, James and Ferguson, George and Blaylock, Nate and Byron, Donna and Chambers, Nathanael and Dzikovska, Myroslava and Galescu, Lucian and Swift, Mary},
  journal={Journal of Biomedical Informatics},
  volume={39},
  number={5},
  pages={500--513},
  year={2006},
  publisher={Elsevier}
}

@article{lisetti2013,
  title={I Can Help You Change! An Empathic Virtual Agent Delivers Behavior Change Health Interventions},
  author={Lisetti, Christine and Amini, Reza and Yasavur, Ugan and Rishe, Naphtali},
  journal={ACM Transactions on Management Information Systems (TMIS)},
  volume={4},
  number={4},
  pages={19},
  year={2013},
  publisher={ACM}
}

@inproceedings{williams2008best,
  title={The best of both worlds: unifying conventional dialog systems and POMDPs.},
  author={Williams, Jason D},
  booktitle={INTERSPEECH},
  pages={1173--1176},
  year={2008}
}

@inproceedings{swartout2010ada,
  title={Ada and Grace: Toward realistic and engaging virtual museum guides},
  author={Swartout, William and Traum, David and Artstein, Ron and Noren, Dan and Debevec, Paul and Bronnenkant, Kerry and Williams, Josh and Leuski, Anton and Narayanan, Shrikanth and Piepol, Diane and others},
  booktitle={Intelligent Virtual Agents},
  pages={286--300},
  year={2010},
  organization={Springer}
}